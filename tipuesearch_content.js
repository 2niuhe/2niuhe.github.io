var tipuesearch = {"pages":[{"title":"Typescript 基础","text":"简介 Typescript 可以在代码编写写做类型检查，可以编写更健壮的代码。 安装 npm config set registry https://registry.npm.taobao.org sudo npm install -g typescript # 安装REPL sudo npm install -g tsun 基本概念 联合类型 表示取值是多种类型中的一种，当 TypeScript 不确定一个联合类型的变量到底是哪个类型的时候，我们只能访问此联合类型的所有类型里共有的属性或方法 let myFavoriteNumber : string | number ; myFavoriteNumber = \"seven\" ; myFavoriteNumber = 7 ; 接口 TypeScript 中的接口是一个非常灵活的概念，除了可用于对类的一部分行为进行抽象以外，也常用于对「对象的形状（Shape）」进行描述。 接口是一个类型，不是一个真正的值，它在编译结果中会被删除 //？可选属性 interface Person { name : string ; age? : number ; } let tom : Person = { name : \"Tom\" , }; let tom : Person1 = { name : \"Tom\" , age : 25 , }; //接口可以继承 interface ApiError extends Error { code : number ; } 接口可以定义任意类型，但是当同时存在可选类型和任意类型，可选类型需要是任意类型的子集 interface Person { name : string ; age? : number ; //任意类型为联合类型 [ propName : string ] : string | number ; } let tom : Person = { name : \"Tom\" , age : 25 , gender : \"male\" , }; 接口属性只读，意味着，只有在创建对象时可被赋值，其后无法修改，而且只读属性必须在对象初始化时进行赋值。 interface Person { readonly id : number ; name : string ; age? : number ; [ propName : string ] : any ; } let tom : Person = { id : 89757 , name : \"Tom\" , gender : \"male\" , }; 数组 习惯性的将数组中的元素类型保持相同 let fibonacci : number [] = [ 1 , 1 , 2 , 3 , 5 ]; //泛型 let fibonacci : Array < number > = [ 1 , 1 , 2 , 3 , 5 ]; //接口表示数组 //用接口表示数组通常用来标识类型 interface NumberArray { //索引是数字，类型是数字 [ index : number ] : number ; } let fibonacci : NumberArray = [ 1 , 1 , 2 , 3 , 5 ]; interface IArguments { [ index : number ] : any ; length : number ; callee : Function ; } 函数 在 JavaScript 中，有两种常见的定义函数的方式——函数声明（Function Declaration）和函数表达式（Function Expression）; 函数声明和函数表达式的词法环境和执行上下文是不一样的，函数声明会做类型提升。 // 函数声明（Function Declaration） function sum ( x , y ) { return x + y ; } // 函数表达式（Function Expression） let mySum = function ( x , y ) { return x + y ; }; 可以手动给函数表达式添加类型，也可以使用类型推断 在 TypeScript 的类型定义中，=> 用来表示函数的定义，左边是输入类型，需要用括号括起来，右边是输出类型。 在 ES6 中，=> 叫做箭头函数，应用十分广泛 let mySum : ( x : number , y : number ) => number = function ( x : number , y : number ) : number { return x + y ; }; 可选参数用？标识，必须接在必需参数的后面 function buildName ( firstName : string , lastName? : string ) { if ( lastName ) { return firstName + \" \" + lastName ; } else { return firstName ; } } let tomcat = buildName ( \"Tom\" , \"Cat\" ); let tom = buildName ( \"Tom\" ); ES6 中允许给参数添加默认值，Typescript 将添加默认值的参数识别为可选参数，并且添加默认值后，就不受「可选参数必须接在必需参数后面」的限制了 默认值参数在必需参数前的话，需要传一个 undefined 进去占位，因此推荐将默认值参数放在后面 function buildName ( firstName : string = \"Tom\" , lastName : string ) { return firstName + \" \" + lastName ; } let tomcat = buildName ( \"Tom\" , \"Cat\" ); //如果默认值参数在必需参数前边，必须传入undefined console . log ( buildName ( undefined , \"cat\" )); function buildName1 ( firstName : string , lastName : string = \"Man\" ) { return firstName + \" \" + lastName ; } console . log ( buildName ( \"good\" )); 剩余 rest 参数（不定长参数） rest 参数只能是最后一个参数 //items是一个数组 function push ( array , ... items ) { items . forEach ( function ( item ) { array . push ( item ); }); } let a : any [] = []; push ( a , 1 , 2 , 3 ); 函数重载允许一个函数接受不同数量或类型的参数时，作出不同的处理。 Typescript 会从最前面的函数定义开始匹配 //前声明（定义）后实现，将精确的声明写在前面 function reverse ( x : number ) : number ; function reverse ( x : string ) : string ; function reverse ( x : number | string ) : number | string { if ( typeof x === \"number\" ) { return Number ( x . toString (). split ( \"\" ). reverse (). join ( \"\" )); } else if ( typeof x === \"string\" ) { return x . split ( \"\" ). reverse (). join ( \"\" ); } } 类型断言 值 as 类型 类型断言只会影响 TypeScript 编译时的类型，类型断言语句在编译结果中会被删除 它不会真的影响到变量的类型。 应用场景: 将一个联合类型断言为其中一个类型，欺骗 tsc 编译器，可能导致运行时出错 将一个父类断言为更加具体的子类 将任何一个类型断言为 any 将 any 断言为一个具体的类型 限制： typescript 是结构类型系统，不关心定义时的类型关系，只比较最终结构有什么关系 联合类型可以被断言为其中一个类型 父类可以被断言为子类 任何类型都可以被断言为 any any 可以被断言为任何类型 要使得 A 能够被断言为 B，只需要 A 兼容 B 或 B 兼容 A 即可 //类型比较 //下面两种Cat的定义是等价的 interface Animal { name : string ; } interface Cat { name : string ; run () : void ; } interface Cat extends Animal { run () : void ; } //联合类型断言 interface Cat { name : string ; run () : void ; } interface Fish { name : string ; swim () : void ; } function isFish ( animal : Cat | Fish ) { if ( typeof ( animal as Fish ). swim === \"function\" ) { return true ; } return false ; } //子类断言 interface ApiError extends Error { code : number ; } interface HttpError extends Error { statusCode : number ; } function isApiError ( error : Error ) { if ( typeof ( error as ApiError ). code === \"number\" ) { return true ; } return false ; } //确保代码无误后，绕过类型检查 //在类型的严格性和开发的便利性之间掌握平衡 ( window as any ). foo = 1 ; //明确类型，后续有了代码补全，提高可维护性 function getCacheData ( key : string ) : any { return ( window as any ). cache [ key ]; } interface Cat { name : string ; run () : void ; } const tom = getCacheData ( \"tom\" ) as Cat ; tom . run (); 类型声明比类型断言约束更严格，如 animal 断言为 Cat，只需要满足 Animal 兼容 Cat 或 Cat 兼容 Animal 即可 animal 赋值给 tom，需要满足 Cat 兼容 Animal 才行 可以用泛型替代类型断言 function getCacheData < T > ( key : string ) : T { return ( window as any ). cache [ key ]; } interface Cat { name : string ; run () : void ; } const tom = getCacheData < Cat > ( \"tom\" ); tom . run (); 声明文件 常用的声明语法 declare var 声明全局变量 declare const 声明全局常量 declare function 声明全局方法 declare class 声明全局类 declare enum 声明全局枚举类型 declare namespace 声明（含有子属性的）全局对象 interface 和 type 声明全局类型 export 导出变量 export namespace 导出（含有子属性的）对象 export default ES6 默认导出 export = commonjs 导出模块 export as namespace UMD 库声明全局变量 declare global 扩展全局变量 declare module 扩展模块 /// <reference /> 三斜线指令 类型别名 类型 c 语言 typedef，在 typescript 中用 type 创建类型别名 type Name = string ; type NameResolver = () => string ; type NameOrResolver = Name | NameResolver ; function getName ( n : NameOrResolver ) : Name { if ( typeof n === \"string\" ) { return n ; } else { return n (); } } 字面量类型 约束取值只能是某几个值中的一个 type EventNames = \"click\" | \"scroll\" | \"mousemove\" ; function handleEvent ( ele : Element , event : EventNames ) { // do something } handleEvent ( document . getElementById ( \"hello\" ), \"scroll\" ); // 没问题 handleEvent ( document . getElementById ( \"world\" ), \"dblclick\" ); // 报错，event 不能为 'dblclick' 元组 数组合并了相同类型的对象，而元组（Tuple）合并了不同类型的对象; 可以对元组中的单个元素赋值； 当直接对元组类型的变量进行初始化或者赋值的时候，需要提供所有元组类型中指定的项; 当添加越界的元素时，它的类型会被限制为元组中每个类型的联合类型 let tom : [ string , number ] = [ \"Tom\" , 25 ]; let tom : [ string , number ]; tom [ 0 ] = \"Tom\" ; tom [ 1 ] = 25 ; tom [ 0 ]. slice ( 1 ); tom [ 1 ]. toFixed ( 2 ); tom = [ \"Tom\" , 25 ]; tom . push ( \"male\" ); 枚举 枚举（Enum）类型用于取值被限定在一定范围内的场景 enum Days { Sun , Mon , Tue , Wed , Thu , Fri , Sat , } console . log ( Days [ \"Sun\" ] === 0 ); // true console . log ( Days [ \"Mon\" ] === 1 ); // true console . log ( Days [ \"Tue\" ] === 2 ); // true console . log ( Days [ \"Sat\" ] === 6 ); // true console . log ( Days [ 0 ] === \"Sun\" ); // true console . log ( Days [ 1 ] === \"Mon\" ); // true console . log ( Days [ 2 ] === \"Tue\" ); // true console . log ( Days [ 6 ] === \"Sat\" ); // true 类 传统方法中，JavaScript 通过构造函数实现类的概念，通过原型链实现继承。而在 ES6 中，我们终于迎来了 class 使用 class 定义类，使用 constructor 定义构造函数。 通过 new 生成新实例的时候，会自动调用构造函数。 使用 extends 关键字实现继承，子类中使用 super 关键字来调用父类的构造函数和方法。 使用 getter 和 setter 可以改变属性的赋值和读取行为： 使用 static 修饰符修饰的方法称为静态方法，它们不需要实例化，而是直接通过类来调用，不可以通过实例来调用： ES6 中实例的属性只能通过构造函数中的 this.xxx 来定义，ES7 提案中可以直接在类里面定义 ES7 提案中，可以使用 static 定义一个静态属性，静态属性属于类； 当构造函数修饰为 private 时，该类不允许被继承或者实例化; 当构造函数修饰为 protected 时，该类只允许被继承，不允许被实例化； 类属性/方法的访问限定符如下: public 修饰的属性或方法是公有的，可以在任何地方被访问到，默认所有的属性和方法都是 public 的 private 修饰的属性或方法是私有的，不能在声明它的类的外部访问 protected 修饰的属性或方法是受保护的，它和 private 类似，区别是它在子类中也是允许被访问的 class Animal { private _name : string ; age = 23 ; static num = 42 ; constructor ( name ) { this . _name = name ; } get name() { return \"get \" + this . _name ; } //name是public的，但是_name是私有的 //不能在set name中再对name赋值，会造成死循环 set name ( value ) { if ( value === \"Dog\" ) { console . log ( \"Animal cannot be dog\" ); return ; } this . _name = value ; console . log ( \"setter: \" + value ); } sayHi() { console . log ( `My name is ${ this . _name } ` ); } static isAnimal ( a ) { return a instanceof Animal ; } } class Cat extends Animal { constructor ( name ) { super ( name ); // 调用父类的 constructor(name) console . log ( this . name ); } //函数重写 sayHi() { return \"Meow, \" + super . sayHi (); // 调用父类的 sayHi() } } let a = new Animal ( \"Jack\" ); Animal . isAnimal ( a ); // true let c = new Cat ( \"Tom\" ); // Tom console . log ( c . sayHi ()); // Meow, My name is Tom 参数属性 修饰符和 readonly 还可以使用在构造函数参数中，等同于类中定义该属性同时给该属性赋值 只读属性关键字，只允许出现在属性声明或索引签名或构造函数中 注意如果 readonly 和其他访问修饰符同时存在的话，需要写在其后面。 abstract 用于定义抽象类和其中的抽象方法。 抽象类不允许被实例化，抽象类中的抽象方法必须被子类实现 abstract class Animal { //public readonly name; public constructor ( public readonly name : string ) { this . name = name ; } //abstract method public abstract eat (); } class Cat extends Animal { public eat() { console . log ( ` ${ this . name } is eating.` ); } } let a = new Cat ( \"Tom\" ); console . log ( a . name ); // Tom 类和接口 实现（implements）是面向对象中的一个重要概念。一般来讲，一个类只能继承自另一个类，有时候不同类之间可以有一些共有的特性，这时候就可以把特 性提取成接口（interfaces），用 implements 关键字来实现。这个特性大大提高了面向对象的灵活性。 接口中所有属性和方法都要求是 public 一个类可以实现一个或者多个接口 接口之间可以是继承关系 接口可以继承类（不推荐），本质上还是接口继承接口，因为在创建类的时候，会创建一个同名的接口类型 创建类时自动生成的类型中包含了除了构造函数的实例属性和实例方法，会保留访问限定符， 如果类属性是 private，将导致该类型的对象无法被初始化，生成的接口类型中不包括： 静态类型和静态方法 构造函数 interface Alarm { alert () : void ; } interface Light { lightOn () : void ; lightOff () : void ; } class Car implements Alarm , Light { alert() { console . log ( \"Car alert\" ); } lightOn() { console . log ( \"Car light on\" ); } lightOff() { console . log ( \"Car light off\" ); } } 接口继承类（晦涩） class Point { x : number ; y : number ; constructor ( x : number , y : number ) { this . x = x ; this . y = y ; } } interface PointInstanceType { x : number ; y : number ; } // 等价于 interface Point3d extends PointInstanceType interface Point3d extends Point { z : number ; } let point3d : Point3d = { x : 1 , y : 2 , z : 3 }; 泛型 泛型（Generics）是指在定义函数、接口或类的时候，不预先指定具体的类型，而在使用的时候再指定类型的一种特性 function createArray < T > ( length : number , value : T ) : Array < T > { let result : T [] = []; for ( let i = 0 ; i < length ; i ++ ) { result [ i ] = value ; } return result ; } createArray < string > ( 3 , \"x\" ); // ['x', 'x', 'x'] //多个类型参数 function swap < T , U > ( tuple : [ T , U ]) : [ U , T ] { return [ tuple [ 1 ], tuple [ 0 ]]; } swap ([ 7 , \"seven\" ]); // ['seven', 7] 泛型约束，可以使用其他类型约束，也可以在类型参数之间进行约束 function copyFields < T extends U , U > ( target : T , source : U ) : T { for ( let id in source ) { target [ id ] = ( < T > source )[ id ]; } return target ; } let x = { a : 1 , b : 2 , c : 3 , d : 4 }; copyFields ( x , { b : 10 , d : 20 }); 参考 Typescript 入门教程","tags":"Angular","url":"pages/2021/01/29/Typescript-Doc/","loc":"pages/2021/01/29/Typescript-Doc/"},{"title":"docker 基本使用","text":"CheatSheet Docker 核心架构： 客户端 Client 服务器 Docker daemon 镜像 Image Registry 容器 Container 容器基本技术： cgroup 资源限额 namespace 资源隔离 Mount UTS IPC PID Network User Docker 采用 C/S 架构，客户端向服务器发送请求，服务器负责构建、运行和分发容器。客户端和服务器可以运行在同一个 host 上，客户端也可以通过 socket 或者 REST API 和远程服务器通信。docker 客户端是和服务器通信的命令行工具。服务器负责创建、运行、监控容器，构建、存储镜像。镜像是一个只读模板，通过镜像可以创建容器。容器就是镜像运行的实例。Registry 是存放镜像的仓库。 构建镜像并启动容器 镜像管理 # pull an image from a registry docker pull myimage:1.0 # retag a local image with new name and tag docker tag myimage:1.0 myrepo/myimage:2.0 # push an image to a registry docker push myrepo/myimage:2.0 # 查看本地镜像 docker images # list all images locally stored docker image ls # delete an image from local image store docker image rm alpine:3.4 从镜像启动容器 # 后台从镜像启动容器，并指定Host和容器的端口映射 docker run -d -p 8000 :80 <image> # 进入容器，附加到前台进程 docker attach <容器> # 离开容器 Ctrl+p Ctrl+q # 进入容器，新开一个终端 docker exec -it <容器> bash # 退出容器 exit # 启动exit的容器 docker start <容器> # 停止容器 docker stop <容器> # rum a container from alpine:3.9 image # name the running container \"web\" # expose port 5000 externally mapped to port 80 inside the container docker container run --name web -p 5000 :80 alpine:3.9 # stop a running container through SIGTERM docker container stop web # stop a running container through SIGKILL docker container kill web # delete all running and stopped containers docker container rm -f $( docker ps -aq ) # print the last 100 lines of a container's logs docker container logs --tail 100 web 构建镜像 # 查看容器 docker ps -a docker container ls -a # 构建镜像 # 1.运行容器 # 2.修改容器 # 3.将容器保存为新镜像 docker commit <镜像> # 从dockerfile构建镜像 docker build -t <image_name> -f <Dockerfile路径> # build an image from Dockerfile in the current directory and tag the image docker build -t myimage:1.0 . # 查看镜像分层 docker history <image> docker 网络 Docker 容器和主机之间网络： bridge host none 自定义 网络相关的命令： brctl show # 显示网桥 ip r # 查看路由表 iptables-save # 查看路由 # 查看docker网桥 docker network inspect bridge # 查看docker网络 docker network ls # 以某种网络配置从镜像启动容器 docker run --network = host -it <镜像> bash 镜像的备份与恢复 docker save 导出镜像到本地文件 # Usage $ docker save [ OPTIONS ] IMAGE [ IMAGE... ] # 导出golang镜像 $ sudo docker save --output golang.tar golang:1.2 docker load 从本地文件导入文件到镜像库 # Usage $ docker load [ OPTIONS ] # 导入golang镜像 $ sudo docker load --input golang.tar docker export 导出容器快照到本地文件 # Usage $ docker export [ OPTIONS ] CONTAINER # 导出hello容器快照 $ sudo docker export --output hello.tar docker import 从容器快照文件中再导入为镜像 # Usage $ docker import [ OPTIONS ] URL | - [ REPOSITORY [ :TAG ]] # 导入hello快照，并制定镜像标签为hello:1.0 $ cat hello.tar | sudo docker import - hello:1.0 容器监控 # 查看所有容器 docker container ls # 查看容器内进程 docker container top <容器> # 查看容器资源状态 # 1. 所有容器 docker container stats # 2. 特定容器 docker container stats <容器...> 工具 Sysdig Weave Scope cAdvisor Prometheus 容器日志 docker 默认将容器日志发送到 STDOUT 和 STDERR， 此外，docker 还提供了多种 logging driver，帮助从容器中提取运行日志， 默认的 logging driver 是 json-file，将容器日志保存在 json file 中， 可以在 host 目录的/var/lib/docker/containers/ 目录下找到日志的 json 文件 一些系统的日志方案 ELK Graylog # 打印容器所有日志 docker logs <容器> # 持续打印日志 docker logs -f <容器> 参考 Docker 从入门到实践 Docker 快速入门 Docker 入门教程 每天 5 分钟玩转 Docker","tags":"Linux","url":"pages/2021/01/23/Docker-Tutorial/","loc":"pages/2021/01/23/Docker-Tutorial/"},{"title":"sqlite3 入门","text":"命令行 # 从文件中执行sql语句 sqlite> .read cars.sql # 打开test.db数据库文件，如果文件不存在，创建 sqlite3 test.db # 元命令 # 显示可用表 .tables sqlite> .mode column sqlite> .headers on sqlite> SELECT * FROM Friends ; Id Name Sex ---------- ---------- ---------- 1 Jane F 2 Thomas M 3 Franklin M 4 Elisabeth F 5 Mary F 6 Lucy F 7 Jack M 本示例说明如何在 sqlite 的列模式下格式化数据。 .headers命令也已用于显示列标题。 默认情况下，标题是隐藏的。 .width命令调整列的大小。 （此 meta 命令仅与列模式下的表有关。） sqlite> SELECT Name, Title FROM Authors NATURAL JOIN Books ; Name Title ----------- ---------- Jane Austen Emma Leo Tolstoy War and Pe Joseph Hell Catch XII Charles Dic David Copp Joseph Hell Good as Go Leo Tolstoy Anna Karen 列宽不足以正确显示所有数据。 sqlite> .width 15 18 sqlite> SELECT Name, Title FROM Authors NATURAL JOIN Books ; Name Title --------------- ------------------ Jane Austen Emma Leo Tolstoy War and Peace Joseph Heller Catch XII Charles Dickens David Copperfield Joseph Heller Good as Gold Leo Tolstoy Anna Karenia SQL 在这里，我们更改列宽。 第一列为 15 个字符，第二列为 18 个字符。 .show命令列出了各种设置。 其中包括输出模式，列表模式中使用的分隔符以及标题是否打开。 .schema命令显示表的结构。 它提供了 DDL SQL 来创建表。 sqlite> .schema Cars CREATE TABLE Cars ( Id INTEGER PRIMARY KEY, Name TEXT, Price INTEGER ) ; SQL .schema命令显示表的结构。 它提供了 DDL SQL 来创建表。 可以使用.prompt命令更改sqlite3的提示。 sqlite> .prompt \"> \" \". \" > SELECT * FROM Cars . LIMIT 2 ; Id Name Price ---------- ---------- ---------- 1 Audi 52642 2 Mercedes 57127 > SQL 有两个提示。 一个是主提示，另一个是继续提示。 默认的主提示是sqlite & gt ; ，默认的继续提示是... & gt ; 。 我们可以从 Shell 执行 SQL 命令。 $ sqlite3 test.db \"SELECT * FROM Cars;\" 我们将使用.dump命令转储该表。 sqlite> .output cars2.sql sqlite> .dump Cars SQL 我们还可以将输出重定向到文件。 .output命令会将输出重定向到cars2.sql文件。 sqlite> .tables Authors Cars Friends Reservations Books Customers Orders sqlite> DROP TABLE Cars ; sqlite> .tables Authors Customers Orders Books Friends Reservations sqlite> .read cars.sql sqlite> .tables Authors Cars Friends Reservations Books Customers Orders sqlite> SELECT * FROM Cars WHERE Id = 1 ; Id Name Price ---------- ---------- ---------- 1 Audi 52642 在这里，我们得到 SELECT 语句的输出。 默认情况下，输出模式为 line，分隔符为|。 使用案例 1、输入\" sqlite3 + 数据库名.db \" (如： \" sqlite3 collect.db \") 打开数据库 2、可输入 \" .table \" 查看数据库中存在哪些表 3、可输入\" .schema ' 查看建表语句 4、通过 SQL 查询语句 \" select _ from 表名 \" （如：\" select _ from Book \"） 参考 sqlite 教程","tags":"Others","url":"pages/2020/12/27/sqlite3-tutorial/","loc":"pages/2020/12/27/sqlite3-tutorial/"},{"title":"Awk 日常使用","text":"快捷键 awk 是 linux 上用于文本处理的脚本语言，你可以实现： 定义变量 使用字符串和算术运算符 使用控制流程和循环 生成格式化的输出 用法：awk [ POSIX 或 GNU 风格选项 ] [ -- ] '程序' 文件 ... POSIX 选项： GNU 长选项： ( 标准 ) -f 脚本文件 --file = 脚本文件 -F fs --field-separator = fs -v var = val --assign = var = val 使用变量 $0 整行 $1 第一列字段 $2 第二列字段 $n 第 n 列字段 空格或者制表符是默认的列分隔符 可以通过-F 指定分隔符 awk -F: '{print $1}' /etc/passwd cat /etc/passwd | awk -F: '{print $1}' 使用脚本文件 将 awk 脚本保存在 testfile 文件中 { print $1 \" home at \" $6 } 然后执行文件 awk -F: -f testfile /etc/passwd 预处理和后处理 保存 testfile 如下 BEGIN { print \"Users and thier corresponding home\" print \" UserName \\t HomePath\" print \"___________ \\t __________\" FS = \":\" } { print $1 \" \\t \" $6 } END { print \"The end\" } 执行脚本 awk -f testfile /etc/passwd 内置变量 一些内置变量如下 FS 指定 field 段分隔符 OFS [Output Filed Separator]输出分隔符 ORS [Output Record Separator] 输出行分隔符 FIELDWIDTHS 按段长度分割 RS [Record Separator]记录分隔符，默认是换行符 指定输出分隔符 awk 'BEGIN{FS=\":\"; OFS=\"-\"} {print $1,$6,$7}' /etc/passwd 使用长度分割 素材如下，保存为 testrecord： 1235 .96521 927 -8.3652 36257 .8157 awk 'BEGIN{FIELDWIDTHS=\"3 4 3\"}{print $1,$2,$3}' testrecord 输出如下： 123 5 .96 521 927 -8.3 652 362 57 .8 157 使用 Record Separator 素材如下，保存为 testrecord： Person Name 123 High Street ( 222 ) 466 -1234 Another person 487 High Street ( 523 ) 643 -8754 awk 'BEGIN{FS=\"\\n\"; RS=\"\"} {print $1,$3}' testrecord 输出如下： Person Name ( 222 ) 466 -1234 Another person ( 523 ) 643 -8754 参考 30 Examples For Awk Command In Text Processing","tags":"Linux","url":"pages/2020/12/05/Awk-Usage/","loc":"pages/2020/12/05/Awk-Usage/"},{"title":"linux 101 Hackers 笔记","text":"# 创建目录并进入 function mkdircd () { mkdir -p \" $@ \" && eval cd \"\\\"\\$ $# \\\"\" ; } 查找文件 # 找到大于100M的文件 find / -type f -size +100M # 找到文件名中含有mail的文件/文件夹 find /etc -name \"*mail*\" # 找到修改时间在60天之前的文件 find . -mtime +60 # 找到修改时间在2天内的文件 find . -mtime -2 # 批量显示TS后缀且大于100M文件的详情 find . -type f -name '*.TS' -size +100M -exec ls -l {} \\; # 批量删除TS后缀且大于100M的文件 find . -type f -name '*.TS' -size +100M -exec rm -f {} \\; # 查找修改时间60天前的文件并打包 find /home/jsmith -type f -mtime +60 | xargs tar -cvf /tmp/ ` date '+%d%m%Y' _archive.tar ` 输出重定向 # 标准输出重定向，只显示error信息 ./shell-script.sh > /dev/null # 标准错误信息重定向 ./shell-script.sh 2 > /dev/null # 标准错误和输出都重定向 ./shell-script.sh > /dev/null 2 > & 1 # 将所有大写转化为小写 tr A-Z a-z < department.txt # 将所有小写转化为大写 tr a-z A-Z < employee.txt xargs 基本使用 # 删除log文件 find ~ -name '*.log' -print0 | xargs -0 rm -f find /etc -name \"*.conf\" | xargs ls -l cat url-list.txt | xargs wget -c find / -name *.jpg -type f -print | xargs tar -cvzf images.tar.gz ls *.jpg | xargs -n1 -i cp {} /external-harddrive/directory 文件中截取列 # 以:分割，第一列 cut -d: -f 1 /etc/passwd # 以:分割，第1和第3列 cut -d: -f 1 ,3 /etc/passwd # 截取每行前边1-8个字符 cut -c 1 -8 /etc/passwd 后台运行 nohup ./backup.sh & screen -S backup # 以特定间隔时间执行命令 watch df -h sed 基础 # thegeekstuff.txt # Instruction Guides 1. Linux Sysadmin, Linux Scripting etc. 2. Databases - Oracle, mySQL etc. 3. Security (Firewall, Network, Online Security etc) 4. Storage in Linux 5. Productivity (Too many technologies to explore, not much time available) # Additional FAQS 6. Windows- Sysadmin, reboot etc. # 将第一个Linux替换为Linux-Unix sed 's/Linux/Linux-Unix/' thegeekstuff.txt # 将所有Linux替换为Linux-Unix sed 's/Linux/Linux-Unix/g' thegeekstuff.txt # 将第2个出现的Linux替换为Linux-Unix sed 's/Linux/Linux-Unix/2' thegeekstuff.txt # 输出修改行并写入指定的output文件 sed -n 's/Linux/Linux-Unix/gpw output' thegeekstuff.txt # 行正则匹配到-，则从-到行尾的字符被替换为空 sed '/\\-/s/\\-.*//g' thegeekstuff.txt # 删除每行的后3个字符 sed 's/...$//' thegeekstuff.txt # 直接修改源文件，去除#开头的注释 sed -e 's/#.*//' thegeekstuff.txt # 直接修改源文件，去除#开头的注释并去除空行 sed -e 's/#.*//;/&#94;$/d' thegeekstuff.txt # 去除html的箭头标签 sed -e 's/<[&#94;>]*>//g' # 同时显示多个文件的日志 tail -f /var/log/syslog -f /var/log/auth.log # 修改命令行提示符号 export PS1 = \"\\u@\\h \\w> \" # 修改系统时间 date { mmddhhmiyyyy.ss } # Jan 31st 2009, 10:19 p.m, 53 seconds date 013122192009 .53 date +%Y%m%d -s \"20090131\" date +%T -s \"22:19:53\" date -s \"01/31/2009 22:19:53\" # 显示时间 date + \"%d-%m-%Y\" 01 -01-2009 date + \"%d/%m/%Y\" # 01/01/2009 date + \"%A,%B %d %Y\" # Thursday,January 01 2009 压缩和解压 zip var-log-files.zip /var/log/* zip -r var-log-dir.zip /var/log/ unzip var-log.zip unzip -v var-log.zip unzip -l var-log.zip unzip -t var-log.zip zip -P mysecurepwd var-log-protected.zip /var/log/* unzip var-log-protected.zip tar [ options ] [ tar-archive-name ] [ other-file-names ] # 压缩文件 tar cvf /tmp/my_home_directory.tar /home/jsmith # 显示压缩文件目录 tar tvf /tmp/my_home_directory.tar # 提取压缩文件 tar xvf /tmp/my_home_directory.tar # 指定提取目录 tar xvfz /tmp/my_home_directory.tar.gz -C /home/ramesh # gzip压缩文件(*.tar.gz) tar cvfz /tmp/my_home_directory.tar.gz /home/jsmith tar xvfz /tmp/my_home_directory.tar.gz tar tvfz /tmp/my_home_directory.tar.gz # bzip压缩文件(*.tar.bz2) tar cvfj /tmp/my_home_directory.tar.bz2 /home/jsmith tar xvfj /tmp/my_home_directory.tar.bz2 tar tvfj /tmp/my_home_directory.tar.bz2 命令行历史 # CTRL+r 查找匹配历史 # CTRL+p 上一条命令 history -c # 清除历史 # 忽略重复命令 export HISTCONTROL = ignoredups # 忽略以空格开头的命令 export HISTCONTROL = ignorespace # 不记录历史 export HISTSIZE = 0 系统管理 # 创建swap分区 dd if = /dev/zero of = /home/swap-fs bs = 1M count = 512 ls -l /home/swap-fs mkswap /home/swap-fs swapon /home/swap-fs # edit in /etc/fstab /home/swap-fs swap swap defaults 0 0 # 生成ssh公钥 ssh-keygen ssh-copy-id -i ~/.ssh/id_rsa.pub remote-host # 定时任务管理 crontab -e { minute } { hour } { day-of-month } { month } { day-of-week } { full-path-to-shell-script } # run at 00:01am 1 0 * * * /root/bin/backup.sh # run at weekday 11:59pm 59 11 * * 1 ,2,3,4,5 /root/bin/backup.sh 59 11 * * 1 -5 /root/bin/backup.sh # run every 5 minute */5 * * * * /root/bin/check-status.sh # run at 13:10pm on lst of every month 10 13 1 * * /root/bin/full-backup.sh # run at 11:00pm every weekday 0 23 * * 1 -5 /root/bin/incremental-backup.sh # 同步文件 rsync options source destination # sync two directory in a local computer # -z enable compression # -v verbose # -r recursive # -a archive mode:will preserve symbolic link/permission/timestamp/owner/group rsync -zvr /var/opt/installation/inventory/ /root/temp # sync one file rsync -v /var/lib/rpm/Pubkeys /root/temp/ # sync to remote machine rsync -avz /root/temp/ thegeekstuff@192.168.200.10:/home/thegeekstuff/temp/ # sync from remote to local rsync -avz thegeekstuff@192.168.200.10:/var/lib/rpm /root/temp # netcat命令nc # 从server1拷贝文件到server2 # 1. 在server2(102.168.200.27)上监听 nc -l 2222 > 1234 .txt # 2. 在server1上开启传输 nc -w 1 102 .168.200.27 2222 < abc.txt # 网络拷贝硬盘 # 1. server2(102.168.200.27)监听 nc -l -p 2222 | dd of = /dev/sda # 2. server1执行传输 dd if = /dev/sda | nc 102 .168.200.27 2222 # nc端口扫描 # 扫描20-30端口 nc -v -w 1 192 .168.200.29 -z 20 -30 系统性能监控 ps axl ps aux ps axuf ps U niuhe netstat -tap netstat --route # 路由表 sar lsof","tags":"Linux","url":"pages/2020/12/05/Linux-101-Hackers/","loc":"pages/2020/12/05/Linux-101-Hackers/"},{"title":"vscode 快捷键和插件记录","text":"快捷键 CTRL+B 打开/收起侧边栏目 CTRL+` 打开内置终端 CTRL+, 打开设置 CTRL+p 快速搜索并打开文件 CTRL+TAB 在已经打开的标签页中跳转 CTRL+\\ 将标签页移动到右侧分割栏 CTRL+w 关闭标签页 CTRL+f 查找内容 CTRL+h 查找并替换 CTRL+SHIFT+f 全局搜索 CTRL+SHIFT+p 命令面板 CTRL+/ 注释/解除注释 CTRL+HOME/END 跳转到文件首/尾 CTRL+c/v 复制或剪切当前光标行/在当前光标行或下一行粘贴 CTRL+SHIFT+箭头上下箭头 多个光标用于列编辑 ALT+CLICK 获取多个编辑的光标 CTRL+d 选中单词 CTRL+SHIFT+l 选中所有该选中的内容 F2 重命名变量 CTRL+CLICK 代码跳转 CTRL+k z 进入/推出 zen 模式 导入/导出扩展 //导出扩展名 code --list-extensions >> vs_code_extensions_list.txt cat vs_code_extensions_list.txt | xargs -n 1 code --install-extension //删除所有扩展 code --list-extensions | xargs -n 1 code --uninstall-extension 2gua.rainbow-brackets Angular.ng-template cyrilletuzi.angular-schematics davidbabel.vscode-simpler-icons dbaeumer.vscode-eslint doggy8088.angular-extension-pack donjayamanne.githistory eamodio.gitlens EditorConfig.EditorConfig EFanZh.graphviz-preview esbenp.prettier-vscode formulahendry.auto-rename-tag golang.go Gruntfuggly.todo-tree humao.rest-client infinity1207.angular2-switcher jebbs.plantuml johnpapa.Angular2 krizzdewizz.refactorix MariusAlchimavicius.json-to-ts Mikael.Angular-BeastCode mikeburgh.xml-format ms-azuretools.vscode-docker ms-mssql.mssql ms-python.python ms-toolsai.jupyter ms-vscode-remote.remote-containers ms-vscode-remote.remote-ssh ms-vscode-remote.remote-ssh-edit ms-vscode.cpptools ms-vscode.typescript-javascript-grammar ms-vscode.vscode-typescript-tslint-plugin msjsdiag.debugger-for-chrome nhoizey.gremlins obenjiro.arrr oderwat.indent-rainbow PKief.material-icon-theme quicktype.quicktype shd101wyy.markdown-preview-enhanced steoates.autoimport stringham.move-ts tht13.html-preview-vscode twxs.cmake wayou.vscode-todo-highlight xabikos.JavaScriptSnippets","tags":"Linux","url":"pages/2020/12/05/vscode-Shortcut/","loc":"pages/2020/12/05/vscode-Shortcut/"},{"title":"RabbitMQ 介绍和命令行","text":"查看所有队列信息： rabbitmqctl list_queues 关闭应用（关闭当前启动节点）： rabbitmqctl stop_app 启动应用，和上述关闭命令配合使用达到清空队列的目的： rabbitmqctl start_app 从管理数据库中移除所有数据，例如配置过的用户和虚拟宿主, 删除所有持久化的消息（这个命令要在 rabbitmqctl stop_app 之后使用）： rabbitmqctl reset 作用和 rabbitmqctl reset 一样，区别是无条件重置节点，不管当前管理数据库状态以及集群的配置。如果数据库或者集群配置发生错误才使用这个最后的手段： rabbitmqctl force_reset 节点状态: rabbitmqctl status 添加用户: rabbitmqctl add_user username password 列出所有用户: rabbitmqctl list_users 列出用户权限: rabbitmqctl list_user_permissions username 修改密码: rabbitmqctl change_password username newpassword 创建虚拟主机: rabbitmqctl add_vhost vhostpath 列出所有虚拟主机: rabbitmqctl list_vhosts 设置用户权限: rabbitmqctl set_permissions -p vhostpath username \".*\" \".*\" \".*\" 列出虚拟主机上的所有权限： rabbitmqctl list_permissions -p vhostpath 清除用户权限： rabbitmqctl clear_permissions -p vhostpath username 清除队列里的消息： rabbitmqctl -p vhostpath purge_queue blue 删除用户： rabbitmqctl delete_user username 删除虚拟主机： rabbitmqctl delete_vhost vhostpath #rabbitmqctl list_users 列出当前用户 #rabbitmqctl cluster_status 查看集群状态 #rabbitmqctl list_queues 查看消息队列","tags":"Openstack","url":"pages/2020/11/23/RabbitMQ-Commandline/","loc":"pages/2020/11/23/RabbitMQ-Commandline/"},{"title":"创建虚拟机","text":"创建虚拟机 1、界面或命令行通过RESTful API向keystone获取认证信息。 2、keystone通过用户请求认证信息，并生成auth-token返回给对应的认证请求。 3、界面或命令行通过RESTful API向nova-api发送一个boot instance的请求（携带auth-token）。 4、nova-api接受请求后向keystone发送认证请求，查看token是否为有效用户和token。 5、keystone验证token是否有效，如有效则返回有效的认证和对应的角色（注：有些操作需要有角色权限才能操作）。 6、通过认证后nova-api和数据库通讯。 7、初始化新建虚拟机的数据库记录。 8、nova-api通过rpc.call向nova-scheduler请求是否有创建虚拟机的资源(Host ID)。 9、nova-scheduler进程侦听消息队列，获取nova-api的请求。 10、nova-scheduler通过查询nova数据库中计算资源的情况，并通过调度算法计算符合虚拟机创建需要的主机。 11、对于有符合虚拟机创建的主机，nova-scheduler更新数据库中虚拟机对应的物理主机信息。 12、nova-scheduler通过rpc.cast向nova-compute发送对应的创建虚拟机请求的消息。 13、nova-compute会从对应的消息队列中获取创建虚拟机请求的消息。 14、nova-compute通过rpc.call向nova-conductor请求获取虚拟机消息。（Flavor） 15、nova-conductor从消息队队列中拿到nova-compute请求消息。 16、nova-conductor根据消息查询虚拟机对应的信息。 17、nova-conductor从数据库中获得虚拟机对应信息。 18、nova-conductor把虚拟机信息通过消息的方式发送到消息队列中。 19、nova-compute从对应的消息队列中获取虚拟机信息消息。 20、nova-compute通过keystone的RESTfull API拿到认证的token，并通过HTTP请求glance-api获取创建虚拟机所需要镜像。 21、glance-api向keystone认证token是否有效，并返回验证结果。 22、token验证通过，nova-compute获得虚拟机镜像信息(URL)。 23、nova-compute通过keystone的RESTfull API拿到认证k的token，并通过HTTP请求neutron-server获取创建虚拟机所需要的网络信息。 24、neutron-server向keystone认证token是否有效，并返回验证结果。 25、token验证通过，nova-compute获得虚拟机网络信息。 26、nova-compute通过keystone的RESTfull API拿到认证的token，并通过HTTP请求cinder-api获取创建虚拟机所需要的持久化存储信息。 27、cinder-api向keystone认证token是否有效，并返回验证结果。 28、token验证通过，nova-compute获得虚拟机持久化存储信息。 29、nova-compute根据instance的信息调用配置的虚拟化驱动来创建虚拟机。 以Nova为例， nova/compute 目录并不是一定在nova-compute节点上运行，而主要是和compute相关(虚拟机操作相关）的功能实现，同样的，scheduler目录代码并不全在scheduler服务节点运行，但主要是和调度相关的代码。不过目录结构遵循一定的规律。 通常一个OpenStack项目的代码目录都会包含 api.py 、 rpcapi.py 、 manager.py ，这三个是最重要的模块。 api.py ： 通常是供其它组件调用的封装库。换句话说，该模块通常并不会由本模块调用。比如compute目录的api.py，通常由nova-api服务的controller调用。可以简单认为是供其他服务调用的sdk。 rpcapi.py ：这个是RPC请求的封装，或者说是RPC封装的client端，该模块封装了RPC请求调用。 manager.py ： 这个才是真正服务的功能实现，也是RPC的server端，即处理RPC请求的入口，实现的方法通常和rpcapi实现的方法一一对应。 关机流程 API节点 nova-api接收用户请求 -> nova-api调用compute/api.py -> compute/api调用compute/rpcapi.py -> rpcapi.py向目标计算节点发起stop_instance()RPC请求 计算节点 收到stop_instance()请求 -> 调用compute/manager.py的callback方法stop_instance() -> 调用libvirt关机虚拟机 前面提到OpenStack项目的目录结构是按照功能划分的，而不是服务组件，因此并不是所有的目录都能有对应的组件。仍以Nova为例: nova/cmd ：这是服务的启动脚本，即所有服务的main函数。看服务怎么初始化，就从这里开始。 nova/db : 封装数据库访问，目前支持的driver为sqlalchemy。 nova/conf ：Nova所有配置项声明都放在这个目录。 nova/locale : 本地化处理。 nova/image : 封装Glance接口。 nova/network : 封装Neutron接口。 nova/volume : 封装Cinder接口。 nova/virt : 这是支持的所有虚拟化驱动实现，即compute driver实现，主流的如 libvirt 、 hyperv 、 ironic 、 vmwareapi 等。 nova/objects : 对象模型，封装了所有Nova对象的CURD操作，相对以前直接调用db的model更安全，并且支持版本控制。 nova/policies ： API policy集合。 nova/tests : 测试代码，如单元测试、功能测试。 nova/hacking : Nova代码规范定义的一些规则。 nova --debug boot --image 81e58b1a-4732-4255-b4f8-c844430485d2 --flavor 1 yikun controller 的 index 方法对应 list 操作、 show 方法对应 get 操作、 create 对应创建操作、 delete 对应删除操作、 update 对应更新操作等。 openstack-nova-compute.service 两个职责，其一，是守护进程，负责基于各种虚拟化技术Hypervisior实现创建和终止虚拟机；其二，整合了计算资源CPU，存储，网络三类资源部署管理虚拟机，实现计算能力的交付。 Cell V2的设计思想是，由API、Super Conductor去访问上层的全局数据库（nova_api数据库），而底下的cell中的组件，只需要关心cell中的逻辑即可 首先，api中进行第一次Quota检测，主要方法就是收集地下各个cell数据库中的资源信息，然后和api数据库中的quota上限进行对比。例如，一个用户可以创建10个虚拟机，在cell1中有2个，cell2中有7个，再创建一个虚拟机时，会搜集cell1和cell2中的虚拟机个数之和（9个），然后加上变化（新增一个），与总配额进行比较。 二次检测（cell v2在super conductor里做）。由于在并发场景下，可能出现同时检测发现满足，之后进行创建，就会造成配额的超分，针对这个问题，社区目前给出的方案是，在创建虚拟机记录之后，再进行recheck，如果发现超额了，会将超额分配的虚拟机标记为ERROR，不再继续往下走了。 在Cell v2场景，虚拟机的创建记录已经需要写入的子cell中，因此，conductor需要做的事，包括一下几个步骤： 进行调度，选出host。 根据host，通过 host_mappings 找到对应的cell 在对应的cell db中创建虚拟机记录，并且记录 instances_mappings 信息 通过cell_mappings来查找对应的cell的mq，然后投递到对应的cell中的compute 完成这些操作时，需要牵扯到3个关键的数据结构，我们来简单的看一下： host_mappings：记录了host和cell的映射信息 instances_mappings：记录了虚拟机和cell的映射信息 cell_mappings：记录了cell和cell对应的mq的映射信息 与Cell v1不太相同，在目前的设计中，认为scheduler能看到的应该是底下能够提供资源的具体的所有的Resource Provider（对于计算资源来说，就是所有的计算节点），而不是整个cell，也就是说所有cell中的资源scheduler都可以看到，而子cell就负责创建就好了。因此，在super conductor中，需要做一些transfer的事情，这样也就不必在像cell v1那样，在子cell里还得搞个scheduler去做调度。 通过Placement获取可用的备选资源，参考 Placement Allocation Requests 的实现。 在Ocata版本时， Resource Providers - Scheduler Filters in DB 这个BP就已经在调度前加了一步，获取备选节点。从BP的标题就可以看出，设计者想通过Placement服务提供的新的一套机制，来做过滤。原因是之前的调度需要在scheduler维护每一个compute节点的hoststate信息，然后调度的时候，再一个个去查，这太低效了，尤其是在计算节点数目比较多的时候。因此，增加了一个\"预过滤\"的流程，通过向Placement查询，Placement服务直接通过SQL去查一把，把满足条件（比如CPU充足、RAM充足等）先获取到。 而原来获取备选节点的时候，只支持获取单一的Resource Provider，这个BP增强了获取备选资源的能力，用于后续支持更复杂的请求，比如共享资源、嵌套资源的Provider查询。后面，Placement还会陆续支持更多的请求，比如对一些非存量不可计数的资源的支持。这样留给后面Filter&Weight的压力就小一些了，再往后，会不会完全取代Filter呢？我想，现有的各种过滤都可以通过Placement支持后，完全有可能的。 Scheduler通过Placement来claim资源。参考 Scheduler claiming resources to the Placement API 的实现。 在最早的时候，claim资源是由compute来做的，现在相当于提前到scheduler去搞了。有什么好处呢？我们先看看原来的问题： 调度时刻和真正的去compute节点去claim资源的时刻之间是由一段时间的，在资源不是那么充足的环境，就会造成在scheduler调度的时候，资源还没刷新，所以调度时候成功了，但是真正下来的时候，才发现compute实际已经没有资源了，然后又\"跨越半个地球\"去做重调度，无形地增加了系统的负载。 而且增加了创建的时长（哦，哪怕创建失败呢？），你想想，用户创了那么久的虚拟机，最后你告诉我调度失败了，用户不太能忍。 所以这个BP就把Claim资源放在调度处了，我上一个调度请求处理完，马上就告诉placement，这资源老子用了，其他人不要动了。OK，世界终于清净了，能拿到资源的拿到了，拿不到资源的马上也知道自己拿不到了，大大增强了调度的用户体验。 2.4 Placement 恩，在调度的时候，已经介绍过这个服务了，在虚拟机创建的流程中，比较常用的接口就是获取备选资源和claim资源。 Placement目标很宏伟，大致的作用就是：资源我来管，要资源问我要，用了资源告诉我。后面准备用一篇文章整体介绍一下Placement。（yep，这个Flag我立下了，会写的） service的详细信息主要包括如下几项： binary, host, zone, status, state 其中： binary，可以理解为service的名称，类似于nova-compute； host是service所在的主机名称； zone是service所属的AZ，其实就是service所在的主机所属的aggregate，只是aggregate的概念不对外呈现，所以用户看到的是AZ。其实，在Nova内部，AZ是AG的metadata而已。 zone的确定，涉及到两个配置项，对于非计算节点，zone的名称依赖于配置项internal_service_availability_zone（默认是internal）； 对于计算节点，如果不属于任何AG，或者所属的AG没有AZ的metadata信息，默认的zone依赖于配置项default_availability_zone（默认是nova）。 status是服务disable属性的体现，该属性可以直接通过API修改; state是服务真实的状态，是通过servicegroup api获取。每个服务在启动时会加入servicegroup，以db后端为例，会在服务中启动定时器，更新service表中的 report_count 的值，同时也会刷新更新时间，后续会根据这个更新时间确定服务的死活； 当然，查询service信息也支持过滤条件，比如： 1、查询某个host相关的service； 2、按binary名称查询service； 其实Nova中没有host这个独立的资源（数据库对象），但是Nova却有针对host的API操作，其实，在内部实现中，就是通过前面的service信息，间接组装返回host信息。 租户：配额 与此同时，虚拟机state或task_state发生变化时，也会向外部发送通知。 前提是配置项notify_on_state_change要配置为vm_state或vm_and_task_state。 Nova中的虚拟机每个操作（启动、停止、暂停、恢复等等），都会在db中保存相关的操作记录，给用户提供查询。利用这个功能， 用户对自己的虚拟机整个生命周期的过程和状态都会了如指掌 ，便于用户的管理。参见 这里 。示例如下： 在内部实现中，nova-api层会记录action开始的记录，在nova-compute层，则会添加event开始和结束的信息，action和event根据request id（一次消息请求的标识）关联。 先说通知，虚拟机操作异常时，一般都会发送error通知，通知中包含异常的函数名称、异常时函数的参数以及异常信息。 再说db，虚拟机操作异常时，无论是在conductor, scheduler还是compute层，除了会发送通知外，还会记录异常信息到数据库（ instance_faults 表），当查询虚拟机信息时，会返回虚拟机的异常信息。 一个hypervisor，是创建虚拟机能够调度到的最小单元。 api.py 提供对外访问的接口，可以从这开始入手跟踪各个功能实现。 rpcapi.py 封装RPC请求调用，大多数是异步调用。 manager.py 各种RPC调用的实现，基本和 rpcapi.py 中调用的名称一一对应。 此外还有一点，Openstack的目录结构是根据功能划分的，比如Nova中compute目录不一定都是在 nova-compute 节点上运行，而是所有和虚拟机创建相关的功能都在这里。 从配置文件可以明显的看出，nova-api对应的文件是 nova/cmd/api.py 的 main() 函数： vm_state power_state task_state _record_action_start notify_about_instance_action elevated @ startuml title : 创建虚拟机 participant \"API\" as api note left of api nova / api / openstack / compute / servers . py end note participant \"Scheduler\" as sch database \"Database\" as db # Green participant \"Condutor(super)\" as pconductor participant \"Placement\" as placement box \"internal service\" participant \"Compute\" as compute participant \"Libvirt\" as virt end box participant \"Conductor(cell)\" as ccondutor participant \"Neutron\" as neutron participant \"Cinder\" as cinder participant \"Glance\" as glance autonumber \"<b> [00]\" [ -> api ++ : 创建虚拟机 api -> api : validate schema api -> api : get context api -> api : get server_dict api -> api : gen create_kwargs api -> api : policy check api -> api : provision instance api -> glance : 获取镜像信息 api -> api : policy校验 api -> api : 配额校验 api -> api : 添加 Group hnote left # FFAAAA vm_state : Building task_state : Scheduling end note api -> db : 创建 instance db -> api : create success [ <- api : return 202 deactivate api api -> pconductor ++: schedule & build pconductor -> sch : select_destination sch -> placement : get allocation candidates placement -> sch : alloc_reqs . provider_summarys sch -> sch : Filter & weighter sch -> placement : claim Resources placement -> sch : hello sch -> pconductor : return host pconductor -> pconductor : in target cell DB中创建instance pconductor -> pconductor : 配额校验 recheck pconductor -> pconductor : 刷新 instance cell 信息 pconductor -> pconductor : 删除 build request () pconductor -> compute : 在指定 cell中创建虚拟机 hnote left # FFAAAA vm_state : Building task_state : None end note compute -> neutron : 创建网络 hnote left # FFAAAA vm_state : Building task_state : Networking end note compute -> cinder : 构建块设备 hnote left # FFAAAA vm_state : Building task_state : Block Device Mapping end note compute -> compute : spawn () hnote left # FFAAAA vm_state : Building task_state : Spawning end note compute -> glance : 下载镜像 compute -> compute : 生成 xml compute -> compute : 刷新虚拟机状态 hnote left # FFAAAA vm_state : Building task_state : None end note @ enduml @startuml title: Lock虚拟机 participant \"API\" as api database \"Database\" as db #Green autonumber \"<b> [00]\" [ -> api : lock api -> api : get_context api -> api : authorize action [ lock ] policy api -> db : get instance by id db -> api : done api -> api : check policy api -> db : instance.locked = True \\n locked_by = owner or admin \\n record locked reason db -> api : done [ <- api : response @enduml @startuml title: Pause虚拟机 participant \"API\" as api database \"Database\" as db #Green box \"internal service\" participant \"Compute\" as compute participant \"Libvirt\" as virt end box autonumber \"<b> [00]\" [ -> api++ : pause instance api -> api : authorize context api -> db++ : get instance by uuid return done api -> api : check policy api -> api : check instance lock api -> api : check instance cell api -> api : ensure instance state is ACTIVE api -> db++ : task_state = PAUSING return done api -> api : record pause action api -> compute++ : pause_instance compute -> compute : notify : pause.start compute -> virt++ : pause virt -> virt : get domain virt -> virt : domain.suspend () return done compute -> db++ : vm_state = PAUSE \\n task_state = None return done compute -> compute : notify: pause.end [ <- api : response @enduml @startuml title: Rename虚拟机 participant \"API\" as api database \"Database\" as db #Green autonumber \"<b> [00]\" [ -> api : update name activate api api -> api : validate schema api -> api : get context api -> api : authorize [ update ] policy api -> api : get update_dict [ \"display_name\" ] api -> db++ : get server by id return done api -> db : update ( update_dict ) db -> db : save [ <- api : responee @enduml @startuml title: Suspend虚拟机 participant \"API\" as api database \"Database\" as db #Green box \"internal service\" participant \"Compute\" as compute participant \"Libvirt\" as virt end box autonumber \"<b> [00]\" [ -> api++ : suspend instance api -> api : authorize context api -> db++ : get instance by uuid return done api -> api : check policy api -> api : check instance lock api -> api : check instance cell api -> api : ensure instance state is ACTIVE api -> db++ : task_state = SUSPANDING return done api -> api : record action : suspand api -> compute++ : suspand_instance compute -> compute : notify : suspand.start compute -> virt++ : suspand virt -> virt : get instance guest virt -> virt : detach pci device virt -> virt : detach sriow ports virt -> virt : guest.save_memory_state () return done compute -> db++ : vm_state = SUSPENDED \\n task_state = None return done compute -> compute : notify: suspend.end [ <- api : response @enduml @startuml hide empty description [ * ] --> State1 State1 --> [ * ] vm_state:powering \\n task_state:good \\n nihao State1 : this is another string State1 -> State2 State2 --> [ * ] @enduml @startuml title: Unlock虚拟机 participant \"API\" as api database \"Database\" as db #Green autonumber \"<b> [00]\" [ -> api : lock api -> api : get_context api -> api : authorize action [ unlock ] policy api -> db : get instance by id db -> api : done api -> api : check policy api -> db : query instance.locked db -> api : done api -> db : instance.locked = False \\n locked_by = None \\n clear locked reason db -> api : done [ <- api : response @enduml @startuml title: Unpause虚拟机 participant \"API\" as api database \"Database\" as db #Green box \"internal service\" participant \"Compute\" as compute participant \"Libvirt\" as virt end box autonumber \"<b> [00]\" [ -> api++ : unpause instance api -> api : authorize context api -> db++ : get instance by uuid return done api -> api : check policy api -> api : check instance lock api -> api : check instance cell api -> api : ensure instance state is PAUSED api -> db++ : task_state = UNPAUSING return done api -> api : record action : unpause api -> compute++ : unpause_instance compute -> compute : notify : unpause.start compute -> virt++ : unpause virt -> virt : get domain virt -> virt : domain.resume () return done compute -> db++ : vm_state = ACTIVE \\n task_state = None return done compute -> compute : notify: unpause.end [ <- api : response @enduml 参考 Openstack虚拟机启动方式 Openstack源码学习笔记 Openstack词汇表 Openstack从硬盘启动实例 Nova虚拟机创建流程分析 Nova创建虚拟机流程分析 如何阅读openstack源码 虚拟机创建的50个步骤和100个知识点 Openstack源码学习之热迁移","tags":"Openstack","url":"pages/2020/10/31/Create-Instance/","loc":"pages/2020/10/31/Create-Instance/"},{"title":"Openstack命令行基础","text":"不同命令的功能有重复和交集 Openstack篇 Openstack每个组件都有其命令，openstack社区为了方便使用，将所有组件的命令进行了统一，以openstack开头 # 查看所有openstack服务 openstack service list # 查看openstack服务状态 openstack-service status # 重启本节点所有openstack服务 openstack-service restart # openstack服务URL列表查询 # endpoint表示一个服务在哪可被访问的URL和端口号列表 openstack endpoint list # 查询domain，domain是一个keystone验证实体 openstack domain list # 查看nova服务列表 openstack compute service list # 查看网络服务列表 openstack network agent list # ======================================================= # 项目（租户）列表查询 openstack project list # 查看租户详情 openstack project show <project_id/name> # 创建租户 openstack project create --description 'Admin Project' <租户名> # 删除租户 openstack project delete <租户id/name> # 禁用启用租户 openstack project set <租户id/name> --disable/enable # 更新租户名称 openstack project set <租户id/name> --name <new name> # ======================================================== # 查看某一个项目下所有用户user openstack user list --project = <project_id/name> # 查看所有用户 openstack user list # 查看用户详情 openstack user show <user_name/id> # 创建用户 openstack user create --domain <域名> --project <项目/租户名> --password <密码> <用户名> # 删除用户 openstack user delete <用户名> # 禁用启用某一个用户 openstack user set <user_name/id> --disable/enable # 更新用户名称 openstack user set <user_name/id> --name <new name> # 查询某一用户与项目、角色的关系 openstack role assignment list --user = 用户名 # ======================================================= # 角色查询 # 一个角色包括一组权利和特权，角色访问控制提供预定义的用户可操作列表，如开启或停止虚机，重置密码等。在身份验证服务和计算服务中均被支持。 openstack role list # 角色详情查询 opensatck role show <role_name/id> # 创建角色 openstack role create <role_name> # 分配角色，将项目和用户加入到角色中 openstack role add --user <用户名> --project <项目名> <角色名> # 删除角色 openstack role remove --user <用户名> --project <项目名> <角色名> # ====================================================== # 列出所有的镜像 openstack image list # 查看某一个镜像信息 openstack image show <image_id> # 设置镜像标签 openstack image set --tag <标签名> <image_name/id> # 创建镜像 # 格式化类型包括raw、qcow2、vmdk等 openstack image create <镜像名> --file <镜像文件名> --disk-format <格式化类型> --container-format bare --public # openstack image create \"test1\" --file cirros-0.5.1-x86_64-disk.img --disk-format qcow2 --container-format bare --public # 查看安全组信息 openstack group list # 查看flavor类型 openstack flavor list # 查询网络信息 openstack network list # 查看端口信息（虚拟网络） openstack port list # 创建虚拟机 openstack server create --image <image_id/name> --flavor <flavor_id/name> --nic net-id = <net_id> <instance_name> # 创建虚拟机帮助 openstack server create --help # ================================================== # 查看openstack环境主机列表 openstack host list # 查看某个host主机资源情况 openstack host show <host_name> # 查看虚拟机列表 openstack server list # 查看虚拟机详情 openstack server show <instance_id> # 虚拟机暂停 openstack server pause <instance_id> # 虚拟机从暂停中恢复 openstack server unpause <instance_id> # 虚拟机重启 openstack server reboot <instance_id> # 虚拟机删除 openstack server delete <instance_id> Nova篇 # 查看openstack版本 nova-manage version # 查看命令帮助信息 nova help <command> # 返回nova服务所在的host信息 # 在电子通信领域，host和node的区别在于，host是向外提供某种服务，而node只需要是连接到网络的设备 # 运行有nova服务的主机被认为是host nova host-list # 查看host具体资源信息 nova host-describe <host_name> # 查看nova服务和状态 nova service-list # ======================================= # 查看计算节点 nova hypervisor-list # 查看计算节点详情 nova hypervisor-show <hypervisor ID> # 查看计算节点上的虚拟机 nova hypervisor-servers <hypervisor ID> # ====================================== # 列出所有flavor(模板) nova flavor-list # 创建flavor，模板ID建议为auto nova flavor-create --is-public true <模板名称> <模板ID> <内存 ( MB ) > <磁盘 ( GB ) > <VCPUS> # 显示flavro详情 nova flavor-show <模板ID> # 删除flavor nova flavor-delet <模板ID> # ======================================= # 查看虚拟机列表 nova list nova list --all-te # 查看虚拟机详情 nova show <instance_id> # 查看虚拟机控制台日志 nova console-log <instance_id> # 查看密钥对列表 nova keypair-list # 查看镜像列表 nova image-list # 查看浮动ip列表 nova floating-ip-list # 查看安全组列表 nova secgroup-list # ===================================== # 查看浮动ip列表 nova-manage floating list # 数据库同步 nova-manage db sync nova-manage api_db sync nova-manage placement sync # 查看数据库版本 nova-manage db version # nova组件更新检查 nova-status upgrade check # ==================================== nova suspend <instance_id> nova resume <instance_id> nova start <instance_id> nova stop <instance_id> nova delete <instance_id> nova reboot <instance_id> # 硬重启 nova reboot --hard <instance_id> # 进入救援模式 nova rescue <instance_id> # 使用指定镜像进入救援模式 nova rescue --image <image_id> <instance_id> # 重启虚拟机，由救援模式进入正常模式 nova unrescue <instance_id> # 重置虚拟机状态 nova reset-state <instance_id> # 指定节点热迁移 nova live-migration <instance_id> <compute_node_id> # 调整虚拟机资源 nova resize <instance_id> <flavor_id> --poll # 确认调整虚拟机资源 nova resize-confirm <instance_id> # 资源调整失败回滚 nova resize-revert <instance_id> # 通过快照创建一个镜像 nova image-create <instance_id> <image_name> # =================================== # 从镜像创建虚拟机 nova boot --image cirros --flavor 1 --nic net-name = net1 vm1 # 从卷(块设备)创建虚拟机 # 1. 从镜像生成volumn cinder create --image-id <image_id> --name <volume_name> <size_in_gb> # 2. 从volumn创建虚拟机 nova boot --flavor <flavor_id> source = volumn,,id = 卷ID,dest = volume,shutdown = preserve,bootindex = 0 虚拟机名称 # ================================== # 挂载云硬盘 nova volume-attach <instance_id> <volume_name> /dev/sdb # 卸载云硬盘 nova volume-detach <instance_id> <volume_name> Neutron篇 # 列出当前租户网络 neutron net-list # 列出所有租户网络 neutron net-list --all-te # 查看网络详情 neutron net-show <net_id> # 删除一个网络 neutron net-delete <net_id> # 查看所有agent neutron agent-list # 查看所有租户拥有的port # port是虚拟网口，是路由器和虚拟机挂接网络的着附点 neutron port-list # 查看port详情 neutron port-show <port_id> # 查看安全组 neutron security-group-rule-list Glance篇 # 列出全部镜像 glance image-list # 查看image具体信息 glance show <image ID> # 上传镜像 glance image-create --visibility public --container-format docker/bare --disk-format raw/qcow2 --name xxx --file /root/xxx --progress glance image-create --name \"CentOS7.0\" --disk-format qcow2 --container-format bare --progress </opt/images/centos_7-x86_64_xiandian.qcow2 Cinder篇 # 显示存储列表 cinder list # 显示存储卷类型列表 cinder type-list # 创建存储卷 cinder create --display-name VOLNAME SIZE（SIZE的单位为GB） Ceilmeter篇 # 查看监控资源 ceilometer meter-list #查看告警列表 ceilometer alarm-list # 删除一个告警 ceilometer alarm-delete -a ALARM_ID # 获取某一个告警信息 ceilometer alarm-state-get ALARM_ID 服务状态 systemctl list-units | grep openstack systemctl status httpd.service # 查看Apache的http服务日志 cd /etc/httpd/logs tail -f <日志文件> 参考 Openstack常用命令 Openstack官方常用命令手册 Openstack命令行操作虚拟机 Nova命令行官方参考 Openstack用户指南","tags":"Openstack","url":"pages/2020/10/23/Openstack-Command-Tutorial/","loc":"pages/2020/10/23/Openstack-Command-Tutorial/"},{"title":"zram 基本使用","text":"参考 zram 官方文档 How to enable the zRAM module for faster swapping on Linux IMPROVE VIRTUAL SERVER PERFORMANCE WITH ZRAM zram: Compressed RAM-based block devices Linux Performance: Almost Always Add Swap. Part 2: ZRAM","tags":"Linux","url":"pages/2020/10/23/Zram-Tutorial/","loc":"pages/2020/10/23/Zram-Tutorial/"},{"title":"Virsh命令和虚拟机","text":"环境搭建和准备 # 查看cpu是否支持硬件虚拟化 grep -E -c \"vmx|svm\" /proc/cpuinfo sudo apt install -y qemu qemu-kvm libvirt-daemon bridge-utils virt-manager virtinst # if centos # yum install -y kvm virt-manager libvirt libvirt-python python-virtinst virt-install qemu-kvm lsmod | grep -i kvm sudo systemctl status libvirtd.service # 如果服务未启动 sudo systemctl enable libvirtd --now # 配置网桥使得libvirt可以从外部访问 cat /etc/netplan/00-installer-config.yaml # 可选，GUI管理工具 sudo apt-get install virt-manager python-spice-client-gtk 下载调试镜像： 从 官方地址 下载cirros镜像，用来调试虚拟机，用户名和密码如下 user : cirros pass : cubswin :) # 不同版本密码不同 通常将cirros镜像放置到 /var/lib/libvirt/boot 路径下 可以查看镜像信息 qemu-img info cirros-0.5.0-x86_64-disk.img 至此，vrish学习的基本环境就搭建完成 Libvirt基本概念 virsh命令大概分组 Domain Management（域管理） Domain Monitoring（域监控） Host and Hypervisor（主机及虚拟化） Interface（网卡接口） Network Filter（网络防火墙） Networking（网络） Node Device（节点设备驱动）存在 Secret Snapshot（快照） Storage Pool（存储池或存储策略） Storage Volume（存储卷） Virsh itself（virsh shell自身相关） 定义过的或者能够被libvirt感知到的虚机的配置文件都在 /etc/libvirt 目录下 虚拟机文件和其它的相关文件都保存在 /var/lib/libvirt/ 下 镜像的默认路径是 /var/lib/libvirt/boot/ 。 上图时一个libvirt虚拟机的生命周期图，虚拟机分为两种： 持久性的 短暂性的 持久性虚拟机会一直存在，直到被删除； 短暂性的虚拟机只有在虚拟机被关机或重启前存在 虚拟机常用命令 virsh和qemu的命令非常多，下面罗列一些常用的命令 virsh help # 查看帮助信息 virsh version # 查看qemu版本 virsh help <特定命令> # 查看特定命令帮助信息 virsh <特定命令> --help # 查看特定命令帮助信息 virsh nodeinfo # 查看宿主机信息 virsh uri # 查看当前主机hyperviso的连接路径； virsh connect <hypervisor uri> # 连接到特定hypervisor,默认qemu:///system virsh sysinfo # 查看hypervisro信息 virsh start <虚拟机名称> # 启动一个之前已经定义define过的虚拟机（domain) virsh shutdown <虚拟机名称> # 关闭虚拟机,类似虚拟机内执行关机 virsh reboot <虚拟机名称> # 重启虚拟机 virsh destroy <虚拟机名称> # 强制关闭虚拟机，类似于断电 virsh suspend <虚拟机名称> # 挂起虚拟机，将当前状态保存在内存中 virsh resume <虚拟机名称> # 恢复虚拟机挂起状态，从内存中恢复虚拟机状态 virsh save <虚拟机名称> <img镜像文件名> # 暂停虚拟机，将虚拟机状态保存在磁盘镜像文件中 virsh restore <img镜像文件名> #重新载入暂停的虚拟机 virsh autostart <虚拟机名称> # 虚拟机随着物理机启动自动启动 virsh autostart <虚拟机名称> --disable # 禁止开机启动 virsh dominfo <虚拟机名称> # 查看虚拟机domain信息 virsh domblklist <虚拟机名称> # 列出虚拟机所有块存储设备 virsh console <虚拟机名称> # 控制台连接虚拟机 virsh dumpxml <虚拟机名称> # 查看虚拟机xml文件 virsh edit <虚拟机名称> # 编辑虚拟机xml文件 virsh managedsave <虚拟机名称> # 保存状态save并关闭虚拟机，下次启动会恢复到之前保存的状态 virsh start <虚拟机名称> # 启动并恢复managedsave保存的状态 virsh reset <虚拟机名称> # 对虚拟机执行强制重启，类似重置电源按钮 virsh create <虚拟机xml文件> # 从xml文件中创建domain，创建完成后会自动启动； # 一个xml对应一个domain虚拟机 virsh define <虚拟机xml文件> # 从xml文件定义define新的domain，不会自动启动 virsh undefine <虚拟机名称> # 对于运行中的持久性虚拟机，将状态转换为暂时的，关机后virsh无法感知其存在 # 对于非活动的虚拟机，undefine后virsh将无法感知其存在 # undefine后磁盘依然存在，只是删除虚拟机的配置文件/etc/libvirt/qemu virsh undefine <虚拟机名称> --remove-all-storage # 删除虚拟机并删除所有磁盘文件 virsh snapshot-create-as <虚拟机名称> --name <快照名称> # 从命令行创建快照 virsh snapshot-create <虚拟机名称> # 从xml文件创建快照 virsh snapshot-list <虚拟机名称> # 查看虚拟机快照列表 virsh snapshot-parent <虚拟机名称> --current # 查看当前快照的上一级快照 virsh snapshot-edit <虚拟机名称> --snapshotname <快照名> # 编辑快照 virsh snapshot-revert <虚拟机名称> --snapshotname <快照名> # 恢复快照 virsh snapshot-delete <虚拟机名称> --snapshotname <快照名> # 删除快照 virsh list # 查看活动虚拟机状态 virsh list --all # 查看所有虚拟机状态 virsh setvcpus <虚拟机名称> 4 --maximum --config # 设置最大vcpu数（只能用--config，下次运行生效） virsh setvcpus <虚拟机名称> 4 --config # 下次启动使用vcpu数 virsh vcpuinfo <虚拟机名称> # 查看vcpu信息 virsh vcpupin <虚拟机名称> # 查询域 vcpu亲和性,即vcpu和物理cpu之间关系 virsh maxvcpus # 显示本机vcpu最大值 virsh setmaxmem <虚拟机名称> [ --size ] 2G --current # 设置最大内存限制值 virsh setmem <虚拟机名称> [ --size ] 2G --current # 设置内存分配 virsh domblklist cirros # 查看虚拟机的存储块设备 创建磁盘文件 #qcow2是文件类型，test1-add1.qcow2是磁盘文件，5G是大小 qemu-img create -f qcow2 /var/lib/libvirt/images/test1-add1.qcow2 5G qemu-img info <虚拟机镜像> # 查看镜像信息 virt-install <命令行> # 通过命令行指定来创建虚拟机 virsh attach-disk <虚拟机名称> virsh attach-device <虚拟机名称> /etc/libvirt/qemu/test2-add.xml --persistent # 从XML文件附加设备 virsh detach-device <虚拟机名称> /etc/libvirt/qemu/test2-add.xml --persistent # 卸载设备 虚拟机操作实践 实验1：修改虚拟机vcpu 修改虚拟机的最大vcpu数量，可以修改maximum config 和current config的值 # 查看vcpu配置 ➜ ~ virsh vcpucount cirros maximum config 2 # 指定下次重启虚拟机后可用的最大vcpu数量 maximum live 2 # 指定运行/暂停状态下虚拟机可用的最大vcpu数量,重启后和maximum config一致 current config 2 # 下次重启时虚拟机使用的vcpu数量 current live 2 # 正在运行的虚拟机vcpu实际数量 通过修改xml文件修改vcpu数量 virsh edit cirros # <vcpu placement='static'>2</vcpu> # 修改为 <vcpu placement = 'static' >3</vcpu> 关闭并重新启动虚拟机 virsh shutdown cirros virsh list --all # 确认已经是shut off状态 virsh start cirros 再次查看vcpu数量，发现已经改变 ➜ ~ virsh vcpucount cirros maximum config 3 maximum live 3 current config 3 current live 3 同样方式，修改xml文件，恢复为2个vcpu，执行virsh reboot 后并没释放vcpu ➜ ~ virsh vcpucount cirros maximum config 2 maximum live 3 current config 2 current live 3 必须执行shutdown或者destory，然后重新start才能改变运行时的vcpu ➜ ~ virsh vcpucount cirros maximum config 2 maximum live 2 current config 2 current live 2 还可以通过命令行修改vcpu的各个配置值 ➜ ~ virsh setvcpus cirros 3 --maximum --config ➜ ~ virsh vcpucount cirros maximum config 3 maximum live 2 current config 2 current live 2 ➜ ~ virsh setvcpus cirros 3 --config # 修改current config ➜ ~ virsh vcpucount cirros maximum config 3 maximum live 2 current config 3 current live 2 # 重启虚拟机使其生效 ➜ ~ virsh shutdown cirros ➜ ~ virsh start cirros ➜ ~ virsh vcpucount cirros maximum config 3 maximum live 3 current config 3 current live 3 在宿主机上无法设置vcpu的current live小于current config ，只能在虚拟机内部执行 chcpu 指令来修改，使得vcpu离线 也可以将最大可用vcpu设置较大，方便后续在虚拟机运行时可以动态调整vcpu的数量 ➜ ~ virsh setvcpus cirros 5 --maximum --config ➜ ~ virsh setvcpus cirros 2 --config ➜ ~ virsh shutdown cirros ➜ ~ virsh start cirros ➜ ~ virsh vcpucount cirros maximum config 5 maximum live 5 current config 2 current live 2 ➜ ~ virsh setvcpus cirros 3 # 动态调整vcpu数量，调整范围[current config，比maximum config] ➜ ~ virsh vcpucount cirros maximum config 5 maximum live 5 current config 2 current live 3 ➜ ~ virsh setvcpus cirros 2 ➜ ~ virsh vcpucount cirros maximum config 5 maximum live 5 current config 2 current live 2 ➜ ~ virsh vcpuinfo cirros # 查看vcpu运行状态 实验2：修改虚拟机的内存 通过修改xml配置文件并重新启动虚拟机 # 修改项，修改完成后 <memory unit = 'KiB' >462144</memory> # 启动后最大允许可用内存 <currentMemory unit = 'KiB' >262144</currentMemory># 启动时使用的内存大小 在最大可用内存范围内，可以在虚拟机运行时调整内存使用 虚拟机最大内存只能在虚拟机关闭状态更改，重启后生效 使用virsh setmaxmem命令，和直接修改xml文件等效 ➜ ~ virsh dominfo cirros | grep memory # 虚拟机启动时显示的used memory不准确 Max memory: 462144 KiB Used memory: 262144 KiB ➜ ~ virsh setmem cirros 300000 ➜ ~ virsh dominfo cirros | grep memory Max memory: 462144 KiB Used memory: 300000 KiB ➜ ~ virsh shutdown cirros ➜ ~ virsh setmaxmem cirros 700000 实验3：调整虚拟机的磁盘 虚拟机支持在虚拟机开机时动态挂载新的磁盘 ➜ ~ qemu-img create -f qcow2 -o size = 20M,preallocation = metadata /var/lib/libvirt/boot/second.qcow2 Formatting '/var/lib/libvirt/boot/second.qcow2' , fmt = qcow2 size = 20971520 cluster_size = 65536 preallocation = metadata lazy_refcounts = off refcount_bits = 16 ➜ ~ qemu-img info /var/lib/libvirt/boot/second.qcow2 image: /var/lib/libvirt/boot/second.qcow2 file format: qcow2 virtual size: 20 MiB ( 20971520 bytes ) disk size: 260 KiB cluster_size: 65536 Format specific information: compat: 1 .1 lazy refcounts: false refcount bits: 16 corrupt: false virsh attach-disk cirros /images/cirros/second.qcow2 vda --targetbus virtio # 卸载磁盘（前提时没有分区或者挂载 virsh detach-disk 26 vda 也可以手动修改xml文件，然后重启虚拟机 # 首先创建一个qcow2磁盘或者raw磁盘 # dd命令创建一个非稀疏的磁盘 dd if = /dev/zero of = /vm-images/vm1-add.img bs = 1M count = 1024 # 在xml文件中加入一个新的xml段 <disk type = 'file' device = 'disk' > <driver name = 'qemu' type = 'raw' cache = 'none' io = 'threads' /> < source file = '/vm-images/vm1-add.img' /> <target dev = 'vdb' bus = 'virtio' /> <address type = 'pci' domain = '0x0000' bus = '0x00' slot = '0x06' function = '0x0' /> </disk> 实验4：创建虚拟机 virt-install --name = cirros --ram = 256 --vcpus = 1 --disk path = /var/lib/libvirt/boot/cirros-0.5.0-x86_64-disk.img,format = qcow2 --import --network network:default --vnc --vncport = 5920 # 也可以通过xml文件来创建 实验5：复制虚拟机 可以通过命令行复制一个虚拟机，也可以通过拷贝并修改配置文件和存储卷文件进行复制 # 通过virt-clone命令复制 # virt-clone -o <虚拟机名称> -n <新虚拟机名称> -f /var/lib/libvirt/images/test4.qcow2 # qcow2磁盘不需要预先创建，创建完成后需要进虚拟机手动改变ip地址和用户名 ➜ ~ virt-clone -o cirros -n cirros1 -f /var/lib/libvirt/boot/cirros1.qcow2 # 自动生产不一样的mac地址和uuid ➜ ~ diff cirros.xml cirros1.xml < <name>cirros</name> < <uuid>874fe199-47ea-45d1-a25d-98d0535dddb3</uuid> --- > <name>cirros1</name> > <uuid>fba2f776-432d-4870-a7ec-bbf73fa1b086</uuid> 39c39 < < source file = '/var/lib/libvirt/boot/cirros-0.5.0-x86_64-disk.img' /> --- > < source file = '/var/lib/libvirt/boot/cirros1.qcow2' /> 63c63 < <mac address = '52:54:00:fa:5c:d3' /> --- > <mac address = '52:54:00:29:8d:06' /> 81c81 < <graphics type = 'vnc' port = '5921' autoport = 'no' > --- > <graphics type = 'vnc' port = '-1' autoport = 'yes' > #virt-clone -f指定的文件不要事先创建，如果有多个磁盘文件就用多个-f选项 如 virt-clone -o <虚拟机名称> -n <新虚拟机名称> -f /home/lib/libvirt/images/test4.qcow2 -f /mnt/images/test4-add1.qcow2 可以手动复制xml文件和磁盘镜像来复制 ➜ qemu cp cirros.xml cirros3.xml # 修改xml文件中的domain name和mac地址等信息 ➜ qemu vim cirros3.xml ➜ qemu cd /var/lib/libvirt/boot # 在define新的克隆虚拟机之前准备好所需的磁盘 ➜ boot cp cirros-0.5.0-x86_64-disk.img cirros3.img ➜ boot qemu-img info cirros3.img image: cirros3.img file format: qcow2 virtual size: 112 MiB ( 117440512 bytes ) disk size: 198 MiB cluster_size: 65536 Snapshot list: ID TAG VM SIZE DATE VM CLOCK 1 1603292226 101 MiB 2020 -10-21 22 :57:06 94 :39:31.435 Format specific information: compat: 1 .1 lazy refcounts: false refcount bits: 16 corrupt: false ➜ ~ virsh define /etc/libvirt/qemu/cirros3.xml Domain cirros3 defined from /etc/libvirt/qemu/cirros3.xml ➜ ~ virsh list --all Id Name State -------------------------- 2 cirros running - cirros3 shut off ➜ ~ virsh start cirros3 Domain cirros3 started # 此时，一个新的克隆虚拟机就创建完成 # 需要手动修改IP和hostname 实验6：误删虚拟机恢复 # 误删除虚拟机 ➜ ~ virsh undefine cirros1 Domain cirros1 has been undefined ➜ ~ virsh dominfo cirros1 Id: 1 Name: cirros1 UUID: fba2f776-432d-4870-a7ec-bbf73fa1b086 OS Type: hvm State: running CPU ( s ) : 2 CPU time: 41 .7s Max memory: 700416 KiB Used memory: 262144 KiB Persistent: no # 已经变为非持久化的，无法重新启动 Autostart: disable Managed save: no Security model: apparmor Security DOI: 0 Security label: libvirt-fba2f776-432d-4870-a7ec-bbf73fa1b086 ( enforcing ) ➜ ~ virsh shutdown cirros1 # 关机后再也启动不了了 ➜ ~ ls /etc/libvirt/qemu # cirros1的xml文件已经不存在 ➜ ~ ls /var/lib/libvirt/boot # cirros1的qcow2镜像仍然存在 # 需要在关闭虚拟机之前，重新定义define一个配置文件即可恢复 virsh dumpxml centos-C > /etc/libvirt/qemu/centos-C.xml virsh define /etc/libvirt/qemu/centos-C.xml # 如果是在关闭着的服务器上执行的virsh undefine centos-C 删除命令，则会把对应的配置文件清空，虚拟机再也启动不了，重新定义也不行 对于 参考 在 Ubuntu 的 KVM 中安装 Windows 系统 virsh使用总结 kvm管理和基础命令 kvm命令总结和虚机器备份迁移 How to Install KVM on Ubuntu 20.04 LTS Server (Focal Fossa) Libvirt虚拟机生命周期 Modify cpu number","tags":"Openstack","url":"pages/2020/10/22/Virsh-Tutorial/","loc":"pages/2020/10/22/Virsh-Tutorial/"},{"title":"tcpdump的基本使用【译】","text":"Tcpdump是一个linux命令行的抓包工具，可以抓取TCP/IP和其他数据包，如UDP,ARP,ICMP，可以使用过滤器过滤出想要的包。 抓取特定接口上的包 当使用tcpdump不加任何参数，将分析所有接口上的数据包。 sudo tcpdump 可以使用 -i 选项指定特定接口 可以使用 -c 选项限制数据包的个数 sudo tcpdump -i wlp2s0 -c 10 抓取特定主机的数据包 可以使用 -host 选项指定和特定主机相关的数据包 sudo tcpdump -i ens160 -c 5 -ttttnnvvS host 14 .249.62.219 通过指定端口抓包 可以指定接口的端口进行抓包，也可以抓取特定接口以外的数据包 # 抓取22端口数据包 sudo tcpdump -i ens160 -c 5 -nn port 22 # 抓取22端口以外数据包 sudo tcpdump -i ens160 -nn not port 22 # 指定端口号的范围 sudo tcpdump -i ens160 -c 3 -nns 0 portrange 20 -23 抓取特定代理的数据包 sudo tcpdump -i ens160 -c 5 -nn tcp 保存抓包日志 使用 -s 选项来指定每个数据包保存的长度，默认保存68个字节，剩余字节被忽略，指定0表示完整保存。 sudo tcpdump -i ens160 -c 5 -nn tcp -w packets-record.pcap -s 0 读取tcpdump记录文件 更常用的是使用wireshark软件分析 sudo tcpdump -r packets-record.pcap 过滤特定源头的数据包 使用 src 选项指定来自特定源IP的数据包 使用 dst 选项指定特定目的IP的数据包 sudo tcpdump src 100 .9.8.40 sudo tcpdump dst 14 .249.62.219 抓取特定网段的数据包 使用 -net 选项指定incoming/outgoing特定网段的数据包 sudu tcpdump net 192 .169.0.0/24 指定数据包格式 # 16进制格式 sudo tcpdump -X -i eth0 # Ascii码格式 sudo tcpdump -A -i eth0 抓取IPV6包 sudo tcpdump -nn ip6 proto 6 过滤Http的User Agent 从http请求头中过滤出user agent和host信息 sudo tcpdump -nn -A -s1500 -l | egrep -i 'User-Agent:|Host:' 过滤cookie信息 sudo tcpdump -nn -A -s0 -l | egrep -i 'Set-Cookie|Host:|Cookie:' 列出可选的接口 sudo tcpdump -D 循环写入抓包文件 对于长时间的抓包，为了防止单个文件过大，每30分钟（1800秒）写入一个新文件，文件大小限制为100M，文件个数的24个 sudo tcpdump -i ens160 -w /tmp/network-%H-%M.pcap -W 24 -G 1800 -C 100 Tcpdump选项 -i <interface> : 监听特定接口 -n : Don't resolve hostnames. You can use -nn to don't resolve hostnames or port names. -t : Print human-readable timestamp on each dump line, -tttt : Give maximally human-readable timestamp output. -X : 以ascii和十六进制两种格式显示数据包内容 -v , -vv , -vvv : 增加获取数据包的数量 -c N : 只获取N个数据包然后停止 -s : Define the snaplength (size) of the capture in bytes. Use -s0 to get everything, unless you are intentionally capturing less. -S : 打印绝对序列号 -q : 显示较少的协议信息 -w <file name> : 将原始数据包写入文件 逻辑运算符号 Tcpdump支持更精确的过滤，使用and/or/not这种逻辑运算。 抓取来自 10.20.0.0/16 网段，并且目的地址是10.30.0.0/16 网段的数据包，使用便于阅读的时间戳， 不求解主机名和端口号，反向输出并使用绝对序号。 Capture traffic coming from 10.20.0.0/16 and going to the network 10.30.0.0/16 with showing human-readable timestamps (tt), with no resolution of hostnames or port numbers (nn), verbose output (vv) and using absolute sequence numbers (S): $ sudo -ttnnvvS tcpdump src net 10 .20.0.0/16 and dst net 10 .30.0.0/16 Display traffic from source 192.168.0.10 which is not UDP protocol: $ sudo tcpdump src 192 .168.0.10 and src net and not udp To capture arp or ping traffic for a specific host and save the output to a file named packetfile.txt: $ sudo tcpdump -nnti eth0 arp or icmp and host 192 .168.0.1 -w packetfile.txt Tcpdump 输出格式 截取一行输出，分析其输出的格式 10 : 31 : 13.440803 IP Ubuntu . ssh > 117.6 . 129.86 . 50736 : Flags [ P .], seq 188 : 400 , ack 1 , win 501 , options [ nop , nop , TS val 468736347 ecr 335665367 ], length 212 其中: 10:31:13.401128 - 本地数据包被抓取的时间 IP - 表示数据包是IPV4协议的 Ubuntu.ssh - 标识源IP地址或者主机名 ，.ssh 表示端口，这里时22端口 117.6.129.86.50376 - 表示数据包的目的IP地址 ，使用 . 分割端口号 标志位： [P.] - This is TCP flags field. [.] - ACK (Acknowledgment). [S] - SYN (Start Connection). [P] - PSH (Push Data). [F] - FIN (Finish Connection). [R] - RST (Reset Connection). [S.] - SYN-ACK (SynAcK Packet). seq 188:400 - 序列号表示该数据包包含序列是188-400字节的数据 win 501 - 窗口大小，表示接受缓冲区中可用的字节 options [nop,nop,TS val 468736347 ecr 335665367] - These are TCP options such as the MSS (Maximum Segment Size) or Window Scale. You can refer more about TCP protocol options . length 212 - 表示数据包中payload数据的字节 参考 Tcpdump基本使用","tags":"Linux","url":"pages/2020/10/19/Tcpdump-Usage/","loc":"pages/2020/10/19/Tcpdump-Usage/"},{"title":"Linux系统性能测试","text":"简介 Linux上对系统进行性能检测的工具非常多，本文介绍一些常用工具的使用 性能观测工具 ▪ 首先学习的Basic Tool有如下： uptime、top(htop)、mpstat、isstat、vmstat、free、ping、nicstat、dstat。 ▪ 高级的命令如下： sar、netstat、pidstat、strace、tcpdump、blktrace、iotop、slabtop、sysctl、/proc。 性能观测工具sar sar # install sudo apt install sysstat # usage sar -u 2 3 sar -u -f /var/log/sa/sa05 sar -P ALL 1 1 sar -r 1 3 sar -W 1 3 top 交互模式的一些快捷操作: 全局命令: <回车/空格> ?, = , A, B, d, G, h, I, k, q, r, s, W, Z 统计区的命令: l, m, t, 1 任务区的命令： 外观: b, x, y, z 内容: c, f, H, o, S, u 大小: #, i, n 排序: <, >, F, O, R 色彩方案: <Ret>, a, B, b, H, M, q, S, T, w, z, 0 - 7 窗口命令: -, _, = , +, A, a, G, g, w Press 'h' or '?' for help with Windows, Type 'q' or <Esc> to continue 如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了！！！！！ 9. netstat - 显示开放的端口和连接 它是 Linux管理员 使用来显示各种网络信息的工具，如查看什么端口开放和什么网络连接已经建立以及何种进程运行在该连接之上。同时它也显示了不同程序间打开的 Unix套接字 的信息。作为大多数Linux发行版本的一部分，netstat的许多命令在 netstat和它的不同输出 中有详细的描述。最为常用的如下： netstat | head -20 netstat -r netstat -rC netstat -i netstat -ie netstat -s netstat -g netstat -tapn vmstat 是虚拟内存( virtual memory statistics)的缩写，作为一个 内存监控 工具，它收集和显示关于 内存 ， 进程 ， 终端 和 分页 和 I/O阻塞 的概括信息。作为一个开源程序，它可以在大部分Linux发行版本中找到，包括Solaris和FreeBSD。它用来诊断大部分的内存性能问题和其他相关问题。 让我们看下如何了解vmstat提供的信息： ----------------------------- procs部分的解释 r 列表示运行和等待cpu时间片的进程数，如果长期大于1，说明cpu不足，需要增加cpu。 b 列表示在等待资源的进程数，比如正在等待I``/O``、或者内存交换等。 ----------------------------- cpu部分的解释 us 列显示了用户方式下所花费 CPU 时间的百分比。us的值比较高时，说明用户进程消耗的cpu时间多，但是如果长期大于50%，需要考虑优化用户的程序。 sy 列显示了内核进程所花费的cpu时间的百分比。这里us + sy的参考值为80%，如果us+sy 大于 80%说明可能存在CPU不足。 wa 列显示了IO等待所占用的CPU时间的百分比。这里wa的参考值为30%，如果wa超过30%，说明IO等待严重，这可能是磁盘大量随机访问造成的，也可能磁盘或者 ``磁盘访问控制器的带宽瓶颈造成的(主要是块操作)。 id` `列显示了cpu处在空闲状态的时间百分比 ----------------------------- system部分的解释 in 列表示在某一时间间隔中观测到的每秒设备中断数。 cs列表示每秒产生的上下文切换次数，如当 cs 比磁盘 I/O 和网络信息包速率高得多，都应进行进一步调查。 ----------------------------- memory部分的解释 swpd 切换到内存交换区的内存数量(k表示)。如果swpd的值不为0，或者比较大，比如超过了100m，只要si、so的值长期为0，系统性能还是正常 free 当前的空闲页面列表中内存数量(k表示) buff 作为buffer cache的内存数量，一般对块设备的读写才需要缓冲。 cache: 作为page cache的内存数量，一般作为文件系统的cache，如果cache较大，说明用到cache的文件较多，如果此时IO中bi比较小，说明文件系统效率比较好。 ----------------------------- swap部分的解释 si 由内存进入内存交换区数量。 so由内存交换区进入内存数量。 ----------------------------- IO部分的解释 bi 从块设备读入数据的总量（读磁盘）（每秒kb）。 bo 块设备写入数据的总量（写磁盘）（每秒kb） Procs procs有 r 列和 b 列。 r 列代表等待访问CPU的进程数量。而b列意味着睡眠进程的数量。在这些列的下面，是它们的值。从上面的截图中，我门有2个进程正在等待访问CPU，0个睡眠进程。 Memory memory有 swpd、 free、 buff 和 cache 这些列。这些信息和命令 free -m 相同。 swpd列 显示了有多少内存已经被交换到了交换文件或者磁盘。 free列 显示了未分配的可用内存。 buff列 显示了使用中的内存。 cache列 显示了有多少内存可以被交换到交换文件或者磁盘上如果一些应用需要他们。 Swap swap显示了从交换系统上发送或取回了多少内存。 si 列告诉我们每秒有多少内存被 从swap移到真实内存 中（In）。 so 列告诉我们每秒有多少内存被 从真实内存移到swap 中（Out）。 I/O io 依据块的读写显示了每秒输入输出的活动。 bi 列告诉我们收到的块数量， bo 列告诉我们发送的块数量。 System system显示了每秒的系统操作数量。 in 列显示了系统每秒被中断的数量。 cs 列显示了系统为了处理所以任务而上下文切换的数量。 CPU CPU告诉了我们CPU资源的使用情况。 us列 显示了处理器在非内核程序消耗的时间。 sy列 显示了处理器在内核相关任务上消耗的时间。 id列 显示了处理器的空闲时间。 wa列 显示了处理器在等待IO操作完成以继续处理任务上的时间。 ss 是 iproute2 包的一部分。iproute2是用来替代一整套标准的 Unix网络 工具组件，它曾经用来完成 网络接口配置，路由表和管理ARP表 任务。ss工具用来记录套接字统计信息，它可以显示类似netstat一样的信息，同时也能显示更多TCP和状态信息。一些例子如下： ss -tnap ss -tnap6 ss -tnap ss -s ss -tn -o state established -p lsof 命令，意为\" list open files \", 用于在许多类Unix系统中显示所有打开的文件及打开它们的进程。在大部分Linux发行版和其他类Linux操作系统中系统管理员用它来检查不同的进程打开了哪些文件。 # lsof +p process_id # lsof | less # lsof –u username # lsof /etc/passwd # lsof –i TCP:ftp # lsof –i TCP:80 缓冲区与特定的块设备关联，并覆盖文件系统元数据的缓存以及跟踪运行中的页面。缓存仅包含驻留的文件数据。也就是说，缓冲区记住目录中的内容，文件权限是什么，并跟踪从特定块设备写入或读取的内存。缓存仅包含文件本身的内容。 \"缓冲区\"表示有多少RAM专用于缓存磁盘块。\"缓存\"类似于\"缓冲区\"，只是这次它缓存文件读取中的页面。 引用答案（供参考）： 简短答案：高速缓存是页面高速缓存的大小。缓冲区是内存中块I / O缓冲区的大小。缓存的事项；缓冲区在很大程度上无关紧要。 长答案：缓存是Linux页面缓存的大小减去交换缓存中的内存，它由SwapCached表示（因此总页面缓存大小为Cached + SwapCached）。Linux通过页面缓存执行所有文件I / O。写操作的实现是简单地将页面缓存中的相应页面标记为脏。然后，刷新程序线程会定期将所有脏页写回到磁盘。通过从页面缓存返回数据来实现读取。如果数据尚未在高速缓存中，则首先填充它。在现代Linux系统上，\"缓存\"可以轻松达到数GB。它只会响应内存压力而缩小。系统将清除页面缓存以及将数据交换到磁盘上，以根据需要提供更多的内存。 缓冲区是内存中的块I / O缓冲区。他们是相对短暂的。在Linux内核版本2.4之前，Linux具有单独的页面和缓冲区高速缓存。从2.4开始，页面和缓冲区高速缓存是统一的，缓冲区是未在页面高速缓存中表示的原始磁盘块，即不是文件数据。因此，\"缓冲区\"度量标准的重要性最低。在大多数系统上，缓冲区通常只有几十兆字节。 它并不像这样简单，但是可能有助于理解： 缓冲区用于存储文件元数据（权限，位置等）。每个内存页面都在此处跟踪。 缓存用于存储实际文件内容。 iostat 解释说明： avg - cpu : 总体 cpu使用情况统计信息 ，对于多核 cpu ，这里为所有 cpu的平均值 %user : 在用户级别运行所使用的 CPU的百分比 . % `` nice `` : `` nice ``操作所使用的 CPU的百分比 . %sys : 在系统级别 ( kernel ) 运行所使用 CPU的百分比 . %iowait : CPU等待硬件I `` / O ``时 , 所占用 CPU百分比 . %idle : CPU空闲时间的百分比 . Device段 : 各磁盘设备的 IO统计信息 tps : 每秒钟发送到的 I `` / O ``请求数 . Blk_read `` / s `` : 每秒读取的 block数 . Blk_wrtn `` / s `` : 每秒写入的 block数 . Blk_read : 读入的 block总数 . Blk_wrtn : 写入的 block总数 . iostat -x -k -d 1 解释说明： rrqm `` / s `` : 每秒对该设备的读请求被合并次数，文件系统会对读取同块 ( block ) 的请求进行合并 wrqm `` / s `` : 每秒对该设备的写请求被合并次数 r `` / s `` : 每秒完成的读次数 w `` / s `` : 每秒完成的写次数 rkB `` / s `` : 每秒读数据量 ( kB为单位 ) wkB `` / s `` : 每秒写数据量 ( kB为单位 ) avgrq - sz : 平均每次 IO操作的数据量 ( 扇区数为单位 ) avgqu - sz : 平均等待处理的 IO请求队列长度 await : 平均每次 IO请求等待时间 ( 包括等待时间和处理时间，毫秒为单位 ) svctm : 平均每次 IO请求的处理时间 ( 毫秒为单位 ) %util : 采用周期内用于 IO操作的时间比率 ，即 IO队列非空的时间比率 如果 %util 接近 100 % ，说明产生的 I `` / O ``请求太多， I `` / O ``系统已经满负荷，该磁盘可能存在瓶颈。 idle小于70 % IO压力就较大了 , 一般读取速度有较多的 wait 。 同时可以结合 vmstat 查看查看 b参数 ( 等待资源的进程数 ) 和 wa参数 ( IO等待所占用的CPU时间的百分比 , 高过 30 % 时 IO压力高 ) 在Linux系统中，为了提高文件系统性能，内核利用一部分物理内存分配出缓冲区，用于缓存系统操作和数据文件，当内核收到读写的请求时，内核先去缓存区找是否有请求的数据，有就直接返回，如果没有则通过驱动程序直接操作磁盘。 缓存机制优点：减少系统调用次数，降低CPU上下文切换和磁盘访问频率。 CPU上下文切换：CPU给每个进程一定的服务时间，当时间片用完后，内核从正在运行的进程中收回处理器，同时把进程当前运行状态保存下来，然后加载下一个任务，这个过程叫做上下文切换。实质上就是被终止运行进程与待运行进程的进程切换。 Swap用途：Swap意思是交换分区，通常我们说的虚拟内存，是从硬盘中划分出的一个分区。当物理内存不够用的时候，内核就会释放缓存区（buffers/cache）里一些长时间不用的程序，然后将这些程序临时放到Swap中，也就是说如果物理内存和缓存区内存不够用的时候，才会用到Swap。 swap清理：swapoff -a && swapon -a 注意：这样清理有个前提条件，空闲的内存必须比已经使用的swap空间大 1. 查看内存使用情况 ， 发现swap虚拟内存空间竟然为0 # free - m 2. 建虚拟内存磁盘卷 。 做法如下 ： # dd if =/ dev / zero of =/ opt / swap bs = 1024 count = 2048000 # mkswap / opt / swap # swapon / opt / swap 再次查看内容 ， 发现swap虚拟内存就有了 # free - m 3. 如果想取消文件虚拟内存 ， 即删除swap ， 做法如下 ：（ 当然根据系统配置 ， 也可以保留swap ， 以后继续用 ）。 # swapoff / opt / swap # rm / opt / swap 4. swap开机挂载 # vim / etc / fstab / opt / swap swap swap defaults 0 0 上面挂载参数分别为 ： 设备文件或伪文件系统 挂载点 文件系统类型 挂载选项 备份频率 开机自检次序 6. 移动虚拟内存空间 如果当前的虚存所在的磁盘空间不够 ， 可以首先关闭虚存服务 ， 将其移动到别的磁盘 ， 再启用即可 。 # swapoff - v / swap / swapadd # mv / swap / swapadd / mnt / swap # swapon / swap / swapadd 释放缓存区内存的方法 1 ） 清理pagecache （ 页面缓存 ） [ root@backup ~ ] # echo 1 > / proc / sys / vm / drop_caches 或者 # sysctl - w vm . drop_caches = 1 2 ） 清理dentries （ 目录缓存 ） 和inodes [ root@backup ~ ] # echo 2 > / proc / sys / vm / drop_caches 或者 # sysctl - w vm . drop_caches = 2 3 ） 清理pagecache 、 dentries和inodes [ root@backup ~ ] # echo 3 > / proc / sys / vm / drop_caches 或者 # sysctl - w vm . drop_caches = 3 上面三种方式都是临时释放缓存的方法 ， 要想永久释放缓存 ， 需要在 / etc / sysctl . conf文件中配置 ： vm . drop_caches = 1 / 2 / 3 ， 然后sysctl - p生效即可 ！ 另外 ， 可以使用sync命令来清理文件系统缓存 ， 还会清理僵尸 ( zombie ) 对象和它们占用的内存 [ root@backup ~ ] # sync 温馨提示 ： 上面操作在大多数情况下都不会对系统造成伤害 ， 只会有助于释放不用的内存 。 但是如果在执行这些操作时正在写数据 ， 那么实际上在数据到达磁盘之前就将它从文件缓存中清除掉了 ， 这可能会造成很不好的影响 。 那么如果避免这种事情发生呢 ？ 因此 ， 这里不得不提一下 / proc / sys / vm / vfs_cache_pressure这个文件 ， 告诉内核 ， 当清理inoe / dentry缓存时应该用什么样的优先级 。 [ root@backup ~ ] # cat / proc / sys / vm / vfs_cache_pressure 100 vfs_cache_pressure = 100 这个是默认值 ， 内核会尝试重新声明dentries和inodes ， 并采用一种相对于页面缓存和交换缓存比较 \"合理\" 的比例 。 减少vfs_cache_pressure的值 ， 会导致内核倾向于保留dentry和inode缓存 。 增加vfs_cache_pressure的值 ，（ 即超过100时 ）， 则会导致内核倾向于重新声明dentries和inodes 总之 ， vfs_cache_pressure的值 ： 小于100的值不会导致缓存的大量减少 超过100的值则会告诉内核你希望以高优先级来清理缓存 。 其实无论vfs_cache_pressure的值采用什么值 ， 内核清理缓存的速度都是比较低的 。 如果将此值设置为10000 ， 系统将会将缓存减少到一个合理的水平 。 测试硬盘写入速度 [ root@redhat73 ~ ] # dd if =/ dev / zero of =/ home / linshi . a bs = 1024000000 count = 2 2 + 0 records in 2 + 0 records out 2048000000 bytes ( 2.0 GB ) copied , 4.67577 s , 438 MB / s 写入一个2GB的文件 ， 用时4 .67577 秒 ， 平均438 MB / s [ root@localhost home ] # free - h total used free shared buff / cache available Mem : 974 M 56 M 818 M 580 K 99 M 787 M Swap : 2.0 G 37 M 2.0 G # 参数解释 - m 以MB为单位输出 - g 以GB为单位输出 - h 以人类可读的单位输出 ， 自动转换KB 、 MB或者GB为单位 - s N 每N秒打印一次 - c N 打印N次后退出 # 输出说明 （ Mem代表物理内存 、 Swap代表虚拟内存 ） total 表示系统的总内存 used 表示应用程序已经使用的内存 free 表示当前还没有被使用的内存 shared 表示共享链接库使用的内存 buff / cache 表示系统的page cache和buffer使用到的内存 available 表示应用程序还可以申请到的内存 怎么判断是否需要加内存 ： 1. swap使用有多少 2. available剩余是多少 ， 而不是看free cache是Linux系统为了提高系统运行效率而将一些程序或文件写入到cache ， 可提高程序运行和加载速度 ， 如果程序需要会马上释放 。 所以判断系统内存是否足够和是否需要增加的时候不能简单的看free Cache Pages : A cache is the part of the memory which transparently stores data so that future requests for that data can be served faster . This memory is utilized by the kernel to cache disk data and improve i / o performance . 系统当前使用到的内存是 ： used + buff / cache ， used中包含了shared 。 所以total = used + buff / cache + free = 56 + 99 + 818 = 973 available （ 787 ） <= free + buff / cache （ 818 + 99 = 917 ）， 为什么是小于呢 ？ 因为系统的一些page或cache是不能回收的 。 查看 CPU信息 # 总核数 = 物理 CPU个数 X 每颗物理 CPU的核数 # 总逻辑 CPU数 = 物理 CPU个数 X 每颗物理 CPU的核数 X 超线程数 # 查看物理 CPU个数 cat / proc / cpuinfo | grep \"physical id\" | sort | uniq | wc - l # 查看每个物理 CPU中core的个数 ( 即核数 ) cat / proc / cpuinfo | grep \"cpu cores\" | uniq # 查看逻辑 CPU的个数 cat / proc / cpuinfo | grep \"processor\" | wc - l # 查看 CPU信息 （型号） cat / proc / cpuinfo | grep name | cut - f2 - d : | uniq - c 性能测评工具 性能调优工具 参考 用十条命令在一分钟内检查Linux服务器性能 你值得拥有 —— 25 个 Linux 性能监控工具 Top命令详解 gglsof命令入门 Linux缓存机制 30个实例详解TOP命令 lsof命令行神器入门 超全整理！Linux性能分析工具汇总合集","tags":"Linux","url":"pages/2020/10/17/Linux-Peformence-Test/","loc":"pages/2020/10/17/Linux-Peformence-Test/"},{"title":"GDB调试Python代码","text":"Core Dump文件 凡事皆有两面性，OS在出Core的同时，虽然会终止掉当前进程，但是也会保留下第一手的现场数据，OS仿佛是一架被按下快门的相机，而照片就是产出的Core文件。里面含有当进程被终止时内存、CPU寄存器等信息，可以供后续开发人员进行调试。 Gdb可以附着在特定进程上调试，但是为了不影响运行中的进程，可以通过生成 core file 的方式来保存进程的当前信息。 实验环境配置 环境是Ubuntu20.04 # 新开一个Shell的时候，ulimit选项都恢复了默认选项，需要重新设置该值 # 查看shell进程资源 ulimit -a # 查看core文件大小限制 ulimit -c # 修改core文件大小限制 ulimit -c unlimited # 查看修改是否生效 ulimit -c # 设置core_pattern # core_pattern文件中定义了当产生core dump后对core文件进行什么操作 cat /proc/sys/kernel/core_pattern # 需要修改core_pattern文件使得core文件保存在磁盘上 # 方法1 # 暂停apport服务 sudo service apport stop cat /proc/sys/kernel/core_pattern # 生成core文件后恢复apport服务 sudo service apport start # 方法2 mkdir /var/cores echo \"/var/cores/core.%e.%p\" > /proc/sys/kernel/core_pattern # 方法3 vim /etc/sysctl.conf # 在最后一行添加kernel.core_uses_pid = 1 sysctl -p # 阅读core文件头 readelf -h core 安装Python-dbg sudo apt install gdb python3-dbg GDB调试Python代码 实验1：直接调试core dump文件 将如下代码保存为explode.py import os def my_exploding_func (): my_local_var = 'hi' number = 4 number2 = 5 number4 = number + 3 os . abort () my_exploding_func () 执行代码，产生core dump文件 python explode.py 同样的Python版本执行gdb调试 # 读取core文件 gdb ` which python ` core 可以使用一些常见的命令调试 #0 __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:50 50 ../sysdeps/unix/sysv/linux/raise.c: 没有那个文件或目录. ( gdb ) py-list 3 def my_exploding_func () : 4 my_local_var = 'hi' 5 number = 4 6 number2 = 5 7 number4 = number+3 >8 os.abort () 9 10 my_exploding_func () ( gdb ) py-bt Traceback ( most recent call first ) : <built-in method abort of module object at remote 0x7f08dfc7d360> File \"explode.py\" , line 8 , in my_exploding_func os.abort () File \"explode.py\" , line 10 , in <module> my_exploding_func () 实验2:主动生成core dump文件 如下代码保存为test.py import time def do ( x ): time . sleep ( 10 ) def main (): for x in range ( 10000 ): do ( x ) if __name__ == '__main__' : main () 运行该代码后找到PID ps -ef | grep \"python test.py\" 主动生成core dump文件,不影响进程继续运行 gdb python PID generate-core-file 所有gdb命令都支持使用，同时还有安装python-dbg支持的命令 在gdb调试命令行中输入 # py + TAB键位弹出常用命令 py-bt py-list py-up py-bt-full py-locals python py-down py-print python-interactive # help + 命令显示帮助信息 help py-bt 参考 gdb Debugging Full Example Linux上Core Dump文件的形成和分析 Linux上coredump实验 GDB调试Python命令 Debuggin with gdb","tags":"Python","url":"pages/2020/10/16/Angular-Tutorial/","loc":"pages/2020/10/16/Angular-Tutorial/"},{"title":"Python进阶下","text":"有两种常用的方法可以使得代码并行执行，多线程和多进程 。因为Cython解释器的实现不是线程安全的，具有GIL锁，同一时刻，只有一个线程可以获得解释器的锁。因此，Python利用多核心的CPU只能通过多进程，而多线程只适用于IO密集型的程序。 多进程基础 创建并开启进程 可以使用 multiprocessing.Process() 来创建进程，它接受两个参数： target，一个可调用的函数，当进程开始时会执行 args，一个元组，提供目标函数的参数 使用 process.start() 来开始执行一个进程 调用 process.join() 来告诉程序等待进程结束再执行后续代码，主进程将会被阻塞 from multiprocessing import Process import os def square_numbers (): for i in range ( 1000 ): result = i * i if __name__ == \"__main__\" : processes = [] num_processes = os . cpu_count () # number of CPUs on the machine. Usually a good choise for the number of processes # create processes and asign a function for each process for i in range ( num_processes ): process = Process ( target = square_numbers ) processes . append ( process ) # start all processes for process in processes : process . start () # wait for all processes to finish # block the main programm until these processes are finished for process in processes : process . join () 进程间分享数据 因为进程的内存空间不同，需要特殊的共享内存对象来分享数据。 数据可以保存在共享内存变量中，使用 Value 或者 Array Value(type, value)创建一个 ctype 对象 Array(type, value)创建一个 ctype 类型的列表 如下程序演示年race condition资源竟态，每次执行结果都不一样，例如当两个进程读取同一个值，并对其执行+1操作，然后写会原有地址，其结果并不是预想的加2。 from multiprocessing import Process , Value , Array import time def add_100 ( number ): for _ in range ( 100 ): time . sleep ( 0.001 ) number . value += 1 def add_100_array ( numbers ): for _ in range ( 100 ): time . sleep ( 0.01 ) for i in range ( len ( numbers )): numbers [ i ] += 1 if __name__ == \"__main__\" : shared_number = Value ( 'i' , 0 ) print ( 'Value at beginning:' , shared_number . value ) shared_array = Array ( 'd' , [ 0.0 , 100.0 , 200.0 ]) print ( 'Array at beginning:' , shared_array [:]) process1 = Process ( target = add_100 , args = ( shared_number ,)) process2 = Process ( target = add_100 , args = ( shared_number ,)) process3 = Process ( target = add_100_array , args = ( shared_array ,)) process4 = Process ( target = add_100_array , args = ( shared_array ,)) process1 . start () process2 . start () process3 . start () process4 . start () process1 . join () process2 . join () process3 . join () process4 . join () print ( 'Value at end:' , shared_number . value ) print ( 'Array at end:' , shared_array [:]) print ( 'end main' ) \"\"\" Value at beginning: 0 Array at beginning: [0.0, 100.0, 200.0] Value at end: 144 Array at end: [134.0, 237.0, 339.0] end main \"\"\" 可以使用锁避免资源竟态 锁（也称为互斥锁）是一种同步机制，用于在存在许多执行进程/线程的环境中强制限制对资源的访问。锁具有两种状态：锁定和解锁。 如果状态为锁定，则在再次解除锁定状态之前，不允许其他并发进程/线程进入此代码段。 # import Lock from multiprocessing import Lock from multiprocessing import Process , Value , Array import time def add_100 ( number , lock ): for _ in range ( 100 ): time . sleep ( 0.001 ) # lock the state lock . acquire () number . value += 1 # unlock the state lock . release () def add_100_array ( numbers , lock ): for _ in range ( 100 ): time . sleep ( 0.01 ) for i in range ( len ( numbers )): lock . acquire () numbers [ i ] += 1 lock . release () if __name__ == \"__main__\" : # create a lock lock1 = Lock () lock2 = Lock () shared_number = Value ( 'i' , 0 ) print ( 'Value at beginning:' , shared_number . value ) shared_array = Array ( 'd' , [ 0.0 , 100.0 , 200.0 ]) print ( 'Array at beginning:' , shared_array [:]) # pass the lock to the target function process1 = Process ( target = add_100 , args = ( shared_number , lock1 )) process2 = Process ( target = add_100 , args = ( shared_number , lock1 )) process3 = Process ( target = add_100_array , args = ( shared_array , lock2 )) process4 = Process ( target = add_100_array , args = ( shared_array , lock2 )) process1 . start () process2 . start () process3 . start () process4 . start () process1 . join () process2 . join () process3 . join () process4 . join () print ( 'Value at end:' , shared_number . value ) print ( 'Array at end:' , shared_array [:]) print ( 'end main' ) \"\"\" Value at beginning: 0 Array at beginning: [0.0, 100.0, 200.0] Value at end: 200 Array at end: [200.0, 300.0, 400.0] end main \"\"\" 在上下文管理器中使用锁 使用上下文管理器管理锁的获取和释放更加安全 def add_100 ( number , lock ): for _ in range ( 100 ): time . sleep ( 0.01 ) with lock : number . value += 1 多进程使用队列通信 使用队列的操作是进程安全的。多进程队列实现了队列的所有方法。done()和join()除外。 q.get() :移除队首第一个元素，默认情况，会阻塞直到有元素可用 q.put(item) 将元素压到队尾，默认情况，阻塞直到队列有空的槽 q.empty() 如果队列为空，返回True q.close() 表明当前进程不会有新的数据放到队列中了 # communicate between processes with the multiprocessing Queue # Queues are thread and process safe from multiprocessing import Process , Queue import time def square ( numbers , queue ): for i in numbers : time . sleep ( 0.01 ) queue . put ( i * i ) def make_negative ( numbers , queue ): for i in numbers : time . sleep ( 0.01 ) queue . put ( i *- 1 ) if __name__ == \"__main__\" : numbers = range ( 1 , 6 ) q = Queue () p1 = Process ( target = square , args = ( numbers , q )) p2 = Process ( target = make_negative , args = ( numbers , q )) p1 . start () p2 . start () p1 . join () p2 . join () # order might not be sequential while not q . empty (): print ( q . get ()) print ( 'end main' ) \"\"\" 1 -1 4 -2 9 -3 16 -4 25 -5 end main \"\"\" 进程池 进程池对象控制一些工作进程worker，可以支持超时和回调以实现异步处理，也有一些并行的map实现。它可以自动管理多个处理器，并将数据分成小块，在多个处理器上并行处理。 重要的函数包括： map(func, iterable[, chunksize]) 将可迭代对象切分成小块，作为独立任务提交到进程池，并行处理。函数将会阻塞，直到返回结果。 close() 阻止更多任务添加到进程池，一旦任务完成，worker进程将退出 join() 等待工作进程退出，在调用 join() 之前需要调用 close() 或者 terminate() apply(func, args) 调用 func 函数，参数是 args 。阻塞直到返回结果， func 函数只在进程池中一个worker中执行 有 map_async() 和 apply_async() 这种非阻塞的异步函数 from multiprocessing import Pool import random import time def cube ( number ): print ( \"Hi\" ) time . sleep ( random . randint ( 1 , 2 )) return number * number * number if __name__ == \"__main__\" : numbers = range ( 10 ) p = Pool () # by default this allocates the maximum number of available # processors for this task --> os.cpu_count() result = p . map ( cube , numbers ) # or # result = [p.apply(cube, args=(i,)) for i in numbers] p . close () p . join () print ( result ) 多线程基础 Python多线程相对比较鸡肋，其使用和多进程类似 创建并开始线程 使用threading库实现 from threading import Thread def square_numbers (): for i in range ( 1000 ): result = i * i if __name__ == \"__main__\" : threads = [] num_threads = 10 # create threads and asign a function for each thread for i in range ( num_threads ): thread = Thread ( target = square_numbers ) threads . append ( thread ) # start all threads for thread in threads : thread . start () # wait for all threads to finish # block the main thread until these threads are finished for thread in threads : thread . join () 线程间共享数据 线程间可以通过全局变量来共享数据，因为线程间是共享内存空间的 from threading import Thread import time # all threads can access this global variable database_value = 0 def increase (): global database_value # needed to modify the global value # get a local copy (simulate data retrieving) local_copy = database_value # simulate some modifying operation local_copy += 1 time . sleep ( 0.1 ) # write the calculated new value into the global variable database_value = local_copy if __name__ == \"__main__\" : print ( 'Start value: ' , database_value ) t1 = Thread ( target = increase ) t2 = Thread ( target = increase ) t1 . start () t2 . start () t1 . join () t2 . join () print ( 'End value:' , database_value ) print ( 'end main' ) \"\"\" Start value: 0 End value: 1 end main \"\"\" 使用锁处理资源竟态 # import Lock from threading import Thread , Lock import time database_value = 0 def increase ( lock ): global database_value # lock the state lock . acquire () local_copy = database_value local_copy += 1 time . sleep ( 0.1 ) database_value = local_copy # unlock the state lock . release () if __name__ == \"__main__\" : # create a lock lock = Lock () print ( 'Start value: ' , database_value ) # pass the lock to the target function t1 = Thread ( target = increase , args = ( lock ,)) # notice the comma after lock since args must be a tuple t2 = Thread ( target = increase , args = ( lock ,)) t1 . start () t2 . start () t1 . join () t2 . join () print ( 'End value:' , database_value ) print ( 'end main' ) 使用上下文管理器 def increase ( lock ): global database_value with lock : local_copy = database_value local_copy += 1 time . sleep ( 0.1 ) database_value = local_copy 多线程消息队列通信 对队列的操作是线程安全的 from threading import Thread , Lock , current_thread from queue import Queue def worker ( q , lock ): while True : value = q . get () # blocks until the item is available # do stuff... with lock : # prevent printing at the same time with this lock print ( f \"in { current_thread () . name } got { value } \" ) # ... # For each get(), a subsequent call to task_done() tells the queue # that the processing on this item is complete. # If all tasks are done, q.join() can unblock q . task_done () if __name__ == '__main__' : q = Queue () num_threads = 10 lock = Lock () for i in range ( num_threads ): t = Thread ( name = f \"Thread { i + 1 } \" , target = worker , args = ( q , lock )) t . daemon = True # dies when the main thread dies t . start () # fill the queue with items for x in range ( 20 ): q . put ( x ) q . join () # Blocks until all items in the queue have been gotten and processed. print ( 'main done' ) \"\"\" in Thread1 got 0 in Thread2 got 1 in Thread2 got 11 in Thread2 got 12 in Thread2 got 13 in Thread2 got 14 in Thread2 got 15 in Thread2 got 16 in Thread2 got 17 in Thread2 got 18 in Thread2 got 19 in Thread8 got 5 in Thread4 got 9 in Thread1 got 10 in Thread5 got 2 in Thread6 got 3 in Thread9 got 6 in Thread7 got 4 in Thread10 got 7 in Thread3 got 8 main done \"\"\" 参考 Python多线程和多进程","tags":"Python","url":"pages/2020/10/13/Python-Advanced-3/","loc":"pages/2020/10/13/Python-Advanced-3/"},{"title":"Python进阶中","text":"生成器Generator def countdown ( num ): print ( 'Starting' ) while num > 0 : yield num num -= 1 # this will not print 'Starting' cd = countdown ( 3 ) # this will print 'Starting' and the first value print ( next ( cd )) # will print the next values print ( next ( cd )) print ( next ( cd )) # this will raise a StopIteration print ( next ( cd )) 迭代器使用方式 # you can iterate over a generator object with a for in loop cd = countdown ( 3 ) for x in cd : print ( x ) # you can use it for functions that take iterables as input cd = countdown ( 3 ) sum_cd = sum ( cd ) print ( sum_cd ) cd = countdown ( 3 ) sorted_cd = sorted ( cd ) print ( sorted_cd ) 生成器表达式 # generator expression mygenerator = ( i for i in range ( 1000 ) if i % 2 == 0 ) print ( sys . getsizeof ( mygenerator ), \"bytes\" ) # list comprehension mylist = [ i for i in range ( 1000 ) if i % 2 == 0 ] print ( sys . getsizeof ( mylist ), \"bytes\" ) # 120bytes # 4272 bytes 生成器概念 类可以实现生成器作为一个可迭代对象，它需要实现 __iter__ 方法和 __next__ 方法，使得类对象可迭代。此外，还需要注意记录迭代次数，以及最后raise一个StopIteration异常。 class firstn : def __init__ ( self , n ): self . n = n self . num = 0 def __iter__ ( self ): return self def __next__ ( self ): if self . num < self . n : cur = self . num self . num += 1 return cur else : raise StopIteration () firstn_object = firstn ( 1000000 ) print ( sum ( firstn_object )) 装饰器Decorators 装饰器的典型使用场景有： 计算函数执行时间 用于调试，打印出函数的参数和调用信息 作为函数的参数校验 以插件的形式注册函数 降低代码执行速度来测试网络，如使用sleep函数 缓存代码执行结果Memoization 附加信息或者更新状态 装饰器就是一个语法糖，如下装饰器就类似 target = somedecorator(target) 装饰器一个特性就是将被装饰函数替换为其他函数 @somedecorator def target (): print ( \"running target\" ) 简单装饰器模板 import functools def my_decorator ( func ): @functools . wraps ( func ) # 保持被装饰函数的属性 def wrapper ( * args , ** kwargs ): # Do something before result = func ( * args , ** kwargs ) # Do something after return result return wrapper 带参数的装饰器函数，可以认为是两层函数，在简单装饰器外部套一个函数来扩展装饰器的行为。 即两层闭包，一个持有外部环境变量的函数就是闭包。 def repeat ( num_times ): def decorator_repeat ( func ): @functools . wraps ( func ) def wrapper ( * args , ** kwargs ): for _ in range ( num_times ): result = func ( * args , ** kwargs ) return result return wrapper return decorator_repeat @repeat ( num_times = 3 ) def greet ( name ): print ( f \"Hello { name } \" ) greet ( 'Alex' ) # 输出 \"\"\" Hello Alex Hello Alex Hello Alex \"\"\" 层叠装饰器 装饰器的执行顺序是decorator(func)，从外到内执行，如果有多个装饰器堆叠在一起，按照decorator2(docorator1(func))的执行顺序。 其更清晰的执行顺序是： func = decorator1(func) func = decorator2(func) func() 多个装饰器装饰函数时，有个规律是从下到上包裹（装饰）函数，在装饰的过程中执行装饰器函数和内部闭包wrapper函数之间代码，闭包函数知识作为一个对象被返回，在装饰过程中并不执行。 而在执行被装饰函数的过程中，从上到下执行wrapper函数内部的代码。 如下代码多个装饰器，其装饰的顺序和wrapper执行的顺序相反。 # 装饰过程 say_hello = start_end_decorator_2 ( start_end_decorator_1 ( say_hello )) say_hello () 多装饰器实验 import functools # a decorator function that prints debug information about the wrapped function def start_end_decorator_2 ( func ): print ( 'Start decorator2' ) @functools . wraps ( func ) def wrapper2 ( * args , ** kwargs ): print ( 'Exec wrapper 2' ) result = func ( * args , ** kwargs ) print ( 'End wrapper 2' ) return result return wrapper2 def start_end_decorator_1 ( func ): print ( 'Start decorator1' ) @functools . wraps ( func ) def wrapper1 ( * args , ** kwargs ): print ( 'Exec wrapper 1' ) result = func ( * args , ** kwargs ) print ( 'End wrapper 1' ) return result return wrapper1 @start_end_decorator_2 @start_end_decorator_1 def say_hello ( name ): greeting = f 'Hello { name } ' print ( greeting ) return greeting \"\"\" 相当于 func = start_end_decorator_1(func) 此时func是下面这个wrapper1函数 def wrapper1(*args, **kwargs): print('Exec wrapper 1') result = func(*args, **kwargs) print('End wrapper 1') return result 再经过下一个装饰器start_end_decorator_2 func再次被替换 func = start_end_decorator_2(start_end_decorator_1(func)) \"\"\" say_hello ( name = 'Alex' ) # exec result \"\"\" Start decorator1 Start decorator2 Exec wrapper 2 Exec wrapper 1 Hello Alex End wrapper 1 End wrapper 2 \"\"\" 装饰器执行时间 装饰器需要区分导入时和运行时， 装饰器一个特性就是装饰的过程在import时执行，当import代码时，装饰器立刻执行，将被装饰函数变为另一个函数。 registry = [] def register ( func ): print ( \"running register( %s )\" % func ) registry . append ( func ) return func @register def f1 (): print ( \"running f1\" ) @register def f2 (): print ( \"running f2\" ) def f3 (): print ( \"running f3\" ) def main (): print ( \"running main\" ) print ( \"registry ->\" , registry ) f1 () f2 () f3 () if __name__ == \"__main__\" : main () # import该模块的输出如下 \"\"\" running register(<function f1 at 0x7f4105056af0>) running register(<function f2 at 0x7f4105056c10>) \"\"\" # 执行main函数的输出如下 # 在运行时，被装饰函数才开始执行 \"\"\" running register(<function f1 at 0x7f65b62d70d0>) running register(<function f2 at 0x7f65b62d7160>) running main registry -> [<function f1 at 0x7f65b62d70d0>, <function f2 at 0x7f65b62d7160>] running f1 running f2 running f3 \"\"\" 类装饰器 可以使用类作为装饰器，因此，需要首先实现魔法方法 __call__ ，使得对象是callable可调用的，类装饰器典型用处是保存状态，如函数被调用次数。我们使用 functools.update_wrapper() 而不是 functools.wraps 来持久化被装饰器函数信息。 import functools class CountCalls : # the init needs to have the func as argument and stores it def __init__ ( self , func ): functools . update_wrapper ( self , func ) self . func = func self . num_calls = 0 # extend functionality, execute function, and return the result def __call__ ( self , * args , ** kwargs ): self . num_calls += 1 print ( f \"Call { self . num_calls } of { self . func . __name__ !r} \" ) return self . func ( * args , ** kwargs ) @CountCalls def say_hello ( num ): print ( \"Hello!\" ) say_hello ( 5 ) say_hello ( 5 ) # result \"\"\" Call 1 of 'say_hello' Hello! Call 2 of 'say_hello' Hello! \"\"\" Context Managers 上下文管理器用于资源管理，允许你方便的分配和释放资源 Python内置的关键字with用于处理上下文管理器，上下文管理器典型的用途有： 打开和关闭文件 打开和关闭数据库连接 获得和释放锁 from threading import Lock lock = Lock () # error-prone: lock . acquire () # do stuff # lock should always be released! lock . release () # Better: with lock : # do stuff 实现一个上下文管理器类 为了支持with关键字，需要在类中实现 __enter__ 和 __exit__ 方法，当Python执行到with语句，会执行 __enter__ 方法，此时应该获取资源并返回，而当离开上下文环境时，将执行 __exit__ 方法，此时应该释放资源。 class ManagedFile : def __init__ ( self , filename ): print ( 'init' , filename ) self . filename = filename def __enter__ ( self ): print ( 'enter' ) self . file = open ( self . filename , 'w' ) return self . file def __exit__ ( self , exc_type , exc_value , exc_traceback ): if self . file : self . file . close () print ( 'exit' ) with ManagedFile ( 'notes.txt' ) as f : print ( 'doing stuff...' ) f . write ( 'some todo...' ) 处理异常 当异常产生时，Python将异常类型、值和traceback信息传递给 __exit__ 方法，它可以处理该异常。如果 __exit__ 方法返回了除True之外的任何值，则由with语句引发异常。 class ManagedFile : def __init__ ( self , filename ): print ( 'init' , filename ) self . filename = filename def __enter__ ( self ): print ( 'enter' ) self . file = open ( self . filename , 'w' ) return self . file def __exit__ ( self , exc_type , exc_value , exc_traceback ): if self . file : self . file . close () print ( 'exc:' , exc_type , exc_value ) print ( 'exit' ) # No exception with ManagedFile ( 'notes.txt' ) as f : print ( 'doing stuff...' ) f . write ( 'some todo...' ) print ( 'continuing...' ) print () # Exception is raised, but the file can still be closed with ManagedFile ( 'notes2.txt' ) as f : print ( 'doing stuff...' ) f . write ( 'some todo...' ) f . do_something () print ( 'continuing...' ) 也可以在 __exit__ 方法中处理异常，并返回 True class ManagedFile : def __init__ ( self , filename ): print ( 'init' , filename ) self . filename = filename def __enter__ ( self ): print ( 'enter' ) self . file = open ( self . filename , 'w' ) return self . file def __exit__ ( self , exc_type , exc_value , exc_traceback ): if self . file : self . file . close () if exc_type is not None : print ( 'Exception has been handled' ) print ( 'exit' ) return True with ManagedFile ( 'notes2.txt' ) as f : print ( 'doing stuff...' ) f . write ( 'some todo...' ) f . do_something () print ( 'continuing...' ) 用生成器实现一个上下文管理器 与其写一个类，也可以写一个生成器函数，并用 contextlib.contextmanager 来装饰它。 为了实现这个目的，函数必须在 try 语句段中 yield 资源，而在 finally 语句中实现类似 __exit__ 的功能，即释放资源。 from contextlib import contextmanager @contextmanager def open_managed_file ( filename ): f = open ( filename , 'w' ) try : yield f finally : f . close () with open_managed_file ( 'notes.txt' ) as f : f . write ( 'some todo...' ) 生成器首先获取资源，然后暂时挂起执行流程，并 yeild 返回资源，资源可以被调用者使用，当调用着离开with上下文，生成器接着执行后续的 finally 语句，释放资源。 Python中的解引用 Python中的 * 号具有多种作用： Use *args for variable-length arguments Use **kwargs for variable-length keyword arguments Use *, followed by more function parameters to enforce keyword-only arguments def my_function ( * args , ** kwargs ): for arg in args : print ( arg ) for key in kwargs : print ( key , kwargs [ key ]) my_function ( \"Hey\" , 3 , [ 0 , 1 , 2 ], name = \"Alex\" , age = 8 ) # Parameters after '*' or '*identifier' are keyword-only parameters and may only be passed using keyword arguments. def my_function2 ( name , * , age ): print ( name ) print ( age ) # my_function2(\"Michael\", 5) --> this would raise a TypeError my_function2 ( \"Michael\" , age = 5 ) Python函数传参以及深拷贝浅拷贝 在Python中，赋值语句 obj_b = obj_a 不产生真正的对象拷贝，只创建一个新的变量和obj_a具有相同的引用，因此当你想要产生可变对象的真正的拷贝，并在不影响原来对象的情况下修改拷贝对象时，需要格外小心。 可以使用copy模块产生真正的拷贝，然而，对于混合/嵌套对象，浅拷贝和深拷贝有重要的区别， 浅拷贝 只有一层深，对于比一层深的嵌套对象是源对象的引用，因此修改会导致源对象的更改 深拷贝 一份完全独立的拷贝，递归产生源对象中所有嵌套对象的拷贝 赋值操作 会产生源对象的一个引用，修改会导致源对象的变更 list_a = [ 1 , 2 , 3 , 4 , 5 ] list_b = list_a list_a [ 0 ] = - 10 print ( list_a ) print ( list_b ) \"\"\" [-10, 2, 3, 4, 5] [-10, 2, 3, 4, 5] \"\"\" 浅拷贝 浅拷贝只有一层深度，修改第一层不会影响源对象，使用 copy.copy() 方法或者对象特定的拷贝方法或者拷贝构造函数 import copy list_a = [ 1 , 2 , 3 , 4 , 5 ] list_b = copy . copy ( list_a ) # not affects the other list list_b [ 0 ] = - 10 print ( list_a ) print ( list_b ) 但是在嵌套对象中，修改第二层或者更深层次的数据时，会影响到源对象，因为在第二层时拷贝的是引用，而不是值。 import copy list_a = [[ 1 , 2 , 3 , 4 , 5 ], [ 6 , 7 , 8 , 9 , 10 ]] list_b = copy . copy ( list_a ) # affects the other! list_a [ 0 ][ 0 ] = - 10 print ( list_a ) print ( list_b ) \"\"\" [[-10, 2, 3, 4, 5], [6, 7, 8, 9, 10]] [[-10, 2, 3, 4, 5], [6, 7, 8, 9, 10]] \"\"\" 对于列表，类似的浅拷贝方法还有 # shallow copies list_b = list ( list_a ) list_b = list_a [:] list_b = list_a . copy () 深拷贝 深拷贝是一份完全独立的克隆，使用 copy.deepcopy 方法实现 import copy list_a = [[ 1 , 2 , 3 , 4 , 5 ], [ 6 , 7 , 8 , 9 , 10 ]] list_b = copy . deepcopy ( list_a ) # not affects the other list_a [ 0 ][ 0 ] = - 10 print ( list_a ) print ( list_b ) \"\"\" [[-10, 2, 3, 4, 5], [6, 7, 8, 9, 10]] [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]] \"\"\" 对象的深拷贝和浅拷贝 可以使用 copy 模块实现对特定对象的深拷贝或者浅拷贝 赋值只拷贝对象引用 class Person : def __init__ ( self , name , age ): self . name = name self . age = age # Only copies the reference p1 = Person ( 'Alex' , 27 ) p2 = p1 p2 . age = 28 print ( p1 . age ) print ( p2 . age ) \"\"\" 28 28 \"\"\" 浅拷贝拷贝一层 # shallow copy import copy p1 = Person ( 'Alex' , 27 ) p2 = copy . copy ( p1 ) p2 . age = 28 print ( p1 . age ) print ( p2 . age ) \"\"\" 27 28 \"\"\" 深拷贝可以完整拷贝 class Company : def __init__ ( self , boss , employee ): self . boss = boss self . employee = employee # shallow copy will affect nested objects boss = Person ( 'Jane' , 55 ) employee = Person ( 'Joe' , 28 ) company = Company ( boss , employee ) company_clone = copy . copy ( company ) company_clone . boss . age = 56 print ( company . boss . age ) print ( company_clone . boss . age ) \"\"\" 56 56 \"\"\" # deep copy will not affect nested objects boss = Person ( 'Jane' , 55 ) employee = Person ( 'Joe' , 28 ) company = Company ( boss , employee ) company_clone = copy . deepcopy ( company ) company_clone . boss . age = 56 print ( company . boss . age ) print ( company_clone . boss . age ) \"\"\" 55 56 \"\"\" 函数传参 在C语言中传参有显式的值传递和地址传递，在Python中也有类似的机制。 Python中数据类型存在可变和不可变的区别，即mutable和immutable。 对于可变类型，例如列表，由于传递的是列表的引用，列表可以在一个方法中被修改 # immutable objects -> no change def foo ( x ): x = 5 # x += 5 also no effect since x is immutable and a new variable must be created var = 10 print ( 'var before foo():' , var ) foo ( var ) print ( 'var after foo():' , var ) \"\"\" var before foo(): 10 var after foo(): 10 \"\"\" 可变对象 # mutable objects -> change def foo ( a_list ): a_list . append ( 4 ) my_list = [ 1 , 2 , 3 ] print ( 'my_list before foo():' , my_list ) foo ( my_list ) print ( 'my_list after foo():' , my_list ) \"\"\" my_list before foo(): [1, 2, 3] my_list after foo(): [1, 2, 3, 4] \"\"\" 重新绑定一个可变对象的引用 # Rebind a mutable reference -> no change def foo ( a_list ): # 赋值操作产生一个新的局部变量 a_list = [ 50 , 60 , 70 ] # a_list is now a new local variable within the function a_list . append ( 50 ) my_list = [ 1 , 2 , 3 ] print ( 'my_list before foo():' , my_list ) foo ( my_list ) print ( 'my_list after foo():' , my_list ) 区分+=和= # another example with rebinding references: def foo ( a_list ): a_list += [ 4 , 5 ] # this chanches the outer variable def bar ( a_list ): a_list = a_list + [ 4 , 5 ] # this rebinds the reference to a new local variable my_list = [ 1 , 2 , 3 ] print ( 'my_list before foo():' , my_list ) foo ( my_list ) print ( 'my_list after foo():' , my_list ) my_list = [ 1 , 2 , 3 ] print ( 'my_list before bar():' , my_list ) bar ( my_list ) print ( 'my_list after bar():' , my_list ) \"\"\" my_list before foo(): [1, 2, 3] my_list after foo(): [1, 2, 3, 4, 5] my_list before bar(): [1, 2, 3] my_list after bar(): [1, 2, 3] \"\"\" 参考 Python-Notebook Python中的*号 闭包概念 Python装饰器","tags":"Python","url":"pages/2020/10/12/Python-Advanced-2/","loc":"pages/2020/10/12/Python-Advanced-2/"},{"title":"锐角云做小开发主机","text":"买了一个二手锐角云小主机，算是支持矿难了，470 元。 硬件配置上，作为一个小主机比树莓派 4B 性能略强，功耗低，可以长时间开机。 机器的 CPU 性能较弱，内存是 8G，一个 64G 的 emmc，一个 128G 的 SSD，收货时卖家已经在 emmc 上安装了阉割版的 win10，用起来还不错。相比而言，SSD 的硬盘性能要略强于板载 emmc，所以我在 128G 的 SSD 上安装了 Ubuntu20.04 作为日常开发主机。 锐角云是通过按 F7 进入 BIOS，安装系统细节不表。装好后其设备信息如下： 装好之后，因为是 Linux 系统，浏览器播放视频时，不支持硬解码，使用 FFmpeg 解码的，CPU 占用接近 100%，播放 720P 视频相对流畅，基本可用。而使用 Mpv 播放器时，支持硬件解码，cpu 占用较低。CPU 性能是机器的瓶颈。 Ubuntu 中有一个 tracker 服务，日常占用 20-30%的 CPU 资源，需要把它干掉。 总之，对日常开发，基本满足一个软件开发者的需求。","tags":"Others","url":"pages/2020/10/11/Triangle-Cloud/","loc":"pages/2020/10/11/Triangle-Cloud/"},{"title":"Ubuntu20.04 上使用 ibus 中文输入法","text":"Ubuntn 上一直以来对中文输入法的支持都不是很完善，在升级到 20.04 版本之后，系统默认自带的是 ibus 输入法，刚刚上手使用之后不是很好用。在尝试安装 fcitx 和搜狗输入法之后，因为搜狗输入法和 Pycharm 等 IDE 冲突，会导致软件卡死，而且资源占用较高。还是切换回了 ibus 输入法。 在简单调教之后，发现 ibus 还是很好用的。 打开 Ibus 首选项 勾选将每个输入记录为新词汇，然后会记录用户的输入历史，方便导出并转移 启用模糊拼音和词典同样可以提高词汇匹配的准确程度 对于用户数据可以定期备份或者清除 当修改配置后，需要重启 ibus 服务使其生效。使用下面命令行重启 ibus ibus-daemon -r -d -x 随着日常使用之后，ibus 会根据你的输入记录，优化其输入法。","tags":"Others","url":"pages/2020/10/11/ibus-input/","loc":"pages/2020/10/11/ibus-input/"},{"title":"PlantUML画时序图","text":"本文主要介绍PlantUML绘图环境的搭建以及时序图的绘制，主要以Linux平台为例。 安装 若安装时序图和活动图以外的图形，需要安装graphviz sudo apt install graphviz VScode安装插件 PlantUML Markdown Preview Enhanced 插件支持的文件名后缀是：.wsd, .pu, .puml, .plantuml, .iuml 编辑文件完成后，按快捷键 ALT+D 预览 Ctrl+Shift+p 可以选择导出图片 需要java sudo apt install default-jre 浏览器插件支持PlantUML PlantUML Viewer插件可以打开UML文本并预览 时序图示例 你可以用 -> 来绘制参与者之间传递的消息， 而不必显式地声明参与者。 @ startuml 用户 -> 认证中心 : 登录操作 认证中心 -> 缓存 : 存放 ( key = token + ip , value = token ) token 用户 <- 认证中心 : 认证成功返回 token 用户 -> 认证中心 : 下次访问头部携带 token认证 认证中心 <- 缓存 : key = token + ip获取token 其他服务 <- 认证中心 : 存在且校验成功则跳转到用户请求的其他服务 其他服务 -> 用户 : 信息 @ enduml 也可以通过关键字声明参与者 @ startuml actor Foo1 boundary Foo2 control Foo3 entity Foo4 database Foo5 collections Foo6 Foo1 -> Foo2 : To boundary Foo1 -> Foo3 : To control Foo1 -> Foo4 : To entity Foo1 -> Foo5 : To database Foo1 -> Foo6 : To collections @ enduml @ startuml title : 序列图 sequence ( 示例 ) participant A participant B participant C participant D participant E note left of A : A左侧说明 note over D : 覆盖 D的说明 note right of F : F右侧说明 A -> x B : 丢失的消息 B -> C : 实线箭头 C ->> D : 实线细箭头 D - \\ E : 实线半箭头 E - \\\\ F : 实线半箭头 F --/ E : 虚线半箭头 E --> o D : 虚线箭头加圈 D -- \\ o C : 虚线半箭头加圈 C <--> B : 实线双向箭头 A --> A : 自己到自己 @ enduml 参考 PlantUML官网 浏览器插件 时序图示例","tags":"Others","url":"pages/2020/09/28/PlantUML-Sequence/","loc":"pages/2020/09/28/PlantUML-Sequence/"},{"title":"编程工具之杂烩","text":"安全和密码 熵 (Entropy) 度量了不确定性并可以用来决定密码的强度。 熵的单位是 比特 。对于一个均匀分布的随机离散变量，熵等于 log_2(所有可能的个数，即n) 。 扔一次硬币的熵是1比特。掷一次（六面）骰子的熵大约为2.58比特。 对称加密与非对称加密 当你运行 ssh-keygen 命令，它会生成一个非对称密钥对：公钥和私钥 (public_key, private_key) 。 生成过程中使用的随机数由系统提供的熵决定。这些熵可以来源于硬件事件(hardware events)等。 公钥最终会被分发，它可以直接明文存储。 但是为了防止泄露，私钥必须加密存储。 ssh-keygen 命令会提示用户输入一个密码，并将它输入密钥生成函数 产生一个密钥。最终， ssh-keygen 使用对称加密算法和这个密钥加密私钥。 在实际运用中，当服务器已知用户的公钥（存储在 .ssh/authorized_keys 文件中，一般在用户HOME目录下），尝试连接的客户端可以使用非对称签名来证明用户的身份——这便是 挑战应答方式 。 简单来说，服务器选择一个随机数字发送给客户端。客户端使用用户私钥对这个数字信息签名后返回服务器。 服务器随后使用 .ssh/authorized_keys 文件中存储的用户公钥来验证返回的信息是否由所对应的私钥所签名。这种验证方式可以有效证明试图登录的用户持有所需的私钥。 大杂烩 修改键位映射 作为一名程序员，键盘是你的主要输入工具。它像计算机里的其他部件一样是可配置的，而且值得你在这上面花时间。 一个很常见的配置是修改键位映射。通常这个功能由在计算机上运行的软件实现。当某一个按键被按下，软件截获键盘发出的按键事件（keypress event）并使用另外一个事件取代。比如： - 将 Caps Lock 映射为 Ctrl 或者 Escape：Caps Lock 使用了键盘上一个非常方便的位置而它的功能却很少被用到，所以我们（讲师）非常推荐这个修改； - 将 PrtSc 映射为播放/暂停：大部分操作系统支持播放/暂停键； - 交换 Ctrl 和 Meta 键（Windows 的徽标键或者 Mac 的 Command 键）。 你也可以将键位映射为任意常用的指令。软件监听到特定的按键组合后会运行设定的脚本。 - 打开一个新的终端或者浏览器窗口； - 输出特定的字符串，比如：一个超长邮件地址或者 MIT ID； - 使计算机或者显示器进入睡眠模式。 甚至更复杂的修改也可以通过软件实现： - 映射按键顺序，比如：按 Shift 键五下切换大小写锁定； - 区别映射单点和长按，比如：单点 Caps Lock 映射为 Escape，而长按 Caps Lock 映射为 Ctrl； - 对不同的键盘或软件保存专用的映射配置。 下面是一些修改键位映射的软件： - macOS - karabiner-elements , skhd 或者 BetterTouchTool - Linux - xmodmap 或者 Autokey - Windows - 控制面板， AutoHotkey 或者 SharpKeys - QMK - 如果你的键盘支持定制固件， QMK 可以直接在键盘的硬件上修改键位映射。保留在键盘里的映射免除了在别的机器上的重复配置。 守护进程 即便守护进程（daemon）这个词看上去有些陌生，你应该已经大约明白它的概念。大部分计算机都有一系列在后台保持运行，不需要用户手动运行或者交互的进程。这些进程就是守护进程。以守护进程运行的程序名一般以 d 结尾，比如 SSH 服务端 sshd ，用来监听传入的 SSH 连接请求并对用户进行鉴权。 Linux 中的 systemd （the system daemon）是最常用的配置和运行守护进程的方法。运行 systemctl status 命令可以看到正在运行的所有守护进程。这里面有很多可能你没有见过，但是掌管了系统的核心部分的进程：管理网络、DNS解析、显示系统的图形界面等等。用户使用 systemctl 命令和 systemd 交互来 enable （启用）、 disable （禁用）、 start （启动）、 stop （停止）、 restart （重启）、或者 status （检查）配置好的守护进程及系统服务。 systemd 提供了一个很方便的界面用于配置和启用新的守护进程或系统服务。下面的配置文件使用了守护进程来运行一个简单的 Python 程序。文件的内容非常直接所以我们不对它详细阐述。 systemd 配置文件的详细指南可参见 freedesktop.org 。 ## /etc/systemd/system/myapp.service [Unit] ## 配置文件描述 Description = My Custom App ## 在网络服务启动后启动该进程 After = network.target [Service] ## 运行该进程的用户 User = foo ## 运行该进程的用户组 Group = foo ## 运行该进程的根目录 WorkingDirectory = /home/foo/projects/mydaemon ## 开始该进程的命令 ExecStart = /usr/bin/local/python3.7 app.py ## 在出现错误时重启该进程 Restart = on-failure [Install] ## 相当于Windows的开机启动。即使GUI没有启动，该进程也会加载并运行 WantedBy = multi-user.target ## 如果该进程仅需要在GUI活动时运行，这里应写作： # WantedBy=graphical.target # graphical.target在multi-user.target的基础上运行和GUI相关的服务 如果你只是想定期运行一些程序，可以直接使用 cron 。它是一个系统内置的，用来执行定期任务的守护进程。 FUSE 现在的软件系统一般由很多模块化的组件构建而成。你使用的操作系统可以通过一系列共同的方式使用不同的文件系统上的相似功能。比如当你使用 touch 命令创建文件的时候， touch 使用系统调用（system call）向内核发出请求。内核再根据文件系统，调用特有的方法来创建文件。这里的问题是，UNIX 文件系统在传统上是以内核模块的形式实现，导致只有内核可以进行文件系统相关的调用。 FUSE （用户空间文件系统）允许运行在用户空间上的程序实现文件系统调用，并将这些调用与内核接口联系起来。在实践中，这意味着用户可以在文件系统调用中实现任意功能。 FUSE 可以用于实现如：一个将所有文件系统操作都使用 SSH 转发到远程主机，由远程主机处理后返回结果到本地计算机的虚拟文件系统。这个文件系统里的文件虽然存储在远程主机，对于本地计算机上的软件而言和存储在本地别无二致。 sshfs 就是一个实现了这种功能的 FUSE 文件系统。 一些有趣的 FUSE 文件系统包括： - sshfs ：使用 SSH 连接在本地打开远程主机上的文件 - rclone ：将 Dropbox、Google Drive、Amazon S3、或者 Google Cloud Storage 一类的云存储服务挂载为本地文件系统 - gocryptfs ：覆盖在加密文件上的文件系统。文件以加密形式保存在磁盘里，但该文件系统挂载后用户可以直接从挂载点访问文件的明文 - kbfs ：分布式端到端加密文件系统。在这个文件系统里有私密（private），共享（shared），以及公开（public）三种类型的文件夹 - borgbackup ：方便用户浏览删除重复数据后的压缩加密备份 备份 任何没有备份的数据都可能在一个瞬间永远消失。复制数据很简单，但是可靠地备份数据很难。下面列举了一些关于备份的基础知识，以及一些常见做法容易掉进的陷阱。 首先，复制存储在同一个磁盘上的数据不是备份，因为这个磁盘是一个单点故障（single point of failure）。这个磁盘一旦出现问题，所有的数据都可能丢失。放在家里的外置磁盘因为火灾、抢劫等原因可能会和源数据一起丢失，所以是一个弱备份。推荐的做法是将数据备份到不同的地点存储。 同步方案也不是备份。即使方便如 Dropbox 或者 Google Drive，当数据在本地被抹除或者损坏，同步方案可能会把这些\"更改\"同步到云端。同理，像 RAID 这样的磁盘镜像方案也不是备份。它不能防止文件被意外删除、损坏、或者被勒索软件加密。 有效备份方案的几个核心特性是：版本控制，删除重复数据，以及安全性。对备份的数据实施版本控制保证了用户可以从任何记录过的历史版本中恢复数据。在备份中检测并删除重复数据，使其仅备份增量变化可以减少存储开销。在安全性方面，作为用户，你应该考虑别人需要有什么信息或者工具才可以访问或者完全删除你的数据及备份。最后一点，不要盲目信任备份方案。用户应该经常检查备份是否可以用来恢复数据。 备份不限制于备份在本地计算机上的文件。云端应用的重大发展使得我们很多的数据只存储在云端。当我们无法登录这些应用，在云端存储的网络邮件，社交网络上的照片，流媒体音乐播放列表，以及在线文档等等都会随之丢失。用户应该有这些数据的离线备份，而且已经有项目可以帮助下载并存储它们。 如果想要了解更多具体内容，请参考本课程2019年关于备份的 课堂笔记 。 API（应用程序接口） 关于如何使用计算机有效率地完成 本地 任务，我们这堂课已经介绍了很多方法。这些方法在互联网上其实也适用。大多数线上服务提供的 API（应用程序接口）让你可以通过编程方式来访问这些服务的数据。比如，美国国家气象局就提供了一个可以从 shell 中获取天气预报的 API。 这些 API 大多具有类似的格式。它们的结构化 URL 通常使用 api.service.com 作为根路径，用户可以访问不同的子路径来访问需要调用的操作，以及添加查询参数使 API 返回符合查询参数条件的结果。 以美国天气数据为例，为了获得某个地点的天气数据，你可以发送一个 GET 请求（比如使用 curl ）到 https://api.weather.gov/points/42.3604,-71.094 。返回中会包括一系列用于获取特定信息（比如小时预报、气象观察站信息等）的 URL。通常这些返回都是 JSON 格式，你可以使用 jq 等工具来选取需要的部分。 有些需要认证的 API 通常要求用户在请求中加入某种私密令牌（secret token）来完成认证。请阅读你想访问的 API 所提供的文档来确定它请求的认证方式，但是其实大多数 API 都会使用 OAuth 。OAuth 通过向用户提供一系列仅可用于该 API 特定功能的私密令牌进行校验。因为使用了有效 OAuth 令牌的请求在 API 看来就是用户本人发出的请求，所以请一定保管好这些私密令牌。否则其他人就可以冒用你的身份进行任何你可以在这个 API 上进行的操作。 IFTTT 这个网站可以将很多 API 整合在一起，让某 API 发生的特定事件触发在其他 API 上执行的任务。IFTTT 的全称If This Then That 足以说明它的用法，比如在检测到用户的新推文后，自动发布在其他平台。但是你可以对它支持的 API 进行任意整合，所以试着来设置一下任何你需要的功能吧！ 常见命令行标志参数及模式 命令行工具的用法千差万别，阅读 man 页面可以帮助你理解每种工具的用法。即便如此，下面我们将介绍一下命令行工具一些常见的共同功能。 大部分工具支持 --help 或者类似的标志参数（flag）来显示它们的简略用法。 会造成不可撤回操作的工具一般会提供\"空运行\"（dry run）标志参数，这样用户可以确认工具真实运行时会进行的操作。这些工具通常也会有\"交互式\"（interactive）标志参数，在执行每个不可撤回的操作前提示用户确认。 --version 或者 -V 标志参数可以让工具显示它的版本信息（对于提交软件问题报告非常重要）。 基本所有的工具支持使用 --verbose 或者 -v 标志参数来输出详细的运行信息。多次使用这个标志参数，比如 -vvv ，可以让工具输出更详细的信息（经常用于调试）。同样，很多工具支持 --quiet 标志参数来抑制除错误提示之外的其他输出。 大多数工具中，使用 - 代替输入或者输出文件名意味着工具将从标准输入（standard input）获取所需内容，或者向标准输出（standard output）输出结果。 会造成破坏性结果的工具一般默认进行非递归的操作，但是支持使用\"递归\"（recursive）标志函数（通常是 -r ）。 有的时候你可能需要向工具传入一个 看上去 像标志参数的普通参数，比如： 使用 rm 删除一个叫 -r 的文件； 在通过一个程序运行另一个程序的时候（ ssh machine foo ），向内层的程序（ foo ）传递一个标志参数。 这时候你可以使用特殊参数 -- 让某个程序 停止处理 -- 后面出现的标志参数以及选项（以 - 开头的内容）： - rm -- -r 会让 rm 将 -r 当作文件名； - ssh machine --for-ssh -- foo --for-foo 的 -- 会让 ssh 知道 --for-foo 不是 ssh 的标志参数。 窗口管理器 大部分人适应了 Windows、macOS、以及 Ubuntu 默认的\"拖拽\"式窗口管理器。这些窗口管理器的窗口一般就堆在屏幕上，你可以拖拽改变窗口的位置、缩放窗口、以及让窗口堆叠在一起。这种堆叠式（floating/stacking）管理器只是窗口管理器中的一种。特别在 Linux 中，有很多种其他的管理器。 平铺式（tiling）管理器就是一个常见的替代。顾名思义，平铺式管理器会把不同的窗口像贴瓷砖一样平铺在一起而不和其他窗口重叠。这和 tmux 管理终端窗口的方式类似。平铺式管理器按照写好的布局显示打开的窗口。如果只打开一个窗口，它会填满整个屏幕。新开一个窗口的时候，原来的窗口会缩小到比如三分之二或者三分之一的大小来腾出空间。打开更多的窗口会让已有的窗口进一步调整。 就像 tmux 那样，平铺式管理器可以让你在完全不使用鼠标的情况下使用键盘切换、缩放、以及移动窗口。它们值得一试！ VPN VPN 现在非常火，但我们不清楚这是不是因为 一些好的理由 。你应该了解 VPN 能提供的功能和它的限制。使用了 VPN 的你对于互联网而言， 最好的情况 下也就是换了一个网络供应商（ISP）。所有你发出的流量看上去来源于 VPN 供应商的网络而不是你的\"真实\"地址，而你实际接入的网络只能看到加密的流量。 虽然这听上去非常诱人，但是你应该知道使用 VPN 只是把原本对网络供应商的信任放在了 VPN 供应商那里——网络供应商 能看到的 ，VPN 供应商 也都能看到 。如果相比网络供应商你更信任 VPN 供应商，那当然很好。反之，则连接VPN的价值不明确。机场的不加密公共热点确实不可以信任，但是在家庭网络环境里，这个差异就没有那么明显。 你也应该了解现在大部分包含用户敏感信息的流量已经被 HTTPS 或者 TLS 加密。这种情况下你所处的网络环境是否\"安全\"不太重要：供应商只能看到你和哪些服务器在交谈，却不能看到你们交谈的内容。 这一切的大前提都是\"最好的情况\"。曾经发生过 VPN 提供商错误使用弱加密或者直接禁用加密的先例。另外，有些恶意的或者带有投机心态的供应商会记录和你有关的所有流量，并很可能会将这些信息卖给第三方。找错一家 VPN 经常比一开始就不用 VPN 更危险。 MIT 向有访问校内资源需求的成员开放自己运营的 VPN 。如果你也想自己配置一个 VPN，可以了解一下 WireGuard 以及 Algo 。 Markdown 你在职业生涯中大概率会编写各种各样的文档。在很多情况下这些文档需要使用标记来增加可读性，比如：插入粗体或者斜体内容，增加页眉、超链接、以及代码片段。 在不使用 Word 或者 LaTeX 等复杂工具的情况下，你可以考虑使用 Markdown 这个轻量化的标记语言（markup language）。你可能已经见过 Markdown 或者它的一个变种。很多环境都支持并使用 Markdown 的一些子功能。 Markdown 致力于将人们编写纯文本时的一些习惯标准化。比如： - 用 * 包围的文字表示强调（ 斜体 ），或者用 ** 表示特别强调（ 粗体 ）； - 以 # 开头的行是标题， # 的数量表示标题的级别，比如： ##二级标题 ； - 以 - 开头代表一个无序列表的元素。一个数字加 . （比如 1. ）代表一个有序列表元素； - 反引号 ` （backtick）包围的文字会以 代码字体 显示。如果要显示一段代码，可以在每一行前加四个空格缩进，或者使用三个反引号包围整个代码片段： ``` 就像这样 ``` 如果要添加超链接，将 需要显示 的文字用方括号包围，并在后面紧接着用圆括号包围链接： [显示文字](指向的链接) 。 Markdown 不仅容易上手，而且应用非常广泛。实际上本课程的课堂笔记和其他资料都是使用 Markdown 编写的。点击 这个链接 可以看到本页面的原始 Markdown 内容。 Hammerspoon (macOS 桌面自动化) Hammerspoon 是面向 macOS 的一个桌面自动化框架。它允许用户编写和操作系统功能挂钩的 Lua 脚本，从而与键盘、鼠标、窗口、文件系统等交互。 下面是 Hammerspoon 的一些示例应用： 绑定移动窗口到的特定位置的快捷键 创建可以自动将窗口整理成特定布局的菜单栏按钮 在你到实验室以后，通过检测所连接的 WiFi 网络自动静音扬声器 在你不小心拿了朋友的充电器时弹出警告 从用户的角度，Hammerspoon 可以运行任意 Lua 代码，绑定菜单栏按钮、按键、或者事件。Hammerspoon 提供了一个全面的用于和系统交互的库，因此它能没有限制地实现任何功能。你可以从头编写自己的 Hammerspoon 配置，也可以结合别人公布的配置来满足自己的需求。 资源 Getting Started with Hammerspoon ：Hammerspoon 官方教程 Sample configurations ：Hammerspoon 官方示例配置 Anish's Hammerspoon config ：Anish 的 Hammerspoon 配置 开机引导以及 Live USB 在你的计算机启动时， BIOS 或者 UEFI 会在加载操作系统之前对硬件系统进行初始化，这被称为引导（booting）。你可以通过按下计算机提示的键位组合来配置引导，比如 Press F9 to configure BIOS. Press F12 to enter boot menu 。在 BIOS 菜单中你可以对硬件相关的设置进行更改，也可以在引导菜单中选择从硬盘以外的其他设备加载操作系统——比如 Live USB。 Live USB 是包含了完整操作系统的闪存盘。Live USB 的用途非常广泛，包括： - 作为安装操作系统的启动盘； - 在不将操作系统安装到硬盘的情况下，直接运行 Live USB 上的操作系统； - 对硬盘上的相同操作系统进行修复； - 恢复硬盘上的数据。 Live USB 通过在闪存盘上 写入 操作系统的镜像制作，而写入不是单纯的往闪存盘上复制 .iso 文件。你可以使用 UNetbootin 、 Rufus 等 Live USB 写入工具制作。 Docker, Vagrant, VMs, Cloud, OpenStack 虚拟机 （Virtual Machine）以及如容器化（containerization）等工具可以帮助你模拟一个包括操作系统的完整计算机系统。虚拟机可以用于创建独立的测试或者开发环境，以及用作安全测试的沙盒。 Vagrant 是一个构建和配置虚拟开发环境的工具。它支持用户在配置文件中写入比如操作系统、系统服务、需要安装的软件包等描述，然后使用 vagrant up 命令在各种环境（VirtualBox，KVM，Hyper-V等）中启动一个虚拟机。 Docker 是一个使用容器化概念的类似工具。 租用云端虚拟机可以享受以下资源的即时访问： 便宜、常开、且有公共IP地址的虚拟机用来托管网站等服务 有大量 CPU、磁盘、内存、以及 GPU 资源的虚拟机 超出用户可以使用的物理主机数量的虚拟机 相比物理主机的固定开支，虚拟机的开支一般按运行的时间计算。所以如果用户只需要在短时间内使用大量算力，租用1000台虚拟机运行几分钟明显更加划算。 受欢迎的 VPS 服务商有 Amazon AWS ， Google Cloud ，以及 DigitalOcean 。 MIT CSAIL 的成员可以使用 CSAIL OpenStack instance 申请免费的虚拟机用于研究。 交互式记事本编程 交互式记事本 可以帮助开发者进行与运行结果交互等探索性的编程。现在最受欢迎的交互式记事本环境大概是 Jupyter 。它的名字来源于所支持的三种核心语言：Julia、Python、R。 Wolfram Mathematica 是另外一个常用于科学计算的优秀环境。 GitHub GitHub 是最受欢迎的开源软件开发平台之一。我们课程中提到的很多工具，从 vim 到 Hammerspoon ，都托管在 Github 上。向你每天使用的开源工具作出贡献其实很简单，下面是两种贡献者们经常使用的方法： 创建一个 议题（issue） 。 议题可以用来反映软件运行的问题或者请求新的功能。创建议题并不需要创建者阅读或者编写代码，所以它是一个轻量化的贡献方式。高质量的问题报告对于开发者十分重要。在现有的议题发表评论也可以对项目的开发作出贡献。 使用 拉取请求（pull request） 提交代码更改。由于涉及到阅读和编写代码，提交拉取请求总的来说比创建议题更加深入。拉取请求是请求别人把你自己的代码拉取（且合并）到他们的仓库里。很多开源项目仅允许认证的管理者管理项目代码，所以一般需要 复刻（fork） 这些项目的上游仓库（upstream repository），在你的 Github 账号下创建一个内容完全相同但是由你控制的复刻仓库。这样你就可以在这个复刻仓库自由创建新的分支并推送修复问题或者实现新功能的代码。完成修改以后再回到开源项目的 Github 页面 创建一个拉取请求 。 提交请求后，项目管理者会和你交流拉取请求里的代码并给出反馈。如果没有问题，你的代码会和上游仓库中的代码合并。很多大的开源项目会提供贡献指南，容易上手的议题，甚至专门的指导项目来帮助参与者熟悉这些项目。 参考 课程列表","tags":"Others","url":"pages/2020/09/27/Coding-Tools-Foobar/","loc":"pages/2020/09/27/Coding-Tools-Foobar/"},{"title":"编程工具之Git","text":"Git版本控制 尽管 Git 的接口有些丑陋，但是它的底层设计和思想却是非常优雅的。丑陋的接口只能靠死记硬背，而优雅的底层设计则非常容易被人理解。因此，我们将通过一种自底向上的方式像您介绍 Git。我们会从数据模型开始，最后再学习它的接口。一旦您搞懂了 Git 的数据模型，再学习其接口并理解这些接口是如何操作数据模型的就非常容易了。 Git 的数据模型 进行版本控制的方法很多。Git 拥有一个经过精心设计的模型，这使其能够支持版本控制所需的所有特性，例如维护历史记录、支持分支和促进协作。 快照 Git 将顶级目录中的文件和文件夹作为集合，并通过一系列快照来管理其历史记录。在Git的术语里，文件被称作Blob对象（数据对象），也就是一组数据。目录则被称之为\"树\"，它将名字与Blob对象或树对象进行映射（使得目录中可以包含其他目录）。快照则是被追踪的最顶层的树。例如，一个树看起来可能是这样的： <root> (tree) | +- foo (tree) | | | + bar.txt (blob, contents = \"hello world\") | +- baz.txt (blob, contents = \"git is wonderful\") 这个顶层的树包含了两个元素，一个名为 \"foo\" 的树(它本身包含了一个blob对象 \"bar.txt\")，以及一个对blob对象 \"baz.txt\"。 历史记录建模：关联快照 版本控制系统和快照有什么关系呢？线性历史记录是一种最简单的模型，它包含了一组按照时间顺序线性排列的快照。不过处于种种原因，Git 并没有采用这样的模型。 在 Git 中，历史记录是一个由快照组成的有向无环图。有向无环图，听上去似乎是什么高大上的数学名词。不过不要怕，您只需要知道这代表 Git 中的每个快照都有一系列的\"父辈\"，也就是其之前的一系列快照。注意，快照具有多个\"父辈\"而非一个，因为某个快照可能由多个父辈而来。例如，经过合并后的两条分支。 在 Git 中，这些快照被称为\"提交\"。通过可视化的方式来表示这些历史提交记录时，看起来差不多是这样的： o <-- o <-- o <-- o &#94; \\ --- o <-- o 上面是一个 ASCII 码构成的简图，其中的 o 表示一次提交（快照）。 箭头指向了当前提交的父辈（这是一种\"在。。。之前\"，而不是\"在。。。之后\"的关系）。在第三次提交之后，历史记录分岔成了两条独立的分支。这可能因为此时需要同时开发两个不同的特性，它们之间是相互独立的。开发完成后，这些分支可能会被合并并创建一个新的提交，这个新的提交会同时包含这些特性。新的提交会创建一个新的历史记录，看上去像这样（最新的合并提交用粗体标记）： o <-- o <-- o <-- o <---- o &#94; / \\ v --- o <-- o Git 中的提交是不可改变的。但这并不代表错误不能被修改，只不过这种\"修改\"实际上是创建了一个全新的提交记录。而引用（参见下文）则被更新为指向这些新的提交。 数据模型及其伪代码表示 以伪代码的形式来学习 Git 的数据模型，可能更加清晰： // 文件就是一组数据 type blob = array < byte > // 一个包含文件和目录的目录 type tree = map < string , tree | file > // 每个提交都包含一个父辈，元数据和顶层树 type commit = struct { parent : array < commit > author : string message : string snapshot : tree } 这是一种简洁的历史模型。 对象和内存寻址 Git 中的对象可以是 blob、树或提交： type object = blob | tree | commit Git 在储存数据时，所有的对象都会基于它们的 SHA-1 hash 进行寻址。 objects = map < string , object > def store ( object ) : id = sha1 ( object ) objects [ id ] = object def load ( id ) : return objects [ id ] Blobs、树和提交都一样，它们都是对象。当它们引用其他对象时，它们并没有真正的在硬盘上保存这些对象，而是仅仅保存了它们的哈希值作为引用。 例如， above 例子中的树（可以通过 git cat-file -p 698281bc680d1995c5f4caaf3359721a5a58d48d 来进行可视化），看上去是这样的： 100644 blob 4448adbf7ecd394f42ae135bbeed9676e894af85 baz.txt 040000 tree c68d233a33c5c06e0340e4c224f0afca87c8ce87 foo 树本身会包含一些指向其他内容的指针，例如 baz.txt (blob) 和 foo (树)。如果我们用 git cat-file -p 4448adbf7ecd394f42ae135bbeed9676e894af85 ，即通过哈希值查看 baz.txte 的内容，会得到以下信息： git is wonderful 引用 现在，所有的快照都可以通过它们的 SHA-1 哈希值来标记了。但这也太不方便了，谁也记不住一串 40 位的十六进制字符。 针对这一问题，Git 的解决方法是给这些哈希值赋予人类可读的名字，也就是引用（references）。引用是指向提交的指针。与对象不同的是，它是可变的（引用可以被更新，指向新的提交）。例如， master 引用通常会指向主分支的最新一次提交。 references = map < string , string > def update_reference ( name , id ) : references [ name ] = id def read_reference ( name ) : return references [ name ] def load_reference ( name_or_id ) : if name_or_id in references : return load ( references [ name_or_id ] ) else : return load ( name_or_id ) 这样，Git 就可以使用诸如 \"master\" 这样人类刻度的名称来表示历史记录中某个特定的提交，而不需要在使用一长串十六进制字符了。 有一个细节需要我们注意， 通常情况下，我们会想要知道\"我们当前所在位置\"，并将其标记下来。这样当我们创建新的快照的时候，我们就可以知道它的相对位置（如何设置它的\"父辈\"）。在 Git 中，我们当前的位置有一个特殊的索引，它就是\"HEAD\"。 仓库 最后，我们可以粗略地给出 Git 仓库的定义了： 对象 和 引用 。 在硬盘上，Git 仅存储对象和引用：因为其数据模型仅包含这些东西。所有的 git 命令都对应着对提交树的操作，例如增加对象，增加或删除引用。 当您输入某个指令时，请思考一些这条命令是如何对底层的图数据结构进行操作的。另一方面，如果您希望修改提交树，例如\"丢弃未提交的修改和将 ‘master' 引用指向提交 5d83f9e 时，有什么命令可以完成该操作（针对这个具体问题，您可以使用 git checkout master; git reset --hard 5d83f9e ） 暂存区 Git 中还包括一个和数据模型完全不相关的概念，但它确是创建提交的接口的一部分。 就上面介绍的快照系统来说，您也许会期望它的实现里包括一个 \"创建快照\" 的命令，该命令能够基于当前工作目录的当前状态创建一个全新的快照。有些版本控制系统确实是这样工作的，但 Git 不是。我们希望简洁的快照，而且每次从当前状态创建快照可能效果并不理想。例如，考虑如下场景，您开发了两个独立的特性，然后您希望创建两个独立的提交，其中第一个提交仅包含第一个特性，而第二个提交仅包含第二个特性。或者，假设您在调试代码时添加了很多打印语句，然后您仅仅希望提交和修复 bug 相关的代码而丢弃所有的打印语句。 Git 处理这些场景的方法是使用一种叫做 \"暂存区（staging area）\"的机制，它允许您指定下次快照中要包括那些改动。 Git 的命令行接口 为了避免重复信息，我们将不会详细解释以下命令行。强烈推荐您阅读 Pro Git 中文版 或可以观看本讲座的视频来学习。 基础 git help <command> : 获取 git 命令的帮助信息 git init : 创建一个新的 git 仓库，其数据会存放在一个名为 .git 的目录下 git status : 显示当前的仓库状态 git add <filename> : 添加文件到暂存区 git commit : 创建一个新的提交 如何编写 良好的提交信息 ! git log : 显示历史日志 git log --all --graph --decorate : 可视化历史记录（有向无环图） git diff <filename> : 显示与上一次提交之间的差异 git diff <revision> <filename> : 显示某个文件两个版本之间的差异 git checkout <revision> : 更新 HEAD 和目前的分支 分支和合并 git branch : 显示分支 git branch <name> : 创建分支 git checkout -b <name> : 创建分支并切换到该分支 相当于 git branch <name>; git checkout <name> git merge <revision> : 合并到当前分支 git mergetool : 使用工具来处理合并冲突 git rebase : 将一系列补丁变基（rebase）为新的基线 远端操作 git remote : 列出远端 git remote add <name> <url> : 添加一个远端 git push <remote> <local branch>:<remote branch> : 将对象传送至远端并更新远端引用 git branch --set-upstream-to=<remote>/<remote branch> : 创建本地和远端分支的关联关系 git fetch : 从远端获取对象/索引 git pull : 相当于 git fetch; git merge git clone : 从远端下载仓库 撤销 git commit --amend : 编辑提交的内容或信息 git reset HEAD <file> : 恢复暂存的文件 git checkout -- <file> : 丢弃修改 Git 高级操作 git config : Git 是一个 高度可定制的 工具 git clone --shallow : 克隆仓库，但是不包括版本历史信息 git add -p : 交互式暂存 git rebase -i : 交互式变基 git blame : 查看最后修改某行的人 git stash : 暂时移除工作目录下的修改内容 git bisect : 通过二分查找搜索历史记录 .gitignore : 指定 故意不追踪的文件 杂项 图形用户界面 : Git 的 图形用户界面客户端 有很多，但是我们自己并不使用这些图形用户界面的客户端，我们选择使用命令行接口 Shell 集成 : 将 Git 状态集成到您的 shell 中会非常方便。( zsh , bash )。 Oh My Zsh 这样的框架中一般以及集成了这一功能 编辑器集成 : 和上面一条类似，将 Git 集成到编辑器中好处多多。 fugitive.vim 是 Vim 中集成 GIt 的常用插件 工作流 :我们已经讲解了数据模型与一些基础命令，但还没讨论到进行大型项目时的一些惯例 ( 有 很多 不同的 处理方法 ) GitHub : Git 并不等同于 GitHub。 在 GitHub 中您需要使用一个被称作 拉取请求（pull request） 的方法来像其他项目贡献代码 Other Git 提供商 : GitHub 并不是唯一的。还有像 GitLab 和 BitBucket 这样的平台。 资源 Pro Git ， 强烈推荐 ！学习前五章的内容可以教会您流畅使用 Git 的绝大多数技巧，因为您已经理解了 Git 的数据模型。后面的章节提供了很多有趣的高级主题。（ Pro Git 中文版 ）； Oh Shit, Git!?! ，简短的介绍了如何从 Git 错误中恢复； Git for Computer Scientists ，简短的介绍了 Git 的数据模型，与本文相比包含较少量的伪代码以及大量的精美图片； Git from the Bottom Up 详细的介绍了 Git 的实现细节，而不仅仅局限于数据模型。好奇的同学可以看看； How to explain git in simple words ； Learn Git Branching 通过基于浏览器的游戏来学习 Git ； 参考 课程列表","tags":"Others","url":"pages/2020/09/27/Coding-Tools-Git/","loc":"pages/2020/09/27/Coding-Tools-Git/"},{"title":"编程工具之调试和性能分析","text":"代码不能完全按照您的想法运行，它只能完全按照您的写法运行，这是编程界的一条金科玉律。 让您的写法符合您的想法是非常困难的。在这节课中，我们会传授给您一些非常有用技术，帮您处理代码中的 bug 和程序性能问题。 调试代码 打印调试法与日志 \"最有效的 debug 工具就是细致的分析，配合恰当位置的打印语句\" — Brian Kernighan, Unix 新手入门 。 调试代码的第一种方法往往是在您发现问题的地方添加一些打印语句，然后不断重复此过程直到您获取了足够的信息并找到问题的根本原因。 另外一个方法是使用日志，而不是临时添加打印语句。日志较普通的打印语句有如下的一些优势： 您可以将日志写入文件、socket 或者甚至是发送到远端服务器而不仅仅是标准输出； 日志可以支持严重等级（例如 INFO, DEBUG, WARN, ERROR等)，这使您可以根据需要过滤日志； 对于新发现的问题，很可能您的日志中已经包含了可以帮助您定位问题的足够的信息。 这里 是一个包含日志的例程序： $ python logger.py # Raw output as with just prints $ python logger.py log # Log formatted output $ python logger.py log ERROR # Print only ERROR levels and above $ python logger.py color # Color formatted output 有很多技巧可以使日志的可读性变得更好，我最喜欢的一个是技巧是对其进行着色。到目前为止，您应该已经知道，以彩色文本显示终端信息时可读性更好。但是应该如何设置呢？ ls 和 grep 这样的程序会使用 ANSI escape codes ，它是一系列的特殊字符，可以使您的 shell 改变输出结果的颜色。例如，执行 echo -e \"\\e[38;2;255;0;0mThis is red\\e[0m\" 会打印红色的字符串： This is red 。下面这个脚本向您展示了如何在终端中打印多种颜色。 #!/usr/bin/env bash for R in $( seq 0 20 255 ) ; do for G in $( seq 0 20 255 ) ; do for B in $( seq 0 20 255 ) ; do printf \"\\e[38;2; ${ R } ; ${ G } ; ${ B } m█\\e[0m\" ; done done done 第三方日志系统 如果您正在构建大型软件系统，您很可能会使用到一些依赖，有些依赖会作为程序单独运行。如 Web 服务器、数据库或消息代理都是此类常见的第三方依赖。 和这些系统交互的时候，阅读它们的日志是非常必要的，因为仅靠客户端侧的错误信息可能并不足以定位问题。 幸运的是，大多数的程序都会将日志保存在您的系统中的某个地方。对于 UNIX 系统来说，程序的日志通常存放在 /var/log 。例如， NGINX web 服务器就将其日志存放于 /var/log/nginx 。 目前，系统开始使用 system log ，您所有的日志都会保存在这里。大多数的（但不是全部）Linux 系统都会使用 systemd ，这是一个系统守护进程，它会控制您系统中的很多东西，例如哪些服务应该启动并运行。 systemd 会将日志以某种特殊格式存放于 /var/log/journal ，您可以使用 journalctl 命令显示这些消息。 类似地，在 macOS 系统中是 /var/log/system.log ，但是有更多的工具会使用系统日志，它的内容可以使用 log show 显示。 对于大多数的 UNIX 系统，您也可以使用 dmesg 命令来读取内核的日志。 如果您希望将日志加入到系统日志中，您可以使用 logger 这个 shell 程序。下面这个例子显示了如何使用 logger 并且如何找到能够将其存入系统日志的条目。 不仅如此，大多数的编程语言都支持向系统日志中写日志。 logger \"Hello Logs\" # On macOS log show --last 1m | grep Hello # On Linux journalctl --since \"1m ago\" | grep Hello 正如我们在数据整理那节课上看到的那样，日志的内容可以非常的多，我们需要对其进行处理和过滤才能得到我们想要的信息。 如果您发现您需要对 journalctl 和 log show 的结果进行大量的过滤，那么此时可以考虑使用它们自带的选项对其结果先过滤一遍再输出。还有一些像 lnav 这样的工具，它为日志文件提供了更好的展现和浏览方式。 调试器 当通过打印已经不能满足您的调试需求时，您应该使用调试器。 调试器是一种可以允许我们和正在执行的程序进行交互的程序，它可以做到： 当到达某一行时将程序暂停； 一次一条指令地逐步执行程序； 程序崩溃后查看变量的值； 满足特定条件是暂停程序； 其他高级功能。 很多编程语言都有自己的调试器。Python 的调试器是 pdb . 下面对 pdb 支持对命令进行简单对介绍： l (ist) - 显示当前行附近的11行或继续执行之前的显示； s (tep) - 执行当前行，并在第一个可能的地方停止 n (ext) - 继续执行直到当前函数的下一条语句或者 return 语句； b (reak) - 设置断点（基于传入对参数）； p (rint) - 在当前上下文对表达式求值并打印结果。还有一个命令是 pp ，它使用 pprint 打印； r (eturn) - 继续执行直到当前函数返回； q (uit) - 退出调试器。 让我们使用 pdb 来修复下面的 Python 代码（参考讲座视频） def bubble_sort ( arr ): n = len ( arr ) for i in range ( n ): for j in range ( n ): if arr [ j ] > arr [ j + 1 ]: arr [ j ] = arr [ j + 1 ] arr [ j + 1 ] = arr [ j ] return arr print ( bubble_sort ([ 4 , 2 , 1 , 8 , 7 , 6 ])) 注意，因为 Python 是一种解释型语言，所以我们可以通过 pdb shell 执行命令。 ipdb 是一种增强型的 pdb ，它使用 IPython 作为 REPL并开启了 tab 补全、语法高亮、更好的回溯和更好的内省，同时还保留了 pdb 模块相同的接口。 对于更底层的编程语言，您可能需要了解一下 gdb ( 以及它的改进版 pwndbg ) 和 lldb 。 它们都对类 C 语言的调试进行了优化，它允许您探索任意进程及其机器状态：寄存器、堆栈、程序计数器等。 专门工具 即使您需要调试的程序是一个二进制的黑盒程序，仍然有一些工具可以帮助到您。当您的程序需要执行一些只有操作系统内核才能完成的操作时，它需要使用 系统调用 。有一些命令可以帮助您追踪您的程序执行的系统调用。在 Linux 中可以使用 strace ，在 macOS 和 BSD 中可以使用 dtrace 。 dtrace 用起来可能有些别扭，因为它使用的是它自有的 D 语言，但是我们可以使用一个叫做 dtruss 的封装使其具有和 strace (更多信息参考 这里 )类似的接口 下面的例子展现来如何使用 strace 或 dtruss 来显示 ls 执行时，对 stat 系统调用进行追踪对结果。若需要深入了解 strace ， 这篇文章 值得一读。 # On Linux sudo strace -e lstat ls -l > /dev/null 4 # On macOS sudo dtruss -t lstat64_extended ls -l > /dev/null 有些情况下，我们需要查看网络数据包才能定位问题。像 tcpdump 和 Wireshark 这样的网络数据包分析工具可以帮助您获取网络数据包的内容并基于不同的条件进行过滤。 对于 web 开发， Chrome/Firefox 的开发者工具非常方便，功能也很强大： - 源码 -查看任意站点的 HTML/CSS/JS 源码； - 实时地修改 HTML, CSS, JS 代码 - 修改网站的内容、样式和行为用于测试（从这一点您也能看出来，网页截图是不可靠的）； - Javascript shell - 在 JS REPL中执行命令； - 网络 - 分析请求的时间线； - 存储 - 查看 Cookies 和本地应用存储。 静态分析 有些问题是您不需要执行代码就能发现的。例如，仔细观察一段代码，您就能发现某个循环变量覆盖了某个已经存在的变量或函数名；或是有个变量在被读取之前并没有被定义。 这种情况下 静态分析 工具就可以帮我们找到问题。静态分析会将程序的源码作为输入然后基于编码规则对其进行分析并对代码的正确性进行推理。 下面这段 Python 代码中存在几个问题。 首先，我们的循环变量 foo 覆盖了之前定义的函数 foo 。最后一行，我们还把 bar 错写成了 baz ，因此当程序完成 sleep (一分钟后)后，执行到这一行的时候便会崩溃。 import time def foo (): return 42 for foo in range ( 5 ): print ( foo ) bar = 1 bar *= 0.2 time . sleep ( 60 ) print ( baz ) 静态分析工具可以发现此类的问题。当我们使用 pyflakes 分析代码的似乎，我们会得到与这两处 bug 相关的错误信息。 mypy 则是另外一个工具，它可以对代码进行类型检查。这里， mypy 会经过我们 bar 起初是一个 int ，然后变成了 float 。这些问题都可以在不允许代码的情况下被发现。 在 shell 工具那一节课的时候，我们介绍了 shellcheck ，这是一个类似的工具，但它是应用于 shell 脚本的。 $ pyflakes foobar.py foobar.py:6: redefinition of unused 'foo' from line 3 foobar.py:11: undefined name 'baz' $ mypy foobar.py foobar.py:6: error: Incompatible types in assignment ( expression has type \"int\" , variable has type \"Callable[[], Any]\" ) foobar.py:9: error: Incompatible types in assignment ( expression has type \"float\" , variable has type \"int\" ) foobar.py:11: error: Name 'baz' is not defined Found 3 errors in 1 file ( checked 1 source file ) 大多数的编辑器和 IDE 都支持在编辑界面显示这些工具的分析结果、高亮有警告和错误的位置。 这个过程通常成为 code linting 。风格检查或安全检查的结果同样也可以进行相应的显示。 在 vim 中，有 ale 或 syntastic 可以帮助您做同样的事情。 在 Python 中， pylint 和 pep8 是两种用于进行风格检查的工具，而 bandit 工具则用于检查安全相关的问题。 对于其他语言的开发者来说，静态分析工具可以参考这个列表： Awesome Static Analysis (您也许会对 Writing 一节感兴趣) 。对于 linters 则可以参考这个列表： Awesome Linters 。 对于风格检查和代码格式化，还有以下一些工具可以作为补充：用于 Python 的 black 、用于 Go 语言的 gofmt 、用于 Rust 的 rustfmt 或是用于 JavaScript, HTML 和 CSS 的 prettier 。这些工具可以自动格式化您的代码，这样代码风格就可以与常见的风格保持一致。 尽管您可能并不想对代码进行风格控制，标准的代码风格有助于方便别人阅读您的代码，也可以方便您阅读它的代码。 性能分析 即使您的代码能够向您期望的一样运行，但是如果它消耗了您全部的 CPU 和内存，那么它显然也不是个好程序。算法课上我们通常会介绍大O标记法，但却没交给我们如何找到程序中的热点。 鉴于 过早的优化是万恶之源 ，您需要学习性能分析和监控工具，它们会帮助您找到程序中最耗时、最耗资源的部分，这样您就可以有针对性的进行性能优化。 计时 和调试代码类似，大多数情况下我们只需要打印两处代码之间的时间即可发现问题。下面这个例子中，我们使用了 Python 的 time 模块。 import time , random n = random . randint ( 1 , 10 ) * 100 ### 获取当前时间 start = time . time () ### 执行一些操作 print ( \"Sleeping for {} ms\" . format ( n )) time . sleep ( n / 1000 ) ### 比较当前时间和起始时间 print ( time . time () - start ) # Output # Sleeping for 500 ms ### 0.5713930130004883 不过，执行时间（wall clock time）也可能会误导您，因为您的电脑可能也在同时运行其他进程，也可能在此期间发生了等待。 对于工具来说，需要区分真实时间、用户时间和系统时间。通常来说，用户时间+系统时间代表了您的进程所消耗的实际 CPU （更详细的解释可以参照 这篇文章 ）。 真实时间 - 从程序开始到结束流失掉到真实时间，包括其他进程到执行时间以及阻塞消耗的时间（例如等待 I/O或网络）； User - CPU 执行用户代码所花费的时间； Sys - CPU 执行系统内核代码所花费的时间。 例如，试着执行一个用于发起 HTTP 请求的命令并在其前面添加 time 前缀。网络不好的情况下您可能会看到下面的输出结果。请求花费了 2s 才完成，但是进程仅花费了 15ms 的 CPU 用户时间和 12ms 的 CPU 内核时间。 $ time curl https://missing.csail.mit.edu & > /dev/null ` real 0m2.561s user 0m0.015s sys 0m0.012s 性能分析工具（profilers） CPU 大多数情况下，当人们提及性能分析工具的时候，通常指的是 CPU 性能分析工具。 CPU 性能分析工具有两种： 追踪分析器（ tracing ）及采样分析器（ sampling ）。 追踪分析器 会记录程序的每一次函数调用，而采样分析器则只会周期性的监测（通常为每毫秒）您的程序并记录程序堆栈。它们使用这些记录来生成统计信息，显示程序在哪些事情上花费了最多的时间。如果您希望了解更多相关信息，可以参考 这篇 介绍性的文章。 大多数的编程语言都有一些基于命令行都分析器，我们可以使用它们来分析代码。它们通常可以集成在 IDE 中，但是本节课我们会专注于这些命令行工具本身。 在 Python 中，我们使用 cProfile 模块来分析每次函数调用所消耗都时间。 在下面的例子中，我们实现了一个基础的 grep 命令： #!/usr/bin/env python import sys , re def grep ( pattern , file ): with open ( file , 'r' ) as f : print ( file ) for i , line in enumerate ( f . readlines ()): pattern = re . compile ( pattern ) match = pattern . search ( line ) if match is not None : print ( \" {} : {} \" . format ( i , line ), end = \"\" ) if __name__ == '__main__' : times = int ( sys . argv [ 1 ]) pattern = sys . argv [ 2 ] for i in range ( times ): for file in sys . argv [ 3 :]: grep ( pattern , file ) 我们可以使用下面的命令来对这段代码进行分析。通过它的输出我们可以直到，IO 消耗了大量的时间，编译正则表达式也比较耗费时间。因为正则表达式只需要编译一次，我们可以将其移动到 for 循环外面来改进性能。 $ python - m cProfile - s tottime grep . py 1000 ' &#94; ( import | \\ s * def )[ &#94; ,] * $' * . py [ omitted program output ] ncalls tottime percall cumtime percall filename : lineno ( function ) 8000 0.266 0.000 0.292 0.000 { built - in method io . open } 8000 0.153 0.000 0.894 0.000 grep . py : 5 ( grep ) 17000 0.101 0.000 0.101 0.000 { built - in method builtins . print } 8000 0.100 0.000 0.129 0.000 { method ' readlines ' of ' _io . _IOBase ' objects } 93000 0.097 0.000 0.111 0.000 re . py : 286 ( _compile ) 93000 0.069 0.000 0.069 0.000 { method ' search ' of ' _sre . SRE_Pattern ' objects } 93000 0.030 0.000 0.141 0.000 re . py : 231 ( compile ) 17000 0.019 0.000 0.029 0.000 codecs . py : 318 ( decode ) 1 0.017 0.017 0.911 0.911 grep . py : 3 ( < module > ) [ omitted lines ] 关于 Python 的 cProfile 分析器（以及其他一些类似的一些分析器），需要注意的是它显示的是每次函数调用的时间。看上去可能快到反直觉，尤其是如果您在代码里面使用了第三方的函数库，因为内部函数调用也会被看作函数调用。 更加符合直觉的显示分析信息的方式是包括每行代码的执行时间，这也是 行分析器 的工作。例如，下面这段 Python 代码会向本课程的网站发起一个请求，然后解析响应返回的页面中的全部 URL： #!/usr/bin/env python import requests from bs4 import BeautifulSoup ### 这个装饰器会告诉行分析器 ### 我们想要分析这个函数 @profile def get_urls (): response = requests . get ( 'https://missing.csail.mit.edu' ) s = BeautifulSoup ( response . content , 'lxml' ) urls = [] for url in s . find_all ( 'a' ): urls . append ( url [ 'href' ]) if __name__ == '__main__' : get_urls () 如果我们使用 Python 的 cProfile 分析器，我们会得到超过2500行的输出结果，即使对其进行排序，我仍然搞不懂时间到底都花在哪了。如果我们使用 line_profiler ，它会基于行来显示时间： $ kernprof -l -v a.py Wrote profile results to urls.py.lprof Timer unit: 1e-06 s Total time: 0 .636188 s File: a.py Function: get_urls at line 5 Line ### Hits Time Per Hit % Time Line Contents ============================================================== 5 @profile 6 def get_urls () : 7 1 613909 .0 613909 .0 96 .5 response = requests.get ( 'https://missing.csail.mit.edu' ) 8 1 21559 .0 21559 .0 3 .4 s = BeautifulSoup ( response.content, 'lxml' ) 9 1 2 .0 2 .0 0 .0 urls = [] 10 25 685 .0 27 .4 0 .1 for url in s.find_all ( 'a' ) : 11 24 33 .0 1 .4 0 .0 urls.append ( url [ 'href' ]) 内存 像 C 或者 C++ 这样的语言，内存泄漏会导致您的程序在使用完内存后不去释放它。为了应对内存类的 Bug，我们可以使用类似 Valgrind 这样的工具来检查内存泄漏问题。 对于 Python 这类具有垃圾回收机制的语言，内存分析器也是很有用的，因为对于某个对象来说，只要有指针还指向它，那它就不会被回收。 下面这个例子及其输出，展示了 memory-profiler 是如何工作的（注意装饰器和 line-profiler 类似）。 @profile def my_func (): a = [ 1 ] * ( 10 ** 6 ) b = [ 2 ] * ( 2 * 10 ** 7 ) del b return a if __name__ == '__main__' : my_func () $ python -m memory_profiler example.py Line ### Mem usage Increment Line Contents ============================================== 3 @profile 4 5 .97 MB 0 .00 MB def my_func () : 5 13 .61 MB 7 .64 MB a = [ 1 ] * ( 10 ** 6 ) 6 166 .20 MB 152 .59 MB b = [ 2 ] * ( 2 * 10 ** 7 ) 7 13 .61 MB -152.59 MB del b 8 13 .61 MB 0 .00 MB return a 事件分析 在我们使用 strace 调试代码的时候，您可能会希望忽略一些特殊的代码并希望在分析时将其当作黑盒处理。 perf 命令将 CPU 的区别进行了抽象，它不会报告时间和内存的消耗，而是报告与您的程序相关的系统事件。 例如， perf 可以报告不佳的缓存局部性（poor cache locality）、大量的页错误（page faults）或活锁（livelocks）。下面是关于常见命令的简介： perf list - 列出可以被 pref 追踪的事件； perf stat COMMAND ARG1 ARG2 - 收集与某个进程或指令相关的事件； perf record COMMAND ARG1 ARG2 - 记录命令执行的采样信息并将统计数据储存在 perf.data 中； perf report - 格式化并打印 perf.data 中的数据。 可视化 使用分析器来分析真实的程序时，由于软件的复杂性，其输出结果中将包含大量的信息。人类是一种视觉动物，非常不善于阅读大量的文字。因此很多工具都提供了可视化分析器输出结果的功能。 对于采样分析器来说，常见的显示 CPU 分析数据的形式是 火焰图 ，火焰图会在 Y 轴显示函数调用关系，并在 X 轴显示其耗时的比例。火焰图同时还是可交互的，您可以深入程序的某一具体部分，并查看其栈追踪（您可以尝试点击下面的图片）。 调用图和控制流图可以显示子程序之间的关系，它将函数作为节点并把函数调用作为边。将它们和分析器的信息（例如调用次数、耗时等）放在一起使用时，调用图会变得非常有用，它可以帮助我们分析程序的流程。 在 Python 中您可以使用 pycallgraph 来生成这些图片。 资源监控 有时候，分析程序性能的第一步是搞清楚它所消耗的资源。程序变慢通常是因为它所需要的资源不够了。例如，没有足够的内存或者网络连接变慢的时候。 有很多很多的工具可以被用来显示不同的系统资源，例如 CPU 占用、内存使用、网络、磁盘使用等。 通用监控 - 最流行的工具要数 htop ,了，它是 top 的改进版。 htop 可以显示当前运行进程的多种统计信息。 htop 有很多选项和快捷键，常见的有： <F6> 进程排序、 t 显示树状结构和 h 打开或折叠线程。 还可以留意一下 glances ，它的实现类似但是用户界面更好。如果需要合并测量全部的进程， dstat 是也是一个非常好用的工具，它可以实时地计算不同子系统资源的度量数据，例如 I/O、网络、 CPU 利用率、上下文切换等等； I/O 操作 - iotop 可以显示实时 I/O 占用信息而且可以非常方便地检查某个进程是否正在执行大量的磁盘读写操作； 磁盘使用 - df 可以显示每个分区的信息，而 du 则可以显示当前目录下每个文件的磁盘使用情况（ d isk u sage）。 -h 选项可以使命令使用对人类（ h uman）更加友好的格式显示数据； ncdu 是一个交互性更好的 du ，它可以让您在不同目录下导航、删除文件和文件夹； 内存使用 - free 可以显示系统当前空闲的内存。内存也可以使用 htop 这样的工具来显示； 打开文件 - lsof 可以列出被进程打开的文件信息。 当我们需要查看某个文件是被哪个进程打开的时候，这个命令非常有用；. 网络连接和配置 - ss le帮助我们监控网络包的收发情况以及网络接口的显示信息。 ss 常见的一个使用场景是找到端口被进程占用的信息。如果要显示路由、网络设备和接口信息，您可以使用 ip 命令。注意， netstat 和 ifconfig 这两个命令已经被前面那些工具所代替了。 网络使用 - nethogs 和 iftop 是非常好的用于对网络占用进行监控的交互式命令行工具。 如果您希望测试一下这些工具，您可以使用 stress 命令来为系统人为地增加负载。 专用工具 有时候，您只需要对黑盒程序进行基准测试，并依此对软件选择进行评估。 类似 hyperfine 这样的命令行可以帮您快速进行基准测试。例如，我们在 shell 工具和脚本那一节课中我们推荐使用 fd 来代替 find 。我们这里可以用 hyperfine 来比较一下它们。 例如，下面的例子中，我们可以看到 fd 比 find 要快20倍。 $ hyperfine --warmup 3 'fd -e jpg' 'find . -iname \"*.jpg\"' Benchmark #1: fd -e jpg Time ( mean ± σ ) : 51 .4 ms ± 2 .9 ms [ User: 121 .0 ms, System: 160 .5 ms ] Range ( min … max ) : 44 .2 ms … 60 .1 ms 56 runs Benchmark #2: find . -iname \"*.jpg\" Time ( mean ± σ ) : 1 .126 s ± 0 .101 s [ User: 141 .1 ms, System: 956 .1 ms ] Range ( min … max ) : 0 .975 s … 1 .287 s 10 runs Summary 'fd -e jpg' ran 21 .89 ± 2 .33 times faster than 'find . -iname \"*.jpg\"' 和 debug 一样，浏览器也包含了很多不错的性能分析工具，可以用来分析页面加载，让我们可以搞清楚时间都消耗在什么地方（加载、渲染、脚本等等）。 更多关于 Firefox 和 Chrome 的信息可以点击链接。 课后练习 调试 使用 Linux 上的 journalctl 或 macOS 上的 log show 命令来获取最近一天中超级用户的登陆信息及其所执行的指令。如果找不到相关信息，您可以执行一些无害的命令，例如 sudo ls 然后再次查看。 学习 这份 pdb 实践教程并熟悉相关的命令。更深入的信息您可以参考 这份 教程。 安装 shellcheck 并尝试对下面的脚本进行检查。这段代码有什么问题吗？请修复相关问题。在您的编辑器中安装一个linter插件，这样它就可以自动地显示相关警告信息。 bash #!/bin/sh ## Example: a typical script with several problems for f in $(ls *.m3u) do grep -qi hq.*mp3 $f \\ && echo -e 'Playlist $f contains a HQ file in mp3 format' done (进阶题) 请阅读 可逆调试 并尝试创建一个可以工作的例子（使用 rr 或 RevPDB ）。 性能分析 这里 有一些排序算法的实现。请使用 cProfile 和 line_profiler 来比较插入排序和快速排序的性能。两种算法的瓶颈分别在哪里？然后使用 memory_profiler 来检查内存消耗，为什么插入排序更好一些？然后在看看原地排序版本的快排。附加题：使用 perf 来查看不同算法的循环次数及缓存命中及丢失情况。 这里有一些用于计算斐波那契数列 Python 代码，它为计算每个数字都定义了一个函数： ```python #!/usr/bin/env python def fib0(): return 0 def fib1(): return 1 s = \"\"\"def fib{}(): return fib{}() + fib{}()\"\"\" if name == ' main ': for n in range ( 2 , 10 ): exec ( s . format ( n , n - 1 , n - 2 )) # from functools import lru_cache # for n in range(10): ### exec(\"fib{} = lru_cache(1)(fib{})\".format(n, n)) print ( eval ( \"fib9()\" )) `` 将代码拷贝到文件中使其变为一个可执行的程序。安装 [ pycallgraph ](http://pycallgraph.slowchop.com/en/master/)。并使用 pycallgraph graphviz -- ./fib.py 来执行代码并查看 pycallgraph.png 这个文件。 fib0 被调用了多少次？我们可以通过？我们可以通过记忆法来对其进行优化。将注释掉的部分放开，然后重新生成图片。这回每个 fibN 函数被调用了多少次？ 3. 我们经常会遇到的情况是某个我们希望去监听的端口已经被其他进程占用了。让我们通过进程的PID查找相应的进程。首先执行 python -m http.server 4444 启动一个最简单的 web 服务器来监听 4444 端口。在另外一个终端中，执行 lsof | grep LISTEN 打印出所有监听端口的进程及相应的端口。找到对应的 PID 然后使用 kill ` 停止该进程。 限制进程资源也是一个非常有用的技术。执行 stress -c 3 并使用 htop 对 CPU 消耗进行可视化。现在，执行 taskset --cpu-list 0,2 stress -c 3 并可视化。 stress 占用了3个 CPU 吗？为什么没有？阅读 man taskset 来寻找答案。附加题：使用 cgroups 来实现相同的操作，尝试使用 stress -m 来限制内存使用 (进阶题) curl ipinfo.io 命令或执行 HTTP 请求并获取关于您 IP 的信息。打开 Wireshark 并抓取 curl 发起的请求和收到的回复报文。（提示：可以使用 http 进行过滤，只显示 HTTP 报文） 参考 课程列表","tags":"Others","url":"pages/2020/09/27/Coding-Tools-Profile/","loc":"pages/2020/09/27/Coding-Tools-Profile/"},{"title":"编程工具之问答","text":"最后一节课，我们回答学生提出的问题: 学习操作系统相关内容的推荐，比如进程，虚拟内存，中断，内存管理等 你会优先学习的工具有那些? 使用 Python VS Bash脚本 VS 其他语言? source script.sh 和 ./script.sh 有什么区别？ 各种软件包和工具存储在哪里？引用过程是怎样的? /bin 或 /lib 是什么？ 我应该用 apt-get install 还是 pip install 去下载软件包呢? 用于提高代码性能，简单好用的性能分析工具有哪些? 你使用那些浏览器插件? 有哪些有用的数据整理工具？ Docker和虚拟机有什么区别? 不同操作系统的优缺点是什么，我们如何选择（比如选择最适用于我们需求的Linux发行版）？ 使用 Vim 编辑器 VS Emacs 编辑器? 机器学习应用的提示或技巧? 还有更多的 Vim 小窍门吗？ 2FA是什么，为什么我需要使用它? 对于不同的 Web 浏览器有什么评价? 学习操作系统相关内容的推荐，比如进程，虚拟内存，中断，内存管理等 首先，不清楚你是不是真的需要了解这些更底层的话题。 当你开始编写更加底层的代码，比如实现或修改内核的时候，这些内容是很重要的。除了其他课程中简要介绍过的进程和信号量之外，大部分话题都不相关。 学习资源： MIT's 6.828 class - 研究生阶段的操作系统课程（课程资料是公开的）。 现代操作系统 第四版（ Modern Operating Systems 4th ed ） - 作者是Andrew S. Tanenbaum 这本书对上述很多概念都有很好的描述。 FreeBSD的设计与实现（ The Design and Implementation of the FreeBSD Operating System ） - 关于FreeBSD OS 不错的资源(注意，FreeBSD OS 不是 Linux)。 其他的指南例如 用 Rust 写操作系统 这里用不同的语言逐步实现了内核，主要用于教学的目的。 你会优先学习的工具有那些？ 值得优先学习的内容： 多去使用键盘，少使用鼠标。这一目标可以通过多加利用快捷键，更换界面等来实现。 学好编辑器。作为程序员你大部分时间都是在编辑文件，因此值得学好这些技能。 学习怎样去自动化或简化工作流程中的重复任务。因为这会节省大量的时间。 学习像 Git 之类的版本控制工具并且知道如何与 GitHub 结合，以便在现代的软件项目中协同工作。 使用 Python VS Bash脚本 VS 其他语言? 通常来说，Bash 脚本对于简短的一次性脚本有效，比如当你想要运行一系列的命令的时候。但是Bash 脚本有一些比较奇怪的地方，这使得大型程序或脚本难以用 Bash 实现： Bash 可以获取简单的用例，但是很难获得全部可能的输入。例如，脚本参数中的空格会导致Bash 脚本出错。 Bash 对于代码重用并不友好。因此，重用你先前已经写好的代码很困难。通常 Bash 中没有软件库的概念。 Bash 依赖于一些像 $? 或 $@ 的特殊字符指代特殊的值。其他的语言却会显式地引用，比如 exitCode 或 sys.args 。 因此，对于大型或者更加复杂的脚本我们推荐使用更加成熟的脚本语言例如 Python 和 Ruby。 你可以找到很多用这些语言编写的，用来解决常见问题的在线库。 如果你发现某种语言实现了你所需要的特定功能库，最好的方式就是直接去使用那种语言。 source script.sh 和 ./script.sh 有什么区别? 这两种情况 script.sh 都会在bash会话中被读取和执行，不同点在于那个会话执行这个命令。 对于 source 命令来说，命令是在当前的bash会话种执行的，因此当 source 执行完毕，对当前环境的任何更改（例如更改目录或是定义函数）都会留存在当前会话中。 单独运行 ./script.sh 时，当前的bash会话将启动新的bash会话（实例），并在新实例中运行命令 script.sh 。 因此，如果 script.sh 更改目录，新的bash会话（实例）会更改目录，但是一旦退出并将控制权返回给父bash会话，父会话仍然留在先前的位置（不会有目录的更改）。 同样，如果 script.sh 定义了要在终端中访问的函数，需要用 source 命令在当前bash会话中定义这个函数。否则，如果你运行 ./script.sh ，只有新的bash会话（进程）才能执行定义的函数，而当前的shell不能。 各种软件包和工具存储在哪里？引用过程是怎样的? /bin 或 /lib 是什么？ 根据你在命令行中运行的程序，这些包和工具会全部在 PATH 环境变量所列出的目录中查找到， 你可以使用 which 命令(或是 type 命令)来检查你的shell在哪里发现了特定的程序。 一般来说，特定种类的文件存储有一定的规范， 文件系统，层次结构标准（Filesystem, Hierarchy Standard） 可以查到我们讨论内容的详细列表。 /bin - 基本命令二进制文件 /sbin - 基本的系统二进制文件，通常是root运行的 /dev - 设备文件，通常是硬件设备接口文件 /etc - 主机特定的系统配置文件 /home - 系统用户的家目录 /lib - 系统软件通用库 /opt - 可选的应用软件 /sys - 包含系统的信息和配置( 第一堂课 介绍的) /tmp - 临时文件( /var/tmp ) 通常在重启之间删除 /usr/ - 只读的用户数据 /usr/bin - 非必须的命令二进制文件 /usr/sbin - 非必须的系统二进制文件，通常是由root运行的 /usr/local/bin - 用户编译程序的二进制文件 /var -变量文件 像日志或缓存 我应该用 apt-get install 还是 pip install 去下载软件包呢? 这个问题没有普遍的答案。这与使用系统程序包管理器还是特定语言的程序包管理器来安装软件这一更笼统的问题相关。需要考虑的几件事： 常见的软件包都可以通过这两种方法获得，但是小众的软件包或较新的软件包可能不在系统程序包管理器中。在这种情况下，使用特定语言的程序包管理器是更好的选择。 同样，特定语言的程序包管理器相比系统程序包管理器有更多的最新版本的程序包。 当使用系统软件包管理器时，将在系统范围内安装库。如果出于开发目的需要不同版本的库，则系统软件包管理器可能不能满足你的需要。对于这种情况，大多数编程语言都提供了隔离或虚拟环境，因此你可以用特定语言的程序包管理器安装不同版本的库而不会发生冲突。对于 Python，可以使用 virtualenv，对于 Ruby，使用 RVM 。 根据操作系统和硬件架构，其中一些软件包可能会附带二进制文件或者软件包需要被编译。例如，在树莓派（Raspberry Pi）之类的ARM架构计算机中，在软件附带二进制文件和软件包需要被编译的情况下，使用系统包管理器比特定语言包管理器更好。这在很大程度上取决于你的特定设置。 你应该仅使用一种解决方案，而不同时使用两种方法，因为这可能会导致难以解决的冲突。我们的建议是尽可能使用特定语言的程序包管理器，并使用隔离的环境（例如 Python 的 virtualenv）以避免影响全局环境。 用于提高代码性能，简单好用的性能分析工具有哪些? 性能分析方面相当有用和简单工具是 print timing 。你只需手动计算代码不同部分之间花费的时间。通过重复执行此操作，你可以有效地对代码进行二分法搜索，并找到花费时间最长的代码段。 对于更高级的工具， Valgrind 的 Callgrind 可让你运行程序并计算所有的时间花费以及所有调用堆栈（即哪个函数调用了另一个函数）。然后，它会生成带注释的代码版本，其中包含每行花费的时间。但是，它会使程序运行速度降低一个数量级，并且不支持线程。其他的， perf 工具和其他特定语言的采样性能分析器可以非常快速地输出有用的数据。 Flamegraphs 是对采样分析器结果的可视化工具。你还可以使用针对特定编程语言或任务的工具。例如，对于 Web 开发而言，Chrome 和 Firefox 内置的开发工具具有出色的性能分析器。 有时，代码中最慢的部分是系统等待磁盘读取或网络数据包之类的事件。在这些情况下，需要检查根据硬件性能估算的理论速度是否不偏离实际数值，也有专门的工具来分析系统调用中的等待时间，包括用于用户程序内核跟踪的 eBPF 。如果需要低级的性能分析， bpftrace 值得一试。 你使用那些浏览器插件? 我们钟爱的插件主要与安全性与可用性有关： - uBlock Origin - 是一个 用途广泛（wide-spectrum） 的拦截器，它不仅可以拦截广告，还可以拦截第三方的页面，也可以拦截内部脚本和其他种类资源的加载。如果你打算花更多的时间去配置，前往 中等模式（medium mode） 或者 强力模式（hard mode） 。在你调整好设置之前一些网站会停止工作，但是这些配置会显著提高你的网络安全水平。另外， 简易模式（easy mode） 作为默认模式已经相当不错了，可以拦截大部分的广告和跟踪，你也可以自定义规则来拦截网站对象。 - Stylus - 是Stylish的分支（不要使用Stylish，它会 窃取浏览记录 )），这个插件可让你将自定义CSS样式加载到网站。使用Stylus，你可以轻松地自定义和修改网站的外观。可以删除侧边框，更改背景颜色，更改文字大小或字体样式。这可以使你经常访问的网站更具可读性。此外，Stylus可以找到其他用户编写并发布在 userstyles.org 中的样式。大多数常用的网站都有一个或几个深色主题样式。 - 全页屏幕捕获 - 内置于 Firefox 和 Chrome 扩展程序 中。这些插件提供完整的网站截图，通常比打印要好用。 - 多账户容器 - 该插件使你可以将Cookie分为\"容器\"，从而允许你以不同的身份浏览web网页并且/或确保网站无法在它们之间共享信息。 - 密码集成管理器 - 大多数密码管理器都有浏览器插件，这些插件帮你将登录凭据输入网站的过程不仅方便，而且更加安全。与简单复制粘贴用户名和密码相比，这些插件将首先检查网站域是否与列出的条目相匹配，以防止冒充网站的网络钓鱼窃取登录凭据。 有哪些有用的数据整理工具？ 在数据整理那一节课程中，我们没有时间讨论一些数据整理工具，包括分别用于JSON和HTML数据的专用解析器， jq 和 pup 。Perl语言是另一个更高级的可以用于数据整理管道的工具。另一个技巧是使用 column -t 命令，可以将空格文本（不一定对齐）转换为对齐的文本。 一般来说，vim和Python是两个不常规的数据整理工具。对于某些复杂的多行转换，vim宏是非常有用的工具。你可以记录一系列操作，并根据需要重复执行多次，例如，在编辑的 讲义 (去年 视频 )中，有一个示例是使用vim宏将XML格式的文件转换为JSON。 对于通常以CSV格式显示的表格数据， Python pandas 库是一个很棒的工具。不仅因为它能让复杂操作的定义（如分组依据，联接或过滤器）变得非常容易，而且还便于根据不同属性绘制数据。它还支持导出多种表格格式，包括 XLS，HTML 或 LaTeX。另外，R语言(一种有争议的 不好 的语言）具有很多功能，可以计算数据的统计数字，这在管道的最后一步中非常有用。 ggplot2 是R中很棒的绘图库。 Docker和虚拟机有什么区别? Docker 基于容器这个更为概括的概念。关于容器和虚拟机之间最大的不同是，虚拟机会执行整个的 OS 栈，包括内核（即使这个内核和主机内核相同）。与虚拟机不同，容器避免运行其他内核实例，而是与主机分享内核。在Linux环境中，有LXC机制来实现，并且这能使一系列分离的主机像是在使用自己的硬件启动程序，而实际上是共享主机的硬件和内核。因此容器的开销小于完整的虚拟机。 另一方面，容器的隔离性较弱而且只有在主机运行相同的内核时才能正常工作。例如，如果你在macOS 上运行 Docker，Docker 需要启动 Linux虚拟机去获取初始的 Linux内核，这样的开销仍然很大。最后，Docker 是容器的特定实现，它是为软件部署而定制的。基于这些，它有一些奇怪之处：例如，默认情况下，Docker 容器在重启之间不会有以任何形式的存储。 不同操作系统的优缺点是什么，我们如何选择（比如选择最适用于我们需求的Linux发行版)? 关于Linux发行版，尽管有相当多的版本，但大部分发行版在大多数使用情况下的表现是相同的。 可以使用任何发行版去学习 Linux 与 UNIX 的特性和其内部工作原理。 发行版之间的根本区别是发行版如何处理软件包更新。 某些版本，例如 Arch Linux 采用滚动更新策略，用了最前沿的软件包（bleeding-edge），但软件可能并不稳定。另外一些发行版（如Debian，CentOS 或 Ubuntu LTS）其更新策略要保守得多，因此更新的内容会更稳定，但会牺牲一些新功能。我们建议你使用 Debian 或 Ubuntu 来获得简单稳定的台式机和服务器体验。 Mac OS 是介于 Windows 和 Linux 之间的一个操作系统，它有很漂亮的界面。但是，Mac OS 是基于BSD 而不是 Linux，因此系统的某些部分和命令是不同的。 另一种值得体验的是 FreeBSD。虽然某些程序不能在 FreeBSD 上运行，但与 Linux 相比，BSD 生态系统的碎片化程度要低得多，并且说明文档更加友好。 除了开发Windows应用程序或需要使用某些Windows系统更好支持的功能（例如对游戏的驱动程序支持）外，我们不建议使用 Windows。 对于双系统，我们认为最有效的是 macOS 的 bootcamp，长期来看，任何其他组合都可能会出现问题，尤其是当你结合了其他功能比如磁盘加密。 使用 Vim 编辑器 VS Emacs 编辑器? 我们三个都使用 vim 作为我们的主要编辑器。但是 Emacs 也是一个不错的选择，你可以两者都尝试，看看那个更适合你。Emacs 不使用 vim 的模式编辑，但是这些功能可以通过 Emacs 插件像 Evil 或 Doom Emacs 来实现。 Emacs的优点是可以用Lisp语言进行扩展（Lisp比vim默认的脚本语言vimscript要更好用）。 机器学习应用的提示或技巧? 课程的一些经验可以直接用于机器学习程序。 就像许多科学学科一样，在机器学习中，你需要进行一系列实验，并检查哪些数据有效，哪些无效。 你可以使用 Shell 轻松快速地搜索这些实验结果，并且以合理的方式汇总。这意味着需要在限定时间内或使用特定数据集的情况下，检查所有实验结果。通过使用JSON文件记录实验的所有相关参数，使用我们在本课程中介绍的工具，这件事情可以变得极其简单。 最后，如果你不使用集群提交你的 GPU 作业，那你应该研究如何使该过程自动化，因为这是一项非常耗时的任务，会消耗你的精力。 还有更多的 Vim 小窍门吗？ 更多的窍门： 插件 - 花时间去探索插件。有很多不错的插件修复了vim的缺陷或者增加了能够与现有vim工作流结合的新功能。关于这部分内容，资源是 VimAwesome 和其他程序员的dotfiles。 标记 - 在vim里你可以使用 m<X> 为字母 X 做标记，之后你可以通过 '<X> 回到标记位置。这可以让你快速定位到文件内或文件间的特定位置。 导航 - Ctrl+O 和 Ctrl+I 命令可以使你在最近访问位置前后移动。 撤销树 - vim 有不错的更改跟踪机制，不同于其他的编辑器，vim存储变更树，因此即使你撤销后做了一些修改，你仍然可以通过撤销树的导航回到初始状态。一些插件比如 gundo.vim 和 undotree 通过图形化来展示撤销树。 时间撤销 - :earlier 和 :later 命令使得你可以用时间而非某一时刻的更改来定位文件。 持续撤销 - 是一个默认未被开启的vim的内置功能，它在vim启动之间保存撤销历史，需要配置在 .vimrc 目录下的 undofile 和 undodir ，vim会保存每个文件的修改历史。 热键（Leader Key） - 热键是一个用于用户自定义配置命令的特殊按键。这种模式通常是按下后释放这个按键（通常是空格键）并与其他的按键组合去实现一个特殊的命令。插件也会用这些按键增加它们的功能，例如，插件UndoTree使用 <Leader> U 去打开撤销树。 高级文本对象 - 文本对象比如搜索也可以用vim命令构成。例如， d/<pattern> 会删除下一处匹配 pattern 的字符串， cgn 可以用于更改上次搜索的关键字。 2FA是什么，为什么我需要使用它? 双因子验证（Two Factor Authentication 2FA）在密码之上为帐户增加了一层额外的保护。为了登录，你不仅需要知道密码，还必须以某种方式\"证明\"可以访问某些硬件设备。最简单的情形是可以通过接收手机的 SMS 来实现（尽管 SMS 2FA 存在 已知问题 ）。我们推荐使用 YubiKey 之类的 U2F 方案。 对于不同的 Web 浏览器有什么评价? 2020的浏览器现状是，大部分的浏览器都与 Chrome 类似，因为它们都使用同样的引擎(Blink)。 Microsoft Edge 同样基于 Blink，至于 Safari 基于 WebKit(与Blink类似的引擎)，这些浏览器仅仅是更糟糕的 Chorme 版本。不管是在性能还是可用性上，Chorme 都是一款很不错的浏览器。如果你想要替代品，我们推荐 Firefox。Firefox 与 Chorme 的在各方面不相上下，并且在隐私方面更加出色。 有一款目前还没有完成的叫 Flow 的浏览器，它实现了全新的渲染引擎，有望比现有引擎速度更快。 参考 课程列表","tags":"Others","url":"pages/2020/09/27/Coding-Tools-QA/","loc":"pages/2020/09/27/Coding-Tools-QA/"},{"title":"编程工具之Vim","text":"Vim编辑器 编辑模式 Vim的设计以大多数时间都花在阅读、浏览和进行少量编辑改动为基础，因此它具有多种操作模式： 正常模式 ：在文件中四处移动光标进行修改 插入模式 ：插入文本 替换模式 ：替换文本 可视化（一般，行，块）模式 ：选中文本块 命令模式 ：用于执行命令 在不同的操作模式下， 键盘敲击的含义也不同。比如， x 在插入模式会插入字母 x ，但是在正常模式 会删除当前光标所在下的字母，在可视模式下则会删除选中文块。 在默认设置下，Vim会在左下角显示当前的模式。 Vim启动时的默认模式是正常模式。通常你会把大部分 时间花在正常模式和插入模式。 你可以按下 <ESC> （逃脱键） 从任何其他模式返回正常模式。 在正常模式，键入 i 进入插入 模式， R 进入替换模式， v 进入可视（一般）模式， V 进入可视（行）模式， <C-v> （Ctrl-V, 有时也写作 &#94;V ）进入可视（块）模式， : 进入命令模式。 因为你会在使用 Vim 时大量使用 <ESC> 键，可以考虑把大小写锁定键重定义成逃脱键 （ MacOS 教程 ）。 基本操作 插入文本 在正常模式， 键入 i 进入插入模式。 现在 Vim 跟很多其他的编辑器一样， 直到你键入 <ESC> 返回正常模式。 你只需要掌握这一点和上面介绍的所有基知识就可以使用 Vim 来编辑文件了 （虽然如果你一直停留在插入模式内不一定高效）。 缓存， 标签页， 窗口 Vim 会维护一系列打开的文件，称为 \"缓存\"。 一个 Vim 会话包含一系列标签页，每个标签页包含 一系列窗口 （分隔面板）。每个窗口显示一个缓存。 跟网页浏览器等其他你熟悉的程序不一样的是， 缓存和窗口不是一一对应的关系； 窗口只是视角。 一个缓存可以在 多个 窗口打开，甚至在同一 个标签页内的多个窗口打开。这个功能其实很好用， 比如在查看同一个文件的不同部分的时候。 Vim 默认打开一个标签页，这个标签也包含一个窗口。 命令行 在正常模式下键入 : 进入命令行模式。 在键入 : 后，你的光标会立即跳到屏幕下方的命令行。 这个模式有很多功能， 包括打开， 保存， 关闭文件， 以及 退出 Vim 。 :q 退出 （关闭窗口） :w 保存 （写） :wq 保存然后退出 :e {文件名} 打开要编辑的文件 :ls 显示打开的缓存 :help {标题} 打开帮助文档 :help :w 打开 :w 命令的帮助文档 :help w 打开 w 移动的帮助文档 Vim 的接口其实是一种编程语言 Vim 最重要的设计思想是 Vim 的界面本身是一个程序语言。 键入操作 （以及他们的助记名） 本身是命令， 这些命令可以组合使用。 这使得移动和编辑更加高效，特别是一旦形成肌肉记忆。 移动 多数时候你会在正常模式下，使用移动命令在缓存中导航。在 Vim 里面移动也被成为 \"名词\"， 因为它们指向文字块。 基本移动: hjkl （左， 下， 上， 右） 词： w （下一个词）， b （词初）， e （词尾） 行： 0 （行初）， &#94; （第一个非空格字符）， $ （行尾） 屏幕： H （屏幕首行）， M （屏幕中间）， L （屏幕底部） 翻页： Ctrl-u （上翻）， Ctrl-d （下翻） 文件： gg （文件头）， G （文件尾） 行数： :{行数}<CR> 或者 {行数}G ({行数}为行数) 杂项： % （找到配对，比如括号或者 /* */ 之类的注释对） 查找： f{字符} ， t{字符} ， F{字符} ， T{字符} 查找/到 向前/向后 在本行的{字符} , / ; 用于导航匹配 搜索: /{正则表达式} , n / N 用于导航匹配 选择 可视化模式: 可视化 可视化行 可视化块 可以用移动命令来选中。 编辑 所有你需要用鼠标做的事， 你现在都可以用键盘：采用编辑命令和移动命令的组合来完成。 这就是 Vim 的界面开始看起来像一个程序语言的时候。Vim 的编辑命令也被称为 \"动词\"， 因为动词可以施动于名词。 i 进入插入模式 但是对于操纵/编辑文本，不单想用退格键完成 O / o 在之上/之下插入行 d{移动命令} 删除 {移动命令} 例如， dw 删除词, d$ 删除到行尾, d0 删除到行头。 c{移动命令} 改变 {移动命令} 例如， cw 改变词 比如 d{移动命令} 再 i x 删除字符 （等同于 dl ） s 替换字符 （等同于 xi ） 可视化模式 + 操作 选中文字, d 删除 或者 c 改变 u 撤销, <C-r> 重做 y 复制 / \"yank\" （其他一些命令比如 d 也会复制） p 粘贴 更多值得学习的: 比如 ~ 改变字符的大小写 计数 你可以用一个计数来结合\"名词\" 和 \"动词\"， 这会执行指定操作若干次。 3w 向前移动三个词 5j 向下移动5行 7dw 删除7个词 修饰语 你可以用修饰语改变 \"名词\" 的意义。修饰语有 i ， 表示 \"内部\" 或者 \"在内\"， 和 a ， 表示 \"周围\"。 ci( 改变当前括号内的内容 ci[ 改变当前方括号内的内容 da' 删除一个单引号字符窗， 包括周围的单引号 自定义 Vim Vim 由一个位于 ~/.vimrc 的文本配置文件 （包含 Vim 脚本命令）。 你可能会启用很多基本 设置。 我们提供一个文档详细的基本设置， 你可以用它当作你的初始设置。 我们推荐使用这个设置因为 它修复了一些 Vim 默认设置奇怪行为。 在 这儿 下载我们的设置， 然后将它保存成 ~/.vimrc . Vim 能够被重度自定义， 花时间探索自定义选项是值得的。 你可以参考其他人的在 GitHub 上共享的设置文件， 比如， 你的授课人的 Vim 设置 ( Anish , Jon (uses neovim ), Jose )。 有很多好的博客文章也聊到了这个话题。 尽量不要复制粘贴别人的整个设置文件， 而是阅读和理解它， 然后采用对你有用的部分。 扩展 Vim Vim 有很多扩展插件。 跟很多互联网上已经过时的建议相反， 你 不 需要在 Vim 使用一个插件 管理器（从 Vim 8.0 开始）。 你可以使用内置的插件管理系统。 只需要创建一个 ~/.vim/pack/vendor/start/ 的文件夹， 然后把插件放到这里 （比如通过 git clone ）。 以下是一些我们最爱的插件： ctrlp.vim : 模糊文件查找 ack.vim : 代码搜索 nerdtree : 文件浏览器 vim-easymotion : 魔术操作 我们尽量避免在这里提供一份冗长的插件列表。 你可以查看讲师们的开源的配置文件 ( Anish , Jon , Jose ) 来看看我们使用的其他插件。 浏览 Vim Awesome 来了解一些很棒的插件。 这个话题也有很多博客文章： 搜索 \"best Vim plugins\"。 Vim 进阶 这里我们提供了一些展示这个编辑器能力的例子。我们无法把所有的这样的事情都教给你， 但是你 可以在使用中学习。 一个好的对策是: 当你在使用你的编辑器的时候感觉 \"一定有更好的方法来做这个\"， 那么很可能真的有： 上网搜寻一下。 搜索和替换 :s （替换） 命令 （ 文档 ）。 %s/foo/bar/g 在整个文件中将 foo 全局替换成 bar %s/\\[.*\\](\\(.*\\))/\\1/g 将有命名的 Markdown 链接替换成简单 URLs 多窗口 用 :sp / :vsp 来分割窗口 同一个缓存可以在多个窗口中显示。 宏 q{字符} 来开始在寄存器 {字符} 中录制宏 q 停止录制 @{字符} 重放宏 宏的执行遇错误会停止 {计数}@{字符} 执行一个宏 {计数} 次 宏可以递归 首先用 q{字符}q 清除宏 录制该宏， 用 @{字符} 来递归调用该宏 （在录制完成之前不会有任何操作） 例子： 将 xml 转成 json ( file ) 一个有 \"name\" / \"email\" 键对象的数组 用一个 Python 程序？ 用 sed / 正则表达式 g/people/d %s/<person>/{/g %s/<name>\\(.*\\)<\\/name>/\"name\": \"\\1\",/g … Vim 命令 / 宏 Gdd , ggdd 删除第一行和最后一行 格式化最后一个元素的宏 （寄存器 e ） 跳转到有 <name> 的行 qe&#94;r\"f>s\": \"<ESC>f<C\"<ESC>q 格式化一个人的宏 跳转到有 <person> 的行 qpS{<ESC>j@eA,<ESC>j@ejS},<ESC>q 格式化一个人然后转到另外一个人的宏 跳转到有 <person> 的行 qq@pjq 执行宏到文件尾 999@q 手动移除最后的 , 然后加上 [ 和 ] 分隔符 扩展资料 vimtutor 是一个 Vim 安装时自带的教程 Vim Adventures 是一个学习使用 Vim 的游戏 Vim Tips Wiki Vim Advent Calendar 有很多 Vim 小技巧 Vim Golf 是用 Vim 的用户界面作为程序语言的 code golf Vi/Vim Stack Exchange Vim Screencasts Practical Vim （书） 参考 课程列表","tags":"Others","url":"pages/2020/09/27/Coding-Tools-Vim/","loc":"pages/2020/09/27/Coding-Tools-Vim/"},{"title":"Python进阶上","text":"Python种基本类型的比较： List is a collection which is ordered and mutable. Allows duplicate members. Tuple is a collection which is ordered and immutable. Allows duplicate members. Set is a collection which is unordered and unindexed. No duplicate members. Dictionary is a collection which is unordered, mutable and indexed. No duplicate members. Strings are immutable sequences of Unicode code points. List Python中的list是一个有序容器，容纳不同类型的数据（但推荐列表内数据类型相同)，同时其是可变类型的． 创建列表 list_1 = [ \"banana\" , \"cherry\" , \"apple\" ] print ( list_1 ) # Or create an empty list with the list function list_2 = list () print ( list_2 ) # Lists allow different data types list_3 = [ 5 , True , \"apple\" ] print ( list_3 ) # Lists allow duplicates list_4 = [ 0 , 0 , 1 , 1 ] print ( list_4 ) 内置方法 修改列表的方法尽量使用内置方法，内置方法效率较高 my_list = [ \"banana\" , \"cherry\" , \"apple\" ] # len() : get the number of elements in a list print ( \"Length:\" , len ( my_list )) # append() : adds an element to the end of the list my_list . append ( \"orange\" ) # insert() : adds an element at the specified position my_list . insert ( 1 , \"blueberry\" ) print ( my_list ) # pop() : removes and returns the item at the given position, default is the last item item = my_list . pop () print ( \"Popped item: \" , item ) # remove() : removes an item from the list my_list . remove ( \"cherry\" ) # Value error if not in the list print ( my_list ) # clear() : removes all items from the list my_list . clear () print ( my_list ) # reverse() : reverse the items my_list = [ \"banana\" , \"cherry\" , \"apple\" ] my_list . reverse () print ( 'Reversed: ' , my_list ) # sort() : sort items in ascending order my_list . sort () print ( 'Sorted: ' , my_list ) # use sorted() to get a new list, and leave the original unaffected. # sorted() works on any iterable type, not just lists my_list = [ \"banana\" , \"cherry\" , \"apple\" ] new_list = sorted ( my_list ) # create list with repeated elements list_with_zeros = [ 0 ] * 5 print ( list_with_zeros ) # concatenation list_concat = list_with_zeros + my_list print ( list_concat ) # convert string to list string_to_list = list ( 'Hello' ) print ( string_to_list ) 复制列表 注意拷贝列表内容还是拷贝引用 list_org = [ \"banana\" , \"cherry\" , \"apple\" ] # this just copies the reference to the list, so be careful list_copy = list_org # now modifying the copy also affects the original list_copy . append ( True ) print ( list_copy ) print ( list_org ) # use copy(), or list(x) to actually copy the list # slicing also works: list_copy = list_org[:] list_org = [ \"banana\" , \"cherry\" , \"apple\" ] list_copy = list_org . copy () # list_copy = list(list_org) # list_copy = list_org[:] # now modifying the copy does not affect the original list_copy . append ( True ) print ( list_copy ) print ( list_org ) 列表切片 # a[start:stop:step], default step is 1 a = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ] b = a [ 1 : 3 ] # Note that the last index is not included print ( b ) b = a [ 2 :] # until the end print ( b ) b = a [: 3 ] # from beginning print ( b ) a [ 0 : 3 ] = [ 0 ] # replace sub-parts, you need an iterable here print ( a ) b = a [:: 2 ] # start to end with every second item print ( b ) a = a [:: - 1 ] # reverse the list with a negative step: print ( a ) b = a [:] # copy a list with slicing print ( b ) Tuple Tuple又称为元组，和List列表类似，主要区别在于元组是不可变类型．不可变意味着元组中的元素无法被重新赋值．使用元组而非列表的有如下原因： Generally used for objects that belong together. Use tuple for heterogeneous (different) datatypes and list for homogeneous (similar) datatypes. Since tuple are immutable, iterating through tuple is slightly faster than with list. Tuples with their immutable elements can be used as key for a dictionary. This is not possible with lists. If you have data that doesn't change, implementing it as tuple will guarantee that it remains write-protected. 创建元组 tuple_1 = ( \"Max\" , 28 , \"New York\" ) tuple_2 = \"Linda\" , 25 , \"Miami\" # Parentheses are optional # Special case: a tuple with only one element needs to have a comma at the end, # otherwise it is not recognized as tuple tuple_3 = ( 25 ,) print ( tuple_1 ) print ( tuple_2 ) print ( tuple_3 ) # Or convert an iterable (list, dict, string) with the built-in tuple function tuple_4 = tuple ([ 1 , 2 , 3 ]) print ( tuple_4 ) 不可变解释 元组不提供修改元素的方法，其中的item本身无法被赋值，即其指向的对象id（类似内存地址)无法改变，但是若元组中元素item自身是可变类型的，元素本身可以改变． Python中可变类型的解释： python中对可变数据类型的定义为： 当该数据类型的对应变量的值发生了改变，那么它对应的内存地址不发生改变，就称可变数据类型 。包括：set（集合）、list（列表）、dict（字典） In [ 7 ]: a = ( 1 ,[ 2 , 3 ]) In [ 8 ]: a [ 1 ] Out [ 8 ]: [ 2 , 3 ] In [ 9 ]: a [ 1 ] = [ 1 , 2 , 3 ] --------------------------------------------------------------------------- TypeError Traceback ( most recent call last ) < ipython - input - 9 - f8fa7e0d45e2 > in < module > ----> 1 a [ 1 ] = [ 1 , 2 , 3 ] TypeError : 'tuple' object does not support item assignment In [ 10 ]: a [ 1 ] . append ( 3 ) In [ 11 ]: a Out [ 11 ]: ( 1 , [ 2 , 3 , 3 ]) 以此执行下面指令，可以理解一下浅拷贝和深拷贝 a = [ 1 ] # shadow copy b = a b is a # True,has same address id ( a ) id ( b ) # deep copy,a point to another memory address a = a + [ 2 ] a id ( a ) # b's address doesn't change id ( b ) 内置方法 my_tuple = ( 'a' , 'p' , 'p' , 'l' , 'e' ,) # len() : get the number of elements in a tuple print ( len ( my_tuple )) # count(x) : Return the number of items that is equal to x print ( my_tuple . count ( 'p' )) # index(x) : Return index of first item that is equal to x print ( my_tuple . index ( 'l' )) # repetition my_tuple = ( 'a' , 'b' ) * 5 print ( my_tuple ) # concatenation my_tuple = ( 1 , 2 , 3 ) + ( 4 , 5 , 6 ) print ( my_tuple ) # convert list to a tuple and vice versa my_list = [ 'a' , 'b' , 'c' , 'd' ] list_to_tuple = tuple ( my_list ) print ( list_to_tuple ) tuple_to_list = list ( list_to_tuple ) print ( tuple_to_list ) # convert string to tuple string_to_tuple = tuple ( 'Hello' ) print ( string_to_tuple ) # Result \"\"\" 5 2 3 ('a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b') (1, 2, 3, 4, 5, 6) ('a', 'b', 'c', 'd') ['a', 'b', 'c', 'd'] ('H', 'e', 'l', 'l', 'o') \"\"\" 元组切片 # a[start:stop:step], default step is 1 a = ( 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ) b = a [ 1 : 3 ] # Note that the last index is not included print ( b ) b = a [ 2 :] # until the end print ( b ) b = a [: 3 ] # from beginning print ( b ) b = a [:: 2 ] # start to end with every second item print ( b ) b = a [:: - 1 ] # reverse tuple # don't change a ,create a new tuple and assign it to b print ( b ) # Result \"\"\" (2, 3) (3, 4, 5, 6, 7, 8, 9, 10) (1, 2, 3) (1, 3, 5, 7, 9) (10, 9, 8, 7, 6, 5, 4, 3, 2, 1) \"\"\" 元组解包 在Python中互换两个变量的值，如 a,b = b,a 就是等号右侧将b,a自动打包为元组 (b,a) ，赋值给左侧后再自动解包，同样的，Python中函数返回多个值，也是隐式的将多个值打包为元组，并返回一个元组． # number of variables have to match number of tuple elements tuple_1 = ( \"Max\" , 28 , \"New York\" ) name , age , city = tuple_1 print ( name ) print ( age ) print ( city ) # tip: unpack multiple elements to a list with * my_tuple = ( 0 , 1 , 2 , 3 , 4 , 5 ) item_first , * items_between , item_last = my_tuple print ( item_first ) print ( items_between ) print ( item_last ) # Result \"\"\" Max 28 New York 0 [1, 2, 3, 4] 5 \"\"\" 元组列表对比 容纳同样的数据，元组的占用空间和迭代速度更高 # compare the size import sys my_list = [ 0 , 1 , 2 , \"hello\" , True ] my_tuple = ( 0 , 1 , 2 , \"hello\" , True ) print ( sys . getsizeof ( my_list ), \"bytes\" ) print ( sys . getsizeof ( my_tuple ), \"bytes\" ) # compare the execution time of a list vs. tuple creation statement import timeit print ( timeit . timeit ( stmt = \"[0, 1, 2, 3, 4, 5]\" , number = 1000000 )) print ( timeit . timeit ( stmt = \"(0, 1, 2, 3, 4, 5)\" , number = 1000000 )) # Result \"\"\" 104 bytes 88 bytes 0.12474981700000853 0.014836141000017733 \"\"\" Dictionary 字典是无序的、可变的、可索引的一种数据类型。 字典创建 my_dict = { \"name\" : \"Max\" , \"age\" : 28 , \"city\" : \"New York\" } print ( my_dict ) # or use the dict constructor, note: no quotes necessary for keys my_dict_2 = dict ( name = \"Lisa\" , age = 27 , city = \"Boston\" ) print ( my_dict_2 ) 常用方法 删除字典元素 my_dict = { \"name\" : \"Max\" , \"age\" : 28 , \"city\" : \"New York\" } # delete a key-value pair del my_dict [ \"email\" ] # this returns the value and removes the key-value pair print ( \"popped value:\" , my_dict . pop ( \"age\" )) # return and removes the last inserted key-value pair # (in versions before Python 3.7 it removes an arbitrary pair) print ( \"popped item:\" , my_dict . popitem ()) print ( my_dict ) # clear() : remove all pairs # my_dict.clear() 检查key是否存在 my_dict = { \"name\" : \"Max\" , \"age\" : 28 , \"city\" : \"New York\" } # use if .. in .. if \"name\" in my_dict : print ( my_dict [ \"name\" ]) # use try except try : print ( my_dict [ \"firstname\" ]) except KeyError : print ( \"No key found\" ) 迭代字典元素 # loop over keys for key in my_dict : print ( key , my_dict [ key ]) # loop over keys for key in my_dict . keys (): print ( key ) # loop over values for value in my_dict . values (): print ( value ) # loop over keys and values for key , value in my_dict . items (): print ( key , value ) 复制字典 dict_org = { \"name\" : \"Max\" , \"age\" : 28 , \"city\" : \"New York\" } # this just copies the reference to the dict, so be careful dict_copy = dict_org # now modifying the copy also affects the original dict_copy [ \"name\" ] = \"Lisa\" print ( dict_copy ) print ( dict_org ) # use copy(), or dict(x) to actually copy the dict dict_org = { \"name\" : \"Max\" , \"age\" : 28 , \"city\" : \"New York\" } dict_copy = dict_org . copy () # dict_copy = dict(dict_org) # now modifying the copy does not affect the original dict_copy [ \"name\" ] = \"Lisa\" print ( dict_copy ) print ( dict_org ) 合并两个字典 # Use the update() method to merge 2 dicts # existing keys are overwritten, new keys are added my_dict = { \"name\" : \"Max\" , \"age\" : 28 , \"email\" : \"max@xyz.com\" } my_dict_2 = dict ( name = \"Lisa\" , age = 27 , city = \"Boston\" ) my_dict . update ( my_dict_2 ) print ( my_dict ) 可能的Key类型 任何不可变类型都可以作为字典的key，包括数字、字符串。元组如果所有元素都是不可变的，也可以作为key。 # use numbers as key, but be careful my_dict = { 3 : 9 , 6 : 36 , 9 : 81 } # do not mistake the keys as indices of a list, e.g my_dict[0] is not possible here print ( my_dict [ 3 ], my_dict [ 6 ], my_dict [ 9 ]) # use a tuple with immutable elements (e.g. number, string) my_tuple = ( 8 , 7 ) my_dict = { my_tuple : 15 } print ( my_dict [ my_tuple ]) # print(my_dict[8, 7]) # a list is not possible because it is not immutable # this will raise an Error: # my_list = [8, 7] # my_dict = {my_list: 15} Sets A Set is an unordered collection data type that is unindexed, mutable, and has no duplicate elements. 创建集合 my_set = { \"apple\" , \"banana\" , \"cherry\" } print ( my_set ) # or use the set function and create from an iterable, e.g. list, tuple, string my_set_2 = set ([ \"one\" , \"two\" , \"three\" ]) my_set_2 = set (( \"one\" , \"two\" , \"three\" )) print ( my_set_2 ) my_set_3 = set ( \"aaabbbcccdddeeeeeffff\" ) print ( my_set_3 ) # careful: an empty set cannot be created with {}, as this is interpreted as dict # use set() instead a = {} print ( type ( a )) a = set () print ( type ( a )) 常用方法 添加元素 my_set = set () # use the add() method to add elements my_set . add ( 42 ) my_set . add ( True ) my_set . add ( \"Hello\" ) # note: the order does not matter, and might differ when printed print ( my_set ) # nothing happens when the element is already present: my_set . add ( 42 ) print ( my_set ) 移除元素 # remove(x): removes x, raises a KeyError if element is not present my_set = { \"apple\" , \"banana\" , \"cherry\" } my_set . remove ( \"apple\" ) print ( my_set ) # KeyError: # my_set.remove(\"orange\") # discard(x): removes x, does nothing if element is not present my_set . discard ( \"cherry\" ) my_set . discard ( \"blueberry\" ) print ( my_set ) # clear() : remove all elements my_set . clear () print ( my_set ) # pop() : return and remove a random element a = { True , 2 , False , \"hi\" , \"hello\" } print ( a . pop ()) print ( a ) 交集和并集 不改变原有集合，只是会产生新的集合 odds = { 1 , 3 , 5 , 7 , 9 } evens = { 0 , 2 , 4 , 6 , 8 } primes = { 2 , 3 , 5 , 7 } # union() : combine elements from both sets, no duplication # note that this does not change the two sets u = odds . union ( evens ) print ( u ) # intersection(): take elements that are in both sets i = odds . intersection ( evens ) print ( i ) i = odds . intersection ( primes ) print ( i ) i = evens . intersection ( primes ) print ( i ) 差集 setB = { 1 , 2 , 3 , 10 , 11 , 12 } # difference() : returns a set with all the elements from the setA that are not in setB. diff_set = setA . difference ( setB ) print ( diff_set ) # A.difference(B) is not the same as B.difference(A) diff_set = setB . difference ( setA ) print ( diff_set ) # symmetric_difference() : returns a set with all the elements that are in setA and setB but not in both diff_set = setA . symmetric_difference ( setB ) print ( diff_set ) # A.symmetric_difference(B) = B.symmetric_difference(A) diff_set = setB . symmetric_difference ( setA ) print ( diff_set ) 更新集合（交/并/差） setA = { 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 } setB = { 1 , 2 , 3 , 10 , 11 , 12 } # update() : Update the set by adding elements from another set. setA . update ( setB ) print ( setA ) # intersection_update() : Update the set by keeping only the elements found in both setA = { 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 } setA . intersection_update ( setB ) print ( setA ) # difference_update() : Update the set by removing elements found in another set. setA = { 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 } setA . difference_update ( setB ) print ( setA ) # symmetric_difference_update() : Update the set by only keeping the elements found in either set, but not in both setA = { 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 } setA . symmetric_difference_update ( setB ) print ( setA ) # Note: all update methods also work with other iterables as argument, e.g lists, tuples # setA.update([1, 2, 3, 4, 5, 6]) 复制集合 set_org = { 1 , 2 , 3 , 4 , 5 } # this just copies the reference to the set, so be careful set_copy = set_org # now modifying the copy also affects the original set_copy . update ([ 3 , 4 , 5 , 6 , 7 ]) print ( set_copy ) print ( set_org ) # use copy() to actually copy the set set_org = { 1 , 2 , 3 , 4 , 5 } set_copy = set_org . copy () # now modifying the copy does not affect the original set_copy . update ([ 3 , 4 , 5 , 6 , 7 ]) print ( set_copy ) print ( set_org ) 子集/不相交 setA = { 1 , 2 , 3 , 4 , 5 , 6 } setB = { 1 , 2 , 3 } # issubset(setX): Returns True if setX contains the set print ( setA . issubset ( setB )) print ( setB . issubset ( setA )) # True # issuperset(setX): Returns True if the set contains setX print ( setA . issuperset ( setB )) # True print ( setB . issuperset ( setA )) # isdisjoint(setX) : Return True if both sets have a null intersection, i.e. no same elements setC = { 7 , 8 , 9 } print ( setA . isdisjoint ( setB )) print ( setA . isdisjoint ( setC )) Frozenset不可变集合 Frozen set是一种不可变的集合，其在创建以后，集合中的元素id不可变 a = frozenset ([ 0 , 1 , 2 , 3 , 4 ]) # The following is not allowed: # a.add(5) # a.remove(1) # a.discard(1) # a.clear() # Also no update methods are allowed: # a.update([1,2,3]) # Other set operations work odds = frozenset ({ 1 , 3 , 5 , 7 , 9 }) evens = frozenset ({ 0 , 2 , 4 , 6 , 8 }) print ( odds . union ( evens )) print ( odds . intersection ( evens )) print ( odds . difference ( evens )) Strings 字符串是一个字符序列，是不可变类型，对于同一个id下的字符串不可变。 字符串创建 # use singe or double quotes my_string = 'Hello' my_string = \"Hello\" my_string = \"I' m a 'Geek'\" # escaping backslash my_string = 'I \\' m a \"Geek\"' my_string = 'I \\' m a \\' Geek \\' ' print ( my_string ) # triple quotes for multiline strings my_string = \"\"\"Hello World\"\"\" print ( my_string ) # backslash if you want to continue in the next line my_string = \"Hello \\ World\" print ( my_string ) 访问字符或者子串 my_string = \"Hello World\" # get character by referring to index b = my_string [ 0 ] print ( b ) # Substrings with slicing b = my_string [ 1 : 3 ] # Note that the last index is not included print ( b ) b = my_string [: 5 ] # from beginning print ( b ) b = my_string [ 6 :] # until the end print ( b ) b = my_string [:: 2 ] # start to end with every second item print ( b ) b = my_string [:: - 1 ] # reverse the string with a negative step: print ( b ) 常用方法 my_string = \" Hello World \" # remove white space my_string = my_string . strip () print ( my_string ) # number of characters print ( len ( my_string )) # Upper and lower cases print ( my_string . upper ()) print ( my_string . lower ()) # startswith and endswith print ( \"hello\" . startswith ( \"he\" )) print ( \"hello\" . endswith ( \"llo\" )) # find first index of a given substring, -1 otherwise print ( \"Hello\" . find ( \"o\" )) # count number of characters/substrings print ( \"Hello\" . count ( \"e\" )) # replace a substring with another string (only if the substring is found) # Note: The original string stays the same message = \"Hello World\" new_message = message . replace ( \"World\" , \"Universe\" ) print ( new_message ) # split the string into a list my_string = \"how are you doing\" a = my_string . split () # default argument is \" \" print ( a ) my_string = \"one,two,three\" a = my_string . split ( \",\" ) print ( a ) # join elements of a list into a string my_list = [ 'How' , 'are' , 'you' , 'doing' ] a = ' ' . join ( my_list ) # the given string is the separator, e.g. ' ' between each argument print ( a ) 格式化字符串 # use braces as placeholders a = \"Hello {0} and {1} \" . format ( \"Bob\" , \"Tom\" ) print ( a ) # the positions are optional for the default order a = \"Hello {} and {} \" . format ( \"Bob\" , \"Tom\" ) print ( a ) a = \"The integer value is {} \" . format ( 2 ) print ( a ) # some special format rules for numbers a = \"The float value is {0:.3f} \" . format ( 2.1234 ) print ( a ) a = \"The float value is {0:e} \" . format ( 2.1234 ) print ( a ) a = \"The binary value is {0:b} \" . format ( 2 ) print ( a ) # old style formatting by using % operator print ( \"Hello %s and %s \" % ( \"Bob\" , \"Tom\" )) # must be a tuple for multiple arguments val = 3.14159265359 print ( \"The decimal value is %d \" % val ) print ( \"The float value is %f \" % val ) print ( \"The float value is %.2f \" % val ) # since python3.6 # Use the variables directly inside the braces. name = \"Eric\" age = 25 a = f \"Hello, { name } . You are { age } .\" print ( a ) pi = 3.14159 a = f \"Pi is { pi : .3f } \" print ( a ) # f-Strings are evaluated at runtime, which allows expressions a = f \"The value is { 2 * 60 } \" print ( a ) More on immutability and concatenation # since a string is immutable, adding strings with +, or += always # creates a new string, and therefore is expensive for multiple operations # --> join method is much faster from timeit import default_timer as timer my_list = [ \"a\" ] * 1000000 # bad start = timer () a = \"\" for i in my_list : a += i end = timer () print ( \"concatenate string with + : %.5f \" % ( end - start )) # good start = timer () a = \"\" . join ( my_list ) end = timer () print ( \"concatenate string with join(): %.5f \" % ( end - start )) 参考 Python-Notebook","tags":"Python","url":"pages/2020/09/26/Python-Advanced-1/","loc":"pages/2020/09/26/Python-Advanced-1/"},{"title":"Microstack 基本使用","text":"Microstack 简介 Microstack 是在 ubuntu 平台上快速部署 Openstack 环境的工具，其通过 snap 构建，而 snap 安装目录是一个独立的只读文件系统，这就导致难以改动代码进行调试。 因此，Microstack 环境只适用于 Openstack 初学者学习命令行和数据库等等，调试的话可以通告 gdb 调试，而不便于通过 pdb 调试，因为无法修改源文件，并在文件还中加断点。 Microstack 是目前 Ubuntu 上最简洁的 Openstack 配置工具，可以在笔记本上部署单节点环境用于学习，也可以在多台设备上部署多节点环境。 Microstack 安装 需要在终端科学上网，否则 snap 镜像很慢,目前支持到 Openstack 上游的 stein 版本． # 配置代理 export https_proxy = http://127.0.0.1:port && export http_proxy = http://127.0.0.1:port \" # 安装snap包 sudo snap install --classic --beta microstack # 初始化microstack环境 sudo microstack.init --auto # 初始化完成后会自动启动Openstack进程 # 查看相关进程 systemctl list-units | grep microstack # 可以看到microstack进程的状态 # 如果全部是loaded active running，表示服务正常启动 Microstack 基本使用 Microstack 由于是 Snap 镜像，可以手动关闭和开启 其源代码在 /snap/microstack/196/lib/python3.6/site-packages 但由于 snap 只读文件系统，代码无法修改 此外，其命令行 Client 都加上了 Microstack 前缀 一些常用的命令行 # 在.bashrc文件中配置别名 alias openstack = \"microstack.openstack\" source ~/.bashrc # 查看帮助 openstack --help # 数据库操作，查看nova库 sudo microstack.mysql nova # 几个数据库包括: # |cinder | # | glance | # | keystone | # | mysql | # | neutron | # | nova | # | nova_api | # | nova_cell0 # 查看配置文件和数据库地址 cd /var/snap/microstack # 配置文件，可修改配置文件重启进程 cd /var/snap/microstack/common/etc 也可以在浏览器访问 web 界面 http://10.20.20.1/ 默认用户名密码是 admin 和 keystone 总结 Microstack 目前不适用于开发者编辑调试代码，只适用于学习者熟悉环境，用于在自己的电脑上快速部署． 参考 Microstack 文档","tags":"Openstack","url":"pages/2020/09/20/Microstack-Usage/","loc":"pages/2020/09/20/Microstack-Usage/"},{"title":"Python 生成ankidroid单词表/语音包","text":"Ankidroid和插件 ankidroid下载网址 https://apps.ankiweb.net/ 目前还是推荐下载anki2.0旧版，2.1版插件支持的不全。 必装插件列表： Awesome TTS :301952613 Review Heatmap :1771074083 Night Mode :1496166067 词库分享 anki-deck 从网络抓取单词/例句文本 示例从 轻松背单词网站 抓取，网站上涵盖了从小学到GRE以及各个专业的单词和例句。内容非常丰富，希望大家多支持这个良心网站。本抓取方法仅作示例，侵删。 网站爬取需要两个参数： book_id group_id 具体爬取代码参见我的github, anki_spider 食用方法 将爬取下来的文本，保存为文本文件 编辑单词书的字段，可自定义样式进行美化 打开anki,选择 文件 ——> 导入，文件类型为以tab分割的文件类型，并允许使用HTML，匹配对应字段 导入结果示意图 用awesomeTTS批量添加单词和句子发音 导出制作好的ankidroid单词包，并分享 完毕","tags":"Python","url":"pages/2019/06/02/anki-python/","loc":"pages/2019/06/02/anki-python/"},{"title":"STM32笔记1","text":"STM32F103学习笔记 GPIO初始化和读写操作 STM32的GPIO引脚有多种模式使用，在使用前需要进行配置。 LED灯实验 #include \"stm32f10x.h\" #define LED GPIO_Pin_All void delay ( u32 i ) { while ( i -- ); } //LED的GPIO初始化程序 void LED_Init () { GPIO_InitTypeDef GPIO_InitStructure ; //GPIO时钟初始化 SystemInit (); RCC_APB2PeriphClockCmd ( RCC_APB2Periph_GPIOC , ENABLE ); //配置GPIO模式和端口 GPIO_InitStructure . GPIO_Pin = LED ; GPIO_InitStructure . GPIO_Mode = GPIO_Mode_Out_PP ; //推挽模式 GPIO_InitStructure . GPIO_Speed = GPIO_Speed_50MHz ; GPIO_Init ( GPIOC , & GPIO_InitStructure ); //初始化GPIO } void led_display () { GPIO_SetBits ( GPIOC , LED ); delay ( 6000000 ); GPIO_ResetBits ( GPIOC , LED ); delay ( 6000000 ); } int main () { LED_Init (); while ( 1 ) { led_display (); } } 蜂鸣器实验 使用无源蜂鸣器 #include \"stm32f10x.h\" #define BZ GPIO_Pin_5 //PB5 定义端口PB5 void delay ( u32 i ) { while ( i -- ); } void BEEP_Init () { GPIO_InitTypeDef GPIO_InitStructure ; //GPIO时钟初始化 SystemInit (); RCC_APB2PeriphClockCmd ( RCC_APB2Periph_GPIOB , ENABLE ); //配置GPIO模式和端口 GPIO_InitStructure . GPIO_Pin = BZ ; GPIO_InitStructure . GPIO_Mode = GPIO_Mode_Out_PP ; //推挽模式 GPIO_InitStructure . GPIO_Speed = GPIO_Speed_50MHz ; GPIO_Init ( GPIOB , & GPIO_InitStructure ); //初始化GPIO } void sound ( u32 i ) // i= 5000救护车，i=1000电动车 { while ( i -- ) { GPIO_SetBits ( GPIOB , BZ ); delay ( i ); GPIO_ResetBits ( GPIOB , BZ ); delay ( i ); } } int main () { BEEP_Init (); //端口初始化 while ( 1 ) { sound ( 5000 ); } } SysTick实验 系统滴答计时器比延时函数更加精确，可移植性更高。systick定时器是24位的定时器，当定时器计数到0时，将自动从RELOAD寄存器中重装定时器初值，如果开启了中断，此时还会产生异常中断信号。 定时器必须要一个时钟来驱动，systick定时器的时钟来源时系统时钟，不过它的时钟可以选择成直接取自系统时钟，也可以将系统时钟8分频后再赋给systick定时器。 systick定时器的操作步骤： 设置systick定时器的时钟源 设置systick定时器的重装初始值（若使用中断，就将中断使能打开） 清零systick定时器计数器的值 打开systick定时器 #include \"stm32f10x.h\" #define LED GPIO_Pin_All void delay_us ( u32 i ) { u32 temp ; SysTick -> LOAD = 9 * i ; //设置重装数值 72MHz时 SysTick -> CTRL = 0x01 ; //使能，减到零时无动作，采用外部时钟源(8分频系统时钟) SysTick -> VAL = 0 ; //清零计数器 do { temp = SysTick -> CTRL ; //读取当前计数值 } while (( temp & 0x01 ) && ( ! ( temp & ( 1 << 16 )))); //与运算取出指定位的数值 //实际上就是CTRL寄存器的第1位为0或第16位为1时，退出循环 SysTick -> CTRL = 0 ; //关闭计数器 SysTick -> VAL = 0 ; //清空计数器 } void delay_ms ( u32 i ) { u32 temp ; SysTick -> LOAD = 9000 * i ; //设置重装数值, 72MHZ时 SysTick -> CTRL = 0x01 ; //使能，减到零是无动作，采用外部时钟源 SysTick -> VAL = 0 ; //清零计数器 do { temp = SysTick -> CTRL ; //读取当前倒计数值 } while (( temp & 0x01 ) && ( ! ( temp & ( 1 << 16 )))); //等待时间到达 SysTick -> CTRL = 0 ; //关闭计数器 SysTick -> VAL = 0 ; //清空计数器 } //LED的GPIO初始化程序 void LED_Init () { GPIO_InitTypeDef GPIO_InitStructure ; //GPIO时钟初始化 SystemInit (); RCC_APB2PeriphClockCmd ( RCC_APB2Periph_GPIOC , ENABLE ); //配置GPIO模式和端口 GPIO_InitStructure . GPIO_Pin = LED ; GPIO_InitStructure . GPIO_Mode = GPIO_Mode_Out_PP ; //推挽模式 GPIO_InitStructure . GPIO_Speed = GPIO_Speed_50MHz ; GPIO_Init ( GPIOC , & GPIO_InitStructure ); //初始化GPIO } int main () { u8 i ; LED_Init (); while ( 1 ) { for ( i = 0 ; i < 8 ; i ++ ) { GPIO_Write ( GPIOC ,( u16 ) ~ ( 0x01 << i )); delay_ms ( 1000 ); //精确延时1秒 } } } 系统时钟实验 STM32一共可以有4个时钟源 HSI（High Speed Inner)内部自带的高速时钟，单片机启动后默认使用的时钟源 HSE (High Speed External)外部高速时钟，大多数时8M晶振 LSE（Low Speed External）外部低速时钟，给单片机内部RTC提供时钟 LSI，内部低速时钟，主要给单片机内部RTC和看门狗提供时钟 STM32的系统时钟源，有3个时钟来源： 直接来自内部高速时钟HSI 直接来自外部的高速时钟HSE 将HSI或HSE进行处理，倍频之后的PLL时钟（Phase-Locked Loops锁相环） STM32设置RCC（复位和时钟控制）时钟的步骤 以设置外部高速时钟作为PLL输入，然后以PLL作为时钟源的例子： 复位RCC时钟 打开HSE外部高速时钟 监测HSE外部高速时钟是否开启成功 设置FLASH读写 设置AHB总线的分频，还有APB1和APB2的分频， 注 ：AHB和APB2最大频率72MHz，APB1做大频率36MHz 设置HSE外部高速时钟作为PLLs时钟的时钟输入 设置PLL时钟的倍频倍数 打开PLL时钟的使能 等待PLL时钟的开启成功 将系统时钟源设置为PLL时 等待时钟源切换成功 //在上一个实验基础上 //自定义系统时钟 void RCC_HSE_Configuration () { RCC_DeInit (); //重置RCC外设寄存器 RCC_HSEConfig ( RCC_HSE_ON ); //设置外部高速晶振（HSE） if ( RCC_WaitForHSEStartUp () == SUCCESS ) //等待HSE起振 { RCC_HCLKConfig ( RCC_SYSCLK_Div1 ); //设置AHB时钟 RCC_PCLK1Config ( RCC_HCLK_Div2 ); //设置低速AHB时钟（PCLK1） RCC_PCLK2Config ( RCC_HCLK_Div1 ); //设置高速AHB时钟（PCLK2） RCC_PLLConfig ( RCC_PLLSource_HSE_Div2 , RCC_PLLMul_9 ); //设置PLL时钟源及倍频系数，实际系统时钟36MHz RCC_PLLCmd ( ENABLE ); //PLL使能 while ( RCC_GetFlagStatus ( RCC_FLAG_PLLRDY ) == RESET ); //检查指定的RCC标志位设置与否，PLL就绪 RCC_SYSCLKConfig ( RCC_SYSCLKSource_PLLCLK ); //设置系统时钟（SYSCLK） while ( RCC_GetSYSCLKSource () 网易 != 0x08 ); //返回用作系统时钟的时钟源，0x08，PLL作为系统时钟 } } int main () { LED_Init (); RCC_HSE_Configuration (); //自定义系统时钟，修改倍频或分频参数 while ( 1 ) { GPIO_SetBits ( GPIOC , LED ); delay_ms ( 500 ); //精确延时0.5s，实际延时1s GPIO_ResetBits ( GPIOC , LED ); delay_ms ( 500 ); } } 按键实验 注意按键5ms-10ms左右的延时消抖，注意按键的上拉还是下拉 #include \"stm32f10x.h\" #define K_UP GPIO_Pin_0 //PA0 #define K_DOWN GPIO_Pin_3 //PE3 #define K_LEFT GPIO_Pin_2 //PE2 #define K_RIGHT GPIO_Pin_4 //PE4 #define k_up GPIO_ReadInputDataBit(GPIOA,K_UP) //获取按键的状态 #define k_down GPIO_ReadInputDataBit(GPIOE,K_DOWN) #define k_left GPIO_ReadInputDataBit(GPIOE,K_LEFT) #define k_right GPIO_ReadInputDataBit(GPIOE,K_RIGHT) #define LED GPIO_Pin_All void delay_ms ( u32 i ) { u32 temp ; SysTick -> LOAD = 9000 * i ; //设置重装数值, 72MHZ时 SysTick -> CTRL = 0x01 ; //使能，减到零是无动作，采用外部时钟源 SysTick -> VAL = 0 ; //清零计数器 do { temp = SysTick -> CTRL ; //读取当前倒计数值 } while (( temp & 0x01 ) && ( ! ( temp & ( 1 << 16 )))); //等待时间到达 SysTick -> CTRL = 0 ; //关闭计数器 SysTick -> VAL = 0 ; //清空计数器 } //LED的GPIO初始化程序 void LED_Init () { GPIO_InitTypeDef GPIO_InitStructure ; //GPIO时钟初始化 SystemInit (); RCC_APB2PeriphClockCmd ( RCC_APB2Periph_GPIOC , ENABLE ); //配置GPIO模式和端口 GPIO_InitStructure . GPIO_Pin = LED ; GPIO_InitStructure . GPIO_Mode = GPIO_Mode_Out_PP ; //推挽模式 GPIO_InitStructure . GPIO_Speed = GPIO_Speed_50MHz ; GPIO_Init ( GPIOC , & GPIO_InitStructure ); //初始化GPIO } void key_init ( void ) { GPIO_InitTypeDef GPIO_InitStructure ; SystemInit (); //开启GPIO时钟 RCC_APB2PeriphClockCmd ( RCC_APB2Periph_GPIOA | RCC_APB2Periph_GPIOE , ENABLE ); /* 配置GPIO的模式和IO口 */ GPIO_InitStructure . GPIO_Pin = K_UP ; //选择你要设置的IO口 GPIO_InitStructure . GPIO_Mode = GPIO_Mode_IPD ; //下拉输入 GPIO_InitStructure . GPIO_Speed = GPIO_Speed_50MHz ; //设置传输速率 GPIO_Init ( GPIOA , & GPIO_InitStructure ); /* 初始化GPIO */ GPIO_InitStructure . GPIO_Pin = K_DOWN | K_LEFT | K_RIGHT ; GPIO_InitStructure . GPIO_Mode = GPIO_Mode_IPU ; //上拉输入 GPIO_InitStructure . GPIO_Speed = GPIO_Speed_50MHz ; GPIO_Init ( GPIOE , & GPIO_InitStructure ); GPIO_ResetBits ( GPIOA , K_UP ); //对K_UP初始化输出0 } void key_pros () //按键处理函数 { if ( k_up == 1 ) //判断按键k_up是否按下 { delay_ms ( 10 ); //消抖处理 if ( k_up == 1 ) //再次判断按键k_up是否按下 { GPIO_Write ( GPIOC ,( u16 ) 0xfe ); } while ( k_up ); //等待按键松开 } if ( k_down == 0 ) { delay_ms ( 10 ); if ( k_down == 0 ) { GPIO_Write ( GPIOC ,( u16 )( 0xfd )); } while ( ! k_down ); } if ( k_left == 0 ) { delay_ms ( 10 ); if ( k_left == 0 ) { GPIO_Write ( GPIOC ,( u16 )( 0xfb )); } while ( ! k_left ); } if ( k_right == 0 ) { delay_ms ( 10 ); if ( k_right == 0 ) { GPIO_Write ( GPIOC ,( u16 )( 0xf7 )); } while ( ! k_right ); } } int main () { LED_Init (); //LED初始化 key_init (); //按键端口初始化函数 GPIO_Write ( GPIOC ,( u16 )( 0xff )); while ( 1 ) { key_pros (); //按键处理函数 } } 数码管实验 #include \"stm32f10x.h\" #define smg_duan (GPIO_Pin_0|GPIO_Pin_1|GPIO_Pin_2|GPIO_Pin_3|GPIO_Pin_4|GPIO_Pin_5|GPIO_Pin_6|GPIO_Pin_7) //PC0~PC7 u8 smgduan [ 16 ] = { 0x3F , 0x06 , 0x5B , 0x4F , 0x66 , 0x6D , 0x7D , 0x07 , 0x7F , 0x6F , 0x77 , 0x7C , 0x39 , 0x5E , 0x79 , 0x71 }; //0~F 数码管段选数据 void delay_ms ( u32 i ) { u32 temp ; SysTick -> LOAD = 9000 * i ; //设置重装数值, 72MHZ时 SysTick -> CTRL = 0x01 ; //使能，减到零是无动作，采用外部时钟源 SysTick -> VAL = 0 ; //清零计数器 do { temp = SysTick -> CTRL ; //读取当前倒计数值 } while (( temp & 0x01 ) && ( ! ( temp & ( 1 << 16 )))); //等待时间到达 SysTick -> CTRL = 0 ; //关闭计数器 SysTick -> VAL = 0 ; //清空计数器 } void smg_init () { GPIO_InitTypeDef GPIO_InitStructure ; //声明一个结构体变量，用来初始化GPIO /* 开启GPIO时钟 */ RCC_APB2PeriphClockCmd ( RCC_APB2Periph_GPIOC , ENABLE ); /* 配置GPIO的模式和IO口 */ GPIO_InitStructure . GPIO_Pin = smg_duan ; //选择你要设置的IO口 GPIO_InitStructure . GPIO_Mode = GPIO_Mode_Out_PP ; GPIO_InitStructure . GPIO_Speed = GPIO_Speed_50MHz ; GPIO_Init ( GPIOC , & GPIO_InitStructure ); /* 初始化GPIO */ } void static_smg_display () //静态数码管显示 { u8 i ; for ( i = 0 ; i < 16 ; i ++ ) { GPIO_Write ( GPIOC ,( u16 )( ~ smgduan [ i ])); delay_ms ( 1000 ); } } int main () { smg_init (); //数码管端口初始化函数 while ( 1 ) { static_smg_display (); //静态数码管显示 } } 中断和定时器 外部中断实验 注意将端口引脚映射到外部中断线路上，注意配置中断优先级 #include \"stm32f10x.h\" #include \"stm32f10x_exti.h\" #include \"misc.h\" #define k_left GPIO_Pin_2 #define LED GPIO_Pin_All void delay_ms ( u32 i ) { u32 temp ; SysTick -> LOAD = 9000 * i ; //设置重装数值, 72MHZ时 SysTick -> CTRL = 0x01 ; //使能，减到零是无动作，采用外部时钟源 SysTick -> VAL = 0 ; //清零计数器 do { temp = SysTick -> CTRL ; //读取当前倒计数值 } while (( temp & 0x01 ) && ( ! ( temp & ( 1 << 16 )))); //等待时间到达 SysTick -> CTRL = 0 ; //关闭计数器 SysTick -> VAL = 0 ; //清空计数器 } //LED的GPIO初始化程序 void led_init ( void ) { GPIO_InitTypeDef GPIO_InitStructure ; //GPIO时钟初始化 SystemInit (); RCC_APB2PeriphClockCmd ( RCC_APB2Periph_GPIOC , ENABLE ); //配置GPIO模式和端口 GPIO_InitStructure . GPIO_Pin = LED ; GPIO_InitStructure . GPIO_Mode = GPIO_Mode_Out_PP ; //推挽模式 GPIO_InitStructure . GPIO_Speed = GPIO_Speed_50MHz ; GPIO_Init ( GPIOC , & GPIO_InitStructure ); //初始化GPIO GPIO_SetBits ( GPIOC , LED ); } void exti_init ( void ) //外部中断初始化 { GPIO_InitTypeDef GPIO_InitStructure ; EXTI_InitTypeDef EXTI_InitStructure ; NVIC_InitTypeDef NVIC_InitStructure ; SystemInit (); //开启GPIO时钟，用到了时引脚复用功能，开启复用时钟 RCC_APB2PeriphClockCmd ( RCC_APB2Periph_AFIO , ENABLE ); RCC_APB2PeriphClockCmd ( RCC_APB2Periph_GPIOE , ENABLE ); GPIO_InitStructure . GPIO_Pin = k_left ; GPIO_InitStructure . GPIO_Mode = GPIO_Mode_IPU ; //上拉输入 GPIO_InitStructure . GPIO_Speed = GPIO_Speed_50MHz ; GPIO_Init ( GPIOE , & GPIO_InitStructure ); //选择外部中断线路对应的GPIO管脚，此处是PE2 GPIO_EXTILineConfig ( GPIO_PortSourceGPIOE , GPIO_PinSource2 ); //设置外部中断的模式 EXTI_InitStructure . EXTI_Line = EXTI_Line2 ; EXTI_InitStructure . EXTI_Mode = EXTI_Mode_Interrupt ; EXTI_InitStructure . EXTI_Trigger = EXTI_Trigger_Falling ; //下降沿触发 EXTI_InitStructure . EXTI_LineCmd = ENABLE ; EXTI_Init ( & EXTI_InitStructure ); //设置NVIC参数（nested vector interrupt config) NVIC_PriorityGroupConfig ( NVIC_PriorityGroup_1 ); NVIC_InitStructure . NVIC_IRQChannel = EXTI2_IRQn ; //打开EXTI2的全局中断 NVIC_InitStructure . NVIC_IRQChannelPreemptionPriority = 0 ; //抢占优先级为0 NVIC_InitStructure . NVIC_IRQChannelSubPriority = 0 ; //响应优先级为0 NVIC_InitStructure . NVIC_IRQChannelCmd = ENABLE ; //使能 NVIC_Init ( & NVIC_InitStructure ); } void EXTI2_IRQHandler ( void ) //外部中断2中断处理函数 { if ( EXTI_GetITStatus ( EXTI_Line2 ) == SET ) { EXTI_ClearITPendingBit ( EXTI_Line2 ); //清除EXTI2线路挂起位 delay_ms ( 10 ); //消抖 if ( GPIO_ReadInputDataBit ( GPIOE , k_left ) == Bit_RESET ) //k_left按下 { delay_ms ( 10 ); //消抖 if ( GPIO_ReadOutputDataBit ( GPIOC , GPIO_Pin_0 ) == Bit_RESET ) { //LED熄灭 GPIO_SetBits ( GPIOC , GPIO_Pin_0 ); } else { //LED发光 GPIO_ResetBits ( GPIOC , GPIO_Pin_0 ); } } while ( GPIO_ReadInputDataBit ( GPIOE , GPIO_Pin_2 ) == 0 ); //等待按键松开 } } int main () { led_init (); exti_init (); while ( 1 ); } 定时器实验 STM32中一共有11个定时器： 2个高级控制定时器 （TIM1,TIM8) 4个通用定时器 （TIM2-TIM5） 2个基本定时器 (TIM6,TIm7) 2个看门狗定时器 1个系统滴答定时器 注 :TIM2-TIM7的时钟由APB1产生，TIM1和TIM8是由APB2产生时钟 //实现1s流水灯实验 #include \"stm32f10x.h\" #include \"stm32f10x_tim.h\" #include \"stm32f10x_exti.h\" #include \"misc.h\" #define LED GPIO_Pin_All //LED的GPIO初始化程序 void led_init ( void ) { GPIO_InitTypeDef GPIO_InitStructure ; //GPIO时钟初始化 SystemInit (); RCC_APB2PeriphClockCmd ( RCC_APB2Periph_GPIOC , ENABLE ); //配置GPIO模式和端口 GPIO_InitStructure . GPIO_Pin = LED ; GPIO_InitStructure . GPIO_Mode = GPIO_Mode_Out_PP ; //推挽模式 GPIO_InitStructure . GPIO_Speed = GPIO_Speed_50MHz ; GPIO_Init ( GPIOC , & GPIO_InitStructure ); //初始化GPIO } void time_init () { TIM_TimeBaseInitTypeDef TIM_TimeBaseInitStructure ; //定时器初始化结构体 NVIC_InitTypeDef NVIC_InitStructure ; //开启定时器3时钟 RCC_APB1PeriphClockCmd ( RCC_APB1Periph_TIM3 , ENABLE ); TIM_ClearITPendingBit ( TIM3 , TIM_IT_Update ); //清除TIMx的中断待处理位：TIM中断源 TIM_TimeBaseInitStructure . TIM_Period = 2000 ; //设置自动重装寄存器周期的值 TIM_TimeBaseInitStructure . TIM_Prescaler = 36000 - 1 ; //设置作为TIMx时钟频率的预分频值，2Khz计数频率 TIM_TimeBaseInitStructure . TIM_ClockDivision = 0 ; //设置时钟分割：TDTS = Tck_tim TIM_TimeBaseInitStructure . TIM_CounterMode = TIM_CounterMode_Up ; //向上计数模式 TIM_TimeBaseInit ( TIM3 , & TIM_TimeBaseInitStructure ); TIM_Cmd ( TIM3 , ENABLE ); //使能或失能TIMx外设 //设置中断参数，并打开中断 TIM_ITConfig ( TIM3 , TIM_IT_Update , ENABLE ); //使能或失能指定的TIM中断 //设置NVIC参数 NVIC_PriorityGroupConfig ( NVIC_PriorityGroup_1 ); NVIC_InitStructure . NVIC_IRQChannel = TIM3_IRQn ; //打开EXTI2的全局中断 NVIC_InitStructure . NVIC_IRQChannelPreemptionPriority = 0 ; //抢占优先级为0 NVIC_InitStructure . NVIC_IRQChannelSubPriority = 1 ; //响应优先级为1 NVIC_InitStructure . NVIC_IRQChannelCmd = ENABLE ; //使能 NVIC_Init ( & NVIC_InitStructure ); } void TIM3_IRQHandler () //定时器3的中断处理函数 { static u8 i = 0 ; TIM_ClearITPendingBit ( TIM3 , TIM_IT_Update ); GPIO_Write ( GPIOC ,( u16 ) ~ ( 0x01 << i ++ )); if ( i == 8 ) i = 0 ; } int main () { time_init (); led_init (); while ( 1 ); }","tags":"Linux","url":"pages/2019/05/12/STM32-example-1/","loc":"pages/2019/05/12/STM32-example-1/"},{"title":"Matlab基础","text":"命令行基础 x = [ 1 , 2 , 3 ] x = 1 : 3 A = [ 1 , 2 ; 3 , 4 ; 5 , 6 ] B = ones ( 3 , 4 ) C = eye ( 4 ) #单位矩阵 D = zeros ( 3 , 4 ) #零矩阵 det ( C ) #行列式 x = inv ( A ) * b ' #解线性方程 , 等价于 A &#94; - 1 * b ' e = eig ( A ) #返回一个列向量，其中包含方阵 A 的特征值。 [ V , D ] = eig ( A ) #返回特征值的对角矩阵 D 和矩阵 V ，其列是对应的右特征向量，使得 A * V = V * D norm ( x ) #计算向量范数和矩阵范数 gallery () #生成测试矩阵 dot ( x , y ) #向量点乘 cross ( x , y ) #向量叉乘 A .* B #矩阵点乘（对应元素相同，要求两个矩阵大小相同） A * B #矩阵叉乘（要求 A的列数等于B的行数 ） whos #查看当前工作空间 class () #数据类型 函数 function y = sinh ( x ) %UNTITLED Summary of this function goes here % Detailed explanation goes here y = ( exp ( x ) - exp ( - x )) / 2 ; end 循环 >> for i = [ 1 3 5 7 9 ] disp ( i ); end >> E = randn ( 1000 , 1 ); >> SSE = 0 ; >> for i = 1 : 1000 SSE = SSE + E ( i ) * E ( i ); end >> SSE SSE = 983.5102 >> SSE / 1000 ans = 0.9835 #对一段程序计时 tic E = randn(1000,1) ; SSE = 0 ; for i = 1:1000 SSE = SSE + E ( i ) * E ( i ); end MSE = SSE/1000 ; toc #Elapsed time is 0.016618 seconds. # 和点乘比较速度 , 明显点乘较快 tic E = randn(1000,1) ; MSE = E .* E / 1000 ; toc # Elapsed time is 0.010042 seconds. 选择 x = 1 : 10 ; y = zeros ( 1 , 10 ); for i =1:10 if mod(x(i),2) == 0 y ( i ) = 1 ; else y(i) = 0 ; end end #另一种写法， Sum输出为18 X = 1 : 10 ; Sum = 0 ; for x = X #x会遍历X中的元素 if mod(x,3) == 0 Sum = Sum + x ; end end x = 1 : 10 found = 0 ; i = 0 ; while ~found i = i + 1 if x(i) == 8 disp ( 'I found it' ); found = 1 ; end end # or for i = 1 : 10 fprintf ( 'i = %d\\n' , i ); if x(i) ==8 disp ( 'i found it' ); break ; end end 数据结构 结构体 >> my_struct . name = 'niuhe' my_struct = name : 'niuhe' >> class ( my_struct ) ans = struct >> my_struct.age = 25 my_struct = name : 'niuhe' age : 25 >> class ( my_struct . name ) ans = char >> isfield(my_struct,'name') ans = 1 >> isfield(my_struct,'gender') ans = 0 >> rmfield(my_struct,'age') ans = name : 'niuhe' >> setfield ( my_struct , 'gender' , 'f' ) ans = name : 'niuhe' age : 25 gender : 'f' >> S = struct ( 'name' , 'bob' , 'age' , 32 , 'email' , '123@gmail.com' ) S = name : 'bob' age : 32 email : '123@gmail.com' 哈希表 >> my_cell { 1 } = 'hello world.' my_cell = 'hello world.' >> my_cell { 'A' } = [ 1 , 2 , 3 , 4 , 5 ] my_cell = Columns 1 through 9 'hello world.' [] [] [] [] [] [] [] [] Columns 10 through 20 [] [] [] [] [] [] [] [] [] [] [] Columns 21 through 31 [] [] [] [] [] [] [] [] [] [] [] Columns 32 through 42 [] [] [] [] [] [] [] [] [] [] [] Columns 43 through 53 [] [] [] [] [] [] [] [] [] [] [] Columns 54 through 64 [] [] [] [] [] [] [] [] [] [] [] Column 65 [ 1 x5 double ] >> my_cell { 1 } ans = hello world. >> my_cell { 'A' } ans = 1 2 3 4 5 plot画图 >> x = [ 0 0.1 0.2 0.3 ]; >> y = 1 : 4 ; >> plot ( x , y ); >> x = linspace ( 0 , 100 , 200 ); >> y = sin ( x ); >> plot ( x , y ); >> x = linspace ( 0 , 2 * pi , 100 ); >> y1 = sin ( x ); >> y2 = cos ( x ); >> plot ( x , y1 , x , y2 ); >> plot ( x , y1 , '-' , x , y2 , '.' ); >> plot ( x , y1 , '--' , x , y2 , '.' ); >> bar ( x ) #画柱状图 >> x = randn ( 1000 , 1 ) #生成1000 * 1的随机数矩阵，服从均值是0，方差是1的正太分布 >> hist ( x ) >> hist ( x , 50 ) >> x = 1 : 5 ; >> pie ( x ); >> x = linspace ( 0 , 2 * pi , 1000 ); >> y = 10 * sin ( x ) + randn ( 1 , 1000 ); >> plot ( x , y ); >> scatter ( x , y ); >> x = randn ( 1000 , 1 ) * 2 ; >> y = 5 * sin ( x ) + rand ( 1000 , 1 ); >> plot ( x , y ); >> scatter ( x , y ); subplot () #子图 surf () contour () title () xlabel () ylabel () 读写文件 CSV文件 csvread () csvwrite () # 保存现有工作空间 save () load ()","tags":"Others","url":"pages/2019/05/06/matlab-basic/","loc":"pages/2019/05/06/matlab-basic/"},{"title":"Virtualbox虚拟机连接雷达和UART串口","text":"目前ROS只支持Linux版，如果不方便装Linux主机，可以通过以太网桥接的方式获得雷达的数据帧；对一些串口传感器，也可以通过Serial to USB，然后在virtualbox里选择对应的USB设备进行调试。 本方法适用于通过以太网/WLAN来传送数据包的雷达。 使用Virtualbox里建立虚拟机，将雷达连接到主机电脑， 设置以太网的IP地址为雷达的目标地址 虚拟机桥接到对应的以太网 在虚拟机中测试收发数据帧 tcpdump","tags":"ROS","url":"pages/2019/05/06/virual-lidar/","loc":"pages/2019/05/06/virual-lidar/"},{"title":"Python3操作二维码图片","text":"python3中如何对二维码QRcode进行编码解码 通常对于二维码，我们需要进行两种操作： 将二维码图片扫描后解析成字符串 将字符串编码生成二维码图片 这是两个逆过程，在python2中，我们可以通过zbar这个第三方库实现两个功能。可以zbar并不支持python3，而且，zbar在window平台上的安装极其繁琐，有很多坑。 所以想通过python3处理二维码的过程中，查了很多资料。目前比较好的解决办法如下： 用 pyzbar 代替zbar解析二维码 安装： pip install pyzbar 这是可能的，因为pyzbar是一个围绕zbar库的基于ctypes的包装器，它包含在dll和Windows Python的轮子中。 使用 ： 网络上二维码图片解析 import requests import array from PIL import Image from io import BytesIO from pyzbar.pyzbar import decode # decode_result的格式是[Decoded(data='****',……)]，列表里包含一个nametuple def decode_qrcode ( url ) decode_result = decode ( Image . open ( BytesIO ( requests . get ( urls , headers = HEADERS ) . content )) return str ( decode_result [ 0 ] . data , encoding = 'utf-8' ) 本地二维码图片解析 from PIL import Image from pyzbar.pyzbar import decode def decode_qrcode ( url ) decode_result = decode ( Image . open ( 'filename' )) return str ( decode_result [ 0 ] . data , encoding = 'utf-8' ) 更详细用法参见 release页面 下载zbar.exe文件并安装，通过系统命令行调用来解码 下载地址： zbar-0.10-setup.exe 说明： 使用： import os os . system ( r 'C:\\zbarimg.exe -d d:\\Winapps\\Zbar\\Examples\\barcode.png' ) Linux平台上 qrtools 解码 注：这个方法我没用过。 安装： sudo apt-get install python-qrtools 使用： import qrtools qr = qrtools . QR () qr . decode ( \"horn.png\" ) print qr . data 用PyQRCode来生成二维码 安装： pip install pyqrcode 用法： import pyqrcode url = pyqrcode . create ( 'http://uca.edu' ) url . svg ( 'uca-url.svg' , scale = 8 ) 说明： pyqrcode具有完善的帮助文档和强大的功能，可以快速生产二维码图片,细节参考： Release页面 帮助文档 其他值得关注的内容 qreader 是一个正在开发中的项目，使用纯Python编写的二维码解析库，不依赖zbar。感兴趣的可以去提交PR。 免费的二维码编码解码API接口 http://api.qrserver.com/ Send a GET request of following form to our system to decode a QR code graphic (=to read a QR code from the web): http(s)://api.qrserver.com/v1/read-qr-code/?fileurl=[URL-encoded-webaddress-url-to-qrcode-image-file] http://www.7xiwang.com/Tools/Index 解码 api ： http : // www . 7 xiwang . com / WebService / QRCodeDecode api参数 ： base64img api请求类型 ： HttpPost 参数数据格式（ JSON ）：{ \"base64img\" : \"\" } api返回数据格式 （ JSON ）： 请求成功：{ \"status\" : \"1\" , \"text\" : \"\" } 请求失败：{ \"status\" : \"0\" , \"Msg\" : \"错误信息\" }","tags":"Python","url":"pages/2019/04/27/Python3-QRcode/","loc":"pages/2019/04/27/Python3-QRcode/"},{"title":"Linux进程——进程创建和同步控制","text":"Linux内核支持用户进程和内核进程两种进程。内核进程指完全运行在内核空间的进程，这种进程主要处理内核事务；用户进程一般运行在用户态，需要使用内核资源时，通过系统调用进入内核态，系统调用结束后，重新返回用户态。 创建进程 可通过fork函数创建子进程，理论上，父子进程拥有各自独立的用户空间。但Linux为了提高效率，采用 COW(copy on write) 算法。 fork函数原型如下: /* 成功：子进程pid返回给父进程，0返回给子进程 失败： -1返回给父进程，设置errno */ pid_t fork (); 案例：创建子进程 #include <unistd.h> #include <stdio.h> int glob = 10 ; int main () { int local ; pid_t pid ; local = 8 ; //向子进程的pid传值0 if (( pid = fork ()) == 0 ) { //子进程 sleep ( 1 ); printf ( \"i am in child process,%d \\n \" , getpid ()); } zijc else { //父进程 printf ( \"i am in father process,%d \\n \" , getpid ()); glob ++ ; local -- ; sleep ( 5 ); } printf ( \"pid = %d,glob = %d,localar = %d \\n \" , getpid (), glob , local ); return 0 ; } /*输出为： i am in father process,13023 i am in child process,13024 pid = 13024,glob = 10,localar = 8 pid = 13023,glob = 11,localar = 7 */ 当用fork()函数创建子进程时，Linux内核为子进程分配一个进程控制块task_struct。子进程的进程控制块用来存放子进程拥有的资源、管理信息和进程状态等。 此时，在父子进程没有对数据进行读写操作之前，父子进程共享用户地址空间。当父进程执行glob++，Linux内核采用COW算法，首先为子进程创建相应的数据区，接着内核 将父进程地址空间中的数据区相关页复制到子进程地址空间中数据区的相关页 ,此时，父子进程各自拥有独立的全局变量glob。 当执行local--语句，内核以同样方法在子进程用户地址空间的栈区的相应页建立复制 。而代码区是只读的，所以父子进程共享代码区，直接建立映射，不进行复制。 程序启动和结束 初始化程序 在加载可执行文件后，首先运行的是称为start-up的代码，此部分代码在程序链接为可执行程序时，由链接器加入，作用是从内核读取进程运行的环境信息，如环境变量、命令行参数等。 start-up完成初始化工作后，调用main函数，执行完进程后，通过exit函数结束进程。 结束进程 每个进程都有父进程，当子进程运行结束后，子进程进程僵尸状态，并向父进程发送SIGCHLD信号，通知子进程已经终止。在该状态下子进程几乎释放了所有内存资源，不能被重新调度，仅在进程列表中保留一个位置，只保留进程如何终止的一些状态信息，以供回收者使用。父进程可以通过调用 wait或waitpid函数 获取子进程的退出码，以便判断子进程结束的原因。由父进程释放子进程余下的所有资源。 但当父进程在子进程之前终止，子进程的父进程将更改为init进程，由init进程负责子进程的善后处理工作。 //终止进程,status返回值 void exit ( int status ); /* 登记终止处理函数，ANSI C规定，一个进程可以登记最多32个终止处理函数，这些函数由exit自动调用。exit以先进后出的方式调用atexit登记的函数，同一函数登记多次，也被调用多次。 根据ANSI C，exit首先调用终止处理函数，然后按需调用fclose，关闭所有打开的文件流，保证基于缓冲区的文件I/O操作完整性。 这样，在进程结束前，将未写入文件的缓冲区数据，通过exit函数进行保存。 func终止处理函数 成功返回0，否则非0 */ int atexit ( void ( * func )( void )); //直接结束进程，不进行任何其他处理 void _exit ( int status ); 案例：直接退出进程 #include <unistd.h> #include <stdio.h> int main () { printf ( \"output begin \\n \" ); printf ( \"content in buffer\" ); printf ( \"drop the buffer\" ); _exit ( 0 ); } 案例：登记终止处理函数 #include <stdio.h> #include <stdlib.h> static void my_exit1 ( void ) { printf ( \"first exit handler \\n \" ); } static void my_exit2 ( void ) { printf ( \"second exit handler \\n \" ); } int main ( void ) { if ( atexit ( my_exit2 ) != 0 ) printf ( \"can't register my_exit2\" ); if ( atexit ( my_exit1 ) != 0 ) printf ( \"can't register my_exit1\" ); if ( atexit ( my_exit1 ) != 0 ) printf ( \"can't register my_exit1\" ); printf ( \"main is done \\n \" ); return 0 ; } 进程同步控制 当创建一个子进程后， 父子进程的执行顺序无法控制 。当父子进程同事操作共享资源，不同的执行次序有可能导致不同的运行结果，从而出现数据不一致性。为解决这一问题，必须提供进程间的同步控制机制。 wait和waitpid可用来实现父子进程同步，用来等待子进程结束。 wait函数的功能是获取子进程如何终止的信息，清除子进程的剩余资源。父进程调用wait函数，进入阻塞队列，等待某个子进程的结束。当子进程结束，会产生结束状态字status,并向父进程发送SIGCHLD信号。 父进程收到SIGCHLD信号，若希望知道子进程结束状态，调用wait,否则忽略该信号。 /* 暂停执行，将子进程结束状态写入status中，并确认子进程已经结束 status 子进程状态 成功返回子进程PID，否则返回-1 */ pid_t wait ( int * status ); /* 等待指定子进程结束 pid 指定等待的子进程 <-1 pid所代表进程组中进程 -1 任何子进程 0 与该进程同组的进程 >0 进程标识符为pid的进程 status 保存子进程状态 options 等待方式 WNOHANG 进程不阻塞 WUNTRACED 当有子进程结束时返回 */ pid_t waitpid ( pid_t pid , int * status , int options ); 案例：依次等待多个子进程结束，并显示结束状态 #include <unistd.h> #include <stdio.h> #include <sys/wait.h> #include <stdlib.h> int main ( void ) { pid_t pid [ 10 ], wpid ; int child_status , i ; //创建5个子进程 for ( i = 0 ; i < 5 ; i ++ ) { if (( pid [ i ] = fork ()) == 0 ) exit ( 100 + i ); } //等待子进程结束，输出status for ( i = 0 ; i < 5 ; i ++ ) { wpid = waitpid ( pid [ i ], & child_status , 0 ); if ( WIFEXITED ( child_status )) printf ( \"Child %d exit with status %d \\n \" , wpid , WEXITSTATUS ( child_status )); else printf ( \"Child %d terminated abnormally \\n \" , wpid ); } return 0 ; }","tags":"Linux","url":"pages/2018/10/09/Linux-C-Process-2/","loc":"pages/2018/10/09/Linux-C-Process-2/"},{"title":"Linux进程——进程环境与加载可执行映像","text":"进程是程序的一次运行过程，除了进程虚拟地址空间和文件描述符等，进程控制块中还存放了进程运行的环境信息，包括用户、用户组、父进程、进程组和会话等。 用户和用户组 //获得当前进程实际用户ID pid_t getuid ( void ); //获得当前进程有效用户ID pid_t geteuid ( void ); //获得当前进程实际用户组ID pid_t getgid ( void ); //获得当前进程有效用户组ID pid_t getegid ( void ); 进程和进程组 获得父子进程ID //获得当前进程ID pid_t getpid ( void ); //获得父进程ID pid_t getppid ( void ); 进程组 有时，为了完成某个工作，需多个进程参与协作，为便于管理，可以将多个进程定义为一个进程组。一个进程组包含一个以上的进程，领头进程的进程ID等于进程组ID，进程组中不包含进程时，进程组自动消失。 会话 会话用于标识用户登录的每一个终端，每个登录终端都有一个会话ID与其对应； 会话包括控制进程（与终端建立连接的领头进程）、一个前台进程组和任意后台进程组。一个会话只能有一个控制终端，通常是登录到其上的终端设备或伪终端设备，产生在控制终端上的输入和信号将发送给会话的前台进程组中的所有进程。 如果调用setsid函数的进程不是进程组中的领头进程，则可建立新的会话，（可在子进程中建立新的会话），该进程成为领头会话，同时产生一个新的进程组，且该进程为新进程组的领头进程，但不拥有终端。 /* 获得进程所属会话ID 成功返回会话ID，错误返回-1 */ pid_t getsid ( pid_t pid ); /* 创建一个新的会话，使进程组ID等于该会话ID 成功返回新的进程组ID，否则-1 */ pid_t setsid ( void ); 案例：在子进程中创建新的领头会话 #include <unistd.h> #include <stdio.h> #include <stdlib.h> int main ( void ) { int p , pid ; printf ( \"now session id %d \\n\\n \" , getsid ( getpid ())); p = fork (); if ( p ) //父进程退出 exit ( 0 ); pid = setsid (); printf ( \"new session id %d \\n \" , pid ); return pid ; } 守护进程 守护进程是一种运行在后台，且不受任何终端影响的进程，因此，需要关闭 标准输入、标准输出、标准错误输出 的文件描述符.通常守护进程以服务进程的形式存在，例如web服务器。 同时要使守护进程脱离用户环境，所以要将工作目录修改为系统工作目录。 创建守护进程步骤： 创建子进程后结束父进程 在子进程中建立新的领头会话 修改工作目录和权限掩码信息 关闭文件描述符0,1,2 案例：创建一个守护进程 #include <unistd.h> #include <stdlib.h> #include <stdio.h> #include <sys/stat.h> int daemon_init () { pid_t pid ; char buf [ 80 ]; FILE * fout ; if (( pid = fork ()) < 0 ) return - 1 ; else if ( pid != 0 ) exit ( 0 ); //结束父进程 setsid (); //创建领头会话 system ( \"cd /\" ); //改变工作目录 umask ( 0 ); //清除权限掩码 close ( 0 ); //关闭文件描述符 close ( 1 ); close ( 2 ); getcwd ( buf , sizeof ( buf )); fout = fopen ( \"/tmp/result.txt\" , \"w\" ); fprintf ( fout , \"work dirctory is %s \\n \" , buf ); fprintf ( fout , \"daemon pid is %d \\n \" , getpid ()); fprintf ( fout , \"daemon parent pid is %d \\n \" , getppid ()); fclose ( fout ); return 0 ; } int main () { FILE * fout ; printf ( \"start init daemon ...\" ); daemon_init (); while ( 1 ) { fout = fopen ( \"/tmp/result.txt\" , \"a\" ); fputs ( \"i am still alive \\n \" , fout ); fflush ( fout ); sleep ( 1 ); } } 加载可执行映像 可执行映像是链接好的可执行的代码。 通常，子进程创建时，继承了父进程的资源，父子进程可以并发运行，它们由同一代码流程控制，具有相似行为。有时，希望子进程拥有独立代码流程，可以通过加载可执行二进制映像文件来实现。内核通过exec系统调用在进程中建立新的运行环境。 ELF格式 Linux系统中，采用ELF(Excutable and Linkable Format)，ELF有3中基本格式 可执行格式 目标文件(.o文件) 共享库（.so文件) 加载可执行文件 ELF的可执行文件的加载是通过系统调用exec完成的，当进程调用exec函数加载ELF可执行文件时，exec将以新加载程序的段替换当前进程的相应的正文、数据、堆和栈段；同时保留大部分的进程属性。例如进程ID、父进程ID、进程组ID、实际用户ID、会话ID、当前目录、文件描述符等。 但当加载可执行文件的SETUID或SETGID位被设置，进程的有效用户ID和有效用户组ID被设置为该文件的属主ID和属主用户组ID。 exec相关函数原型： #include <unistd.h> int execl ( const char * path , const char * arg ,...) int execv (.........)......... int execle (........) int execve (.........) int execlp (.........) int execvp (.........)","tags":"Linux","url":"pages/2018/10/09/Linux-C-Process-3/","loc":"pages/2018/10/09/Linux-C-Process-3/"},{"title":"Linux进程——地址空间","text":"可执行程序是存储在磁盘设备上由代码和数据按某种格式组织的静态实体，而进程是可被调度的代码的动态运行。在Linux系统中，在一个进程的生命周期里，都有各自的运行环境和所需的资源，这些信息储存在各自的进程控制块中。 进程控制块主要结构如下: 用户标识 进程和会话标识 虚拟地址管理 文件描述符表 信号 进程地址空间 在32位地址总线的计算机上，每个进程拥有4GB的虚拟地址空间。 可执行程序被加载至进程的用户虚拟地址空阿金，即将可执行程序中的代码段和数据段的内容复制到用户地址空间。为了执行程序，内核需在用户虚拟地址空间中建立一些辅助区域，例如堆区和栈区等，从而将用户虚拟地址空间划分为若干区域，分别为代码区、未初始化数据区、初始化数据区、环境变量和命令行参数区、堆区、栈区。不同区域中存储了不同的信息，有各自不同的属性。 代码区 包含指令序列和只读数据，没和在创建进程加载可执行二进制映像文件时，将这部分内容映射到进程的用户地址空间形成代码区。进程运行期间，代码区内容不会改变。 因此，一个可执行映像的多个进程可共享代码区，只需保持一个复制。 在可执行映像文件中，代码区的内容被保存在文本段中，文本段又称代码段。 未初始化数据区 在可执行二进制映像文件中，未初始化数据包括没有初始化的全局变量和静态局部变量，它们在映像文件中不占用储存空间，只保留其地址和大小信息。 若映像文件中存在未初始化数据段，内核创建进程时，在进程的用户地址空间中为其分配一块区域，用于进程运行过程中对未初始化数据的存取，成为未初始化数据区。 初始化数据区 初始化数据区包括已初始化的全局变量和静态局部变量。在映像文件中，初始化数据被组织在数据段中，内核将初始化数据段映射至用户地址空间形成初始化数据区。该区内容运行过程中会发生变化，一个程序的多个进程实体拥有各自的数据区。 堆heap 堆位于数据区和栈之间，用于应用程序的动态内存管理。Linux将动态内存的管理通过glibc实现。Linux的进程控制块中记录了虚拟内存各区域的地址信息，它们在进程初始化时由系统设置，其中包含堆的起始地址和结束地址。 在初始状态下，brk指针指向堆的顶部。堆区大小可以通过brk和sbrk函数调整。 栈stack 栈用来存放进程运行过程中的局部变量、函数返回地址、参数和进程上下文环境。 环境变量和命令行 环境变量继承自父进程，作用范围是进程本身及其子孙进程。命令行保存执行程序时的输入参数，它们都被保存在栈区域。 自由空间 堆栈之间的自由空间，内核可为进程创建新的区域用于加载共享库、映射共享内存和映射文件I/O等，可以通过mmap和munmap函数申请和释放。 环境变量/命令行参数 每个进程的环境变量以字符串的形式存放在数组中，数组地址存放在全局变量environ中，可通过getenv和putenv对环境变量进行存取。 命令行参数保存在用户地址空间的栈区域。 案例：显示当前进程所有环境变量 #include <stdio.h> int main ( int argc , char * argv []) { int i ; char ** ptr ; extern char ** environ ; for ( ptr = environ ; * ptr != NULL ; ptr ++ ) printf ( \"%s \\n \" , * ptr ); return 0 ; } 案例:使用getenv和putenv存取环境变量 #include <stdio.h> #include <stdlib.h> int main ( int argc , char * argv [], char * envp []) { int i ; extern char ** environ ; printf ( \"form argument envp \\n \" ); for ( i = 0 ; envp [ i ]; i ++ ) puts ( envp [ i ]); putenv ( \"HONE=/\" ); printf ( \" \\n From global variable environ \\n \" ); for ( i = 0 ; environ [ i ]; i ++ ) puts ( environ [ i ]); return 0 ; } 案例:显示所有命令行参数 #include <stdio.h> int main ( int argc , char * argv []) { int i ; for ( i = 0 ; i < argc ; i ++ ) printf ( \"argv[%d}:%s \\n \" , i , argv [ i ]); return 0 ; } 动态内存管理 堆介于栈和全局数据区之间，这部分空间用于进程的动态内存分配，堆采用自下向上生长。相关API函数如下： void * malloc ( size_t size ); void free ( void * ptr ); /* 设置堆区域的大小 pend设置数据区域的边界 incr扩展堆区域的字节数 对brk,成功返回0，否则-1 对sbrk成功返回原来的brk,否则-1 */ int brk ( void * pend ); void * sbrk ( int incr ); 案例:使用brk和sbrk调整heap大小 #include <stdio.h> #include <unistd.h> extern int etext , edata , end ; void foo ( int ); int main () { int ret ; void * bv ; printf ( \"text ends at %10p \\n \" , & etext ); printf ( \"initailized data ends at %10p \\n \" , & edata ); printf ( \"uninitialized data ends at %10p \\n \" , & end ); bv = sbrk ( 0 ); //当前堆区边界地址 printf ( \"Current break value is %10p \\n\\n \" , bv ); ret = brk ( bv + 512 ); puts ( \"heap incresed 512bytes\" ); printf ( \"brk returned ....%d \\n \" , ret ); bv = sbrk ( 0 ); //当前堆区边界地址 printf ( \"Current break value is %10p \\n\\n \" , bv ); foo ( 64 ); foo ( - 1024 ); return 0 ; } void foo ( int size ) { void * bv ; bv = sbrk ( size ); printf ( \"heap increased %dbytes \\n \" , size ); printf ( \"sbrk returned %10p \\n \" , bv ); bv = sbrk ( 0 ); //当前堆区边界地址 printf ( \"Current break value is %10p \\n\\n \" , bv ); } 注 通过brk、sbrk、mmap系统调用会频繁的触发软中断，使程序陷入内核态，比较消耗资源。为了较少系统调用产生的损耗，glibc采用内存池的设计，增加一个代理层，每次内存分配，优先从内存池中寻找一个大小相近的内存块(chunk),若内存池中无法提供，再向内核申请。 具体参考 glibc内存管理","tags":"Linux","url":"pages/2018/10/08/Linux-C-Process-1/","loc":"pages/2018/10/08/Linux-C-Process-1/"},{"title":"Linux信号处理——发送信号","text":"Linux提供了应用编程接口，通过这些接口，进程可以向其他进程或进程组发送信号。root权限的进程可以向任何进程发送信号，非root权限的进程智能向属于同一个回话或同一个用户的进程发送信号。 发送信号 常用的函数原型如下 /* 向进程发送信号 pid>0 进程ID为pid的进程 pid=0 同一进程组的进程 pid<0 && pid!=-1 进程组ID为-pid的所有进程 pid=-1 除发送给进程自身外，还发送给所有进程ID>1的进程 成功返回0，否则-1 */ int kill ( pid_t pid , int signo ); /*向进程本身发送信号，等价于kill(getpid(),sig),成功返回0，否则-1*/ int raise ( int signo ); /*向进程发送SIGABORT信号,默认情况下进程会退出*/ void abort ( void ); /* 向进程发送实时信号 pid 接收信号的进程ID，只能向一个进程发送信号 sig 指定即将发送的信号 val指定信号传递的参数 成功返回0，否则-1 */ int sigqueue ( pid_t pid , int sig , const union sigval val ); union sigval { int sival_int ; //传送一个整形数 void * sival_ptr ; //传送任何数据结构的指针 }; typedef struct { int si_signo ; int si_code ; union sigval si_value ; int si_errno ; pid_t si_pid ; uid_t si_uid ; void * si_addr ; int si_status ; int si_band ; } siginfo_t ; 案例:使用sigqueue发送带参数的信号 #include <signal.h> #include <stdio.h> #include <unistd.h> void SigHandler ( int signo , siginfo_t * info , void * context ) { printf ( \"%s \\n \" ,( char * ) info -> si_value . sival_ptr ); } int main () { struct sigaction sigAct ; sigval_t val ; char * pMsg = \"i still believe\" ; sigAct . sa_flags = SA_SIGINFO ; sigAct . sa_sigaction = SigHandler ; if ( sigaction ( SIGUSR1 , & sigAct , NULL ) ==- 1 ) { printf ( \"fail set sig_handler\" ); return 1 ; } val . sival_ptr = pMsg ; if ( sigqueue ( getpid (), SIGUSR1 , val ) ==- 1 ) { printf ( \"fail send sigqueue\" ); return 2 ; } sleep ( 3 ); } sleep睡眠延时 可以使用sleep函数将程序延迟一段时间后继续执行，其实现机制是： 调用alarm函数设置延迟时间 调用pause函数挂起进程，等待系统发送SIGALARM信号，当SIGALARM信号到达进程时，进程被唤醒。 /* 设置时间闹钟 seconds表示闹钟间隔时间，原有闹钟无效 若调用alarm函数前，进程已经设置了闹钟，则返回上一个闹钟剩余时间，否则返回0 */ unsigned int alarm ( unsigned int seconds ); //等待信号,进程收到信号后，执行信号处理函数，pause函数返回，原进程继续执行 void pause (); 案例：实现sleep函数 #include <stdio.h> #include <signal.h> #include <unistd.h> #include <stdlib.h> void alarmhandler ( int signum ) { printf ( \"Alarm received from kernel \\n \" ); } int mysleep ( unsigned int time ) { printf ( \"about to sleep for %d seconds \\n \" , time ); signal ( SIGALRM , alarmhandler ); alarm ( time ); pause (); printf ( \"continue from alarm \\n \" ); return 0 ; } int main ( int argc , char * argv []) { printf ( \"start run the program. \\n \" ); unsigned int time = atoi ( argv [ 1 ]); mysleep ( time ); printf ( \"i am awake,haha \\n \" ); return 0 ; } 间隔计时器 alarm函数计时单位是秒，当延迟时间到来，只能触发一次。不能满足需要高精度时间、有周期性定时需求的需求。为此，引入间隔计时器，其原理是： 当等待时间来到，内核向处于等待状态的进程发送信号，同时，再次设置时间间隔。间隔计时器属于面向进程的计时器。 进程运行时间 通常，LInux系统最小时钟间隔是10ms，意味着每秒产生100个时钟中断。进程以时间片的形式分享CPU，进程的执行有两种模式：用户态和内核态。当进程执行的是用户地址空间的代码，称进程运行在用户态；当进程进入系统调用或硬件中断，称进程运行在内核态。此外，进程还有休眠态，即将CPU交给其他进程。所以进程并非时刻都在运行，而是在用户态、内核态、休眠态之间切换。 由此内核提供三种计时器： 真实时间 用户态+内核态+休眠态时间 虚拟时间 用户态时间 实用时间 用户态+内核态时间 /* 获得当前进程中指定类型间隔计时器的值 which 计时器类型 ITIMER_REAL 真实时间，经过指定时间，内核发送SIGALRM限号 ITIMER_VIRTUAL 用户态时间，经过指定时间，内核发送SIGVTALRM信号 ITIMER_PROF 实用时间，经过指定时间，内核发送SIGPRT信号 value 存储获得的间隔计时器的值 */ int getitimer ( int which , struct itmerval * value ); struct itimerval { struct timeval it_interval ; //下一个值 struct timeval it_value //当前值 }; struct timeval { long tv_sec ; //秒 long tv_usec ; //微秒 }; /* 设置间隔计时器 which 指定定时器类型 newval指向被设置值 oldval指向被替换设置值 成功返回0，否则-1 若oldval不为NULL，之前计时器的值将被复制到oldval */ int setitimer ( int which , const struct itimerval * newval , struct itimerval * oldval );","tags":"Linux","url":"pages/2018/10/07/Linux-C-SIGNAL-2/","loc":"pages/2018/10/07/Linux-C-SIGNAL-2/"},{"title":"Linux下glic库操作文件和目录","text":"文件系统概述 Linux内核的各种真实文件系统、块设备和字符设备统一在虚拟文件系统的框架中，虚拟文件系统为应用提供了一组抽象的文件输入输出接口。 虚拟文件系统是对各种真实文件系统的抽象，在虚拟文件系统中定义了抽象的超级块、i节点和目录，它为真实文件系统提供了一种统一的框架接口。真实文件系统通过这些接口与虚拟文件系统相连接，真实文件系统是这些抽象接口的具体实现。 虚拟文件系统存在于内存中，在系统启动时产生，随着系统关闭而消失。 文件操作常用的头文件 C POSIX library 是C语言的 POSIX 系统下的标准库。包含了一些在 C语言标准库 之外的函数。 #include <unistd.h> //多种必要的POSIX函数与常量 #include <fcntl.h> //文件打开、创建、加锁等操作 #include <sys/stat.h>//文件信息(stat (Unix)等) #include <sys/types.h>//不同的数据类型 #include <dirent.h> //打开与列出目录内容 //此外，还有C标注库中的 #include <stdio.h> //标准缓存输入输出 文件基本输入输出 文件输入输出涉及到以下函数： open、creat 在 <fcntl.h> 中 read、write、lseek、close 在 <unistd.h> 中 案例:复制文件 //cp.c #include <stdio.h> #include <unistd.h> #include <fcntl.h> #define PMODE 0644 //权限定义为rw-r--r-- #define BUFSIZE 200 int main ( int argc , char * argv []) { int fdin , fdout , n ; char buf [ BUFSIZ ]; if ( argc != 3 ) { fprintf ( stderr , \"Usage:%s filein fileout \\n \" , argv [ 0 ]); return 1 ; } if (( fdin = open ( argv [ 1 ], O_RDONLY )) == - 1 ) { perror ( argv [ 1 ]); return 2 ; } if (( fdout = open ( argv [ 2 ], O_WRONLY | O_CREAT | O_TRUNC , PMODE )) == - 1 ) { perror ( argv [ 2 ]); return 3 ; } while (( n = read ( fdin , buf , BUFSIZE )) > 0 ) write ( fdout , buf , n ); close ( fdin ); close ( fdout ); return 0 ; } 文件属性操作 文件的属性信息存放在文件对应的i节点中，对于不同类型的物理文件系统，文件属性的组织形式不尽相同，为了获得统一的文件属性格式，Linux定义了struct stat这个数据结构，类型定义如下： struct stat { dev_t st_dev ; /* 文件设备编号*/ ino_t st_ino ; /* i节点号 */ mode_t st_mode ; /* 文件类型和存储权限 */ nlink_t st_nlink ; /* 硬链接 */ uid_t st_uid ; /* 用户ID */ gid_t st_gid ; /* 用户组ID */ dev_t st_rdev ; /* Device ID (if special file)*/ off_t st_size ; /* 文件字节数bytes */ blksize_t st_blksize ; /* 块大小 */ blkcnt_t st_blocks ; /* 以512bytes为单位的块数 */ struct timespec st_atim ; /* 文件最后一次访问时间 */ struct timespec st_mtim ; /* 文件最后一次修改时间 */ struct timespec st_ctim ; /* 文件属性最后一次改变时间 */ }; 以之前的cp.c为例: 可以看到cp.c文件实际大小640bytes，在磁盘上占用了一个4096bytes的块，也就是8个512bytes的块。` 文件属性操作常用函数： stat 获取文件属性信息 chmod 设置文件权限 chown 设置文件属主 utime 获取时间 案例：改变文件读写权限 #include <stdio.h> #include <sys/stat.h> int main () { mode_t fdmode = ( S_IRUSR | S_IWUSR | S_IRGRP | S_IROTH ); if ( chmod ( \"cp.c\" , fdmode ) == - 1 ) { printf ( \"error \\n \" ); return 1 ; } return 0 ; } 编译运行，结果如下，可见文件权限已经被修改。 niuhe@niuhe-ubuntu:~/Linux$ gcc -o chmod chmod.c niuhe@niuhe-ubuntu:~/Linux$ ls chmod chmod.c cp cp.c niuhe@niuhe-ubuntu:~/Linux$ ll cp.c -rw-rw-r-- 1 niuhe niuhe 640 10月 6 16 :55 cp.c niuhe@niuhe-ubuntu:~/Linux$ ./chmod niuhe@niuhe-ubuntu:~/Linux$ ll cp.c -rw-r--r-- 1 niuhe niuhe 640 10月 6 16 :55 cp.c 目录操作 目录是一种特殊的文件，其内容由若干目录项组成，一个目录项包括文件名和i节点号。为了便于管理，每个目录中都包含当前目录\".\"和父目录\"..\",当前目录项指向当前目录的i节点编号，父目录项记录了父目录对应的i节点编号。 常用库函数及头文件如下： #include <sys/stat.h> //在某目录中创建一个目录项，分配一个i节点和目录项相链接 //分配一个逻辑块用来存放目录内容，并在其中建立当前目录和父目录两个目录项 int mkdir ( const char * pathname , mode_t mode ); #include <unistd.h> //删除空目录 int rmdir ( const char * pathname ); //改变工作目录；在每个进程的进程控制块中保存着当前工作目录的i节点 //初始工作目录继承自父进程，进程运行过程可以改变工作目录 int chdir ( const char * pathname ); //获得调用者进程的当前工作目录，buf存放路径，size路径包含字节数 char * getcwd ( char * buf , size_t size ); #include <dirent.h> //打开目录,成功返回目录流（字符串） DIR * opendir ( const char * pahtname ); //读目录，成功返回下一个目录项 struct dirent * readdir ( DIR * dp ); //关闭目录 int closedir ( DIR * dp ); 目录是一种特殊的文件，存放着很多目录项，每一个目录项是一个结构体。 struct dirent { long d_ino ; //i节点号 char d_name [ NAME_MAX + 1 ]; //文件名 off_t d_off ; //在目录文件中偏移量 unsigned short d_reclen ; //文件名长度 } 案例：改变当前进程工作目录 #include <unistd.h> #include <stdio.h> int main ( void ) { if ( chdir ( \"/tmp\" ) < 0 ) printf ( \"chdir failed\" ); printf ( \"chdir to /tmp succeeded \\n \" ); return 0 ; } 案例：浏览目录中所有文件名 #include <stdio.h> #include <dirent.h> int main ( int argc , char * argv []) { DIR * dirp ; struct dirent * direntp ; if (( dirp = opendir ( argv [ 1 ])) == NULL ) { printf ( \"cannot open the %s directory\" , argv [ 1 ]); return 1 ; } while (( direntp = readdir ( dirp )) != NULL ) printf ( \"%s \\n \" , direntp -> d_name ); closedir ( dirp ); return 0 ; } C标准I/O库 运用read、write等系统底层函数进行输入输出时，需要在用户态和内核态之间来回切换。若每次读取或写入数据较少，将导致频繁的I/O操作，降低了程序运行效率。 标准I/O库对底层I/O系统调用进行了封装，提供了带格式转换的I/O操作，并在用户空间增加了缓冲管理，可减少程序和输出设备之间I/O次数。函数原型定义在 中。 细节略 I/O重定向 文件描述符 Linux系统中，进程拥有各自打开文件的描述符。文件描述符按生成的顺序存放在文件描述符表中，Linux内核将文件描述符表用一维数组表述，每个打开的文件占用一个单元，用来存放操作文件的必要信息，如读写操作当前位置、文件打开方式、文件操作集等。 进程在打开一个文件时，返回的是文件描述符所在数组的下标，称为文件描述符。 通常，创建子进程时，子进程从父进程继承文件描述符表，前3个描述符0,1,2分别对应标准输入、标准输出、标准错误输出，与进程的控制终端设备对应。通常已经被打开，进行读写操作时无需重新打开。 一个文件可以同时被多个进程打开，它在不同进程中对应的文件描述符以及操作状态也未必相同。 I/O重定向 程序根据打开文件的描述符对文件进行读写操作，真正完成读写操作的是进程描述符表相应位置中的内容。以输出重定向为例，若将进程描述符表中1号单元的内容替换为打开的文件test，则进程在向标准输出文件输出信息时，原本数据应显示在终端显示器上，但现在这些数据将被输出至文件test。 实现I/O重定向可以通过: open close open方法 系统函数调用：dupdup2 open close open方法 Linux在为进程新打开文件分配描述符时，从下表0开始扫描进程文件描述符表，将打开的文件信息放在找到的第一个空闲单元，并将该下表作为打开文件的描述符。 以标准输入0为例，将标准输入关闭，使得文件描述符表第0号单元成为空闲单元，此时，进程新打开另一个文件，内核将文件描述符表0号单元分配给新打开的文件，并返回描述符0，也就实现了输入重定向。 dup和dup2函数 使用dup和dup2函数，只是复制文件描述符，使两个文件描述符指向同一个file结构体，并且file结构体引用计数是2。此时，打开文件的状态保存在同一个file结构体中。而使用open函数两次打开一个文件会存在两份file结构体，分别有各自的状态。 #include <unistd.h> //从进程文件描述符表中寻找一个可用的最小描述符,返回此描述符 //并复制oldfd对应的File结构指针到新的最小描述符 int dup ( int oldfd ); //oldfd需要复制的文件描述符，newfd是复制后oldfd在文件描述符表中新的序号。 //成功返回一个新描述符，否则返回-1 //若newfd已经打开，则先关闭newfd,然后复制oldfd到newfd,使newfd也指向oldfd,此时oldfd和newfd两个描述符共享同一个文件。 int dump2 ( int oldfd , int newfd ); 案例:输出重定向 #include <stdio.h> #include <unistd.h> #include <fcntl.h> int main () { int fileID ; fileID = creat ( \"ls.tst\" , 0640 ); if ( fileID < 0 ) { fprintf ( stderr , \"error creating ls.tst \\n \" ); return 1 ; } dup2 ( fileID , 1 ); close ( fileID ); execl ( \"/bin/ls\" , \"ls\" , NULL ); return 0 ; } 参考 库函数列表 C POSIX LIB","tags":"Linux","url":"pages/2018/10/06/Linux-C-IO/","loc":"pages/2018/10/06/Linux-C-IO/"},{"title":"Linux信号处理——自定义信号处理函数","text":"信号是内核和进程之间通信的一种方式，信号是由内核产生，并发送给一个或一组进程的短消息，用不同特定的数字表示不同的信号，信号的作用是表示某种事件的发生。 信号简介 分类 非实时不可靠信号，值为1-31 实时的可靠信号，值为32-63 信号由内核生成，信号生成和事件的发生密切相关，可将事件发生源分为以下三类： 信号事件发生源： 用户，如键入CTRL+C，终端驱动程序将通知内核产生信号发送到相应的进程 内核，内核执行过程中，遇到非法指令和浮点数溢出等情况 进程，一个进程调用kill函数向另一个进程发送信号，进行进程间通信 通常，LInux为每个信号定义了缺省的处理方式，但是用户可根据需要，对信号的处理方式进行重新定义。 信号的缺省处理方式包括 A 结束进程 B 忽略信号 C 结束进程并写入内核文件 D 停止进程 E 信号不能被捕获 F 信号不能被忽略 G 非POSIX信号 自定义信号处理函数 必须重新建立信号值和处理方式之间的对应关系，才能重新定义信号的处理方式。LInux提供signal和sigaction函数来实现信号的设置。signal和sigaction的区别在于signal不支持项信号处理函数传递数据。 注：SIGKILL和SIGSTOP不能被重定义或忽略。 signal函数原型: // __sig为需设置的信号，__handler为新信号处理函数；失败返回SIG_ERR，否则成功。 //__handler为SIG_IGN忽略信号，SIG_DEL默认信号处理 extern __sighandler_t signal ( int __sig , __sighandler_t __handler ) __THROW ; 案例：使用signal重定义SIGINT处理函数 #include <stdio.h> #include <signal.h> #include <unistd.h> int main () { void f ( int ); int i ; signal ( SIGINT , f ); for ( i = 0 ; i < 5 ; i ++ ) { printf ( \"hello \\n \" ); sleep ( 1 ); } return 0 ; } void f ( int signum ) { printf ( \"hello Linux \\n \" ); } sigaction函数原型 /* signo需要处理的信号 act指向描述信号操作的结构 oact指向被替换操作的结构 成功返回0，否则返回-1 */ int sigaction ( int signo , const struct sigaction * act , struct sigaction * oact ); /* sa_mask指定在信号处理过程中，何种信号被阻塞。缺省情况是当前信号被阻塞，以免信号处理函数被递归调用。 */ struct sigaction { void ( * sa_handler )( int ); //信号处理函数 void ( * sa_sigaction )( int , siginfo_t * , void * ); //带参数的信号处理函数 sigset_t sa_mask ; //信号掩码 int sa_flags ; //设定信号处理相关行为 } 案例：sigaction定义信号SIGINT处理函数，并屏蔽其他信号 #include <stdio.h> #include <signal.h> #include <unistd.h> int num = 0 ; void int_handle ( int signum ) { printf ( \"SIGINT:%d]n\" , signum ); printf ( \"int_handle called %d times \\n \" , ++ num ); } int main ( void ) { static struct sigaction act ; void int_handle ( int ); act . sa_handler = int_handle ; sigfillset ( & ( act . sa_mask )); sigaction ( SIGINT , & act , NULL ); while ( 1 ) { printf ( \"i am sleepy.. \\n \" ); sleep ( 1 ); if ( num >= 3 ) { return 0 ; } } } 信号集、信号屏蔽与阻塞 信号屏蔽就是临时阻塞信号被发送到某个进程，它包含一个被阻塞的信号集。当进程屏蔽某个信号时，内核将不发送该信号至屏蔽它的进程，直至该信号的屏蔽被解除。 信号集用于描述所有信号的集合。对于sigaction中的sa_mask字段，每一位对应一个信号，若某一位被设置为1，表示该位对应信号被屏蔽。 信号集定义及其操作函数 typedef struct { unsigned long sig [ 2 ]; } sigset_t int sigemptyset ( sigset_t * set ); //清空信号集中所有信号 int sigfillset ( sigset_t * set ); //在set信号集中加入linux支持的所有信号 int sigaddset ( sigset_t * set , int signum ); //向信号集中加入signum信号 int sigdelset ( sigset_t * set , int signum ); //从信号集中删除signum信号 int sigismember ( const sigset_t * set , int signum ) //判断signum信号是否在信号集set中 每个进程定义一个信号掩码，该掩码对应一个信号集，该信号集中的所有信号在发送至进程后都将被阻塞。通过更改进程的信号掩码来阻塞或解除阻塞所选择的信号。以此来保护不希望由信号中断的临界代码。 信号阻塞函数sigprocmask /* how 如何修改信号掩码 SIG_BLOCK 添加信号到进程屏蔽 SIG_UNBLOCK将信号从进程屏蔽中删除 SIG_SETMASK将set的值设定为新的信号掩码 set 指向设置信号列表 oldset指向之前的信号掩码列表 */ int sigprocmask ( int how , const sigset_t * set , sigset_t * oldset ); 案例:阻塞SIGINT信号3秒后恢复 #include <signal.h> #include <stdio.h> #include <unistd.h> int main ( void ) { sigset_t set ; int count = 3 ; sigemptyset ( & set ); sigaddset ( & set , SIGINT ); sigprocmask ( SIG_BLOCK , & set , NULL ); while ( count ) { printf ( \"don't disturb me (%d) \\n \" , count -- ); sleep ( 1 ); } sigprocmask ( SIG_UNBLOCK , & set , NULL ); printf ( \"you did not disturb me!! \\n \" ); return 0 ; }","tags":"Linux","url":"pages/2018/10/06/Linux-C-SIGNAL-1/","loc":"pages/2018/10/06/Linux-C-SIGNAL-1/"},{"title":"Linux下创建和使用C语言函数库","text":"函数库介绍 函数库分为： 静态库 共享库（动态加载库） 应用程序在链接静态库时候，将使用的静态库对象嵌入至可执行映像文件中；而在链接共享库时，仅在可执行映像文件中保留加载目标对象所需的信息，在调用时，才真正将目标对象加载至内存。 静态库特点： 运行时无需外部库的支持，可执行文件中已经嵌入了所需的静态库目标对象，所以可执行文件可以脱离静态库独立运行。 较高的运行速度，运行时不需要加载其他目标对象 可执行文件体积较大 不容易维护，每次修改静态库，必须重新链接 共享库特点： 可执行文件体积较小 容易维护，共享库中对象发生变化，应用程序不需要重新编译 可执行文件中不包含共享库中调用的目标对象，因此不能离开动态库独立运行 运行速度比较慢，因为程序启动时需要加载共享库 静态库 静态库创建 静态库命名规则是lib开头，.a作为文件名后缀。可以使用ar命令作为静态库管理工具。ar可以将多个.o文件打包在一起，构成一个静态库文件。 案例: 先准备两个C源文件如下： //exam1.c int add ( int x , int y ) { return x + y ; } //exam2.c int func ( int count ) { int sum = 0 ; int j ; for ( j = 0 ; j <= count ; j ++ ) { sum = sum + j ; } return sum ; } 编译两个源文件,后使用ar创建静态库： gcc -c -Wall exam1.c gcc -c -Wall exam2.c ar -crq libdemo.a exam1.o exam2.o 这样，我们就创建了一个简单的静态库。 静态库使用 定义静态库应用接口 //exam.h extern int add ( int x , int y ); extern int func ( int count ); 使用静态库 //testexam.c #include <stdio.h> #include \"exam.h\" int main ( void ) { int val ; int x , y ; x = 12 ; y = 18 ; val = add ( x , y ); printf ( \"the mult of x adn y is %d \\n \" , val ); val = func ( 100 ); printf ( \"the sum is %d \\n \" , val ); return 0 ; } 编译运行 gcc -o testexam testexam.c -L ./ -ldemo 解释： -L指定了静态库所在的目录， ./就是当前目录 -ldemo指定了静态库的名称libdemo.a 共享库 若在同一目录下存在同名的共享库和静态库，gcc会优先使用共享库，除非指定了-static. 创建共享库 gcc -fPIC -c exam1.c gcc -fPIC -c exam2.c gcc -shared -o libdemo.so exam1.o exam2.o 以上三句指令将exam1.c和exam2.c编译成了libdemo.so共享库文件。 -fPIC告诉gcc创建地址独立的目标文件 -shared告诉gcc创建一个共享库文件 共享库使用 链接着共享库的应用启动时，一个程序装载器将自动运行，该程序装载器为/lib64/ld-linux.so.X,,它的作用是查找并装载应用程序所依赖的所有共享库的中的目标对象。 将共享库libdemo.so放在/usr/local/lib/目录下 链接共享库 gcc -o testexam testexam.c /usr/local/lib/libdemo.so 查看程序使用共享库情况 ldd testexam 动态链接库 动态链接库是使用共享库的 一种方式 ，在运行的任何时刻可以动态加载共享库。和一般共享库不同，通常应用程序启动时，不立即加载共享库，而是在需要时，动态加载共享库。 以动态链接的方式使用共享库分为三个步骤： 打开共享库文件 接着取得要调用函数的地址，根据地址使用函数指针进行调用 关闭共享库 Linux环境提供了一组API函数可以动态链接共享库，头文件定义在 /usr/include/dlfcn.h 中。 案例 //exam.c #include <stdio.h> #include <dlfcn.h> #include \"exam.h\" #include <stdlib.h> int main ( void ) { int val ; int ( * add_d )( int , int ); int ( * func_d )( int ); void * handle ; char * err ; int x , y ; x = 12 ; y = 18 ; handle = dlopen ( \"/usr/local/lib/libdemo.so\" , RTLD_LAZY ); if ( handle == ( void * ) 0 ) { fputs ( dlerror (), stderr ); exit ( - 1 ); } add_d = dlsym ( handle , \"add\" ); err = dlerror (); if ( err != NULL ) { fputs ( err , stderr ); exit ( - 1 ); } func_d = dlsym ( handle , \"func\" ); err = dlerror (); if ( err != NULL ) { fputs ( err , stderr ); exit ( - 1 ); } val = ( * add_d )( x , y ); printf ( \"the mult of x and y is %d \\n \" , val ); val = ( * func_d )( 100 ); printf ( \"the sum of 1 to 100 is %d \\n \" , val ); dlclose ( handle ); return 0 ; } 编译链接 gcc -rdynamic exam.c -o exam -ldl 执行 niuhe@niuhe-ubuntu:/tmp/exp$ ./exam the mult of x and y is 30 the sum of 1 to 100 is 5050 GUN C函数库——glibc glibc是GNU开发的一套标准C语言标准函数库的实现。通常linux发行版都默认安装好了，查看glic的版本号 ldd --version .","tags":"Linux","url":"pages/2018/09/26/Linux-C-Lib/","loc":"pages/2018/09/26/Linux-C-Lib/"},{"title":"Shell 编程基础笔记","text":"Shell 是一种命令行解释器，目前 Linux 下最常用的是 bash 解释器。Shell 不仅可以解释用户输入的命令，还可以解释执行基于命令的 Shell 脚本语言。 Shell 脚本是由命令、Shell 变量和控制语句灯语法元素构成的文本文件。默认情况下，Shell 对脚本中的内容逐行分析，并依次在不同的进程中解释执行。通常 Shell 脚本结构如下： #!/bin/bash var1 = \"hello,shell.\" echo $var1 Shell 变量 Shell 变量分为四类： 用户自定义变量 环境变量 位置变量 预定义变量 变量的几种操作: 操作整数赋值：变量名=变量值 引用：$变量名 清除：unset 变量名 查看：set 输出为环境变量：export 用户自定义变量 位置变量: -位置变量和传递参数的位置有关 $0:脚本程序名称 \\ \\(1，\\\\) 2.....:传递给脚本的参数，\\$1 代表第一个参数 预定义变量: 预定义变量 含义 $* 传递到脚本的所有参数内容 $? 命令执行后的返回状态，0 成功，其他值表示错误 $$ 当前进程的进程号 $! 后台运行的最后一个进程号 $# 传递到脚本的参数的数量 命令替换 命令替换可以使命令的输出结果赋值给变量，注意语法形式 2 中是反引号`,不是单引号\\' 语法形式： var = $(command) var = `command` 案例： echo \"today is\" ` date ` 输入输出 read 命令 功能：从键盘读取输入，并赋值给变量 语法： read [选项] 变量名列表 选项列表： 选项 含义 -p prompt 设置提示信息 -n num 当 read 读 n 个字符后返回 -s 键盘输入不回显 -t timeout 设置超时时间 -r 取消转义字符的转义作用 -d delim 定义新的换行符 案例： read -s -n 1 -p \"Yes(Y) or not(N)?\" answer echo $answer echo 命令 功能：显示字符串或变量的值 语法：echo [选项] 字符串 选项列表： 选项 -含义 -n 不再最后自动换行 -e 启用反斜线控制字符的转换 -E 不处理转义字符，缺省选项 支持的转义符列表： \\t\\n\\r\\\\b\\a等 引号 反引号 :命令替换 单引号 :单引号中所有字符保留原有字符含义，不能包含单引号。不支持元字符、变量替换、命令替换。 双引号 :不支持元字符，支持变量替换、命令替换。 条件表达式 条件表达式用力啊判断条件是否满足 #!/bin/bash hour = $( date + \"%H\" ) case $hour in 0 [ 1 -9 ] | 1 [ 01 ]) echo \"Good morning!!\" ;; 1 [ 2 -7 ]) echo \"Good afternoon\" ;; * ) echo \"Good evening\" ;; esac 测试条件表达式真假方法如下，真 0 假 1： test 条件表达式 [条件表达式] 条件表达式中常用五类操作符： 文件状态操作符 字符串操作符 数字操作符 逻辑操作符 文件状态操作符（略）: -x filename 文件可执行返回真 字符串操作符: 操作符 含义 string string 非空为真 -n string string 长度大于 0 为真 -z sring string 长度为 0 为真 string1=string2 相等为真 string1 != string2 不等为真 数字操作符: 操作符 含义 n1 -eq n2 n1 和 n2 相等返回 0，否则 1 n1 -ne n2 不等为真 n1 -lt n2 n1 < n2 为真 n1 -gt n2 n1 > n2 为真 n1 -le n2 n1 <= n2 为真 n1 -ge n2 n1 >= n2 为真 逻辑操作符: 操作符 含义 e1 -a e2 e1 和 e2 两个表达式同时为真返回 0，否则 1 e1 -o e2 e1,e2 有一个为真返回 0 !e1 e1 不为真时返回 0 命令分隔符 命令分隔符可以在一行中运行多个命令 命令分隔符 含义 cmd1;cmd2 以独立进程依次运行 cmd1 和 cmd2 (cmd1;cmd2) 在同一进程中依次运行 cmd1 和 cmd2 cmd1 & cmd2 cmd1 和 cmd2 同时运行，分属不同进程组 cmd1 && cmd2 当 cmd1 为真时，才执行 cmd2 cmd1 || cmd2 当 cmd1 为假时，才执行 cmd2 cmd1 | cmd2 管道符号，cmd1 的输出作为 cmd2 的输入 cmd1 & cmd1 在后台运行 判断语句 案例 1：比较两个数字大小 #!/bin/bash echo \"Enter the first interger:\" read first echo \"Enter the second interger:\" read second if (( first > second )) ; then echo \" $first is greater than $second \" elif (( first < second )) ; then echo \" $first is less than $second \" else echo \" $first is equal to $second \" echo \"Done\" fi 案例 2：获取系统时间，判断上午、下午、晚上 #!/bin/bash hour = $( date + \"%H\" ) case $hour in 0 [ 1 -9 ] | 1 [ 01 ]) echo \"Good morning!!\" ;; 1 [ 2 -7 ]) echo \"Good afternoon\" ;; * ) echo \"Good evening\" ;; esac 循环语句 案例 1：for 循环打印所有命令行参数 #!/bin/bash #you can write this in short:for arg for arg in $* do echo $arg done 案例 2：while 计算 1-99 的和 #!/bin/bash i = 1 sum = 0 while [ $i -lt 100 ] do sum = ` expr $sum + $i ` i = ` expr $i + 1 ` done echo The sum is $sum 案例 3：显示 1-100 之间的整数 #!/bin/bash i = 1 until [ $i -gt 100 ] do echo $i i = ` expr $i + 1 ` done break [n] 跳出 n 重循环，默认为 1 continue [n] exit [n] 函数 语法： 函数名() { 命令列表 return } ` 调用方式: 函数名 参数列表 注意： 调用前，必须先定义 使用 shell 位置变量接收参数传递，例如 \\(0\\\\) 1 返回值取自函数中 return 语句或函数中最后一条命令的返回状态，通过$?获得 使用 local 声明的局部变量，作用仅限于函数本身 案例： #!/bin/bash #name:getsum.sh get_sum () { i = $1 sum = 0 while [ $i -lt $2 ] do sum = ` expr $sum + $i ` i = ` expr $i + 1 ` done return $sum } get_sum $2 $3 result = $? echo $1 echo sum of $2 to $3 is $result 运行 : ./getsum.sh \"test\" 5 7 注意事项 变量赋值的=两侧不能有空格 条件表达式[ ]和表达式间必须有空格 expr 算式表达式中每个运算符两侧必须有空格","tags":"Linux","url":"pages/2018/09/25/Basic-Shell/","loc":"pages/2018/09/25/Basic-Shell/"},{"title":"Pyserial快速上手","text":"现在很多传感器都使用串口进行数据传送，我们再window上通常使用sscom33这类调试工具，在linux下通常使用带界面的cutecom或者命令行界面的minicom进行调试。 而使用Python写几行程API序进行自定义调试，就非常有用。并且可以快速的对传感器进行测试。本文介绍python的串口读写模块Pyserial 安装 sudo pip install pyserial 使用 确定串口设备名 Linux下把串口设备抽象成了文件，通常放在 /dev/ 目录下，先找出串口设备的名称。 断开串口设备的连接，执行 ls /dev/ > /tmp/old.txt 将串口设备连接到计算机，执行 ls /dev/ > /tmp/new.txt 最后，比较old.txt和new.txt，new.txt中多出的设备名就是我们的串口设备 diff /tmp/old.txt /tmp/new.txt 例程 以下是我读取超声波测距传感器的例程，传感器返回串口数据,每一帧数据的帧头是0xFF,其后的2byte数据是距离值。 import serial import time with serial . Serial ( '/dev/ttyUSB0' , 9600 , stopbits = serial . STOPBITS_ONE , bytesize = serial . EIGHTBITS ) as ser : while 1 : head = ser . read ( 1 ) if head == b ' \\xFF ' : distance = int . from_bytes ( ser . read ( 2 ), byteorder = 'big' , signed = False ) print ( str ( distance / 1000 ) + 'm' ) 常用方法 在创建串口对象后，即 ser = serial.Serial('/dev/ttyUSB0') ，可以操作串口读写。 ser.read(size) ser.readline(size) ser.write(str_data) ser.close() 具体使用参见官方文档API 参考 API参考","tags":"Raspberry","url":"pages/2018/09/13/Pyserial_tutorial/","loc":"pages/2018/09/13/Pyserial_tutorial/"},{"title":"LSM303DLHC 3轴地磁传感器文档","text":"简介 LSM303DLHC是一个三轴加速度和三轴磁场的传感器，具有倾斜补偿，工作电压在2.5-5.5V之间，工作电流10mA，数据接口是I2C接口。 引脚定义 VIN 2.5-5.5V电压供电引脚，SCL和SDA引脚的高电平电压和VIN引脚的电压相同。 VDD 根据VIN引脚的连接情况，VDD引脚用途不同，若VIN引脚连接了大于3.3V的电源，VDD可以想歪提供3.3V的电压和大约150mA的电流。如果VIN断开连接，可以使用2.5-3.3的电源连接VDD给LSM303DLHC模块供电。 注意： - 不能同时使用VIN和VDD给LSM303DLHC供电，只能选取一个。 - 不要将VDD连接到大于3.6V的电源上，会损坏LSM303DLHC模块 GND 0V，连接到电源的地。注意和I2C总线共地。 SCL 时钟线，高电平是VIN，低电平是0V。SCL和SDA都有电平转换电路，可以使得模块可以使用VIN的逻辑电平进行通信。 SDA 数据线，高电平是VIN，低电平是0V DRDY 数据可读指示，3.3V逻辑电平输出，高电平(3.3V)指示磁场数据可读，低电平表示正在向数据寄存器中写入新的数据。此输出没有电平转换。 INT1 INT2 两个惯性中断，没有电平转换，3.3V输出。 例程和库 Arduino例程和库参考： https://github.com/pololu/lsm303-arduino Linux例程： https://github.com/ControlEverythingCommunity/LSM303DLHC 参考 产品说明书","tags":"Raspberry","url":"pages/2018/09/10/LSM303DLHC-Doc/","loc":"pages/2018/09/10/LSM303DLHC-Doc/"},{"title":"远程ssh连接家中的树莓派","text":"在局域网下可以通过扫描端口号，获得局域网下树莓派的ip地址，如192.168.1.118。之后通过ssh或者VNC等方法访问树莓派。那么如果我们离开局域网，怎么访问到家中的树莓派呢？ 公网IP相当于街道中的门牌号，如果远程访问到互联网中的设备，必须知道设备的公网IP。 VPS + SSH远程代理隧道 这是这篇文章重点，需要： 一个安装了linux的VPS，如一台腾讯云服务器。（如果没有，请看下一种方法：公网IP+路由器端口转发） 连上网络的树莓派,将树莓派ssh公钥放到VPS上 树莓派上使用autossh+crontab sudo apt install autossh cd ~/ echo \"sleep 20; /usr/bin/autossh -M 5678 -NfR 9999:localhost:22 user@T.T.T.T -i /home/user/.ssh/id_rsa\" > autossh.sh chmod +x autossh.sh crontab -e 在crontab的配置文件中加入 @reboot /home/nh/autossh.sh >> tunnel.log 在服务器上操作 ssh -fCNL \"*:11111:localhost:9999\" localhost 远程登录 现在就可以使用服务器作为跳板，连接到家中的树莓派。 ssh -p 11111 user@T.T.T.T 注：user@T.T.T.T,user是树莓派用户名，T.T.T.T是服务器公网IP。-p指定向服务器1111端口发送ssh请求，1111端口转发到9999端口，也就是树莓派的22端口。 显示效果如下： 以下树莓派配置方法均不推荐，想折腾的自己玩，服务器配置方法都一样 树莓派上安装sshpass(可选） sudo apt-get install sshpass 树莓派上编辑shell脚本 #!/bin/bash #saved as create_ssh_tunnel.sh createTunnel () { sshpass -p \"Password\" ssh -o \"ServerAliveInterval 300\" -o \"ServerAliveCountMax 2\" -fCNR 9999 :localhost:22 user@T.T.T.T if [[ $? -eq 0 ]] ; then echo $( date ) Tunnel to jumpbox created successfully >> /root/tunnel.log else echo $( date ) An error occurred creating a tunnel to jumpbox. RC was $? >> /root/tunnel.log fi } /bin/pidof ssh if [[ $? -ne 0 ]] ; then echo $( date ) Creating new tunnel connection >> /root/tunnel.log createTunnel fi 注：这种方式非常危险，不推荐这种方式，因为明文存储了服务器密码。 \"Password\"指的是你的服务器密码 user@T.T.T.T是你的服务器用户名和IP地址 9999是将树莓派的22端口绑定到服务器额9999端口 推荐将树莓派上的公钥放到远程服务器上，然后使用如下脚本 #saved as create_ssh_tunnel.sh createTunnel () { ssh -o \"ServerAliveInterval 300\" -o \"ServerAliveCountMax 2\" -NR 9999 :localhost:22 user@T.T.T.T if [[ $? -eq 0 ]] ; then echo $( date ) Tunnel to jumpbox created successfully >> ~/tunnel.log else echo $( date ) An error occurred creating a tunnel to jumpbox. RC was $? >> ~/tunnel.log fi } /bin/pidof ssh if [[ $? -ne 0 ]] ; then echo $( date ) Creating new tunnel connection >> ~/tunnel.log createTunnel fi 给脚本添加执行权限 chmod +x creat_ssh_tunnel.sh 树莓派上开启cron定时任务 sudo crontab -e 在文件最后一行添加： */10 * * * * ～/create_ssh_tunnel.sh >> tunnel.log 2 > & 1 意思是每十分钟执行一次刚刚我们编辑的shell脚本 公网IP + 路由器端口转发 如果用网线将树莓派连接到互联网上，只要获得公网IP，皆可以通过ssh访问。但是我们在家中通常是用wifi连接树莓派，我们获得的公网iP，只是路由器的IP。由于一个路由器上连接很多设备，我们无法通过这个公网IP访问到树莓派。而且由于路由器的公网IP是会变动的。所以我们要解决的问题是： 找到路由器的公网IP 通过公网IP找到路由器下连接的树莓派 可以在路由器设置里将树莓派分配固定的IP，并绑定固定端口。这样就可以通过访问这个端口访问到局域网下的树莓派。之后不管是将公网IP发送到邮箱还是，使用动态DNS解析服务，通过域名访问树莓派，都可以很容易实现。 参考 SSH反向代理 外网访问树莓派方法汇总 用DDNS服务通过域名访问树莓派 使用crontab让SSH反向代理更持久","tags":"Raspberry","url":"pages/2018/09/04/Raspi_Remote_SSH_Tunnel/","loc":"pages/2018/09/04/Raspi_Remote_SSH_Tunnel/"},{"title":"Arduino简易示波器检测树莓派产生的方波","text":"在使用超声测距模块时，需要给超声模块一个方波信号。于是可以用树莓派的的PWM功能产生一个低频的方波信号。 产生方波信号后，如果手边没有示波器，还可以使用Arduino的ADC采样功能，做一个简单的示波器。 树莓派产生方波 树莓派的pin12、pin33(GPIO_18、GPIO_13)是树莓派提供的PWM硬件接口，可以产生高频的PWM信号。 由于我只需要产生一个大约50Hz的方波信号。用最简单的GPIO库就可以产生可用的方波。 #!/usr/bin/python3 # -*- coding: utf-8 -*- import RPi.GPIO as GPIO from time import sleep GPIO . setmode ( GPIO . BOARD ) GPIO . setup ( 12 , GPIO . OUT ) GPIO . setwarnings ( False ) p = GPIO . PWM ( 12 , 50 ) # 12是pin12,50是频率 p . start ( 30 ) # 30表示占空比30% input ( \"Press Enter key to Stop 50Hz PWM @ 30 % d uty cycle\" ) p . stop () GPIO . cleanup () 运行该脚本，就可以在树莓派pin12上产生方波信号。 Arduino和树莓派连线 连线图如下所示： 注意： 要将树莓派和Arduino的地线连接在一起，使它们共地。 Arduino 进行ADC采样 Arduino 有A0-A5共6个模拟输入口，每个模拟口可以进行12位的采样，可以接受0-5V的电压输入，对应着0-1023的采样输出。 使用A0口进行采样： void setup () { Serial . begin ( 9600 ); // Starting Serial Terminal } void loop () { int value = analogRead ( A0 ); Serial . println ( value ); } 打开Arduino官方的IDE的【工具】-> 【串口绘图器】 设置波特率为9600,可以观察到： 注：树莓派GPIO引脚输出电压为3.3V，而Arduino采样范围是0-5V 还可以使用 SerialPlot 这个功能更丰富的串口绘图器，当做简易的示波器。 显示的波形如下： Arduino串口绘图器 Arduino串口绘图器可以绘制多个连续图形，如下程序就是在串口绘图器中画出sin和cos函数图像。 double i = 0 ; void setup () { Serial . begin ( 9600 ); } void loop () { double temp = i * 3.1415926 / 10.0 ; Serial . print ( sin ( temp )); Serial . print ( ',' ); Serial . println ( cos ( temp )); i += 0.1 ; delay ( 5 ); } 注： 若只绘制一个图像，使用Serial.println()函数即可 若绘制多个图像，在每个串口值间使用Serial.print(',')进行分隔","tags":"Raspberry","url":"pages/2018/09/01/Arduino-Raspberry-SqureWave/","loc":"pages/2018/09/01/Arduino-Raspberry-SqureWave/"},{"title":"Arduino产生方波信号","text":"Arduino可以使用PWM产生方波信号，在我的Arduino UNO R3上，支持PWM的输出口是pin 3,5,6,9,10,11这几个引脚，支持大约980Hz的PWM输出。这方面不再赘述。 本文介绍另一种产生方波的方法，可以使用任何引脚产生方波信号。功能： 固定频率，占空比，偏移量的方波 通过模拟口连接可调电位器，产生可变频率、占空比、偏移量的方波 // High-accuracy square wave generator // based on Arduino UNO // with runtime adjustable frequency, PWM width and offset // Output wave at pin 13 double freq ; // Hz double offset ; // percent (0.0 to 1.0) double width ; // percent (0.0 to 1.0) // unit: microsecond unsigned long cycle_time ; unsigned long raising_edge ; unsigned long falling_edge ; unsigned long prev_micros ; // compare 2 unsigned value // true if X > Y while for all possible (X, Y), X - Y < Z #define TIME_CMP(X, Y, Z) (((X) - (Y)) < (Z)) inline void setHigh () { // 2 CPU cycles to balance execution time with setLow() // this is based on measurement on Arduino UNO R3, your mileage may vary PORTB = B00100000 ; PORTB = B00100000 ; } inline void setLow () { PORTB = B00000000 ; } void setup () { DDRB = B00100000 ; prev_micros = micros (); while ( 1 ) { // read everything from analog input (potentiometer) // frequency: 0.1-102.4 Hz // width: 0-100% // offset: 0-100% //freq = (double)(analogRead(1) + 1) / 10; //width = (double)(analogRead(0) + 1) / 1024; //offset = (double)analogRead(2) / 1024; // OR manual settings // max possible frequency is around 55000Hz with <1KHz deviation // based on measurements on Arduino UNO R3 // you may get to ~77500Hz with significantly larger deviation // note: please uncomment the next 3 expressions, then // move the following 6 expressions ahead of while loop // if you are going to use manual settings, because it is no worth // to recalculate them. freq = 50 ; width = 0.3 ; offset = 0.0 ; cycle_time = 1000000 / freq ; raising_edge = ( unsigned long )( offset * cycle_time ) % cycle_time ; falling_edge = ( unsigned long )(( offset + width ) * cycle_time ) % cycle_time ; if ( width + offset < 1 ) { // raising edge should appear earlier while ( TIME_CMP ( micros (), prev_micros + raising_edge , cycle_time )); setHigh (); while ( TIME_CMP ( micros (), prev_micros + falling_edge , cycle_time )); setLow (); } else { // falling edge should appear earlier while ( TIME_CMP ( micros (), prev_micros + falling_edge , cycle_time )); setLow (); while ( TIME_CMP ( micros (), prev_micros + raising_edge , cycle_time )); setHigh (); } pin prev_micros += cycle_time ; } } 解释： PORTB表示的是控制pin8-pin13的寄存器，最高的两位6&7不使用。 可以改变B00100000来在其他pin脚上产生方波信号 同样的PROTD寄存器控制digital pin0-pin7 参考 程序来源；James Swineson github@public.swineson.me , 2017-05 https://gist.github.com/Jamesits/8d164818946a65d0cafcd6203e3e5049 https://blog.swineson.me/high-frequency-square-wave-generator-based-on-arduino-uno/ 操控Arduino端口寄存器","tags":"Arduino","url":"pages/2018/09/01/Arduino-SqureWave/","loc":"pages/2018/09/01/Arduino-SqureWave/"},{"title":"树莓派连接LCD1602做一个电子钟","text":"安装LCD库 使用AdaFruit库来控制lcd库，这个库支持AdaFruit屏幕和使用HD44780的显示屏。 通过源码安装： git clone https://github.com/adafruit/Adafruit_Python_CharLCD.git cd ./Adafruit_Python_CharLCD sudo python setup.py install 将树莓派和LCD1602连接 连接的图如下所示： LCD电子钟程序 #!/usr/bin/python3 # -*- coding: utf-8 -*- import RPi.GPIO as gpio #to add the LCD library import Adafruit_CharLCD as LCD import time gpio . setmode ( gpio . BCM ) #声明 LCD pins（对应BCM引脚） lcd_rs = 17 lcd_en = 18 lcd_d4 = 27 lcd_d5 = 22 lcd_d6 = 23 lcd_d7 = 10 lcd_backlight = 2 lcd_columns = 16 #Lcd column lcd_rows = 2 #number of LCD rows lcd = LCD . Adafruit_CharLCD ( lcd_rs , lcd_en , \\ lcd_d4 , lcd_d5 , lcd_d6 , lcd_d7 , lcd_columns , lcd_rows , \\ lcd_backlight ) lcd . set_cursor ( 0 , 0 ) lcd . message ( ' CLOCK' ) while True : lcd . set_cursor ( 0 , 1 ) localtime = time . asctime ( time . localtime ( time . time ()) )[ 4 : - 5 ] print ( localtime ) lcd . message ( localtime ) time . sleep ( 1 ) 效果图 显示的效果图如下，可以显示日期和时间，每秒钟刷新屏幕一次：","tags":"Raspberry","url":"pages/2018/08/28/raspberrypi-lcd-clock/","loc":"pages/2018/08/28/raspberrypi-lcd-clock/"},{"title":"树莓派3启用UART并连接GPS传感器","text":"在树莓派3B+里启用串口，并通过UART读取GPS模块的数据帧。 树莓派3启用UART 先更新系统 sudo apt-get update sudo apt-get upgrade sudo raspi-config 在raspi-config中设置： disable login shell over serial enable serial hardware port 然后重启 sudo reboot 编辑配置文件 sudo nano /boot/config.txt 在最后一段加上： dtparam = spi = on dtoverlay = pi3-disable-bt core_freq = 250 enable_uart = 1 force_turbo = 1 然后编辑cmdline.txt sudo cp boot/cmdline.txt boot/cmdline_backup.txt sudo nano /boot.cmdline.txt 将cmdline.txt的内容替换为： dwc_otg.lpm_enable=0 console=tty1 root=/dev/mmcblk0p2 rootfstype=ext4 elevator=deadline fsck.repair=yes rootwait quiet splash plymouth.ignore-serial-consoles 禁用树莓派Serial Getty服务 sudo systemctl stop serial-getty@ttyS0.service sudo systemctl disable serial-getty@ttyS0.service 重启系统 sudo reboot 激活ttyAMAO 上一步我们禁用了ttyS0,现在我们启用ttyAMA0. sudo systemctl enable serial-getty@ttyAMA0.service 好了到了现在，我们已经启用了树莓派的串口，并可以通过/dev/ttyAMA0来访问串口设备。 树莓派的串口引脚 树莓派的引脚定义图如下所示： UART的收发引脚分别为： Tx ——GPIO14（pin8) Rx ——GPIO15（pin10) 连接串口设备并测试 我们使用GPS串口设备进行测试，GPS模块有如下5个引脚： VCC GND TX RX PPS GPS模块和树莓派连接方式如下： VCC ——pin01 GND——pin06 TX——pin10 其他引脚可以不连接。 使用cat或者minicom调试GPS串口： cat /dev/ttyAMA0 #或者 minicom -D /dev/ttyAMA0 -b 9600 能够读取到类似下边的串口输出： $ GPTXT , 01 , 01 , 01 , ANTENNA OK * 35 $ GNGGA , 115810 . 475 ,,,,, 0 , 00 , 25 . 5 ,,,,,, * 70 $ GNGLL ,,,,, 115810 . 475 , V , M * 6 D $ GPGSA , A , 1 ,,,,,,,,,,,,, 25 . 5 , 25 . 5 , 25 . 5 * 02 $ BDGSA , A , 1 ,,,,,,,,,,,,, 25 . 5 , 25 . 5 , 25 . 5 * 13 $ GPGSV , 3 , 1 , 09 , 05 , 05 , 121 ,, 10 , 25 , 314 , 27 , 12 , 14 , 138 ,, 13 , 13 , 058 , 16 * 73 $ GPGSV , 3 , 2 , 09 , 15 , 49 , 043 , 32 , 20 , 53 , 321 , 18 , 21 , 52 , 249 ,, 24 , 77 , 090 , * 77 $ GPGSV , 3 , 3 , 09 , 32 , 11 , 265 , * 40 ​ ``` 参考 树莓派UART文档 Raspberry Pi GPS Module Interfacing Tutorial","tags":"Raspberry","url":"pages/2018/08/25/activate-serial-uart/","loc":"pages/2018/08/25/activate-serial-uart/"},{"title":"树莓派GPIO入门","text":"本文介绍树莓派上GPIO引脚的三种编号方式，同时介绍控制引脚的方式。并以BCM-17引脚为例，动手点亮led灯并使其闪烁。 GPIO是通用输入输出接口。树莓派上有40个引脚，对这40个引脚主要有两种编号方式。 BOARD 和引脚物理顺序一致 BCM wiringpi编号 wiringPi是一个用来控制GPIO的库，它对40个引脚的编号方式如下： 详细信息参考 此网址 wiringPi 安装方式 应用于C语言和shell git clone git://git.drogon.net/wiringPi cd wiringPi git pull origin ./build # 测试安装成功 gpio -vmake gpio readall 应用于Python sudo pip install wiringpi2 测试example程序 将发光二极管的阳极连接BOARD的pin11,也就是BCM17，wiringPi 0，中间需要串一个100-500欧姆的限流电阻。阴极连接到GND引脚（BOARD 9）。 命令行输入： gpio write 0 1 可观察到发光二极管被点亮 gpio函数其他用法参见 文档 编译示例C语言程序程序，使led闪烁 cd wiringPi/examples/ ./blink.sh # 或者 make blink ./blink 使用Python控制GPIO 树莓派原生系统内置的python已经安装了RPi.GPIO库，通过它可以方便的控制GPIO 可以参考以下两份文档： General-RPIO Python-RPIO Python实现LED闪烁，引脚依然是BCM-17 #!/usr/bin/python3 # -*- coding: utf-8 -*- import RPi.GPIO as GPIO from time import sleep GPIO . setmode ( GPIO . BCM ) GPIO . setwarnings ( False ) GPIO . setup ( 17 , GPIO . OUT ) print ( \"All set in Python! Let's blink the LCD on BCM-17\" ) for i in range ( 1 , 10 ): GPIO . output ( 17 , GPIO . HIGH ) sleep ( 1 ) GPIO . output ( 17 , GPIO . LOW ) sleep ( 1 ) GPIO . cleanup () 使用wiringpi库来控制连接BCM-17的led灯闪烁，具体使用说明参看： python-wiringpi使用教程 #!/usr/bin/python3 # -*- coding: utf-8 -*- import wiringpi from time import sleep # 设置wiringpi编号0引脚为输出模式 wiringpi . wiringPiSetup () wiringpi . pinMode ( 0 , 1 ) while True : wiringpi . digitalWrite ( 0 , True ) sleep ( 1 ) wiringpi . digitalWrite ( 0 , False ) sleep ( 1 ) 以下为wiringpi的三种引脚编号： BCM BOARD wiringpi 三种控制模式： input output pwm 设置示范如下： # GPIO 引脚号就是BCM编号 import wiringpi wiringpi . wiringPiSetupGpio () wiringpi . pinMode ( 25 , 0 ) # sets GPIO 25 to input wiringpi . pinMode ( 24 , 1 ) # sets GPIO 24 to output wiringpi . pinMode ( 18 , 2 ) # sets GPIO 18 to PWM mode # wiringpi 编号 import wiringpi wiringpi . wiringPiSetup () wiringpi . pinMode ( 6 , 0 ) # sets WP pin 6 to input wiringpi . pinMode ( 5 , 1 ) # sets WP pin 5 to output wiringpi . pinMode ( 1 , 2 ) # sets WP pin 1 to PWM mode # 物理编号 BOARD编号 import wiringpi wiringPiSetupPhys () wiringpi . pinMode ( 22 , 0 ) # sets P1 pin 22 to input wiringpi . pinMode ( 18 , 1 ) # sets P1 pin 18 to output wiringpi . pinMode ( 12 , 2 ) # sets P1 pin 12 to PWM mode","tags":"Raspberry","url":"pages/2018/08/25/wiringPi-gpio/","loc":"pages/2018/08/25/wiringPi-gpio/"},{"title":"在Linux终端里浏览知乎日报","text":"程序效果图如下： 程序的效果就是可以在Terminal浏览一下每天知乎日报的标题和url，然后根据兴趣选择是否继续阅读。 程序十分简单，只十几行代码。 使用python3，需要安装requests包。 源代码如下，也可以从 我的github 下载。 #!/usr/bin/python3 #-*- coding: utf-8 -*- import requests import json headers = { 'User-Agent' : 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)' } def get_daily (): page = requests . get ( 'http://news-at.zhihu.com/api/3/news/latest' , headers = headers ) . text response = json . loads ( page ) date = response [ 'date' ] stories = response [ 'stories' ] date = ' \\n %s 年 %s 月 %s 日' % ( date [: 4 ], date [ 4 : 6 ], date [ 6 :]) print ( ' %s 共 %d 条日报 \\n ' % ( date , len ( stories ))) for index , story in enumerate ( stories , 1 ): print ( ' {0:<2d} ： {1:s} \\n url：http://news-at.zhihu.com/story/ {2:d} ' . format ( index , story [ 'title' ], story [ 'id' ])) if __name__ == '__main__' : get_daily () 保存为 zhdaily.py 文件，然后将文件放到 /usr/local/bin/ 目录下，并给zhdaily.py增加执行权限： $ sudo mv zhdaily.py /usr/local/bin/ $ cd /usr/local/bin/ $ sudo chmod +x zhdaily.py 这样，当你下次进入终端，可以直接执行： $ zhdaily.py 就可以获得图示的效果。 碎碎念： 曾经知乎是一个优秀的社区，也确实让我发现了更大的世界。可是，从某个时刻开始，充斥我时间线的内容都是被知乎官方筛选的。整个社区充斥着喧嚣、广告、营销和带节奏。 我不喜欢： 被煽动的愤怒 被策划的欢乐 最后，我又回到了RSS的怀抱，可以控制我接收到相对有价值的信息。 不过，浏览知乎日报能了解下当下热点，增加聊天谈资。省的聊天时都不知道《创造101》是啥？赫赫:) 我基本每天只浏览日报的标题，这个小程序正好满足需求。","tags":"Python","url":"pages/2018/05/18/zhihu-daily-crawler/","loc":"pages/2018/05/18/zhihu-daily-crawler/"},{"title":"wordcloud源码阅读2——Cython","text":"上一节中， IntegralOccupancyMap() 函数用来确定单词位置，其中调用了 query_integral_image() 方法。而 query_integral_image 是用来Cython。下边介绍Cython。 Cython介绍 Cython 的本质可以总结如下：Cython 是包含C 数据类型的Python。 Cython可以将Python代码编译成动态链接库，在某些情况下，可以极大提高Python程序的运行效率。 可以看到源码中包括了 query_integral_image.pyx 和 query_integral_image.c 两个文件。其中 .c 文件是Cython自动生产的对应 query_integral_image.pyx C语言程序。 Cython的工作流程大致如下： 我们只需要关心 .pyx 文件中的代码 为了测试使用Cython是否真的可以提高程序效率，我们做如下测试， 系统：Ubuntu 16 环境：python3.5 依赖： Cython==0.28.2 numpy==1.14.2 Pillow==5.1.0 测试代码均可从 github 下载 测试过程 目录tree . ├── python_query_integral_image.py ├── query_integral_image.pyx ├── setup.py ├── test.py └── venv setup.py用来编译动态链接库,内容如下： from distutils.core import setup from Cython.Build import cythonize setup ( ext_modules = cythonize ( \"query_integral_image.pyx\" ) ) 执行： python setup.py build_ext --inplace 然后目录变为了： . ├── build ├── python_query_integral_image.py ├── query_integral_image.c ├── query_integral_image.cpython-35m-i386-linux-gnu.so ├── query_integral_image.pyx ├── setup.py ├── test.py └── venv 下边我们就可以在python程序中import编译后的 .so 文件了, 测试程序test.py如下： # 导入python编写的程序，为了和.so区别，改名为python_query_integral_image from python_query_integral_image import query_integral_image as q1 # 导入经过Cython处理的.so链接库 from query_integral_image import query_integral_image as q2 from random import Random import numpy as np import timeit DX = 3000 DY = 3000 # 相当于一个3000*3000=900万像素的图片 integral = np . zeros (( DX , DY ), dtype = np . uint32 ) random_state = Random () start_time = timeit . default_timer () q1 ( integral , 50 , 50 , random_state ) end_time = timeit . default_timer () q1_dur = ( end_time - start_time ) / 60. start_time = timeit . default_timer () q2 ( integral , 50 , 50 , random_state ) end_time = timeit . default_timer () q2_dur = ( end_time - start_time ) / 60. print ( 'C程序耗时' , q2_dur , 'Python耗时' , q1_dur ) print ( '相差 %f 倍' % ( float ( q1_dur ) / float ( q2_dur ))) 运行测试程序，结果令人吃惊： C程序耗时 0.0007940871333024309 Python耗时 0.6854850105833369 相差863.236516倍 经过Cython简单的处理，同样的代码，运行效率提高了800多倍。刺不刺激？ 可见在作矩阵计算或者循环次数较多时，Cython具有较大作用。 参考 Cython三分钟入门 Cython官方文档中文版","tags":"Python","url":"pages/2018/04/17/wordcloud-src-note2/","loc":"pages/2018/04/17/wordcloud-src-note2/"},{"title":"wordcloud源码阅读1——初探","text":"wordcloud是python用来生成词云的第三方库，github地址是 word_cloud 下载源码： git clone https://github.com/amueller/word_cloud 然后，直接看最老的版本，有精力的话看完最老版本可以再看最新的版本。 git tag git checkout 1 .2.1 现在我们的目录结构如下： 可以看到，核心代码都在wordcloud目录下： wordcloud项目主要用了以下第三方库： Numpy PIL Cython 储备知识： HSL和HSV色彩空间 图片RGB 框架大体流程： 可以看出wordcloud类的两个核心方法 process_text() 和 generate_from_frequencies() 。 如果输入是处理后的{string:frequency}字典类型，直接生成词云的 layout ，若输入是未处理过的字符串，就要先进行 process_text() 统计词频等工作。 继续看 generate_from_frequencies() 的流程： 就得到了词云的layout，后边可以通过 recolor() 重新上色。 mask 是一个n维数组（图片），在我的理解是photoshop里的蒙板，也叫遮色片。在wordcloud里mask决定了生成词云的位置。白色 #FFFFFF 称为 mask out ，即不在白色区域绘制词云。 layout is list of tuple ,格式 (string, int, (int, int), int, color)) 定义了每个单词的（字符串，字体大小，（x位置，y位置), 方向， 颜色） 参考： wordcloud的API可以参考 wordcloud文档中文翻译 具体使用也可以参考 网易云音乐歌手词云","tags":"Python","url":"pages/2018/04/16/wordcloud-src-note1/","loc":"pages/2018/04/16/wordcloud-src-note1/"},{"title":"Git学习记录","text":"本篇记录分为四部分: git本地仓库管理 git与github搭配使用 git图形操作界面学习 git的高级操作 打算长期更新,直到我将这些操作都熟悉了. git本地仓库管理 初始化/创建git项目 git init 效果是在当前目录创建 /.git/ 的隐藏文件夹 将文件添加到git索引 只要文件有修改,必须先添加索引 git add <文件/文件夹名> 常用 git add . 来将当前目录所有文件添加到git管理， . 代表当前目录 查看git管理状态 git目录下的文件状态分为： 未跟踪 已跟踪 未修改 已修改 暂存 已提交 修改后提交文档 git add . git commit -m '这次操作说明' --author = '操作者姓名<email>' -m表示message,--author可以不填写 启动git图形界面 gitk 配置git环境 git config -l 输出结果如下: $ git config -l color.status = auto color.branch = auto filter.lfs.clean = git-lfs clean -- %f user.name = niu_he user.email = *******@gmail.com 列出所有config文件里的设置项 git config --system -l # 系统级的配置 /etc文件加下 git config --global -l # 用户级的配置 /home/用户名/的文件下 git config --local -l # 仓库/项目级 ./.git/目录下 配置具体的某一项 git config 命令均可加上--system或者--golba --local来指定设置的作用范围,未指定则默认配置当前git项目 git config user.name '你的姓名' git config user.email '你的email' 删除配置文件中的配置项 git config --unset user.name 查看配置文件中的配置项 git config --get user.name 定义指令别名 # git config alias.指令别名 '标准指令' git config alias.con 'config -l' git con git config --unset alias.con 创建.gitignore文件 vi .gitignore .gitignore文件规定了git系统该忽略哪些文件 /images *.txt !requirements.txt 如以上配置规定了git忽略 /images目录下的所有文件 除了requirements.txt外的所有txt文件 git和github搭配使用 git的图形操作界面学习 git的高级操作","tags":"Python","url":"pages/2018/04/11/Git_Tutorial/","loc":"pages/2018/04/11/Git_Tutorial/"},{"title":"WordCloud文档中文翻译","text":"Python模块wordcloud参考文档的中文翻译 官网链接： wordcloud api reference Github链接： wordcloud 所有函数均封装在WordCloud类里: WordCloud([...]) 生成并绘制WordCloud对象 ImageColorGenerator(image) 词云颜色生成器（基于图片颜色） random_color_func([]) 词云颜色随机生成 wordcloud.WordCloud class wordcloud . WordCloud ( font_path = None , width = 400 , height = 200 , margin = 2 , ranks_only = None , prefer_horizontal = 0.9 , mask = None , scale = 1 , color_func = None , max_words = 200 , min_font_size = 4 , stopwords = None , random_state = None , background_color = 'black' , max_font_size = None , font_step = 1 , mode = 'RGB' , relative_scaling = 0.5 , regexp = None , collocations = True , colormap = None , normalize_plurals = True ) 参数： font_path : string 需要使用的字体路径(支持OTF和TTF)。Linux系统上默认指向DroidSansMono路径。若使用其他操作系统或者没有DroidSansMono字体，需要指定字体路径。 width : int (default=400) 画布的宽度。 height : int (default=200) 画布的高度。 prefer_horizontal : float (default=0.90) 尝试水平摆放字体和垂直摆放字体的比例，若prefer_horizontal < 1，当摆放不合适的时候，算法将尝试旋转单词。目前没有内置的方法来获取垂直单词 mask : nd-array or None (default=None) 如果不是None，则在哪里绘制单词时给出二进制掩码。 如果mask不是None，那么宽度和高度将被忽略，并且将使用mask的形状。 所有白色（#FF或#FFFFFF）条目将被视为\"被遮盖\"，而其他条目将被自由绘制。 [这在最新版本中发生了变化！] scale : float (default=1) 计算值和绘图之间的缩放比例。 对于大型文字云图像，使用缩放而不是较大的画布尺寸要快得多，但可能导致较粗糙的文字。 min_font_size : int (default=4) 使用最小的字体大小。 当没有更多的空间时停止绘制。 font_step : int (default=1) 字体的步长。 font_step > 1时可能会加快计算速度，但会导致糟糕的字体适应性布局。 max_words : number (default=200) 单词的最大数目。 stopwords : set of strings or None 敏感词集合，这些词将被忽略。 如果没有，则将使用内置的STOPWORDS列表。 background_color : color value (default=\"black\") 词云图像的背景颜色。 max_font_size : int or None (default=None) 使用的最大字体大小。 默认使用图像的高度。 mode : string (default=\"RGB\") 当模式为\"RGBA\"且background_color为None时，会生成透明背景。 relative_scaling : float (default=.5) 字体大小的相对单词频率的重要性。 relative_scaling = 0时，只考虑单词等级。 使用relative_scaling = 1时，频繁两倍的单词将具有两倍的大小。 如果你想考虑单词的频率，而不仅仅是他们的等级，那么0.5左右的relative_scaling通常看起来不错。 color_func : callable, default=None 可用参数关键字 font_size, position, orientation, font_path, random_state 调用，它为每个单词返回一个PIL颜色。 覆盖\"colormap\"。 请参阅colormap来指定matplotlib的颜色映射。 regexp : string or None (optional) 正则表达式将输入文本拆分为待处理文本中的标记。 如果指定None，则使用r\"\\ w [\\ w'] +\"。 collocations : bool, default=True 是否包含两个词的搭配（bigrams），默认为True。 colormap : string or matplotlib colormap, default=\"viridis\" Matplotlib色彩映射表为每个单词随机绘制颜色。 如果指定了\"color_func\"，则忽略。 normalize_plurals : bool, default=True 是否从文字中删除\"尾随\"。 如果为真，当出现以's'结尾的单词，则以's'结尾的单词将被删除，并将其计数添加到没有's'结尾的版本 以'ss'结尾的单词被忽略。 注意： 较大的画布使代码明显变慢。 如果您需要较大的单词云，请尝试较小的画布大小，然后设置缩放参数。 根据最大字体大小和缩放启发式算法，相比单词实际出现的频率，算法可能会给单词的等级更多的权重。 属性： words_ (dict of string to float) 单词标识对应其出现次数，如{'hello':90, 'good':30} .. versionchanged: 2.0 words_ : 现在是一个字典 layout_ (list of tuples (string, int, (int, int), int, color))) 编码拟合词云，为每个单词编码字符串，字体大小，位置，方向和颜色。 方法： # 初始化实例 __init__ ( font_path = None , width = 400 , height = 200 , margin = 2 , ranks_only = None , prefer_horizontal = 0.9 , mask = None , scale = 1 , color_func = None , max_words = 200 , min_font_size = 4 , stopwords = None , random_state = None , background_color = 'black' , max_font_size = None , font_step = 1 , mode = 'RGB' , relative_scaling = 0.5 , regexp = None , collocations = True , colormap = None , normalize_plurals = True ) fit_words(frequencies) 根据单词和频率创建一个word_cloud。 别名为generate_from_frequencies。 参数 : frequencies : array of tuples 元组包含单词及其频率。Note:最新版已经改为字典了。 返回值 ： self generate(text) 从文本生成wordcloud。 别名generate_from_text。 实际调用process_text和generate_from_frequencies。 返回值 ： self generate_from_frequencies(frequencies, max_font_size=None) 根据单词和频率创建词云。 参数 : frequencies : dict from string to float 字典包含单词及其频率。 max_font_size : int 使用此最大字体大，而不是self.max_font_size 返回值 ： self generate_from_text(text) 从文本生成wordcloud。 实际调用process_text和generate_from_frequencies。 ..versionchanged:: 1.2.2 process_text（)的返回值不再是generate_from_frequencies（）的参数。 返回值： self process_text(text) 将长文本拆分为单词，去除停用词(敏感词)。 参数 : text : string 待处理的文本 返回值 ： words : dict (string, int) 带有关联频率的词语标记。 ..versionchanged:: 1.2.2 将返回类型从元组列表更改为字典。 Notes 有更好的方法做词频分析，在此不做赘述。 recolor(random_state=None, color_func=None, colormap=None) 重新着色现有布局。 应用新的着色要比生成整个词云快得多。 参数 : random_state : RandomState, int, or None, default=None 如果不是None，则使用固定的随机状态。 如果给出了一个int，它将用作random.Random状态的种子。 color_func : function or None, default=None 根据(word count, font size, position and orientation)字数，字体大小，位置和方向生成新颜色的函数。 如果为None，则使用self.color_func。 colormap : string or matplotlib colormap, default=None 使用此颜色映射表来生成新的颜色。 如果指定了color_func，则忽略。 如果没有，则使用self.color_func（或self.color_map）。 返回值 ： self to_array() 转换为numpy数组。 返回值 ： image : n维数组 (width, height, 3) 词云图像作为numpy矩阵。 to_file(filename) 导出为图像文件。 参数 : filename : string 要写入的位置。 返回值 ： self wordcloud.ImageColorGenerator class wordcloud . ImageColorGenerator ( image ) 基于彩色图像的颜色生成器. 根据RGB图像生成颜色。 一个单词将使用彩色图像中包围矩形的平均颜色进行着色。 构造完成后，该对象充当可调用对象，可以将其作为color_func传递给WordCloud类的构造函数或recolor这个重新着色方法。 参数 : image : n维矩阵, shape (height, width, 3) 用于生成文字颜色的图像。 Alpha通道 被忽略。对于wordcloud实例，这应该和画布大小相同。 方法 __call__(word, font_size, font_path, ...) 使用特定图像为给定单词生成颜色。 __init__(image) wordcloud.random_color_func wordcloud . random_color_func ( word = None , font_size = None , position = None , orientation = None , font_path = None , random_state = None ) 随机色调颜色生成. 默认着色方法。 这只是随机选择一个值为80％和光照50％的色调。 参数 : word, font_size, position, orientation : ignored. random_state : random.Random object or None, (default=None) 如果给定了一个随机对象，则用它来生成随机数。","tags":"Python","url":"pages/2018/04/08/word-cloud-doc-cn/","loc":"pages/2018/04/08/word-cloud-doc-cn/"},{"title":"Daily PyTrick","text":"2018-3-28 # How to merge two dictionaries # in Python 3.5+ >>> x = { 'a' : 1 , 'b' : 2 } >>> y = { 'b' : 3 , 'c' : 4 } >>> z = { ** x , ** y } >>> z { 'c' : 4 , 'a' : 1 , 'b' : 3 } # In Python 2.x you could # use this: >>> z = dict ( x , ** y ) >>> z { 'a' : 1 , 'c' : 4 , 'b' : 3 } # In these examples, Python merges dictionary keys # in the order listed in the expression, overwriting # duplicates from left to right. 2018-3-29 # Different ways to test multiple # flags at once in Python x , y , z = 0 , 1 , 0 if x == 1 or y == 1 or z == 1 : print ( 'passed' ) if 1 in ( x , y , z ): print ( 'passed' ) # These only test for truthiness: if x or y or z : print ( 'passed' ) if any (( x , y , z )): print ( 'passed' ) 2018-3-30 # How to sort a Python dict by value # (== get a representation sorted by value) >>> xs = { 'a' : 4 , 'b' : 3 , 'c' : 2 , 'd' : 1 } >>> sorted ( xs . items (), key = lambda x : x [ 1 ]) [( 'd' , 1 ), ( 'c' , 2 ), ( 'b' , 3 ), ( 'a' , 4 )] # Or: >>> import operator >>> sorted ( xs . items (), key = operator . itemgetter ( 1 )) [( 'd' , 1 ), ( 'c' , 2 ), ( 'b' , 3 ), ( 'a' , 4 )] 2018-4-2 # The get() method on dicts # and its \"default\" argument name_for_userid = { 382 : \"Alice\" , 590 : \"Bob\" , 951 : \"Dilbert\" , } def greeting ( userid ): return \"Hi %s !\" % name_for_userid . get ( userid , \"there\" ) >>> greeting ( 382 ) \"Hi Alice!\" >>> greeting ( 333333 ) \"Hi there!\" 2018-4-4 # Why Python is Great: Namedtuples # Using namedtuple is way shorter than # defining a class manually: >>> from collections import namedtuple >>> Car = namedtuple ( 'Car' , 'color mileage' ) # Our new \"Car\" class works as expected: >>> my_car = Car ( 'red' , 3812.4 ) >>> my_car . color 'red' >>> my_car . mileage 3812.4 # We get a nice string repr for free: >>> my_car Car ( color = 'red' , mileage = 3812.4 ) # Like tuples, namedtuples are immutable: >>> my_car . color = 'blue' AttributeError : \"can't set attribute\" 2018-4-7 >>> import this The Zen of Python , by Tim Peters Beautiful is better than ugly . Explicit is better than implicit . Simple is better than complex . Complex is better than complicated . Flat is better than nested . Sparse is better than dense . Readability counts . Special cases aren 't special enough to break the rules. Although practicality beats purity . Errors should never pass silently . Unless explicitly silenced . In the face of ambiguity , refuse the temptation to guess . There should be one -- and preferably only one -- obvious way to do it . Although that way may not be obvious at first unless you 're Dutch. Now is better than never . Although never is often better than * right * now . If the implementation is hard to explain , it 's a bad idea. If the implementation is easy to explain , it may be a good idea . Namespaces are one honking great idea -- let 's do more of those! 2018-4-10 # The standard string repr for dicts is hard to read: >>> my_mapping = { 'a' : 23 , 'b' : 42 , 'c' : 0xc0ffee } >>> my_mapping { 'b' : 42 , 'c' : 12648430. 'a' : 23 } # 😞 # The \"json\" module can do a much better job: >>> import json >>> print ( json . dumps ( my_mapping , indent = 4 , sort_keys = True )) { \"a\" : 23 , \"b\" : 42 , \"c\" : 12648430 } # Note this only works with dicts containing # primitive types (check out the \"pprint\" module): >>> json . dumps ({ all : 'yup' }) TypeError : keys must be a string 2018-04-11 # Why Python Is Great : # Function argument unpacking def myfunc ( x , y , z ): print ( x , y , z ) tuple_vec = ( 1 , 0 , 1 ) dict_vec = { 'x' : 1 , 'y' : 0 , 'z' : 1 } >>> myfunc ( * tuple_vec ) 1 , 0 , 1 >>> myfunc ( ** dict_vec ) 1 , 0 , 1 2018-4-16 # The \"timeit\" module lets you measure the execution # time of small bits of Python code >>> import timeit >>> timeit . timeit ( '\"-\".join(str(n) for n in range(100))' , number = 10000 ) 0.3412662749997253 >>> timeit . timeit ( '\"-\".join([str(n) for n in range(100)])' , number = 10000 ) 0.2996307989997149 >>> timeit . timeit ( '\"-\".join(map(str, range(100)))' , number = 10000 ) 0.24581470699922647 2018-4-19 # Why Python Is Great: # In-place value swapping # Let's say we want to swap # the values of a and b... a = 23 b = 42 # The \"classic\" way to do it # with a temporary variable: tmp = a a = b b = tmp # Python also lets us # use this short-hand: a , b = b , a 2018-5-7 # Python has a HTTP server built into the # standard library. This is super handy for # previewing websites. # Python 3.x $ python3 - m http . server # Python 2.x $ python - m SimpleHTTPServer 8000 # (This will serve the current directory at # http://localhost:8000) 2018-5-7 # Because Python has first-class functions they can # be used to emulate switch/case statements def dispatch_if ( operator , x , y ): if operator == 'add' : return x + y elif operator == 'sub' : return x - y elif operator == 'mul' : return x * y elif operator == 'div' : return x / y else : return None def dispatch_dict ( operator , x , y ): return { 'add' : lambda : x + y , 'sub' : lambda : x - y , 'mul' : lambda : x * y , 'div' : lambda : x / y , } . get ( operator , lambda : None )() >>> dispatch_if ( 'mul' , 2 , 8 ) 16 >>> dispatch_dict ( 'mul' , 2 , 8 ) 16 >>> dispatch_if ( 'unknown' , 2 , 8 ) None >>> dispatch_dict ( 'unknown' , 2 , 8 ) None 2018-5-7 # Functions are first-class citizens in Python. # They can be passed as arguments to other functions, # returned as values from other functions, and # assigned to variables and stored in data structures. >>> def myfunc ( a , b ): ... return a + b ... >>> funcs = [ myfunc ] >>> funcs [ 0 ] < function myfunc at 0x107012230 > >>> funcs [ 0 ]( 2 , 3 ) 5 2018-5-7 # \"is\" vs \"==\" >>> a = [ 1 , 2 , 3 ] >>> b = a >>> a is b True >>> a == b True >>> c = list ( a ) >>> a == c True >>> a is c False # • \"is\" expressions evaluate to True if two # variables point to the same object # • \"==\" evaluates to True if the objects # referred to by the variables are equal 2018-05-18 # Python's list comprehensions are awesome. vals = [ expression for value in collection if condition ] # This is equivalent to: vals = [] for value in collection : if condition : vals . append ( expression ) # Example: >>> even_squares = [ x * x for x in range ( 10 ) if not x % 2 ] >>> even_squares [ 0 , 4 , 16 , 36 , 64 ] 2018-05-19 # 'type annotation'不改变Python运行时，但可以在开发程序时用其他第三方工具进行类型检查。 # Python 3.5+ supports 'type annotations' that can be # used with tools like Mypy to write statically typed Python: def my_add ( a : int , b : int ) -> int : return a + b 2018-05-20 # Python's list slice syntax can be used without indices # for a few fun and useful things: # You can clear all elements from a list: >>> lst = [ 1 , 2 , 3 , 4 , 5 ] >>> del lst [:] >>> lst [] # You can replace all elements of a list # without creating a new list object: >>> a = lst >>> lst [:] = [ 7 , 8 , 9 ] >>> lst [ 7 , 8 , 9 ] >>> a [ 7 , 8 , 9 ] >>> a is lst True # You can also create a (shallow) copy of a list: >>> b = lst [:] >>> b [ 7 , 8 , 9 ] >>> b is lst False 2018-05-29 # collections.Counter lets you find the most common # elements in an iterable: >>> import collections >>> c = collections . Counter ( 'helloworld' ) >>> c Counter ({ 'l' : 3 , 'o' : 2 , 'e' : 1 , 'd' : 1 , 'h' : 1 , 'r' : 1 , 'w' : 1 }) >>> c . most_common ( 3 ) [( 'l' , 3 ), ( 'o' , 2 ), ( 'e' , 1 )] 2018-06-06 # itertools.permutations() generates permutations # for an iterable. Time to brute-force those passwords ;-) >>> import itertools >>> for p in itertools . permutations ( 'ABCD' ): ... print ( p ) ( 'A' , 'B' , 'C' , 'D' ) ( 'A' , 'B' , 'D' , 'C' ) ( 'A' , 'C' , 'B' , 'D' ) ( 'A' , 'C' , 'D' , 'B' ) ( 'A' , 'D' , 'B' , 'C' ) ( 'A' , 'D' , 'C' , 'B' ) ( 'B' , 'A' , 'C' , 'D' ) ( 'B' , 'A' , 'D' , 'C' ) ( 'B' , 'C' , 'A' , 'D' ) ( 'B' , 'C' , 'D' , 'A' ) ( 'B' , 'D' , 'A' , 'C' ) ( 'B' , 'D' , 'C' , 'A' ) ( 'C' , 'A' , 'B' , 'D' ) ( 'C' , 'A' , 'D' , 'B' ) ( 'C' , 'B' , 'A' , 'D' ) ( 'C' , 'B' , 'D' , 'A' ) ( 'C' , 'D' , 'A' , 'B' ) ( 'C' , 'D' , 'B' , 'A' ) ( 'D' , 'A' , 'B' , 'C' ) ( 'D' , 'A' , 'C' , 'B' ) ( 'D' , 'B' , 'A' , 'C' ) ( 'D' , 'B' , 'C' , 'A' ) ( 'D' , 'C' , 'A' , 'B' ) ( 'D' , 'C' , 'B' , 'A' )","tags":"Python","url":"pages/2018/04/05/Python-Tricks/","loc":"pages/2018/04/05/Python-Tricks/"},{"title":"My First Blog","text":"This is my first blog powered by pelican . 美国诗人纳·斯待尔在87岁那年写过一首诗：《 我会采更多的雏菊 》，摘取片段于下。 如果我能够从头活过， 我会试着犯更多的错。 我会放松一点，我会灵活一点。 我会比这一趟过得傻。 很少有什么事情能让我当真。 我会疯狂一些，我会少讲点卫生。 我会冒更多的险。我会更经常的旅行。 我会爬更多的山，游更多的河，看更多的日落。 我会多吃冰激凌，少吃豆子。 我会惹更多的麻烦，可是不在想象中担忧。 噢，我有过难忘的时刻。 如果我能够重来一次，我会要更多这样的时刻。 我会更经常的逃学。 我不会考那么高的分数，除非是一不小心。 我会多骑些旋转木马， 我会采更多的雏菊。 人不仅要拥有此生此世，还要那诗意的世界","tags":"Life : )","url":"pages/2018/03/22/my-first-blog/","loc":"pages/2018/03/22/my-first-blog/"}]};