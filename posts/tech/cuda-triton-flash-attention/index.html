<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>CUDA、Triton 与 Flash Attention 学习之旅 | Niuhe&#39;s Blog</title>
<meta name="keywords" content="GPU, HowToLearn, Flash Attention">
<meta name="description" content="深入探讨 CUDA、Triton 和 Flash Attention 的学习路径与关键概念">
<meta name="author" content="Niuhe">
<link rel="canonical" href="https://blog.niuhemoon.win/posts/tech/cuda-triton-flash-attention/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css" integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe&#43;FVUFzPh7U=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://blog.niuhemoon.win/base/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://blog.niuhemoon.win/base/favicon.ico">
<link rel="icon" type="image/png" sizes="32x32" href="https://blog.niuhemoon.win/base/favicon.ico">
<link rel="apple-touch-icon" href="https://blog.niuhemoon.win/base/avatar.jpeg">
<link rel="mask-icon" href="https://blog.niuhemoon.win/base/avatar.jpeg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-116933089-1', 'auto');
	
	ga('send', 'pageview');
}
</script><meta property="og:title" content="CUDA、Triton 与 Flash Attention 学习之旅" />
<meta property="og:description" content="深入探讨 CUDA、Triton 和 Flash Attention 的学习路径与关键概念" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://blog.niuhemoon.win/posts/tech/cuda-triton-flash-attention/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-04-08T00:00:00+00:00" />
<meta property="article:modified_time" content="2025-04-08T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="CUDA、Triton 与 Flash Attention 学习之旅"/>
<meta name="twitter:description" content="深入探讨 CUDA、Triton 和 Flash Attention 的学习路径与关键概念"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "📚文章",
      "item": "https://blog.niuhemoon.win/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "👨🏻‍💻 技术",
      "item": "https://blog.niuhemoon.win/posts/tech/"
    }, 
    {
      "@type": "ListItem",
      "position":  4 ,
      "name": "CUDA、Triton 与 Flash Attention 学习之旅",
      "item": "https://blog.niuhemoon.win/posts/tech/cuda-triton-flash-attention/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "CUDA、Triton 与 Flash Attention 学习之旅",
  "name": "CUDA、Triton 与 Flash Attention 学习之旅",
  "description": "深入探讨 CUDA、Triton 和 Flash Attention 的学习路径与关键概念",
  "keywords": [
    "GPU", "HowToLearn", "Flash Attention"
  ],
  "articleBody": "引言 Info\n在深度学习和高性能计算领域，GPU 加速技术已成为提升模型训练和推理速度的关键。CUDA、Triton 和 Flash Attention 作为这一领域的重要技术，对于理解和优化大型语言模型尤为重要。本文将客观地探讨这些技术的学习路径、核心概念以及学习过程中的关键策略。\n学习方法论的演变 传统的学习理念常常强调\"授人以鱼不如授人以渔\"，即教授具体技能比直接提供解决方案更有价值。然而，在技术快速迭代的今天，这一理念需要进一步发展。现代学习方法论更强调\"教人学习新技能\"的重要性：\n授人以鱼，仅解一日之饥； 授人以渔，可解一生之需； 教人学习新技能，则能建造渔船，养活整村。\n这一理念尤为重要，因为在毕业后，人们往往发现自己身处\"丛林\"而非\"海洋\"，传统教育中习得的\"钓鱼技能\"可能无法直接应用。掌握学习新技能的能力，才是应对快速变化的技术环境的关键。\nCUDA、Triton 与 Flash Attention 概述 Flash Attention Flash Attention 是一种针对 Transformer 模型的优化 Attention 机制实现，其核心目标是最小化 GPU 上的内存拷贝（IO aware）。在大型语言模型中，Attention 机制是计算密集型操作，而 Flash Attention 通过优化内存访问模式，显著提升了性能。\nCUDA CUDA 是英伟达提供的软件栈，允许开发者编写在英伟达 GPU 上运行的 GPU kernels。它提供了直接访问 GPU 计算资源的能力，是高性能计算的基础工具。\nTriton Triton 是 OpenAI 的项目，旨在提供一种更标准化、硬件无关的方式来编写 GPU kernels。它允许使用 Python 编写代码并编译到 CUDA 或 ROCm 等后端，弥合了机器学习从业者（通常熟悉 Python）和 GPU kernel 开发者之间的差距。\nGPU 内存层级与性能优化 理解 GPU 内存层级结构是掌握性能优化的关键。GPU 内存主要分为两类：\nDRAM/HBM：容量大但访问速度相对较慢 SRAM：容量小但访问速度快 在 GPU 编程中，频繁的内存拷贝是性能瓶颈的主要来源。Kernel Fusion 是 Flash Attention 使用的关键优化技术之一，它通过合并多个操作到一个 kernel 中，减少内存访问次数，从而提升性能。\n学习驱动力：解决实际问题 学习新技术的动力应源于解决实际问题，而非盲目追逐技术热点。对于 CUDA 和 Triton 的学习，一个常见的驱动力是希望能够理解、调试和优化深度学习架构中的底层 GPU kernels，从而突破现有代码的性能限制。\n利用现代工具辅助学习 在学习复杂技术时，现代工具可以提供巨大帮助：\nTip\nAI 辅助工具：ChatGPT 等 AI 工具可以作为学习过程中的\"最佳助手\"，随时提供帮助，解锁学习过程中的障碍 个性化学习路径：不必过分依赖预设的学习路线图，可以通过不断提问和探索，基于自身知识构建个性化的学习路径 实践导向的学习策略 Note\n动手实践的重要性\n学习不仅仅是理论研究，更重要的是动手实践。对于 Triton 和 CUDA 的学习，直接开始官方教程是一个良好的起点。学习过程中，应该\"边学边做\"，通过实践加深理解。\n设定明确的学习目标\n学习任何新技术时，设定明确的目标至关重要。这些目标应该是具体的、可衡量的，并且与实际问题相关。例如，“实现一个基本的 CUDA kernel\"或\"优化特定模型中的 Attention 机制\"都是良好的学习目标。\n实用学习策略示例 Vector Addition 学习示例 即使是像 Vector Addition 这样基础的教程，对于没有 GPU 编程经验的人来说也可能存在理解障碍。有效的学习策略包括：\n首先让代码能够运行起来 通过调试工具（如 Triton Interpreter）理解代码执行过程 遇到知识盲区时，有针对性地查找相关资源，但要带着目标去学习，不要偏离主线 攻克 Flash Attention 理解 Flash Attention 这类复杂算法的有效方法：\n首先通读相关论文，获取整体理解，并标记不理解的概念 不要立即停下来深入研究每一个不理解的点，而是先读完一遍，然后再针对性地查阅资料 对于重要的算法和证明，进行\"主动学习\"，例如尝试编写代码实现或手动推导证明过程 Flash Attention 的关键知识点 Online Softmax Flash Attention 为了在分块计算 Attention 时正确计算 Softmax 的归一化因子，使用了在线计算 Softmax 的方法。理解这一算法需要掌握相关数学原理，并通过编码实现和手动推导来加深理解。\nBlock Matrix Multiplication Flash Attention 将查询（Queries）、键（Keys）和值（Values）分块进行计算，因此理解分块矩阵乘法是掌握该算法的关键。\nTensor Shapes and Strides 理解 tensor 在内存中的存储方式（形状和步长）对于编写高效的 GPU kernels 至关重要，因为 GPU kernel 直接操作内存地址。\nBack Propagation Flash Attention 的反向传播过程也需要在 GPU kernel 中实现，因此需要理解反向传播的原理和梯度计算。PyTorch 通过链式法则计算梯度，并在矩阵乘法中避免显式计算 Jacobian 矩阵，这些优化方法对于理解和实现高效的反向传播至关重要。\n持续学习的建议 Warning\n追随好奇心而非炒作\n不要盲目追逐热门技术，而是应该基于自己的兴趣和目标进行学习。技术热点可能转瞬即逝，但解决实际问题的能力将长期有效。\n持续学习的关键要素 注重持续性 学习是一个长期的过程，持续的努力比一时的冲动更重要。即使起点不高，只要坚持不懈，最终也能取得进步。\n避免噪音 市场和社交媒体上有很多噪音，要专注于自己的学习路径和长期目标。可以了解新技术动态（“双流学习”），但不要轻易改变学习方向。\n长期投入才能精通 精通任何技能都需要时间的积累，学习是一个循序渐进的过程。“10000小时定律\"在技术学习中依然适用，尽管现代工具可以在一定程度上加速学习过程。\n学习成功的关键：自信与行动 学习成功的关键在于学习者自身的态度和行动。建立自信心至关重要，而自信来源于完成困难的任务。不要仅仅停留在观看教程的被动学习阶段，要积极主动地挑战自己，尝试改进已有的工作。\n参与社区活动和挑战（如排行榜竞赛）是提升技能的有效方式，即使一开始成绩不佳也没关系，“唯一的失败是不参与”。参与本身就是一种挑战和进步。\n实用学习资源 对于没有 GPU 的学习者，可以利用以下资源进行学习和实践：\nInfo\nGoogle Colab 云平台上的 GPU 实例 Triton Interpreter 结语 CUDA、Triton 和 Flash Attention 的学习是一个循序渐进的过程，需要理论与实践相结合，持续投入时间和精力。通过设定明确目标、积极实践、利用现代工具和保持持续学习的态度，任何人都能够逐步掌握这些复杂的技术，并将其应用于解决实际问题。\n在技术快速发展的今天，掌握\"学习如何学习\"的能力比掌握特定技术更为重要，这将使学习者能够不断适应新的技术环境，并在技术变革中保持竞争力。\n参考资源 NOTEBOOKLM音频 Youtube ",
  "wordCount" : "2599",
  "inLanguage": "zh",
  "datePublished": "2025-04-08T00:00:00Z",
  "dateModified": "2025-04-08T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Niuhe"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://blog.niuhemoon.win/posts/tech/cuda-triton-flash-attention/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Niuhe's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://blog.niuhemoon.win/base/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://blog.niuhemoon.win" accesskey="h" title="Niuhe&#39;s Blog (Alt + H)">
                <img src="https://blog.niuhemoon.win/base/avatar.jpeg" alt="" aria-label="logo"
                    height="35">Niuhe&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://blog.niuhemoon.win/search" title="🔍搜索 (Alt &#43; /)" accesskey=/>
                    <span>🔍搜索</span>
                </a>
            </li>
            <li>
                <a href="https://blog.niuhemoon.win/" title="🏠主页">
                    <span>🏠主页</span>
                </a>
            </li>
            <li>
                <a href="https://blog.niuhemoon.win/posts" title="📚文章">
                    <span>📚文章</span>
                </a>
            </li>
            <li>
                <a href="https://blog.niuhemoon.win/tags" title="🔖标签">
                    <span>🔖标签</span>
                </a>
            </li>
            <li>
                <a href="https://blog.niuhemoon.win/archives/" title="⏱时间轴">
                    <span>⏱时间轴</span>
                </a>
            </li>
            <li>
                <a href="https://blog.niuhemoon.win/about" title="🙋🏻‍♂️关于">
                    <span>🙋🏻‍♂️关于</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://blog.niuhemoon.win">🏠主页</a>&nbsp;»&nbsp;<a href="https://blog.niuhemoon.win/posts/">📚文章</a>&nbsp;»&nbsp;<a href="https://blog.niuhemoon.win/posts/tech/">👨🏻‍💻 技术</a></div>
    <h1 class="post-title">
      CUDA、Triton 与 Flash Attention 学习之旅
    </h1>
    <div class="post-description">
      深入探讨 CUDA、Triton 和 Flash Attention 的学习路径与关键概念
    </div>
    <div class="post-meta"><span title='2025-04-08 00:00:00 +0000 UTC'>2025-04-08</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;2599 字&nbsp;·&nbsp;Niuhe

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">文章目录</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e5%bc%95%e8%a8%80" aria-label="引言">引言</a></li>
                <li>
                    <a href="#%e5%ad%a6%e4%b9%a0%e6%96%b9%e6%b3%95%e8%ae%ba%e7%9a%84%e6%bc%94%e5%8f%98" aria-label="学习方法论的演变">学习方法论的演变</a></li>
                <li>
                    <a href="#cudatriton-%e4%b8%8e-flash-attention-%e6%a6%82%e8%bf%b0" aria-label="CUDA、Triton 与 Flash Attention 概述">CUDA、Triton 与 Flash Attention 概述</a><ul>
                        
                <li>
                    <a href="#flash-attention" aria-label="Flash Attention">Flash Attention</a></li>
                <li>
                    <a href="#cuda" aria-label="CUDA">CUDA</a></li>
                <li>
                    <a href="#triton" aria-label="Triton">Triton</a></li></ul>
                </li>
                <li>
                    <a href="#gpu-%e5%86%85%e5%ad%98%e5%b1%82%e7%ba%a7%e4%b8%8e%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96" aria-label="GPU 内存层级与性能优化">GPU 内存层级与性能优化</a></li>
                <li>
                    <a href="#%e5%ad%a6%e4%b9%a0%e9%a9%b1%e5%8a%a8%e5%8a%9b%e8%a7%a3%e5%86%b3%e5%ae%9e%e9%99%85%e9%97%ae%e9%a2%98" aria-label="学习驱动力：解决实际问题">学习驱动力：解决实际问题</a></li>
                <li>
                    <a href="#%e5%88%a9%e7%94%a8%e7%8e%b0%e4%bb%a3%e5%b7%a5%e5%85%b7%e8%be%85%e5%8a%a9%e5%ad%a6%e4%b9%a0" aria-label="利用现代工具辅助学习">利用现代工具辅助学习</a></li>
                <li>
                    <a href="#%e5%ae%9e%e8%b7%b5%e5%af%bc%e5%90%91%e7%9a%84%e5%ad%a6%e4%b9%a0%e7%ad%96%e7%95%a5" aria-label="实践导向的学习策略">实践导向的学习策略</a></li>
                <li>
                    <a href="#%e5%ae%9e%e7%94%a8%e5%ad%a6%e4%b9%a0%e7%ad%96%e7%95%a5%e7%a4%ba%e4%be%8b" aria-label="实用学习策略示例">实用学习策略示例</a><ul>
                        
                <li>
                    <a href="#vector-addition-%e5%ad%a6%e4%b9%a0%e7%a4%ba%e4%be%8b" aria-label="Vector Addition 学习示例">Vector Addition 学习示例</a></li>
                <li>
                    <a href="#%e6%94%bb%e5%85%8b-flash-attention" aria-label="攻克 Flash Attention">攻克 Flash Attention</a></li></ul>
                </li>
                <li>
                    <a href="#flash-attention-%e7%9a%84%e5%85%b3%e9%94%ae%e7%9f%a5%e8%af%86%e7%82%b9" aria-label="Flash Attention 的关键知识点">Flash Attention 的关键知识点</a><ul>
                        
                <li>
                    <a href="#online-softmax" aria-label="Online Softmax">Online Softmax</a></li>
                <li>
                    <a href="#block-matrix-multiplication" aria-label="Block Matrix Multiplication">Block Matrix Multiplication</a></li>
                <li>
                    <a href="#tensor-shapes-and-strides" aria-label="Tensor Shapes and Strides">Tensor Shapes and Strides</a></li>
                <li>
                    <a href="#back-propagation" aria-label="Back Propagation">Back Propagation</a></li></ul>
                </li>
                <li>
                    <a href="#%e6%8c%81%e7%bb%ad%e5%ad%a6%e4%b9%a0%e7%9a%84%e5%bb%ba%e8%ae%ae" aria-label="持续学习的建议">持续学习的建议</a></li>
                <li>
                    <a href="#%e6%8c%81%e7%bb%ad%e5%ad%a6%e4%b9%a0%e7%9a%84%e5%85%b3%e9%94%ae%e8%a6%81%e7%b4%a0" aria-label="持续学习的关键要素">持续学习的关键要素</a><ul>
                        
                <li>
                    <a href="#%e6%b3%a8%e9%87%8d%e6%8c%81%e7%bb%ad%e6%80%a7" aria-label="注重持续性">注重持续性</a></li>
                <li>
                    <a href="#%e9%81%bf%e5%85%8d%e5%99%aa%e9%9f%b3" aria-label="避免噪音">避免噪音</a></li>
                <li>
                    <a href="#%e9%95%bf%e6%9c%9f%e6%8a%95%e5%85%a5%e6%89%8d%e8%83%bd%e7%b2%be%e9%80%9a" aria-label="长期投入才能精通">长期投入才能精通</a></li></ul>
                </li>
                <li>
                    <a href="#%e5%ad%a6%e4%b9%a0%e6%88%90%e5%8a%9f%e7%9a%84%e5%85%b3%e9%94%ae%e8%87%aa%e4%bf%a1%e4%b8%8e%e8%a1%8c%e5%8a%a8" aria-label="学习成功的关键：自信与行动">学习成功的关键：自信与行动</a></li>
                <li>
                    <a href="#%e5%ae%9e%e7%94%a8%e5%ad%a6%e4%b9%a0%e8%b5%84%e6%ba%90" aria-label="实用学习资源">实用学习资源</a></li>
                <li>
                    <a href="#%e7%bb%93%e8%af%ad" aria-label="结语">结语</a></li>
                <li>
                    <a href="#%e5%8f%82%e8%80%83%e8%b5%84%e6%ba%90" aria-label="参考资源">参考资源</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h3 id="引言">引言<a hidden class="anchor" aria-hidden="true" href="#引言">#</a></h3>
<style type="text/css">.notice{--root-color:#444;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#c33;--warning-content:#fee;--info-title:#fb7;--info-content:#fec;--note-title:#6be;--note-content:#e7f2fa;--tip-title:#5a5;--tip-content:#efe}@media (prefers-color-scheme:dark){.notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}}body.dark .notice{--root-color:#ddd;--root-background:#eff;--title-color:#fff;--title-background:#7bd;--warning-title:#800;--warning-content:#400;--info-title:#a50;--info-content:#420;--note-title:#069;--note-content:#023;--tip-title:#363;--tip-content:#121}.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:var(--root-color);background:var(--root-background)}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:var(--title-color);background:var(--title-background)}.notice.warning .notice-title{background:var(--warning-title)}.notice.warning{background:var(--warning-content)}.notice.info .notice-title{background:var(--info-title)}.notice.info{background:var(--info-content)}.notice.note .notice-title{background:var(--note-title)}.notice.note{background:var(--note-content)}.notice.tip .notice-title{background:var(--tip-title)}.notice.tip{background:var(--tip-content)}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative}</style>
<div><svg width="0" height="0" display="none" xmlns="http://www.w3.org/2000/svg"><symbol id="tip-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379 0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628 0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628 0l-22.627 22.627c-6.248 6.248-6.248 16.379 0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z"/></symbol><symbol id="note-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z"/></symbol><symbol id="warning-notice" viewBox="0 0 576 512" preserveAspectRatio="xMidYMid meet"><path d="M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937 0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154 0l239.94 416.028zM288 354c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z"/></symbol><symbol id="info-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z"/></symbol></svg></div><div class="notice info" >
<p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#info-notice"></use></svg></span>Info</p><p>在深度学习和高性能计算领域，GPU 加速技术已成为提升模型训练和推理速度的关键。CUDA、Triton 和 Flash Attention 作为这一领域的重要技术，对于理解和优化大型语言模型尤为重要。本文将客观地探讨这些技术的学习路径、核心概念以及学习过程中的关键策略。</p></div>
<h3 id="学习方法论的演变">学习方法论的演变<a hidden class="anchor" aria-hidden="true" href="#学习方法论的演变">#</a></h3>
<p>传统的学习理念常常强调&quot;授人以鱼不如授人以渔&quot;，即教授具体技能比直接提供解决方案更有价值。然而，在技术快速迭代的今天，这一理念需要进一步发展。现代学习方法论更强调&quot;教人学习新技能&quot;的重要性：</p>










  





  


<blockquote>
  <p>授人以鱼，仅解一日之饥；
授人以渔，可解一生之需；
教人学习新技能，则能建造渔船，养活整村。</p>
  <footer>
    <strong></strong>
    
      
        
      
    
  </footer>
</blockquote>
<p>这一理念尤为重要，因为在毕业后，人们往往发现自己身处&quot;丛林&quot;而非&quot;海洋&quot;，传统教育中习得的&quot;钓鱼技能&quot;可能无法直接应用。掌握学习新技能的能力，才是应对快速变化的技术环境的关键。</p>
<h3 id="cudatriton-与-flash-attention-概述">CUDA、Triton 与 Flash Attention 概述<a hidden class="anchor" aria-hidden="true" href="#cudatriton-与-flash-attention-概述">#</a></h3>
<h4 id="flash-attention">Flash Attention<a hidden class="anchor" aria-hidden="true" href="#flash-attention">#</a></h4>
<p>Flash Attention 是一种针对 Transformer 模型的优化 Attention 机制实现，其核心目标是最小化 GPU 上的内存拷贝（IO aware）。在大型语言模型中，Attention 机制是计算密集型操作，而 Flash Attention 通过优化内存访问模式，显著提升了性能。</p>
<h4 id="cuda">CUDA<a hidden class="anchor" aria-hidden="true" href="#cuda">#</a></h4>
<p>CUDA 是英伟达提供的软件栈，允许开发者编写在英伟达 GPU 上运行的 GPU kernels。它提供了直接访问 GPU 计算资源的能力，是高性能计算的基础工具。</p>
<h4 id="triton">Triton<a hidden class="anchor" aria-hidden="true" href="#triton">#</a></h4>
<p>Triton 是 OpenAI 的项目，旨在提供一种更标准化、硬件无关的方式来编写 GPU kernels。它允许使用 Python 编写代码并编译到 CUDA 或 ROCm 等后端，弥合了机器学习从业者（通常熟悉 Python）和 GPU kernel 开发者之间的差距。</p>
<h3 id="gpu-内存层级与性能优化">GPU 内存层级与性能优化<a hidden class="anchor" aria-hidden="true" href="#gpu-内存层级与性能优化">#</a></h3>
<p>理解 GPU 内存层级结构是掌握性能优化的关键。GPU 内存主要分为两类：</p>
<ul>
<li><strong>DRAM/HBM</strong>：容量大但访问速度相对较慢</li>
<li><strong>SRAM</strong>：容量小但访问速度快</li>
</ul>
<p>在 GPU 编程中，频繁的内存拷贝是性能瓶颈的主要来源。Kernel Fusion 是 Flash Attention 使用的关键优化技术之一，它通过合并多个操作到一个 kernel 中，减少内存访问次数，从而提升性能。</p>
<h3 id="学习驱动力解决实际问题">学习驱动力：解决实际问题<a hidden class="anchor" aria-hidden="true" href="#学习驱动力解决实际问题">#</a></h3>
<p>学习新技术的动力应源于解决实际问题，而非盲目追逐技术热点。对于 CUDA 和 Triton 的学习，一个常见的驱动力是希望能够理解、调试和优化深度学习架构中的底层 GPU kernels，从而突破现有代码的性能限制。</p>
<h3 id="利用现代工具辅助学习">利用现代工具辅助学习<a hidden class="anchor" aria-hidden="true" href="#利用现代工具辅助学习">#</a></h3>
<p>在学习复杂技术时，现代工具可以提供巨大帮助：</p>
<div class="notice tip" >
<p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#tip-notice"></use></svg></span>Tip</p><ul>
<li><strong>AI 辅助工具</strong>：ChatGPT 等 AI 工具可以作为学习过程中的&quot;最佳助手&quot;，随时提供帮助，解锁学习过程中的障碍</li>
<li><strong>个性化学习路径</strong>：不必过分依赖预设的学习路线图，可以通过不断提问和探索，基于自身知识构建个性化的学习路径</li>
</ul></div>
<h3 id="实践导向的学习策略">实践导向的学习策略<a hidden class="anchor" aria-hidden="true" href="#实践导向的学习策略">#</a></h3>
<div class="notice note" >
<p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#note-notice"></use></svg></span>Note</p><p><strong>动手实践的重要性</strong></p>
<p>学习不仅仅是理论研究，更重要的是动手实践。对于 Triton 和 CUDA 的学习，直接开始官方教程是一个良好的起点。学习过程中，应该&quot;边学边做&quot;，通过实践加深理解。</p>
<p><strong>设定明确的学习目标</strong></p>
<p>学习任何新技术时，设定明确的目标至关重要。这些目标应该是具体的、可衡量的，并且与实际问题相关。例如，&ldquo;实现一个基本的 CUDA kernel&quot;或&quot;优化特定模型中的 Attention 机制&quot;都是良好的学习目标。</p></div>
<h3 id="实用学习策略示例">实用学习策略示例<a hidden class="anchor" aria-hidden="true" href="#实用学习策略示例">#</a></h3>
<h4 id="vector-addition-学习示例">Vector Addition 学习示例<a hidden class="anchor" aria-hidden="true" href="#vector-addition-学习示例">#</a></h4>
<p>即使是像 Vector Addition 这样基础的教程，对于没有 GPU 编程经验的人来说也可能存在理解障碍。有效的学习策略包括：</p>
<ol>
<li>首先让代码能够运行起来</li>
<li>通过调试工具（如 Triton Interpreter）理解代码执行过程</li>
<li>遇到知识盲区时，有针对性地查找相关资源，但要带着目标去学习，不要偏离主线</li>
</ol>
<h4 id="攻克-flash-attention">攻克 Flash Attention<a hidden class="anchor" aria-hidden="true" href="#攻克-flash-attention">#</a></h4>
<p>理解 Flash Attention 这类复杂算法的有效方法：</p>
<ol>
<li>首先通读相关论文，获取整体理解，并标记不理解的概念</li>
<li>不要立即停下来深入研究每一个不理解的点，而是先读完一遍，然后再针对性地查阅资料</li>
<li>对于重要的算法和证明，进行&quot;主动学习&quot;，例如尝试编写代码实现或手动推导证明过程</li>
</ol>
<h3 id="flash-attention-的关键知识点">Flash Attention 的关键知识点<a hidden class="anchor" aria-hidden="true" href="#flash-attention-的关键知识点">#</a></h3>
<h4 id="online-softmax">Online Softmax<a hidden class="anchor" aria-hidden="true" href="#online-softmax">#</a></h4>
<p>Flash Attention 为了在分块计算 Attention 时正确计算 Softmax 的归一化因子，使用了在线计算 Softmax 的方法。理解这一算法需要掌握相关数学原理，并通过编码实现和手动推导来加深理解。</p>
<h4 id="block-matrix-multiplication">Block Matrix Multiplication<a hidden class="anchor" aria-hidden="true" href="#block-matrix-multiplication">#</a></h4>
<p>Flash Attention 将查询（Queries）、键（Keys）和值（Values）分块进行计算，因此理解分块矩阵乘法是掌握该算法的关键。</p>
<h4 id="tensor-shapes-and-strides">Tensor Shapes and Strides<a hidden class="anchor" aria-hidden="true" href="#tensor-shapes-and-strides">#</a></h4>
<p>理解 tensor 在内存中的存储方式（形状和步长）对于编写高效的 GPU kernels 至关重要，因为 GPU kernel 直接操作内存地址。</p>
<h4 id="back-propagation">Back Propagation<a hidden class="anchor" aria-hidden="true" href="#back-propagation">#</a></h4>
<p>Flash Attention 的反向传播过程也需要在 GPU kernel 中实现，因此需要理解反向传播的原理和梯度计算。PyTorch 通过链式法则计算梯度，并在矩阵乘法中避免显式计算 Jacobian 矩阵，这些优化方法对于理解和实现高效的反向传播至关重要。</p>
<h3 id="持续学习的建议">持续学习的建议<a hidden class="anchor" aria-hidden="true" href="#持续学习的建议">#</a></h3>
<div class="notice warning" >
<p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#warning-notice"></use></svg></span>Warning</p><p><strong>追随好奇心而非炒作</strong></p>
<p>不要盲目追逐热门技术，而是应该基于自己的兴趣和目标进行学习。技术热点可能转瞬即逝，但解决实际问题的能力将长期有效。</p></div>
<h3 id="持续学习的关键要素">持续学习的关键要素<a hidden class="anchor" aria-hidden="true" href="#持续学习的关键要素">#</a></h3>
<h4 id="注重持续性">注重持续性<a hidden class="anchor" aria-hidden="true" href="#注重持续性">#</a></h4>
<p>学习是一个长期的过程，持续的努力比一时的冲动更重要。即使起点不高，只要坚持不懈，最终也能取得进步。</p>
<h4 id="避免噪音">避免噪音<a hidden class="anchor" aria-hidden="true" href="#避免噪音">#</a></h4>
<p>市场和社交媒体上有很多噪音，要专注于自己的学习路径和长期目标。可以了解新技术动态（&ldquo;双流学习&rdquo;），但不要轻易改变学习方向。</p>
<h4 id="长期投入才能精通">长期投入才能精通<a hidden class="anchor" aria-hidden="true" href="#长期投入才能精通">#</a></h4>
<p>精通任何技能都需要时间的积累，学习是一个循序渐进的过程。&ldquo;10000小时定律&quot;在技术学习中依然适用，尽管现代工具可以在一定程度上加速学习过程。</p>
<h3 id="学习成功的关键自信与行动">学习成功的关键：自信与行动<a hidden class="anchor" aria-hidden="true" href="#学习成功的关键自信与行动">#</a></h3>
<p>学习成功的关键在于学习者自身的态度和行动。建立自信心至关重要，而自信来源于完成困难的任务。不要仅仅停留在观看教程的被动学习阶段，要积极主动地挑战自己，尝试改进已有的工作。</p>
<p>参与社区活动和挑战（如排行榜竞赛）是提升技能的有效方式，即使一开始成绩不佳也没关系，&ldquo;唯一的失败是不参与&rdquo;。参与本身就是一种挑战和进步。</p>
<h3 id="实用学习资源">实用学习资源<a hidden class="anchor" aria-hidden="true" href="#实用学习资源">#</a></h3>
<p>对于没有 GPU 的学习者，可以利用以下资源进行学习和实践：</p>
<div class="notice info" >
<p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#info-notice"></use></svg></span>Info</p><ul>
<li>Google Colab</li>
<li>云平台上的 GPU 实例</li>
<li>Triton Interpreter</li>
</ul></div>
<h3 id="结语">结语<a hidden class="anchor" aria-hidden="true" href="#结语">#</a></h3>
<p>CUDA、Triton 和 Flash Attention 的学习是一个循序渐进的过程，需要理论与实践相结合，持续投入时间和精力。通过设定明确目标、积极实践、利用现代工具和保持持续学习的态度，任何人都能够逐步掌握这些复杂的技术，并将其应用于解决实际问题。</p>
<p>在技术快速发展的今天，掌握&quot;学习如何学习&quot;的能力比掌握特定技术更为重要，这将使学习者能够不断适应新的技术环境，并在技术变革中保持竞争力。</p>
<h3 id="参考资源">参考资源<a hidden class="anchor" aria-hidden="true" href="#参考资源">#</a></h3>
<ul>
<li><a href="https://notebooklm.google.com/notebook/4bcfedbd-2cd6-4ef1-830e-db60ffa7aa15/audio">NOTEBOOKLM音频</a></li>
<li><a href="https://youtu.be/4jQTb6sRGLg?si=_ikZsDSG-tp3PH1M">Youtube</a></li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://blog.niuhemoon.win/tags/gpu/">GPU</a></li>
      <li><a href="https://blog.niuhemoon.win/tags/howtolearn/">HowToLearn</a></li>
      <li><a href="https://blog.niuhemoon.win/tags/flash-attention/">Flash Attention</a></li>
    </ul>
<div class="footer-comments">
  <p>For comments, please   <a href="mailto:carlton2tang@gmail.com" class="email-button" style="font-size: inherit; padding: 5px 10px; background-color: #3f6b9a; color: white; text-decoration: none; border-radius: 3px; transition: background-color 0.3s;">
    send an email
</a> to me</p>

</div>
<nav class="paginav">
  <a class="next" href="https://blog.niuhemoon.win/posts/tech/docker-compose-guide/">
    <span class="title">下一页 »</span>
    <br>
    <span>Docker Compose 实用指南：从入门到实践</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
      
    <span>&copy; 2025 <a href="https://blog.niuhemoon.win">Niuhe&#39;s Blog</a></span>
    <span xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/">
        Licensed under
        <a
          href="http://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1"
          target="_blank"
          rel="license noopener noreferrer"
          style="display:inline-block;"
          >CC BY-NC-SA 4.0 </a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = '📄复制';

        function copyingDone() {
            copybutton.innerHTML = '👌🏻已复制!';
            setTimeout(() => {
                copybutton.innerHTML = '📄复制';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
