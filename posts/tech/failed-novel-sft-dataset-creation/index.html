<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>记录一次失败的小说SFT数据集创建 | Niuhe&#39;s Blog</title>
<meta name="keywords" content="LLM, SFT, Dataset">
<meta name="description" content="本来想拿喜欢的小说做数据集，然后制作SFT数据集，通过微调，让LLM学会小说内容、文风，从而分析人物关系，进行续写，但尝试失败">
<meta name="author" content="Niuhe">
<link rel="canonical" href="https://blog.niuhemoon.win/posts/tech/failed-novel-sft-dataset-creation/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css" integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe&#43;FVUFzPh7U=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://blog.niuhemoon.win/base/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://blog.niuhemoon.win/base/favicon.ico">
<link rel="icon" type="image/png" sizes="32x32" href="https://blog.niuhemoon.win/base/favicon.ico">
<link rel="apple-touch-icon" href="https://blog.niuhemoon.win/base/avatar.jpeg">
<link rel="mask-icon" href="https://blog.niuhemoon.win/base/avatar.jpeg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-116933089-1', 'auto');
	
	ga('send', 'pageview');
}
</script><meta property="og:title" content="记录一次失败的小说SFT数据集创建" />
<meta property="og:description" content="本来想拿喜欢的小说做数据集，然后制作SFT数据集，通过微调，让LLM学会小说内容、文风，从而分析人物关系，进行续写，但尝试失败" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://blog.niuhemoon.win/posts/tech/failed-novel-sft-dataset-creation/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-01-13T00:00:00+00:00" />
<meta property="article:modified_time" content="2025-03-15T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="记录一次失败的小说SFT数据集创建"/>
<meta name="twitter:description" content="本来想拿喜欢的小说做数据集，然后制作SFT数据集，通过微调，让LLM学会小说内容、文风，从而分析人物关系，进行续写，但尝试失败"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "📚文章",
      "item": "https://blog.niuhemoon.win/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "👨🏻‍💻 技术",
      "item": "https://blog.niuhemoon.win/posts/tech/"
    }, 
    {
      "@type": "ListItem",
      "position":  4 ,
      "name": "记录一次失败的小说SFT数据集创建",
      "item": "https://blog.niuhemoon.win/posts/tech/failed-novel-sft-dataset-creation/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "记录一次失败的小说SFT数据集创建",
  "name": "记录一次失败的小说SFT数据集创建",
  "description": "本来想拿喜欢的小说做数据集，然后制作SFT数据集，通过微调，让LLM学会小说内容、文风，从而分析人物关系，进行续写，但尝试失败",
  "keywords": [
    "LLM", "SFT", "Dataset"
  ],
  "articleBody": "背景介绍 最近我一直在研究如何让LLM更好地理解和生成特定领域的内容。我选择了自己喜欢的小说《逍遥小散仙》作为实验数据，希望通过SFT（Supervised Fine-Tuning）让模型学习小说的内容、人物关系和写作风格，最终能够进行相关的分析和续写。这篇文章详细记录了我的数据集创建过程，以及最终的微调结果。\n数据集创建过程 数据预处理 首先将小说用calibre从epub格式转成txt格式，为后续的处理做准备。\n方法一：使用LLM提取问答数据 第一种方法是使用LLM从小说文本中提取问答对。这种方法的核心思想是将小说分成多个段落，然后让LLM为每个段落生成相关的问题和答案。\n1. 设置LLM接口 首先，我创建了llm.py文件，用于与LLM API进行交互：\nfrom openai import OpenAI from typing import List, Dict import json import re BaseURL = 'https://api.aiproxy.io/v1' APIKEY = 'sk-xxxx' # 已隐藏真实API密钥 Model = 'gpt-4o-mini-2024-07-18' # 也可以使用DeepSeek API # BaseURL='https://api.deepseek.com/v1' # APIKEY='sk-xxxx' # Model='deepseek-chat' client = OpenAI(api_key=APIKEY, base_url=BaseURL) def get_qa(raw_content, stream=False) -\u003e str: response = client.chat.completions.create( model=Model, messages=[ {'role': 'system', 'content': '你是一位小说分析师，负责从以下文本中提取信息并生成问答对。输出格式要求:\\n```json\\n[{\"question\": \"*\", \"answer\": \"*\"}]```'}, {'role': 'user', 'content': f'请仔细阅读文本,并根据文本内容生成问题和答案,问答对要包含文本所有有效信息, 问答对互相独立,看不到其它问题。确保问题涵盖角色、情节、情感和背景等多方面。答案应直接复制原文内容。直接用JSON格式回答。文本:\\n[{raw_content}]\\n请生成JSON格式(列表)问答对:\\n'} ], temperature=0.7, top_p=1.0, max_tokens=4096, stream=stream ) if stream: for chunk in response: if chunk.choices[0].delta.content is not None: print(chunk.choices[0].delta.content, end='') else: r_content = response.choices[0].message.content json_match = re.findall(r'```(?:json)?\\n(.*?)\\n```', r_content, re.DOTALL) return json_match[0] if json_match else None 2. 加载和处理数据 接下来，创建main.py文件来加载小说文本并分块处理：\nfrom datasets import load_dataset from llm import get_qa import tqdm import json import time from typing import List # 加载整个TXT文件作为训练集 dataset = load_dataset(\"text\", data_files={\"train\": \"xiaoyao.txt\"}, sample_by=\"paragraph\") # 输出数据集信息 print(dataset) chunk_size = 10 output_file = 'results.jsonl' def convert_to_json(s) -\u003e List: try: return json.loads(s) except Exception: return False total_chunks = (len(dataset['train']) + chunk_size - 1) // chunk_size pbar = tqdm.tqdm(total=len(dataset['train'])) for idx in tqdm.tqdm(range(0, len(dataset['train']), chunk_size), total=total_chunks): chunk = '\\n'.join(dataset['train'][idx: idx+chunk_size]['text']) # 获取 QA 结果 response = get_qa(chunk) # 处理响应并保存 try: j_list = convert_to_json(response) if isinstance(j_list, list): with open(output_file, 'a', encoding='utf-8') as f: for item in j_list: if not item: continue json.dump(item, f, ensure_ascii=False) f.write('\\n') else: # 如果是单个对象，直接写入 with open(output_file, 'a', encoding='utf-8') as f: json.dump(response, f, ensure_ascii=False) f.write('\\n') except Exception as e: print(f\"Error processing response: {e}\") 这段代码的工作流程是：\n使用datasets库加载小说文本，按段落进行分割 每次取10个段落组成一个chunk 将chunk发送给LLM进行问答对生成 解析LLM返回的JSON格式问答对 将问答对保存到JSONL文件中 3. 数据转换为SFT格式 生成问答对后，需要将其转换为SFT训练所需的格式。创建convert.py文件：\nimport json # 初始化一个空列表来存储转换后的数据 data = [] with open('results.jsonl', 'r', encoding='utf-8') as file: for line in file: # 解析每一行的 JSON 数据 json_object = json.loads(line) new_format = { \"instruction\": json_object[\"question\"], \"input\": \"\", # 如果需要，可以根据需要填充 \"output\": json_object[\"answer\"] } # 将新格式字典添加到列表中 data.append(new_format) with open('output.json', 'w', encoding='utf-8') as outfile: json.dump(data, outfile, ensure_ascii=False, indent=2) 这段代码将问答对转换为SFT训练常用的指令格式：\ninstruction：问题 input：输入（在这个场景中为空） output：答案 4. 生成的数据示例 以下是生成的问答对数据示例：\n{ \"instruction\": \"小玄对自己的处境有何自我安慰的想法？\", \"input\": \"\", \"output\": \"忽尔厚颜无耻地思道：男子汉大丈夫，自古以来就三妻四妾，她们老爹不就娶了五房夫人嘛，岳父可以放火，女婿就不能点灯么，姐妹俩总不能一点情理也不讲吧......\" }, { \"instruction\": \"水若对小玄的反应是什么？\", \"input\": \"\", \"output\": \"水若突地一呆，用手抵住了他的胸口，怔怔盯了他片刻，猛然地将其推开，挣扎坐起，恼恨交加道：滚开！以后，再不许你碰我！\" } 方法二：提取对话数据 第二种方法是提取小说中的对话内容。我使用了extract-dialogue工具来完成这项工作，该工具可以从小说文本中自动识别并提取对话内容，包括说话人和对话内容。\n1. 安装和配置工具 首先，克隆工具仓库并安装依赖：\ngit clone https://github.com/KMnO4-zx/extract-dialogue.git cd extract-dialogue \u0026\u0026 pip install -r requirements.txt 2. 配置API 创建.env文件，配置DeepSeek API：\n# 创建.env文件 DEEPSEEK_BASE_URL=https://api.deepseek.com DEEPSEEK_API=sk-xxxx 3. 创建主程序 创建main.py文件，用于处理小说文本并提取对话：\nfrom extract import system_prompt from schema import novel_schema from LLM import DeepseekChat from utils import ReadFiles from tqdm import tqdm import json # 指定小说文件路径 file_path = './xiaoyao.txt' # 读取文件内容并分块，每块最大token数为500 docs = ReadFiles(file_path).get_content(max_token_len=500, cover_content=0) # 获取系统提示词，用于指导LLM提取对话 sys_prompt = system_prompt(novel_schema) # 初始化DeepSeek模型 model = DeepseekChat() # 获取文件名（不含扩展名）用于输出文件命名 file_name = file_path.split('/')[-1].split('.')[0] # 遍历所有文本块，提取对话 for i in tqdm(range(len(docs))): response = model.chat(sys_prompt, docs[i]) try: # 解析JSON响应 response = json.loads(response) # 将每条对话写入JSONL文件 for item in response: with open(f'{file_name}.jsonl', 'a', encoding='utf-8') as f: json.dump(item, f, ensure_ascii=False) f.write('\\n') except Exception as e: print(e) 4. 提取结果示例 运行程序后，会得到包含角色和对话内容的JSONL文件，每行是一个JSON对象：\n{\"role\": \"小玄\", \"dialogue\": \"办不到。\"} {\"role\": \"方少麟\", \"dialogue\": \"办不到？你是不想？还是办不到？\"} {\"role\": \"小玄\", \"dialogue\": \"换个条件。\"} {\"role\": \"方少麟\", \"dialogue\": \"我想不出别的。如果这两个都做不到，那么我无法相信你之前说的话。\"} {\"role\": \"方少麟\", \"dialogue\": \"行，你告诉我，除此之外，你还能做到什么？\"} {\"role\": \"小玄\", \"dialogue\": \"我能让皇朝军退兵。如果你也退回泽阳，就可避免两败俱伤，令万千生灵涂炭！\"} {\"role\": \"方少麟\", \"dialogue\": \"我不能。朝廷失政日久，如今天下荒荒，皆要推倒昏君，如果你无法证明昏君已经不在，凭我是说服不了别人的。\"} 失败原因与经验总结 后续使用了LammaFactory工具进行SFT微调，测试效果都比较差，模型只能简单记忆问答对，而不能进行更复杂的对话。我认为一方面是数据集质量比较差，并且在微调时候产生了过拟合，模型遗忘了原有的能力。但更主要问题在于直接进行SFT可能不是最佳选择，应该先进行领域适应性的预训练。此外，数据集的规模和质量也有待提高。\n",
  "wordCount" : "2361",
  "inLanguage": "zh",
  "datePublished": "2025-01-13T00:00:00Z",
  "dateModified": "2025-03-15T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Niuhe"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://blog.niuhemoon.win/posts/tech/failed-novel-sft-dataset-creation/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Niuhe's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://blog.niuhemoon.win/base/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://blog.niuhemoon.win" accesskey="h" title="Niuhe&#39;s Blog (Alt + H)">
                <img src="https://blog.niuhemoon.win/base/avatar.jpeg" alt="" aria-label="logo"
                    height="35">Niuhe&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://blog.niuhemoon.win/search" title="🔍搜索 (Alt &#43; /)" accesskey=/>
                    <span>🔍搜索</span>
                </a>
            </li>
            <li>
                <a href="https://blog.niuhemoon.win/" title="🏠主页">
                    <span>🏠主页</span>
                </a>
            </li>
            <li>
                <a href="https://blog.niuhemoon.win/posts" title="📚文章">
                    <span>📚文章</span>
                </a>
            </li>
            <li>
                <a href="https://blog.niuhemoon.win/tags" title="🔖标签">
                    <span>🔖标签</span>
                </a>
            </li>
            <li>
                <a href="https://blog.niuhemoon.win/archives/" title="⏱时间轴">
                    <span>⏱时间轴</span>
                </a>
            </li>
            <li>
                <a href="https://blog.niuhemoon.win/about" title="🙋🏻‍♂️关于">
                    <span>🙋🏻‍♂️关于</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://blog.niuhemoon.win">🏠主页</a>&nbsp;»&nbsp;<a href="https://blog.niuhemoon.win/posts/">📚文章</a>&nbsp;»&nbsp;<a href="https://blog.niuhemoon.win/posts/tech/">👨🏻‍💻 技术</a></div>
    <h1 class="post-title">
      记录一次失败的小说SFT数据集创建
    </h1>
    <div class="post-description">
      本来想拿喜欢的小说做数据集，然后制作SFT数据集，通过微调，让LLM学会小说内容、文风，从而分析人物关系，进行续写，但尝试失败
    </div>
    <div class="post-meta"><span title='2025-01-13 00:00:00 +0000 UTC'>2025-01-13</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;2361 字&nbsp;·&nbsp;Niuhe

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">文章目录</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#%e8%83%8c%e6%99%af%e4%bb%8b%e7%bb%8d" aria-label="背景介绍">背景介绍</a></li>
                <li>
                    <a href="#%e6%95%b0%e6%8d%ae%e9%9b%86%e5%88%9b%e5%bb%ba%e8%bf%87%e7%a8%8b" aria-label="数据集创建过程">数据集创建过程</a><ul>
                        
                <li>
                    <a href="#%e6%95%b0%e6%8d%ae%e9%a2%84%e5%a4%84%e7%90%86" aria-label="数据预处理">数据预处理</a></li>
                <li>
                    <a href="#%e6%96%b9%e6%b3%95%e4%b8%80%e4%bd%bf%e7%94%a8llm%e6%8f%90%e5%8f%96%e9%97%ae%e7%ad%94%e6%95%b0%e6%8d%ae" aria-label="方法一：使用LLM提取问答数据">方法一：使用LLM提取问答数据</a><ul>
                        
                <li>
                    <a href="#1-%e8%ae%be%e7%bd%aellm%e6%8e%a5%e5%8f%a3" aria-label="1. 设置LLM接口">1. 设置LLM接口</a></li>
                <li>
                    <a href="#2-%e5%8a%a0%e8%bd%bd%e5%92%8c%e5%a4%84%e7%90%86%e6%95%b0%e6%8d%ae" aria-label="2. 加载和处理数据">2. 加载和处理数据</a></li>
                <li>
                    <a href="#3-%e6%95%b0%e6%8d%ae%e8%bd%ac%e6%8d%a2%e4%b8%basft%e6%a0%bc%e5%bc%8f" aria-label="3. 数据转换为SFT格式">3. 数据转换为SFT格式</a></li>
                <li>
                    <a href="#4-%e7%94%9f%e6%88%90%e7%9a%84%e6%95%b0%e6%8d%ae%e7%a4%ba%e4%be%8b" aria-label="4. 生成的数据示例">4. 生成的数据示例</a></li></ul>
                </li>
                <li>
                    <a href="#%e6%96%b9%e6%b3%95%e4%ba%8c%e6%8f%90%e5%8f%96%e5%af%b9%e8%af%9d%e6%95%b0%e6%8d%ae" aria-label="方法二：提取对话数据">方法二：提取对话数据</a><ul>
                        
                <li>
                    <a href="#1-%e5%ae%89%e8%a3%85%e5%92%8c%e9%85%8d%e7%bd%ae%e5%b7%a5%e5%85%b7" aria-label="1. 安装和配置工具">1. 安装和配置工具</a></li>
                <li>
                    <a href="#2-%e9%85%8d%e7%bd%aeapi" aria-label="2. 配置API">2. 配置API</a></li>
                <li>
                    <a href="#3-%e5%88%9b%e5%bb%ba%e4%b8%bb%e7%a8%8b%e5%ba%8f" aria-label="3. 创建主程序">3. 创建主程序</a></li>
                <li>
                    <a href="#4-%e6%8f%90%e5%8f%96%e7%bb%93%e6%9e%9c%e7%a4%ba%e4%be%8b" aria-label="4. 提取结果示例">4. 提取结果示例</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#%e5%a4%b1%e8%b4%a5%e5%8e%9f%e5%9b%a0%e4%b8%8e%e7%bb%8f%e9%aa%8c%e6%80%bb%e7%bb%93" aria-label="失败原因与经验总结">失败原因与经验总结</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h3 id="背景介绍">背景介绍<a hidden class="anchor" aria-hidden="true" href="#背景介绍">#</a></h3>
<p>最近我一直在研究如何让LLM更好地理解和生成特定领域的内容。我选择了自己喜欢的小说《逍遥小散仙》作为实验数据，希望通过SFT（Supervised Fine-Tuning）让模型学习小说的内容、人物关系和写作风格，最终能够进行相关的分析和续写。这篇文章详细记录了我的数据集创建过程，以及最终的微调结果。</p>
<h3 id="数据集创建过程">数据集创建过程<a hidden class="anchor" aria-hidden="true" href="#数据集创建过程">#</a></h3>
<h4 id="数据预处理">数据预处理<a hidden class="anchor" aria-hidden="true" href="#数据预处理">#</a></h4>
<p>首先将小说用calibre从epub格式转成txt格式，为后续的处理做准备。</p>
<h4 id="方法一使用llm提取问答数据">方法一：使用LLM提取问答数据<a hidden class="anchor" aria-hidden="true" href="#方法一使用llm提取问答数据">#</a></h4>
<p>第一种方法是使用LLM从小说文本中提取问答对。这种方法的核心思想是将小说分成多个段落，然后让LLM为每个段落生成相关的问题和答案。</p>
<h5 id="1-设置llm接口">1. 设置LLM接口<a hidden class="anchor" aria-hidden="true" href="#1-设置llm接口">#</a></h5>
<p>首先，我创建了<code>llm.py</code>文件，用于与LLM API进行交互：</p>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> openai <span style="color:#fff;font-weight:bold">import</span> OpenAI
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> typing <span style="color:#fff;font-weight:bold">import</span> List, Dict
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> json
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> re
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>BaseURL = <span style="color:#0ff;font-weight:bold">&#39;https://api.aiproxy.io/v1&#39;</span>
</span></span><span style="display:flex;"><span>APIKEY = <span style="color:#0ff;font-weight:bold">&#39;sk-xxxx&#39;</span>  <span style="color:#007f7f"># 已隐藏真实API密钥</span>
</span></span><span style="display:flex;"><span>Model = <span style="color:#0ff;font-weight:bold">&#39;gpt-4o-mini-2024-07-18&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 也可以使用DeepSeek API</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># BaseURL=&#39;https://api.deepseek.com/v1&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># APIKEY=&#39;sk-xxxx&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># Model=&#39;deepseek-chat&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>client = OpenAI(api_key=APIKEY, base_url=BaseURL)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> get_qa(raw_content, stream=<span style="color:#fff;font-weight:bold">False</span>) -&gt; <span style="color:#fff;font-weight:bold">str</span>:
</span></span><span style="display:flex;"><span>    response = client.chat.completions.create(
</span></span><span style="display:flex;"><span>        model=Model,
</span></span><span style="display:flex;"><span>        messages=[
</span></span><span style="display:flex;"><span>            {<span style="color:#0ff;font-weight:bold">&#39;role&#39;</span>: <span style="color:#0ff;font-weight:bold">&#39;system&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;content&#39;</span>: <span style="color:#0ff;font-weight:bold">&#39;你是一位小说分析师，负责从以下文本中提取信息并生成问答对。输出格式要求:</span><span style="color:#0ff;font-weight:bold">\n</span><span style="color:#0ff;font-weight:bold">```json</span><span style="color:#0ff;font-weight:bold">\n</span><span style="color:#0ff;font-weight:bold">[{&#34;question&#34;: &#34;*&#34;, &#34;answer&#34;: &#34;*&#34;}]```&#39;</span>},
</span></span><span style="display:flex;"><span>            {<span style="color:#0ff;font-weight:bold">&#39;role&#39;</span>: <span style="color:#0ff;font-weight:bold">&#39;user&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;content&#39;</span>: <span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;请仔细阅读文本,并根据文本内容生成问题和答案,问答对要包含文本所有有效信息, 问答对互相独立,看不到其它问题。确保问题涵盖角色、情节、情感和背景等多方面。答案应直接复制原文内容。直接用JSON格式回答。文本:</span><span style="color:#0ff;font-weight:bold">\n</span><span style="color:#0ff;font-weight:bold">[</span><span style="color:#0ff;font-weight:bold">{</span>raw_content<span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">]</span><span style="color:#0ff;font-weight:bold">\n</span><span style="color:#0ff;font-weight:bold">请生成JSON格式(列表)问答对:</span><span style="color:#0ff;font-weight:bold">\n</span><span style="color:#0ff;font-weight:bold">&#39;</span>}
</span></span><span style="display:flex;"><span>        ],
</span></span><span style="display:flex;"><span>        temperature=<span style="color:#ff0;font-weight:bold">0.7</span>,
</span></span><span style="display:flex;"><span>        top_p=<span style="color:#ff0;font-weight:bold">1.0</span>,
</span></span><span style="display:flex;"><span>        max_tokens=<span style="color:#ff0;font-weight:bold">4096</span>,
</span></span><span style="display:flex;"><span>        stream=stream
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">if</span> stream:
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> chunk in response:
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">if</span> chunk.choices[<span style="color:#ff0;font-weight:bold">0</span>].delta.content is not <span style="color:#fff;font-weight:bold">None</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#fff;font-weight:bold">print</span>(chunk.choices[<span style="color:#ff0;font-weight:bold">0</span>].delta.content, end=<span style="color:#0ff;font-weight:bold">&#39;&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>        r_content = response.choices[<span style="color:#ff0;font-weight:bold">0</span>].message.content
</span></span><span style="display:flex;"><span>        json_match = re.findall(<span style="color:#0ff;font-weight:bold">r</span><span style="color:#0ff;font-weight:bold">&#39;```(?:json)?\n(.*?)\n```&#39;</span>, r_content, re.DOTALL)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> json_match[<span style="color:#ff0;font-weight:bold">0</span>] <span style="color:#fff;font-weight:bold">if</span> json_match <span style="color:#fff;font-weight:bold">else</span> <span style="color:#fff;font-weight:bold">None</span>
</span></span></code></pre></div><h5 id="2-加载和处理数据">2. 加载和处理数据<a hidden class="anchor" aria-hidden="true" href="#2-加载和处理数据">#</a></h5>
<p>接下来，创建<code>main.py</code>文件来加载小说文本并分块处理：</p>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> datasets <span style="color:#fff;font-weight:bold">import</span> load_dataset
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> llm <span style="color:#fff;font-weight:bold">import</span> get_qa
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> tqdm
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> json
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> time
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> typing <span style="color:#fff;font-weight:bold">import</span> List
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 加载整个TXT文件作为训练集</span>
</span></span><span style="display:flex;"><span>dataset = load_dataset(<span style="color:#0ff;font-weight:bold">&#34;text&#34;</span>, data_files={<span style="color:#0ff;font-weight:bold">&#34;train&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;xiaoyao.txt&#34;</span>}, sample_by=<span style="color:#0ff;font-weight:bold">&#34;paragraph&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 输出数据集信息</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(dataset)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>chunk_size = <span style="color:#ff0;font-weight:bold">10</span>
</span></span><span style="display:flex;"><span>output_file = <span style="color:#0ff;font-weight:bold">&#39;results.jsonl&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">def</span> convert_to_json(s) -&gt; List:
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">try</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> json.loads(s)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">except</span> Exception:
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> <span style="color:#fff;font-weight:bold">False</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>total_chunks = (<span style="color:#fff;font-weight:bold">len</span>(dataset[<span style="color:#0ff;font-weight:bold">&#39;train&#39;</span>]) + chunk_size - <span style="color:#ff0;font-weight:bold">1</span>) // chunk_size
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pbar = tqdm.tqdm(total=<span style="color:#fff;font-weight:bold">len</span>(dataset[<span style="color:#0ff;font-weight:bold">&#39;train&#39;</span>]))
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">for</span> idx in tqdm.tqdm(<span style="color:#fff;font-weight:bold">range</span>(<span style="color:#ff0;font-weight:bold">0</span>, <span style="color:#fff;font-weight:bold">len</span>(dataset[<span style="color:#0ff;font-weight:bold">&#39;train&#39;</span>]), chunk_size), total=total_chunks):
</span></span><span style="display:flex;"><span>    chunk = <span style="color:#0ff;font-weight:bold">&#39;</span><span style="color:#0ff;font-weight:bold">\n</span><span style="color:#0ff;font-weight:bold">&#39;</span>.join(dataset[<span style="color:#0ff;font-weight:bold">&#39;train&#39;</span>][idx: idx+chunk_size][<span style="color:#0ff;font-weight:bold">&#39;text&#39;</span>])
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 获取 QA 结果</span>
</span></span><span style="display:flex;"><span>    response = get_qa(chunk)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># 处理响应并保存</span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">try</span>:
</span></span><span style="display:flex;"><span>        j_list = convert_to_json(response)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">if</span> <span style="color:#fff;font-weight:bold">isinstance</span>(j_list, <span style="color:#fff;font-weight:bold">list</span>):
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">with</span> <span style="color:#fff;font-weight:bold">open</span>(output_file, <span style="color:#0ff;font-weight:bold">&#39;a&#39;</span>, encoding=<span style="color:#0ff;font-weight:bold">&#39;utf-8&#39;</span>) <span style="color:#fff;font-weight:bold">as</span> f:
</span></span><span style="display:flex;"><span>                <span style="color:#fff;font-weight:bold">for</span> item in j_list:
</span></span><span style="display:flex;"><span>                    <span style="color:#fff;font-weight:bold">if</span> not item:
</span></span><span style="display:flex;"><span>                        <span style="color:#fff;font-weight:bold">continue</span>
</span></span><span style="display:flex;"><span>                    json.dump(item, f, ensure_ascii=<span style="color:#fff;font-weight:bold">False</span>)
</span></span><span style="display:flex;"><span>                    f.write(<span style="color:#0ff;font-weight:bold">&#39;</span><span style="color:#0ff;font-weight:bold">\n</span><span style="color:#0ff;font-weight:bold">&#39;</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#007f7f"># 如果是单个对象，直接写入</span>
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">with</span> <span style="color:#fff;font-weight:bold">open</span>(output_file, <span style="color:#0ff;font-weight:bold">&#39;a&#39;</span>, encoding=<span style="color:#0ff;font-weight:bold">&#39;utf-8&#39;</span>) <span style="color:#fff;font-weight:bold">as</span> f:
</span></span><span style="display:flex;"><span>                json.dump(response, f, ensure_ascii=<span style="color:#fff;font-weight:bold">False</span>)
</span></span><span style="display:flex;"><span>                f.write(<span style="color:#0ff;font-weight:bold">&#39;</span><span style="color:#0ff;font-weight:bold">\n</span><span style="color:#0ff;font-weight:bold">&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">except</span> Exception <span style="color:#fff;font-weight:bold">as</span> e:
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">print</span>(<span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#34;Error processing response: </span><span style="color:#0ff;font-weight:bold">{</span>e<span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">&#34;</span>)
</span></span></code></pre></div><p>这段代码的工作流程是：</p>
<ol>
<li>使用<code>datasets</code>库加载小说文本，按段落进行分割</li>
<li>每次取10个段落组成一个chunk</li>
<li>将chunk发送给LLM进行问答对生成</li>
<li>解析LLM返回的JSON格式问答对</li>
<li>将问答对保存到JSONL文件中</li>
</ol>
<h5 id="3-数据转换为sft格式">3. 数据转换为SFT格式<a hidden class="anchor" aria-hidden="true" href="#3-数据转换为sft格式">#</a></h5>
<p>生成问答对后，需要将其转换为SFT训练所需的格式。创建<code>convert.py</code>文件：</p>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> json
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 初始化一个空列表来存储转换后的数据</span>
</span></span><span style="display:flex;"><span>data = []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">with</span> <span style="color:#fff;font-weight:bold">open</span>(<span style="color:#0ff;font-weight:bold">&#39;results.jsonl&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;r&#39;</span>, encoding=<span style="color:#0ff;font-weight:bold">&#39;utf-8&#39;</span>) <span style="color:#fff;font-weight:bold">as</span> file:
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">for</span> line in file:
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 解析每一行的 JSON 数据</span>
</span></span><span style="display:flex;"><span>        json_object = json.loads(line)
</span></span><span style="display:flex;"><span>        new_format = {
</span></span><span style="display:flex;"><span>            <span style="color:#0ff;font-weight:bold">&#34;instruction&#34;</span>: json_object[<span style="color:#0ff;font-weight:bold">&#34;question&#34;</span>],
</span></span><span style="display:flex;"><span>            <span style="color:#0ff;font-weight:bold">&#34;input&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;&#34;</span>,  <span style="color:#007f7f"># 如果需要，可以根据需要填充</span>
</span></span><span style="display:flex;"><span>            <span style="color:#0ff;font-weight:bold">&#34;output&#34;</span>: json_object[<span style="color:#0ff;font-weight:bold">&#34;answer&#34;</span>]
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 将新格式字典添加到列表中</span>
</span></span><span style="display:flex;"><span>        data.append(new_format)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">with</span> <span style="color:#fff;font-weight:bold">open</span>(<span style="color:#0ff;font-weight:bold">&#39;output.json&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;w&#39;</span>, encoding=<span style="color:#0ff;font-weight:bold">&#39;utf-8&#39;</span>) <span style="color:#fff;font-weight:bold">as</span> outfile:
</span></span><span style="display:flex;"><span>    json.dump(data, outfile, ensure_ascii=<span style="color:#fff;font-weight:bold">False</span>, indent=<span style="color:#ff0;font-weight:bold">2</span>)
</span></span></code></pre></div><p>这段代码将问答对转换为SFT训练常用的指令格式：</p>
<ul>
<li><code>instruction</code>：问题</li>
<li><code>input</code>：输入（在这个场景中为空）</li>
<li><code>output</code>：答案</li>
</ul>
<h5 id="4-生成的数据示例">4. 生成的数据示例<a hidden class="anchor" aria-hidden="true" href="#4-生成的数据示例">#</a></h5>
<p>以下是生成的问答对数据示例：</p>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="font-weight:bold">&#34;instruction&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;小玄对自己的处境有何自我安慰的想法？&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="font-weight:bold">&#34;input&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="font-weight:bold">&#34;output&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;忽尔厚颜无耻地思道：男子汉大丈夫，自古以来就三妻四妾，她们老爹不就娶了五房夫人嘛，岳父可以放火，女婿就不能点灯么，姐妹俩总不能一点情理也不讲吧......&#34;</span>
</span></span><span style="display:flex;"><span>}<span style="color:#f00">,</span>
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="font-weight:bold">&#34;instruction&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;水若对小玄的反应是什么？&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="font-weight:bold">&#34;input&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="font-weight:bold">&#34;output&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;水若突地一呆，用手抵住了他的胸口，怔怔盯了他片刻，猛然地将其推开，挣扎坐起，恼恨交加道：滚开！以后，再不许你碰我！&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h4 id="方法二提取对话数据">方法二：提取对话数据<a hidden class="anchor" aria-hidden="true" href="#方法二提取对话数据">#</a></h4>
<p>第二种方法是提取小说中的对话内容。我使用了<code>extract-dialogue</code>工具来完成这项工作，该工具可以从小说文本中自动识别并提取对话内容，包括说话人和对话内容。</p>
<h5 id="1-安装和配置工具">1. 安装和配置工具<a hidden class="anchor" aria-hidden="true" href="#1-安装和配置工具">#</a></h5>
<p>首先，克隆工具仓库并安装依赖：</p>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/KMnO4-zx/extract-dialogue.git
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">cd</span> extract-dialogue &amp;&amp; pip install -r requirements.txt
</span></span></code></pre></div><h5 id="2-配置api">2. 配置API<a hidden class="anchor" aria-hidden="true" href="#2-配置api">#</a></h5>
<p>创建<code>.env</code>文件，配置DeepSeek API：</p>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f"># 创建.env文件</span>
</span></span><span style="display:flex;"><span>DEEPSEEK_BASE_URL=https://api.deepseek.com
</span></span><span style="display:flex;"><span>DEEPSEEK_API=sk-xxxx  
</span></span></code></pre></div><h5 id="3-创建主程序">3. 创建主程序<a hidden class="anchor" aria-hidden="true" href="#3-创建主程序">#</a></h5>
<p>创建<code>main.py</code>文件，用于处理小说文本并提取对话：</p>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> extract <span style="color:#fff;font-weight:bold">import</span> system_prompt
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> schema <span style="color:#fff;font-weight:bold">import</span> novel_schema
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> LLM <span style="color:#fff;font-weight:bold">import</span> DeepseekChat
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> utils <span style="color:#fff;font-weight:bold">import</span> ReadFiles
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> tqdm <span style="color:#fff;font-weight:bold">import</span> tqdm
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> json
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 指定小说文件路径</span>
</span></span><span style="display:flex;"><span>file_path = <span style="color:#0ff;font-weight:bold">&#39;./xiaoyao.txt&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 读取文件内容并分块，每块最大token数为500</span>
</span></span><span style="display:flex;"><span>docs = ReadFiles(file_path).get_content(max_token_len=<span style="color:#ff0;font-weight:bold">500</span>, cover_content=<span style="color:#ff0;font-weight:bold">0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 获取系统提示词，用于指导LLM提取对话</span>
</span></span><span style="display:flex;"><span>sys_prompt = system_prompt(novel_schema)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 初始化DeepSeek模型</span>
</span></span><span style="display:flex;"><span>model = DeepseekChat()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 获取文件名（不含扩展名）用于输出文件命名</span>
</span></span><span style="display:flex;"><span>file_name = file_path.split(<span style="color:#0ff;font-weight:bold">&#39;/&#39;</span>)[-<span style="color:#ff0;font-weight:bold">1</span>].split(<span style="color:#0ff;font-weight:bold">&#39;.&#39;</span>)[<span style="color:#ff0;font-weight:bold">0</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 遍历所有文本块，提取对话</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">for</span> i in tqdm(<span style="color:#fff;font-weight:bold">range</span>(<span style="color:#fff;font-weight:bold">len</span>(docs))):
</span></span><span style="display:flex;"><span>    response = model.chat(sys_prompt, docs[i])
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">try</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 解析JSON响应</span>
</span></span><span style="display:flex;"><span>        response = json.loads(response)
</span></span><span style="display:flex;"><span>        <span style="color:#007f7f"># 将每条对话写入JSONL文件</span>
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">for</span> item in response:
</span></span><span style="display:flex;"><span>            <span style="color:#fff;font-weight:bold">with</span> <span style="color:#fff;font-weight:bold">open</span>(<span style="color:#0ff;font-weight:bold">f</span><span style="color:#0ff;font-weight:bold">&#39;</span><span style="color:#0ff;font-weight:bold">{</span>file_name<span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">.jsonl&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;a&#39;</span>, encoding=<span style="color:#0ff;font-weight:bold">&#39;utf-8&#39;</span>) <span style="color:#fff;font-weight:bold">as</span> f:
</span></span><span style="display:flex;"><span>                json.dump(item, f, ensure_ascii=<span style="color:#fff;font-weight:bold">False</span>)
</span></span><span style="display:flex;"><span>                f.write(<span style="color:#0ff;font-weight:bold">&#39;</span><span style="color:#0ff;font-weight:bold">\n</span><span style="color:#0ff;font-weight:bold">&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">except</span> Exception <span style="color:#fff;font-weight:bold">as</span> e:
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">print</span>(e)
</span></span></code></pre></div><h5 id="4-提取结果示例">4. 提取结果示例<a hidden class="anchor" aria-hidden="true" href="#4-提取结果示例">#</a></h5>
<p>运行程序后，会得到包含角色和对话内容的JSONL文件，每行是一个JSON对象：</p>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{<span style="font-weight:bold">&#34;role&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;小玄&#34;</span>, <span style="font-weight:bold">&#34;dialogue&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;办不到。&#34;</span>}
</span></span><span style="display:flex;"><span>{<span style="font-weight:bold">&#34;role&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;方少麟&#34;</span>, <span style="font-weight:bold">&#34;dialogue&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;办不到？你是不想？还是办不到？&#34;</span>}
</span></span><span style="display:flex;"><span>{<span style="font-weight:bold">&#34;role&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;小玄&#34;</span>, <span style="font-weight:bold">&#34;dialogue&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;换个条件。&#34;</span>}
</span></span><span style="display:flex;"><span>{<span style="font-weight:bold">&#34;role&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;方少麟&#34;</span>, <span style="font-weight:bold">&#34;dialogue&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;我想不出别的。如果这两个都做不到，那么我无法相信你之前说的话。&#34;</span>}
</span></span><span style="display:flex;"><span>{<span style="font-weight:bold">&#34;role&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;方少麟&#34;</span>, <span style="font-weight:bold">&#34;dialogue&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;行，你告诉我，除此之外，你还能做到什么？&#34;</span>}
</span></span><span style="display:flex;"><span>{<span style="font-weight:bold">&#34;role&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;小玄&#34;</span>, <span style="font-weight:bold">&#34;dialogue&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;我能让皇朝军退兵。如果你也退回泽阳，就可避免两败俱伤，令万千生灵涂炭！&#34;</span>}
</span></span><span style="display:flex;"><span>{<span style="font-weight:bold">&#34;role&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;方少麟&#34;</span>, <span style="font-weight:bold">&#34;dialogue&#34;</span>: <span style="color:#0ff;font-weight:bold">&#34;我不能。朝廷失政日久，如今天下荒荒，皆要推倒昏君，如果你无法证明昏君已经不在，凭我是说服不了别人的。&#34;</span>}
</span></span></code></pre></div><h3 id="失败原因与经验总结">失败原因与经验总结<a hidden class="anchor" aria-hidden="true" href="#失败原因与经验总结">#</a></h3>
<p>后续使用了LammaFactory工具进行SFT微调，测试效果都比较差，模型只能简单记忆问答对，而不能进行更复杂的对话。我认为一方面是数据集质量比较差，并且在微调时候产生了过拟合，模型遗忘了原有的能力。但更主要问题在于直接进行SFT可能不是最佳选择，应该先进行领域适应性的预训练。此外，数据集的规模和质量也有待提高。</p>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://blog.niuhemoon.win/tags/llm/">LLM</a></li>
      <li><a href="https://blog.niuhemoon.win/tags/sft/">SFT</a></li>
      <li><a href="https://blog.niuhemoon.win/tags/dataset/">Dataset</a></li>
    </ul>
<div class="footer-comments">
  <p>For comments, please   <a href="mailto:carlton2tang@gmail.com" class="email-button" style="font-size: inherit; padding: 5px 10px; background-color: #3f6b9a; color: white; text-decoration: none; border-radius: 3px; transition: background-color 0.3s;">
    send an email
</a> to me</p>

</div>
<nav class="paginav">
  <a class="prev" href="https://blog.niuhemoon.win/posts/tech/c-language-cheetsheet/">
    <span class="title">« 上一页</span>
    <br>
    <span>C Language Cheetsheet</span>
  </a>
  <a class="next" href="https://blog.niuhemoon.win/posts/tech/whisper-transcript-pytorch-dev-podcast/">
    <span class="title">下一页 »</span>
    <br>
    <span>whisper模型转录Pytorch播客内容</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
      
    <span>&copy; 2025 <a href="https://blog.niuhemoon.win">Niuhe&#39;s Blog</a></span>
    <span xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/">
        Licensed under
        <a
          href="http://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1"
          target="_blank"
          rel="license noopener noreferrer"
          style="display:inline-block;"
          >CC BY-NC-SA 4.0 </a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = '📄复制';

        function copyingDone() {
            copybutton.innerHTML = '👌🏻已复制!';
            setTimeout(() => {
                copybutton.innerHTML = '📄复制';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
