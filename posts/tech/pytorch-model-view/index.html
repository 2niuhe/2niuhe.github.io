<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Pytorch模型可视化 | Niuhe&#39;s Blog</title>
<meta name="keywords" content="Python, Pytorch">
<meta name="description" content="Pytorch模型可视化">
<meta name="author" content="Niuhe">
<link rel="canonical" href="https://blog.niuhemoon.win/posts/tech/pytorch-model-view/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css" integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe&#43;FVUFzPh7U=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://blog.niuhemoon.win/base/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://blog.niuhemoon.win/base/favicon.ico">
<link rel="icon" type="image/png" sizes="32x32" href="https://blog.niuhemoon.win/base/favicon.ico">
<link rel="apple-touch-icon" href="https://blog.niuhemoon.win/base/avatar.jpeg">
<link rel="mask-icon" href="https://blog.niuhemoon.win/base/avatar.jpeg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-116933089-1', 'auto');
	
	ga('send', 'pageview');
}
</script><meta property="og:title" content="Pytorch模型可视化" />
<meta property="og:description" content="Pytorch模型可视化" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://blog.niuhemoon.win/posts/tech/pytorch-model-view/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-04-10T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-04-10T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Pytorch模型可视化"/>
<meta name="twitter:description" content="Pytorch模型可视化"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "📚文章",
      "item": "https://blog.niuhemoon.win/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "👨🏻‍💻 技术",
      "item": "https://blog.niuhemoon.win/posts/tech/"
    }, 
    {
      "@type": "ListItem",
      "position":  4 ,
      "name": "Pytorch模型可视化",
      "item": "https://blog.niuhemoon.win/posts/tech/pytorch-model-view/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Pytorch模型可视化",
  "name": "Pytorch模型可视化",
  "description": "Pytorch模型可视化",
  "keywords": [
    "Python", "Pytorch"
  ],
  "articleBody": "Linear Regression 这里举一个回归模型的例子，展示几种模型可视化的方法，分别是\nprint torchinfo.summary torchsummary torchviz torchview netron工具 首先创建一个简单的回归模型\nimport torch # 定义带有两个全连接层和ReLU激活函数的线性回归模型 class LinearRegression(torch.nn.Module): def __init__(self, input_dim, hidden_dim, output_dim): super(LinearRegression, self).__init__() self.fc1 = torch.nn.Linear(input_dim, hidden_dim) self.relu = torch.nn.ReLU() self.fc2 = torch.nn.Linear(hidden_dim, output_dim) def forward(self, x): out = self.fc1(x) out = self.relu(out) out = self.fc2(out) return out # 输入输出维度和隐藏层维度 input_dim = 1 hidden_dim = 64 output_dim = 1 batch_size = 32 # 创建模型 model = LinearRegression(input_dim, hidden_dim, output_dim) # 打印模型 print(model) # LinearRegression( # (fc1): Linear(in_features=1, out_features=64, bias=True) # (relu): ReLU() # (fc2): Linear(in_features=64, out_features=1, bias=True) # ) Model Summary 打印模型的简要信息，包括可训练参数等\nimport torchinfo # 打印模型summary torchinfo.summary( model, input_size=(batch_size, input_dim), col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"] ) ============================================================================================================================================ Layer (type:depth-idx) Input Shape Output Shape Param # Trainable ============================================================================================================================================ LinearRegression [32, 1] [32, 1] -- True ├─Linear: 1-1 [32, 1] [32, 64] 128 True ├─ReLU: 1-2 [32, 64] [32, 64] -- -- ├─Linear: 1-3 [32, 64] [32, 1] 65 True ============================================================================================================================================ Total params: 193 Trainable params: 193 Non-trainable params: 0 Total mult-adds (Units.MEGABYTES): 0.01 ============================================================================================================================================ Input size (MB): 0.00 Forward/backward pass size (MB): 0.02 Params size (MB): 0.00 Estimated Total Size (MB): 0.02 ============================================================================================================================================ 还可以打印简单的信息\nimport torchsummary torchsummary.summary(model, input_size=(batch_size, input_dim)) ---------------------------------------------------------------- Layer (type) Output Shape Param # ================================================================ Linear-1 [-1, 32, 64] 128 ReLU-2 [-1, 32, 64] 0 Linear-3 [-1, 32, 1] 65 ================================================================ Total params: 193 Trainable params: 193 Non-trainable params: 0 ---------------------------------------------------------------- Input size (MB): 0.00 Forward/backward pass size (MB): 0.03 Params size (MB): 0.00 Estimated Total Size (MB): 0.03 ---------------------------------------------------------------- Torchviz 可以导出graphviz图，需要计算机安装graphviz 执行dot -V 验证graphviz成功安装\nimport torchviz # 定义一个示例输入 example_input = torch.randn(batch_size, input_dim) model = LinearRegression(input_dim, hidden_dim, output_dim) # 使用torchviz绘制计算图 output = model(example_input) dot = torchviz.make_dot(output, params=dict(model.named_parameters()), show_attrs=False, show_saved=True) dot.render(\"linear_regression_torchviz\", format=\"png\", cleanup=True, view=False) # 如果不是在Jupyter中，注释下面两行 from IPython.display import Image, display display(Image('./linear_regression.png')) ◎ Torchviz图示 Torchview 可以绘制规范的线框图，便于展示模型的层次\nfrom torchview import draw_graph model = LinearRegression(input_dim, hidden_dim, output_dim) # device='meta' -\u003e no memory is consumed for visualization model_graph = draw_graph( model, input_size=(batch_size, input_dim), expand_nested=True, save_graph=True, filename=\"linear_regression_torchview\", device='meta') model_graph.visual_graph.render(\"linear_regression_torchview\", format=\"png\") model_graph.visual_graph netron工具 可以看出详细的计算图，但是需要将模型导出成ONNX格式\n# 导出onnx并用netron展示 model = LinearRegression(input_dim, hidden_dim, output_dim) example_input = torch.randn(batch_size, input_dim) torch.onnx.export(model, example_input, \"linear_regression.onnx\", verbose=True) Transfomer 如下是Pytorch的Transformer图示\n# Transformer模型可视化 import torch from torch.nn import Transformer from torch.nn import TransformerDecoder from torch.nn import TransformerDecoderLayer transformer_model = Transformer(num_encoder_layers=2, num_decoder_layers=2) src = torch.rand(10,32,512) tgt = torch.rand(20,32,512) print(transformer_model) Model Summary import torchinfo torchinfo.summary( transformer_model, input_size=((10,32,512), (20,32,512)), col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"] ) ================================================================================================================================================= Layer (type:depth-idx) Input Shape Output Shape Param # Trainable ================================================================================================================================================= Transformer [10, 32, 512] [20, 32, 512] -- True ├─TransformerEncoder: 1-1 [10, 32, 512] [10, 32, 512] -- True │ └─ModuleList: 2-1 -- -- -- True │ │ └─TransformerEncoderLayer: 3-1 [10, 32, 512] [10, 32, 512] 3,152,384 True │ │ └─TransformerEncoderLayer: 3-2 [10, 32, 512] [10, 32, 512] 3,152,384 True │ └─LayerNorm: 2-2 [10, 32, 512] [10, 32, 512] 1,024 True ├─TransformerDecoder: 1-2 [20, 32, 512] [20, 32, 512] -- True │ └─ModuleList: 2-3 -- -- -- True │ │ └─TransformerDecoderLayer: 3-3 [20, 32, 512] [20, 32, 512] 4,204,032 True │ │ └─TransformerDecoderLayer: 3-4 [20, 32, 512] [20, 32, 512] 4,204,032 True │ └─LayerNorm: 2-4 [20, 32, 512] [20, 32, 512] 1,024 True ================================================================================================================================================= Total params: 14,714,880 Trainable params: 14,714,880 Non-trainable params: 0 Total mult-adds (Units.MEGABYTES): 126.18 ================================================================================================================================================= Input size (MB): 1.97 Forward/backward pass size (MB): 64.23 Params size (MB): 33.64 Estimated Total Size (MB): 99.84 ================================================================================================================================================= Torchview from torchview import draw_graph transformer_model = Transformer(num_encoder_layers=1, num_decoder_layers=1) model_graph = draw_graph( transformer_model, input_size=((10,32,512), (20,32,512)), expand_nested=True, save_graph=True, filename=\"transformer_torchview\", device='meta') model_graph.visual_graph.render(\"transformer_torchview\", format=\"png\") model_graph.visual_graph 单纯decoder图示\nimport torch from torch.nn import Transformer from torch.nn import TransformerDecoder from torch.nn import TransformerDecoderLayer decoder_layer = TransformerDecoderLayer(d_model=512, nhead=8) decoder_model = TransformerDecoder(decoder_layer=decoder_layer, num_layers=2) model_graph = draw_graph( decoder_model, input_size=((10,32,512), (20,32,512)), expand_nested=True, save_graph=True, filename=\"transformer_torchview\", device='meta') model_graph.visual_graph.render(\"transformer_torchview\", format=\"png\") model_graph.visual_graph Ref pytorch模型网络可视化画图工具合集(文后附上完整代码) | by MLTalks | Medium\nNetron\n",
  "wordCount" : "1170",
  "inLanguage": "zh",
  "datePublished": "2024-04-10T00:00:00Z",
  "dateModified": "2024-04-10T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Niuhe"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://blog.niuhemoon.win/posts/tech/pytorch-model-view/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Niuhe's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://blog.niuhemoon.win/base/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://blog.niuhemoon.win" accesskey="h" title="Niuhe&#39;s Blog (Alt + H)">
                <img src="https://blog.niuhemoon.win/base/avatar.jpeg" alt="" aria-label="logo"
                    height="35">Niuhe&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://blog.niuhemoon.win/search" title="🔍搜索 (Alt &#43; /)" accesskey=/>
                    <span>🔍搜索</span>
                </a>
            </li>
            <li>
                <a href="https://blog.niuhemoon.win/" title="🏠主页">
                    <span>🏠主页</span>
                </a>
            </li>
            <li>
                <a href="https://blog.niuhemoon.win/posts" title="📚文章">
                    <span>📚文章</span>
                </a>
            </li>
            <li>
                <a href="https://blog.niuhemoon.win/tags" title="🔖标签">
                    <span>🔖标签</span>
                </a>
            </li>
            <li>
                <a href="https://blog.niuhemoon.win/archives/" title="⏱时间轴">
                    <span>⏱时间轴</span>
                </a>
            </li>
            <li>
                <a href="https://blog.niuhemoon.win/about" title="🙋🏻‍♂️关于">
                    <span>🙋🏻‍♂️关于</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://blog.niuhemoon.win">🏠主页</a>&nbsp;»&nbsp;<a href="https://blog.niuhemoon.win/posts/">📚文章</a>&nbsp;»&nbsp;<a href="https://blog.niuhemoon.win/posts/tech/">👨🏻‍💻 技术</a></div>
    <h1 class="post-title">
      Pytorch模型可视化
    </h1>
    <div class="post-description">
      Pytorch模型可视化
    </div>
    <div class="post-meta"><span title='2024-04-10 00:00:00 +0000 UTC'>2024-04-10</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;1170 字&nbsp;·&nbsp;Niuhe

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">文章目录</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#linear-regression" aria-label="Linear Regression">Linear Regression</a><ul>
                        
                <li>
                    <a href="#model-summary" aria-label="Model Summary">Model Summary</a></li>
                <li>
                    <a href="#torchviz" aria-label="Torchviz">Torchviz</a></li>
                <li>
                    <a href="#torchview" aria-label="Torchview">Torchview</a></li>
                <li>
                    <a href="#netron%e5%b7%a5%e5%85%b7" aria-label="netron工具">netron工具</a></li></ul>
                </li>
                <li>
                    <a href="#transfomer" aria-label="Transfomer">Transfomer</a><ul>
                        
                <li>
                    <a href="#model-summary-1" aria-label="Model Summary">Model Summary</a></li>
                <li>
                    <a href="#torchview-1" aria-label="Torchview">Torchview</a></li></ul>
                </li>
                <li>
                    <a href="#ref" aria-label="Ref">Ref</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h3 id="linear-regression">Linear Regression<a hidden class="anchor" aria-hidden="true" href="#linear-regression">#</a></h3>
<blockquote>
<p>这里举一个回归模型的例子，展示几种模型可视化的方法，分别是</p>
<ul>
<li>print</li>
<li>torchinfo.summary</li>
<li>torchsummary</li>
<li>torchviz</li>
<li>torchview</li>
<li>netron工具</li>
</ul>
</blockquote>
<p><strong>首先创建一个简单的回归模型</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 定义带有两个全连接层和ReLU激活函数的线性回归模型</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">class</span> LinearRegression(torch.nn.Module):
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> __init__(self, input_dim, hidden_dim, output_dim):
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">super</span>(LinearRegression, self).__init__()
</span></span><span style="display:flex;"><span>        self.fc1 = torch.nn.Linear(input_dim, hidden_dim)
</span></span><span style="display:flex;"><span>        self.relu = torch.nn.ReLU()
</span></span><span style="display:flex;"><span>        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#fff;font-weight:bold">def</span> forward(self, x):
</span></span><span style="display:flex;"><span>        out = self.fc1(x)
</span></span><span style="display:flex;"><span>        out = self.relu(out)
</span></span><span style="display:flex;"><span>        out = self.fc2(out)
</span></span><span style="display:flex;"><span>        <span style="color:#fff;font-weight:bold">return</span> out
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 输入输出维度和隐藏层维度</span>
</span></span><span style="display:flex;"><span>input_dim = <span style="color:#ff0;font-weight:bold">1</span>
</span></span><span style="display:flex;"><span>hidden_dim = <span style="color:#ff0;font-weight:bold">64</span>
</span></span><span style="display:flex;"><span>output_dim = <span style="color:#ff0;font-weight:bold">1</span>
</span></span><span style="display:flex;"><span>batch_size = <span style="color:#ff0;font-weight:bold">32</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 创建模型</span>
</span></span><span style="display:flex;"><span>model = LinearRegression(input_dim, hidden_dim, output_dim)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 打印模型</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(model)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># LinearRegression(</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  (fc1): Linear(in_features=1, out_features=64, bias=True)</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  (relu): ReLU()</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f">#  (fc2): Linear(in_features=64, out_features=1, bias=True)</span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># )</span>
</span></span></code></pre></div><h4 id="model-summary">Model Summary<a hidden class="anchor" aria-hidden="true" href="#model-summary">#</a></h4>
<blockquote>
<p>打印模型的简要信息，包括可训练参数等</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torchinfo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 打印模型summary</span>
</span></span><span style="display:flex;"><span>torchinfo.summary(
</span></span><span style="display:flex;"><span>    model,
</span></span><span style="display:flex;"><span>    input_size=(batch_size, input_dim),
</span></span><span style="display:flex;"><span>    col_names=[<span style="color:#0ff;font-weight:bold">&#34;input_size&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;output_size&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;num_params&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;trainable&#34;</span>]
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>============================================================================================================================================
</span></span><span style="display:flex;"><span>Layer (type:depth-idx)                   Input Shape               Output Shape              Param <span style="color:#007f7f">#                   Trainable</span>
</span></span><span style="display:flex;"><span>============================================================================================================================================
</span></span><span style="display:flex;"><span>LinearRegression                         [32, 1]                   [32, 1]                   --                        True
</span></span><span style="display:flex;"><span>├─Linear: 1-1                            [32, 1]                   [32, 64]                  <span style="color:#ff0;font-weight:bold">128</span>                       True
</span></span><span style="display:flex;"><span>├─ReLU: 1-2                              [32, 64]                  [32, 64]                  --                        --
</span></span><span style="display:flex;"><span>├─Linear: 1-3                            [32, 64]                  [32, 1]                   <span style="color:#ff0;font-weight:bold">65</span>                        True
</span></span><span style="display:flex;"><span>============================================================================================================================================
</span></span><span style="display:flex;"><span>Total params: <span style="color:#ff0;font-weight:bold">193</span>
</span></span><span style="display:flex;"><span>Trainable params: <span style="color:#ff0;font-weight:bold">193</span>
</span></span><span style="display:flex;"><span>Non-trainable params: <span style="color:#ff0;font-weight:bold">0</span>
</span></span><span style="display:flex;"><span>Total mult-adds (Units.MEGABYTES): 0.01
</span></span><span style="display:flex;"><span>============================================================================================================================================
</span></span><span style="display:flex;"><span>Input size (MB): 0.00
</span></span><span style="display:flex;"><span>Forward/backward pass size (MB): 0.02
</span></span><span style="display:flex;"><span>Params size (MB): 0.00
</span></span><span style="display:flex;"><span>Estimated Total Size (MB): 0.02
</span></span><span style="display:flex;"><span>============================================================================================================================================
</span></span></code></pre></div><blockquote>
<p>还可以打印简单的信息</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torchsummary
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>torchsummary.summary(model, input_size=(batch_size, input_dim))
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>----------------------------------------------------------------
</span></span><span style="display:flex;"><span>        Layer (<span style="color:#fff;font-weight:bold">type</span>)               Output Shape         Param <span style="color:#007f7f">#</span>
</span></span><span style="display:flex;"><span>================================================================
</span></span><span style="display:flex;"><span>            Linear-1               [-1, 32, 64]             <span style="color:#ff0;font-weight:bold">128</span>
</span></span><span style="display:flex;"><span>              ReLU-2               [-1, 32, 64]               <span style="color:#ff0;font-weight:bold">0</span>
</span></span><span style="display:flex;"><span>            Linear-3                [-1, 32, 1]              65
</span></span><span style="display:flex;"><span>================================================================
</span></span><span style="display:flex;"><span>Total params: <span style="color:#ff0;font-weight:bold">193</span>
</span></span><span style="display:flex;"><span>Trainable params: <span style="color:#ff0;font-weight:bold">193</span>
</span></span><span style="display:flex;"><span>Non-trainable params: <span style="color:#ff0;font-weight:bold">0</span>
</span></span><span style="display:flex;"><span>----------------------------------------------------------------
</span></span><span style="display:flex;"><span>Input size (MB): 0.00
</span></span><span style="display:flex;"><span>Forward/backward pass size (MB): 0.03
</span></span><span style="display:flex;"><span>Params size (MB): 0.00
</span></span><span style="display:flex;"><span>Estimated Total Size (MB): 0.03
</span></span><span style="display:flex;"><span>----------------------------------------------------------------
</span></span></code></pre></div><h4 id="torchviz">Torchviz<a hidden class="anchor" aria-hidden="true" href="#torchviz">#</a></h4>
<blockquote>
<p>可以导出graphviz图，需要计算机安装graphviz
执行<code>dot -V</code> 验证graphviz成功安装</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torchviz
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 定义一个示例输入</span>
</span></span><span style="display:flex;"><span>example_input = torch.randn(batch_size, input_dim)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model = LinearRegression(input_dim, hidden_dim, output_dim)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 使用torchviz绘制计算图</span>
</span></span><span style="display:flex;"><span>output = model(example_input)
</span></span><span style="display:flex;"><span>dot = torchviz.make_dot(output, params=<span style="color:#fff;font-weight:bold">dict</span>(model.named_parameters()), show_attrs=<span style="color:#fff;font-weight:bold">False</span>, show_saved=<span style="color:#fff;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>dot.render(<span style="color:#0ff;font-weight:bold">&#34;linear_regression_torchviz&#34;</span>, <span style="color:#fff;font-weight:bold">format</span>=<span style="color:#0ff;font-weight:bold">&#34;png&#34;</span>, cleanup=<span style="color:#fff;font-weight:bold">True</span>, view=<span style="color:#fff;font-weight:bold">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># 如果不是在Jupyter中，注释下面两行</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> IPython.display <span style="color:#fff;font-weight:bold">import</span> Image, display
</span></span><span style="display:flex;"><span>display(Image(<span style="color:#0ff;font-weight:bold">&#39;./linear_regression.png&#39;</span>))
</span></span></code></pre></div>





  <span class="caption-wrapper">
    <img style="display: block;width: 90%; margin: auto;" src="/img/torchviz.png" title="Torchviz图示" alt="Torchviz图示">
    <span style="display:block;text-align: center;font-size: 90%;;">◎ Torchviz图示</span>
  </span>
<h4 id="torchview">Torchview<a hidden class="anchor" aria-hidden="true" href="#torchview">#</a></h4>
<blockquote>
<p>可以绘制规范的线框图，便于展示模型的层次</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torchview <span style="color:#fff;font-weight:bold">import</span> draw_graph
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model = LinearRegression(input_dim, hidden_dim, output_dim)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># device=&#39;meta&#39; -&gt; no memory is consumed for visualization</span>
</span></span><span style="display:flex;"><span>model_graph = draw_graph(
</span></span><span style="display:flex;"><span>    model,
</span></span><span style="display:flex;"><span>    input_size=(batch_size, input_dim), 
</span></span><span style="display:flex;"><span>    expand_nested=<span style="color:#fff;font-weight:bold">True</span>,
</span></span><span style="display:flex;"><span>    save_graph=<span style="color:#fff;font-weight:bold">True</span>, 
</span></span><span style="display:flex;"><span>    filename=<span style="color:#0ff;font-weight:bold">&#34;linear_regression_torchview&#34;</span>,
</span></span><span style="display:flex;"><span>    device=<span style="color:#0ff;font-weight:bold">&#39;meta&#39;</span>)
</span></span><span style="display:flex;"><span>model_graph.visual_graph.render(<span style="color:#0ff;font-weight:bold">&#34;linear_regression_torchview&#34;</span>, <span style="color:#fff;font-weight:bold">format</span>=<span style="color:#0ff;font-weight:bold">&#34;png&#34;</span>)
</span></span><span style="display:flex;"><span>model_graph.visual_graph
</span></span></code></pre></div><p><img loading="lazy" src="/img/torchview.svg" alt="torchview"  />
</p>
<h4 id="netron工具">netron工具<a hidden class="anchor" aria-hidden="true" href="#netron工具">#</a></h4>
<blockquote>
<p>可以看出详细的计算图，但是需要将模型导出成ONNX格式</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f"># 导出onnx并用netron展示</span>
</span></span><span style="display:flex;"><span>model = LinearRegression(input_dim, hidden_dim, output_dim)
</span></span><span style="display:flex;"><span>example_input = torch.randn(batch_size, input_dim)
</span></span><span style="display:flex;"><span>torch.onnx.export(model, example_input, <span style="color:#0ff;font-weight:bold">&#34;linear_regression.onnx&#34;</span>, verbose=<span style="color:#fff;font-weight:bold">True</span>)
</span></span></code></pre></div><h3 id="transfomer">Transfomer<a hidden class="anchor" aria-hidden="true" href="#transfomer">#</a></h3>
<blockquote>
<p>如下是Pytorch的Transformer图示</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007f7f"># Transformer模型可视化</span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch.nn <span style="color:#fff;font-weight:bold">import</span> Transformer
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch.nn <span style="color:#fff;font-weight:bold">import</span> TransformerDecoder
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch.nn <span style="color:#fff;font-weight:bold">import</span> TransformerDecoderLayer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>transformer_model = Transformer(num_encoder_layers=<span style="color:#ff0;font-weight:bold">2</span>, num_decoder_layers=<span style="color:#ff0;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>src = torch.rand(<span style="color:#ff0;font-weight:bold">10</span>,<span style="color:#ff0;font-weight:bold">32</span>,<span style="color:#ff0;font-weight:bold">512</span>)
</span></span><span style="display:flex;"><span>tgt = torch.rand(<span style="color:#ff0;font-weight:bold">20</span>,<span style="color:#ff0;font-weight:bold">32</span>,<span style="color:#ff0;font-weight:bold">512</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">print</span>(transformer_model)
</span></span></code></pre></div><h4 id="model-summary-1">Model Summary<a hidden class="anchor" aria-hidden="true" href="#model-summary-1">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torchinfo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>torchinfo.summary(
</span></span><span style="display:flex;"><span>    transformer_model,
</span></span><span style="display:flex;"><span>    input_size=((<span style="color:#ff0;font-weight:bold">10</span>,<span style="color:#ff0;font-weight:bold">32</span>,<span style="color:#ff0;font-weight:bold">512</span>), (<span style="color:#ff0;font-weight:bold">20</span>,<span style="color:#ff0;font-weight:bold">32</span>,<span style="color:#ff0;font-weight:bold">512</span>)),
</span></span><span style="display:flex;"><span>    col_names=[<span style="color:#0ff;font-weight:bold">&#34;input_size&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;output_size&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;num_params&#34;</span>, <span style="color:#0ff;font-weight:bold">&#34;trainable&#34;</span>]
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>=================================================================================================================================================
</span></span><span style="display:flex;"><span>Layer (type:depth-idx)                        Input Shape               Output Shape              Param <span style="color:#007f7f">#                   Trainable</span>
</span></span><span style="display:flex;"><span>=================================================================================================================================================
</span></span><span style="display:flex;"><span>Transformer                                   [10, 32, 512]             [20, 32, 512]             --                        True
</span></span><span style="display:flex;"><span>├─TransformerEncoder: 1-1                     [10, 32, 512]             [10, 32, 512]             --                        True
</span></span><span style="display:flex;"><span>│    └─ModuleList: 2-1                        --                        --                        --                        True
</span></span><span style="display:flex;"><span>│    │    └─TransformerEncoderLayer: 3-1      [10, 32, 512]             [10, 32, 512]             3,152,384                 True
</span></span><span style="display:flex;"><span>│    │    └─TransformerEncoderLayer: 3-2      [10, 32, 512]             [10, 32, 512]             3,152,384                 True
</span></span><span style="display:flex;"><span>│    └─LayerNorm: 2-2                         [10, 32, 512]             [10, 32, 512]             1,024                     True
</span></span><span style="display:flex;"><span>├─TransformerDecoder: 1-2                     [20, 32, 512]             [20, 32, 512]             --                        True
</span></span><span style="display:flex;"><span>│    └─ModuleList: 2-3                        --                        --                        --                        True
</span></span><span style="display:flex;"><span>│    │    └─TransformerDecoderLayer: 3-3      [20, 32, 512]             [20, 32, 512]             4,204,032                 True
</span></span><span style="display:flex;"><span>│    │    └─TransformerDecoderLayer: 3-4      [20, 32, 512]             [20, 32, 512]             4,204,032                 True
</span></span><span style="display:flex;"><span>│    └─LayerNorm: 2-4                         [20, 32, 512]             [20, 32, 512]             1,024                     True
</span></span><span style="display:flex;"><span>=================================================================================================================================================
</span></span><span style="display:flex;"><span>Total params: 14,714,880
</span></span><span style="display:flex;"><span>Trainable params: 14,714,880
</span></span><span style="display:flex;"><span>Non-trainable params: <span style="color:#ff0;font-weight:bold">0</span>
</span></span><span style="display:flex;"><span>Total mult-adds (Units.MEGABYTES): 126.18
</span></span><span style="display:flex;"><span>=================================================================================================================================================
</span></span><span style="display:flex;"><span>Input size (MB): 1.97
</span></span><span style="display:flex;"><span>Forward/backward pass size (MB): 64.23
</span></span><span style="display:flex;"><span>Params size (MB): 33.64
</span></span><span style="display:flex;"><span>Estimated Total Size (MB): 99.84
</span></span><span style="display:flex;"><span>=================================================================================================================================================
</span></span></code></pre></div><h4 id="torchview-1">Torchview<a hidden class="anchor" aria-hidden="true" href="#torchview-1">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torchview <span style="color:#fff;font-weight:bold">import</span> draw_graph
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>transformer_model = Transformer(num_encoder_layers=<span style="color:#ff0;font-weight:bold">1</span>, num_decoder_layers=<span style="color:#ff0;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model_graph = draw_graph(
</span></span><span style="display:flex;"><span>    transformer_model,
</span></span><span style="display:flex;"><span>    input_size=((<span style="color:#ff0;font-weight:bold">10</span>,<span style="color:#ff0;font-weight:bold">32</span>,<span style="color:#ff0;font-weight:bold">512</span>), (<span style="color:#ff0;font-weight:bold">20</span>,<span style="color:#ff0;font-weight:bold">32</span>,<span style="color:#ff0;font-weight:bold">512</span>)), 
</span></span><span style="display:flex;"><span>    expand_nested=<span style="color:#fff;font-weight:bold">True</span>,
</span></span><span style="display:flex;"><span>    save_graph=<span style="color:#fff;font-weight:bold">True</span>,
</span></span><span style="display:flex;"><span>    filename=<span style="color:#0ff;font-weight:bold">&#34;transformer_torchview&#34;</span>,
</span></span><span style="display:flex;"><span>    device=<span style="color:#0ff;font-weight:bold">&#39;meta&#39;</span>)
</span></span><span style="display:flex;"><span>model_graph.visual_graph.render(<span style="color:#0ff;font-weight:bold">&#34;transformer_torchview&#34;</span>, <span style="color:#fff;font-weight:bold">format</span>=<span style="color:#0ff;font-weight:bold">&#34;png&#34;</span>)
</span></span><span style="display:flex;"><span>model_graph.visual_graph
</span></span></code></pre></div><p><img loading="lazy" src="/img/torchview_transformer.svg" alt="transformer_torchview"  />
</p>
<blockquote>
<p>单纯decoder图示</p>
</blockquote>
<div class="highlight"><pre tabindex="0" style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch.nn <span style="color:#fff;font-weight:bold">import</span> Transformer
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch.nn <span style="color:#fff;font-weight:bold">import</span> TransformerDecoder
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> torch.nn <span style="color:#fff;font-weight:bold">import</span> TransformerDecoderLayer
</span></span><span style="display:flex;"><span>decoder_layer = TransformerDecoderLayer(d_model=<span style="color:#ff0;font-weight:bold">512</span>, nhead=<span style="color:#ff0;font-weight:bold">8</span>)
</span></span><span style="display:flex;"><span>decoder_model = TransformerDecoder(decoder_layer=decoder_layer, num_layers=<span style="color:#ff0;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model_graph = draw_graph(
</span></span><span style="display:flex;"><span>    decoder_model,
</span></span><span style="display:flex;"><span>    input_size=((<span style="color:#ff0;font-weight:bold">10</span>,<span style="color:#ff0;font-weight:bold">32</span>,<span style="color:#ff0;font-weight:bold">512</span>), (<span style="color:#ff0;font-weight:bold">20</span>,<span style="color:#ff0;font-weight:bold">32</span>,<span style="color:#ff0;font-weight:bold">512</span>)), 
</span></span><span style="display:flex;"><span>    expand_nested=<span style="color:#fff;font-weight:bold">True</span>,
</span></span><span style="display:flex;"><span>    save_graph=<span style="color:#fff;font-weight:bold">True</span>,
</span></span><span style="display:flex;"><span>    filename=<span style="color:#0ff;font-weight:bold">&#34;transformer_torchview&#34;</span>,
</span></span><span style="display:flex;"><span>    device=<span style="color:#0ff;font-weight:bold">&#39;meta&#39;</span>)
</span></span><span style="display:flex;"><span>model_graph.visual_graph.render(<span style="color:#0ff;font-weight:bold">&#34;transformer_torchview&#34;</span>, <span style="color:#fff;font-weight:bold">format</span>=<span style="color:#0ff;font-weight:bold">&#34;png&#34;</span>)
</span></span><span style="display:flex;"><span>model_graph.visual_graph
</span></span></code></pre></div><p><img loading="lazy" src="/img/torchview_decoder.svg" alt="decoder_torchview"  />
</p>
<h3 id="ref">Ref<a hidden class="anchor" aria-hidden="true" href="#ref">#</a></h3>
<p><a href="https://mltalks.medium.com/pytorch%E6%A8%A1%E5%9E%8B%E7%BD%91%E7%BB%9C%E5%8F%AF%E8%A7%86%E5%8C%96%E7%94%BB%E5%9B%BE%E5%B7%A5%E5%85%B7%E5%90%88%E9%9B%86-%E6%96%87%E5%90%8E%E9%99%84%E4%B8%8A%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81-a796ee726a87">pytorch模型网络可视化画图工具合集(文后附上完整代码) | by MLTalks | Medium</a></p>
<p><a href="https://netron.app/">Netron</a></p>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://blog.niuhemoon.win/tags/python/">Python</a></li>
      <li><a href="https://blog.niuhemoon.win/tags/pytorch/">Pytorch</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://blog.niuhemoon.win/posts/tech/linux-fake-node/">
    <span class="title">« 上一页</span>
    <br>
    <span>制作Docker镜像模拟服务器节点</span>
  </a>
  <a class="next" href="https://blog.niuhemoon.win/posts/tech/cka-study-record/">
    <span class="title">下一页 »</span>
    <br>
    <span>CKA备考笔记</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
      
    <span>&copy; 2024 <a href="https://blog.niuhemoon.win">Niuhe&#39;s Blog</a></span>
    <span xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/">
        Licensed under
        <a
          href="http://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1"
          target="_blank"
          rel="license noopener noreferrer"
          style="display:inline-block;"
          >CC BY-NC-SA 4.0 </a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = '📄复制';

        function copyingDone() {
            copybutton.innerHTML = '👌🏻已复制!';
            setTimeout(() => {
                copybutton.innerHTML = '📄复制';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
