[{"content":"记录一下CKA考试的备考过程\nCKA考试备考笔记\n记录备考CKA的过程\n学习K8S的资源主要有三个：\nCertified Kubernetes Administrator (CKA) Practice Exam Tests | Udemy kubectl Cheat Sheet | Kubernetes Udemy Labs - Certified Kubernetes Administrator with Practice Tests - KodeKloud 其中kodekloud提供了在线的实验环境，无需自己搭建k8s集群测试环境 最终考了94分，高分飘过\n考试技巧 考试环境是类似远程桌面，是一个远程的ubuntu桌面，只能在远程桌面内操作，不能使用你自己电脑上的浏览器，但是可以使用远程桌面里的firefox浏览器\n提前30分钟就可以进入考场，出示证件并检查环境\n考试命令行各种快捷键和命令补全都已经配置好了，不用操心\n如果要求是写shell命令行到文件中，不能用k缩写，必须是完整的kubelet命令\n考试时可以复制粘贴k8s官网的内容\n一定要看看网上历年真题，并实际联系，题目几乎一样（很关键）\n最好看英文试题，不会因为翻译产生误解\n最好参加下Killer Shell - Exam Simulators的模拟考试，模拟难度很大，分析学习完会有明显提高\n必学命令\nvim grep命令 yaml语法 netstat命令 ip命令 systemctl命令 journalctl命令 ipcalc命令(可选) apt-cache madison apt-get json-path 笔记 核心概念 核心概念 一切皆是资源\n通过如下命令可以列出api支持的资源\nkubectl api-resources Short name Full name csr certificatesigningrequests cs componentstatuses cm configmaps ds daemonsets deploy deployments ep endpoints ev events hpa horizontalpodautoscalers ing ingresses limits limitranges ns namespaces no nodes pvc persistentvolumeclaims pv persistentvolumes po pods pdb poddisruptionbudgets psp podsecuritypolicies rs replicasets rc replicationcontrollers quota resourcequotas sa serviceaccounts svc services 通用命令 # 列出api接口支持的资源(也包含了资源的apiVersiono和kind信息) kubectl api-resources # 解释具体的资源 kubectl explain \u0026lt;resource-name\u0026gt; kubectl explain replicaset kubectl explain rs | head -n3 # 列出当前namespace所有资源 kubectl get all Pod # 查看所有pods kubectl get pods kubectl get pods -o wide # 创建一个nginx容器 kubectl run nginx --image=nginx # 查看pod的详情 kubectl describe pod \u0026lt;podname\u0026gt; | less # 删除pod kubectl delete pod \u0026lt;podname\u0026gt; # 查找特定lable的pods k get pods --selector env=dev,bu=finance 利用声明式接口创建pod\ndry run机制生成yaml kubectl create -f 从yaml文件生成pod controlplane ~ ➜ kubectl run redis --image=redis123 --dry-run=client -o yaml \u0026gt; redis-definition.yaml controlplane ~ ➜ cat redis-definition.yaml apiVersion: v1 kind: Pod metadata: creationTimestamp: null labels: run: redis name: redis spec: containers: - image: redis123 name: redis resources: {} dnsPolicy: ClusterFirst restartPolicy: Always status: {} controlplane ~ ➜ kubectl create -f redis-definition.yaml pod/redis created 刚才创建的pod中image名字redis123无法pull镜像，现在进行修复\n方式1:\nkubectl edit pod redis将spec段中的redis123修改为redis，保存即可生效\n方式2:\n直接编辑redis-definition.yaml文件，修改image名后\nkubectl apply -f redis-definition.yaml 方式3:\n先获取pod的yaml\nkubectl get pod redis -o yaml \u0026gt; redis-definition.yaml\n编辑修改后再进行替换\nkubectl replace -f redis-definition.yaml --force\n一些例子\n# 创建带lable的pod kubectl run redis --image=redis:alpine --labels tier=db # 为pod创建一个service k expose pod redis --port 6379 --name redis-service # 创建pod并制定端口 k run custom-nginx --image=nginx --port=8080 # 创建pod同时创建同名的service k run httpd --image httpd:alpine --port=80 --expose 查看/创建static pod\nstatic pod由kubelet直接管理，只能从api接口查看，无法从api管理\n# 查看哪些是static pod，以-controlplane结尾的是的 k get pods --all-namespaces | grep -controlplane # 查找static pod的yaml配置路径 # step1: 查看kubelet的配置文件（启动时通过命令行传递） ps -aux | grep /usr/bin/kubelet # kubelet的配置路径为/var/lib/kubelet/config.yaml grep -i staticpod /var/lib/kubelet/config.yaml # 创建static pod # 首先创建定义pod的yaml文件，然后放到/etc/kubernetes/manifests路径下 kubectl run --restart=Never --image=busybox static-busybox --dry-run=client -o yaml --command -- sleep 1000 \u0026gt; /etc/kubernetes/manifests/static-busybox.yaml Replicaset # 列出replicasets资源 kubectl get replicasets kubectl get rs # 查看replicasets更多信息 kubectl get rs -o wide kubectl describe replicaset \u0026lt;replicaset-name\u0026gt; # 从yaml文件创建replicasets # 命令式：资源已存在会报错 kubectl create -f replicaset-definition.yaml # 声明式：资源已存在不会报错，更适用于版本更新 kubectl apply -f replicaset-definition.yaml # 删除replicasets kubectl delete rs \u0026lt;replicaset-name\u0026gt; # 修复错误的replicasets # step1: 修复配置 kubectl edit rs \u0026lt;replicaset-name\u0026gt; # step2: 删除之前未成功的pods k get po | grep \u0026lt;replicaset-name\u0026gt; | awk \u0026#39;{print $1}\u0026#39; | xargs -n 1 k delete po # scale扩容或缩容 k scale rs \u0026lt;replicaset-name\u0026gt; --replicas=5 # 或者直接k edit编辑replicas k edit rs \u0026lt;replicaset-name\u0026gt; 一些例子\nk create deployment webapp --image kodekloud/webapp-color --replicas DaemonSet # 获取所有namespace中的daemonsets k get daemonsets --all-namespaces # 查看daemonset详情 kubectl describe ds \u0026lt;daemonset-name\u0026gt; --namespace=\u0026lt;namespace-name\u0026gt; # 创建一个daemonset的yaml # step1: 先通过dry run方式创建一个deployment的yaml # step2: 编辑yaml，移除replicas, strategy and status 段 # step3: 将kind从Deployment 改为 DaemonSet 创建daemonset的例子\nk create deployment elasticsearch -n kube-system --image registry.k8s.io/fluentd-elasticsearch:1.20 --dry-run=client -o yaml \u0026gt; daemonset.yaml apiVersion: apps/v1 kind: DaemonSet metadata: creationTimestamp: null labels: app: elasticsearch name: elasticsearch namespace: kube-system spec: selector: matchLabels: app: elasticsearch template: metadata: creationTimestamp: null labels: app: elasticsearch spec: containers: - image: registry.k8s.io/fluentd-elasticsearch:1.20 name: fluentd-elasticsearch resources: {} k apply -f daemonset.yaml Deployment # 列出deployments资源 kubectl get deployments kubectl get deploy # 创建deployment # 方式1:直接命令创建 kubectl create deployment --image httpd:2.4-alpine --replicas 3 httpd-frontent # 方式2:先dry-run生成yaml，然后修改后再apply kubectl create deployment --image httpd:2.4-alpine --replicas 3 --dry-run=client httpd-frontent -o yaml \u0026gt; httpd-deployment.yaml kubectl apply -f httpd-deployment.yaml # 删除deployment k delete deploy \u0026lt;deployment-name\u0026gt; 一些例子\n# 指定namespace创建deployment kubectl create deployment redis-deploy -n dev-ns --image redis --replicas 2 Namespace # 列出所有namespace k get namespaces k get ns # 获取环境中namespace个数 k get ns --no-headers | wc -l # 列出特定namespace中的pods k get pods -n \u0026lt;namespace-name\u0026gt; # 获取所有namespace中的pods k get pods --all-namespaces # 在特定namespace中创建pod k run redis --image=redis -n finance k run redis --image=redis --dry-run=client -n finance -o yaml # 列出特定namespace中的service k get service -n \u0026lt;namespace-name\u0026gt; # 创建一个新的namespace k create namespace \u0026lt;namespace-name\u0026gt; 备注：\nservice的DNS解析策略 同namespace，可以直接用service的名字 不同namesapce，需要加上namespace的后缀，例如 db-service.dev db-service.dev.svc.cluster.local Service # 列出所有services k get services k get svc # 查看特定service详情 k describe svc \u0026lt;service-name\u0026gt; # 创建service，使用类似下民的yaml创建 k apply -f service-definition.yaml --- apiVersion: v1 kind: Service metadata: name: webapp-service namespace: default spec: ports: - nodePort: 30080 port: 8080 targetPort: 8080 selector: name: simple-webapp type: NodePort Node # 获取集群中所有node的信息 kubectl get nodes # 查看节点详情 k describe node \u0026lt;node-name\u0026gt; 调度部分 通过指定nodeName指定节点部署\n--- apiVersion: v1 kind: Pod metadata: name: nginx spec: nodeName: node01 containers: - image: nginx name: nginx Taint和Tolerance\n# 为节点node01添加taint，效果是NoSchedule k taint node node01 spary=mortein:NoSchedule # 为节点node01移除key是spary的taint k taint node node01 spary- 创建可以容忍特定taint的pod\n--- apiVersion: v1 kind: Pod metadata: name: bee spec: containers: - image: nginx name: bee tolerations: - key: spray value: mortein effect: NoSchedule operator: Equal Label\n# 为节点添加lable color=blue kubectl label node node01 color=blue 使用label实现一个deployment中的pod调度亲和\n--- apiVersion: apps/v1 kind: Deployment metadata: name: blue spec: replicas: 3 selector: matchLabels: run: nginx template: metadata: labels: run: nginx spec: containers: - image: nginx imagePullPolicy: Always name: nginx affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: color operator: In values: - blue 遇到pod定义的资源不足以运行\nkubectl get pod elephant -o yaml \u0026gt; ele.yaml # 编辑资源request后 kubectl replace -f ele.yaml --force pod通过schedulerName指定调度器\n--- apiVersion: v1 kind: Pod metadata: name: nginx spec: schedulerName: my-scheduler containers: - image: nginx name: nginx 度量和日志Metric \u0026amp; Log Metrics # Metrics度量 git clone https://github.com/kodekloudhub/kubernetes-metrics-server.git cd kubernetes-metrics-server/ kubectl create -f . # wait a minute kubectl top node # cpu占用最高的节点 kubectl top node --sort-by=\u0026#39;cpu\u0026#39; --no-headers | head -1 # 内存占用最高的节点 kubectl top node --sort-by=\u0026#39;memory\u0026#39; --no-headers | head -1 # 内存占用最多的pod kubectl top pod --sort-by=\u0026#39;memory\u0026#39; --no-headers | head -1 # 内存占用最少的pod kubectl top pod --sort-by=\u0026#39;memory\u0026#39; --no-headers | tail -1 Log # 查看pod日志 kubectl logs \u0026lt;pod-name\u0026gt; # 指定pod中容器查看日志（一个pod可以有多个container） kubectl logs \u0026lt;pod-name\u0026gt; -c \u0026lt;container-name\u0026gt; # 登入pod中指定的容器 kubectl exec -it \u0026lt;pod-name\u0026gt; -c \u0026lt;container-name\u0026gt; -- /bin/bash 应用生命周期管理 更新deployment版本 # 查看deployment的策略 k describe deploy \u0026lt;deployment-name\u0026gt; | grep StrategyType # RollingUpdate意味着一次只更新部分pod # Recreate意味着同时终止pod并重新创建 k describe deploy \u0026lt;deployment-name\u0026gt; | grep RollingUpdateStrategy # 25% max unavailable, 25% max surge意味着最多可以同时终止25%的pod # 更新deployment的镜像 k edit deploy \u0026lt;deployment-name\u0026gt; 命令行 指定容器命令行\napiVersion: v1 kind: Pod metadata: name: ubuntu-sleeper-2 spec: containers: - name: ubuntu image: ubuntu command: - \u0026#34;sleep\u0026#34; - \u0026#34;5000\u0026#34; apiVersion: v1 kind: Pod metadata: name: webapp-green labels: name: webapp-green spec: containers: - name: simple-webapp image: kodekloud/webapp-color command: [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] args: [\u0026#34;--color\u0026#34;, \u0026#34;pink\u0026#34;] Secret # 列出secrets k get secrets # 查看secret详情 k describe secrets \u0026lt;secret-name\u0026gt; # 创建secret，名为db-secret kubectl create secret generic db-secret --from-literal=DB_Host=sql01 --from-literal=DB_User=root pod使用secret\n--- apiVersion: v1 kind: Pod metadata: labels: name: webapp-pod name: webapp-pod namespace: default spec: containers: - image: kodekloud/simple-webapp-mysql imagePullPolicy: Always name: webapp envFrom: - secretRef: name: db-secret Multi Container apiVersion: v1 kind: Pod metadata: creationTimestamp: null labels: run: yellow name: yellow spec: containers: - image: busybox name: lemon resources: {} command: [\u0026#34;sleep\u0026#34;, \u0026#34;1000\u0026#34;] - image: redis name: gold resources: {} dnsPolicy: ClusterFirst restartPolicy: Always status: {} 多容器共享文件系统\n--- apiVersion: v1 kind: Pod metadata: name: app namespace: elastic-stack labels: name: app spec: containers: - name: app image: kodekloud/event-simulator volumeMounts: - mountPath: /log name: log-volume - name: sidecar image: kodekloud/filebeat-configured volumeMounts: - mountPath: /var/log/event-simulator/ name: log-volume volumes: - name: log-volume hostPath: # directory location on host path: /var/log/webapp # this field is optional type: DirectoryOrCreate Init Container --- apiVersion: v1 kind: Pod metadata: name: red namespace: default spec: containers: - command: - sh - -c - echo The app is running! \u0026amp;\u0026amp; sleep 3600 image: busybox:1.28 name: red-container initContainers: - image: busybox name: red-initcontainer command: - \u0026#34;sleep\u0026#34; - \u0026#34;20\u0026#34; Cluster 维护 升级OS # 升级node01，首先清空node01上的pod # 效果 pod evicted, node drained # drain会默认将node cordon，即不可调度 kubectl drain node01 --ignore-daemonsets # node01维护完毕后，将node01设置为可调度 kubectl uncordon node01 # NOTE: drain只能处理replicaset，单独的pod需要强制执行 k drain node01 --ignore-daemonsets --force # 对不属于replicaset的pod，将会永久丢失 # 将node01设置不可调度 kubectl cordon node01 升级K8S # 查看控制节点版本 k version --short # 查看node版本，当前1.26 k get nodes # 查看远端可升级版本 kubeadm upgrade plan # 有两个node分别是controlplane和node01 # 先清空controlplane的pod kubectl drain controlplane --ignore-daemonsets # 开始升级controlplane apt update # 首先升级kubeadm apt-get install kubeadm=1.27.0-00 kubeadm upgrade apply v1.27.0 # 升级命令行 apt-get install kubelet=1.27.0-00 # 重启服务 systemctl daemon-reload systemctl restart kubelet # controlplane升级完毕，标记为可调度 kubectl uncordon controlplane # 需要解除controlplane的taint k drain node01 # 接着ssh登录到node01上，升级node01 apt-get update apt-get install kubeadm=1.27.0-00 kubeadm upgrade node apt-get install kubelet=1.27.0-00 systemctl daemon-reload systemctl restart kubelet # 最后让node01可调度 kubectl uncordon node01 备份恢复 # 查看etcd版本（查看日志或者镜像） kubectl -n kube-system logs etcd-controlplane | grep -i \u0026#39;etcd-version\u0026#39; kubectl -n kube-system describe pod etcd-controlplane | grep Image: # 查看etcd的endpoint kubectl -n kube-system describe pod etcd-controlplane | grep \u0026#39;\\--listen-client-urls\u0026#39; # 查看etcd的cert文件 kubectl -n kube-system describe pod etcd-controlplane | grep \u0026#39;\\--cert-file\u0026#39; # 查看etcd的ca cert文件 kubectl -n kube-system describe pod etcd-controlplane | grep \u0026#39;\\--trusted-ca-file\u0026#39; # 在维护或者对环境做操作前先备份etcd ETCDCTL_API=3 etcdctl --endpoints=https://[127.0.0.1]:2379 \\ --cacert=/etc/kubernetes/pki/etcd/ca.crt \\ --cert=/etc/kubernetes/pki/etcd/server.crt \\ --key=/etc/kubernetes/pki/etcd/server.key \\ snapshot save /opt/snapshot-pre-boot.db # 在维护窗口期间丢失了一些pod或deployment，需要恢复 # 首先将etcd快照恢复到一个新的目录 ETCDCTL_API=3 etcdctl --data-dir /var/lib/etcd-from-backup \\ snapshot restore /opt/snapshot-pre-boot.db # 修改etcd这个staticpod的yaml，指向恢复的data-dir vim /etc/kubernetes/manifests/etcd.yaml # 修改成如下，将etcd-data这个volume指向hostPath: /var/lib/etcd-from-backup # volumes: # - hostPath: # path: /var/lib/etcd-from-backup # type: DirectoryOrCreate # name: etcd-data # 更新yaml后，etcd会自动重建，若etcd一直PENDING，手动删除触发重启 kubectl delete pod -n kube-system etcd-controlplane 多cluster\n# 查看cluster信息 kubectl config view # 或者 kubectl config get-clusters # 查看当前的cluster kubectl config view | grep current-context # 切换cluster kubectl config use-context cluster2 # Type1: Stacked ETCD Topology # 如下命令可以在cluster中查找到etcd的pod kubectl get pods -n kube-system | grep etcd kubectl -n kube-system describe pod etcd-cluster1-controlplane # Type2: External ETCD # cluster内没有etcd的pod，kube-apiserver直接指向一个外部的etcd endpoint ps -aux | grep etcd # 查看ETCD集群的members ETCDCTL_API=3 etcdctl \\ --endpoints=https://127.0.0.1:2379 \\ --cacert=/etc/etcd/pki/ca.pem \\ --cert=/etc/etcd/pki/etcd.pem \\ --key=/etc/etcd/pki/etcd-key.pem \\ member list # 备份Stacked ETCD kubectl config use-context cluster1 kubectl describe pods -n kube-system etcd-cluster1-controlplane | grep advertise-client-urls # --advertise-client-urls=https://10.1.218.16:2379 kubectl describe pods -n kube-system etcd-cluster1-controlplane | grep pki # --cert-file=/etc/kubernetes/pki/etcd/server.crt # --key-file=/etc/kubernetes/pki/etcd/server.key # --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt # --peer-key-file=/etc/kubernetes/pki/etcd/peer.key # --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt # --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt # /etc/kubernetes/pki/etcd from etcd-certs (rw) # Path: /etc/kubernetes/pki/etcd # 登录到etcd pod所在的节点 ETCDCTL_API=3 etcdctl --endpoints=https://10.1.220.8:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key snapshot save /opt/cluster1.db # 恢复External ETCD ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/etcd/pki/ca.pem --cert=/etc/etcd/pki/etcd.pem --key=/etc/etcd/pki/etcd-key.pem snapshot restore /root/cluster2.db --data-dir /var/lib/etcd-data-new systemctl status etcd.service vim /etc/systemd/system/etcd.service systemctl daemon-reload # service的User是etcd，修改文件权限 chown -R etcd:etcd /var/lib/etcd-data-new systemctl restart etcd # 推荐重启控制平面的pod(kube-scheduler, kube-controller-manager, kubelet) 安全Security TLS和证书介绍 Certificate: Data: Version: 3 (0x2) Serial Number: 3478545236123834268 (0x304646764e49d79c) Signature Algorithm: sha256WithRSAEncryption Issuer: CN = kubernetes Validity Not Before: Dec 1 12:24:30 2023 GMT Not After : Nov 30 12:24:30 2024 GMT Subject: CN = kube-apiserver Subject Public Key Info: Public Key Algorithm: rsaEncryption RSA Public-Key: (2048 bit) Modulus: 00:ce:fc:11:8c:a0:2c:83:2d:20:b2:47:83:dc:38: ec:3f:7f:b5:9a:09:c8:a5:7a:16:7a:c7:2d:1d:62: ae:a6:02:7e:d0:be:6a:c6:fd:71:d3:1a:a8:fd:9b: 4d:11:45:f1:21:aa:20:a1:9d:4e:d7:be:f1:22:25: a9:82:52:87:f8:e5:ce:d5:30:e6:1f:99:a5:13:56: e1:38:e3:68:f5:54:de:67:e1:d1:7e:7a:30:12:6c: 48:fd:d9:89:95:07:2a:51:8e:d8:fa:0c:02:79:54: c4:8f:16:42:b1:f4:a9:0e:ac:83:20:f7:d4:eb:c6: 8f:e2:74:2a:03:c7:2a:b6:d9:c4:ea:28:3c:b8:14: 3f:dd:f0:d9:d9:b2:1f:6c:89:93:0b:37:cd:1b:57: 1c:8e:53:fe:d1:40:f5:80:ee:2d:8d:c6:ce:c2:39: 03:d6:c7:aa:61:cb:b5:8d:5c:d6:73:99:ef:c8:6b: 87:ac:0e:3b:59:bb:ec:e2:c5:04:54:4b:ad:d5:da: 48:16:f5:15:0c:bb:29:fe:13:c7:ed:29:dc:bc:01: b5:ac:dd:84:c9:01:e1:fc:40:1e:8f:c5:4a:82:c5: 69:3a:4a:54:b3:22:c6:4b:61:78:54:59:e9:21:ef: a9:5d:cf:a1:b4:c8:f2:18:4e:6a:03:d3:44:3c:be: 9e:d9 Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Key Usage: critical Digital Signature, Key Encipherment X509v3 Extended Key Usage: TLS Web Server Authentication X509v3 Basic Constraints: critical CA:FALSE X509v3 Authority Key Identifier: keyid:27:89:3A:1C:08:4F:74:4E:60:20:1A:44:E0:47:AC:D6:F9:05:93:E5 X509v3 Subject Alternative Name: DNS:controlplane, DNS:kubernetes, DNS:kubernetes.default, DNS:kubernetes.default.svc, DNS:kubernetes.default.svc.cluster.local, IP Address:10.96.0.1, IP Address:192.21.43.6 Signature Algorithm: sha256WithRSAEncryption 8e:75:b2:8e:47:5c:8f:a1:6c:c8:49:da:ef:e0:09:09:6d:cf: dd💿35:f0:e2:df:b2🇩🇪b0:f0:8a:0a:4b:4b:32:7e:46:45: 6b:0b:52:7b:8d:ad:17:67:59:fb:7d:68:86:2b:d1:91:7d:99: c8:ff:d2:17:46:a0:92:ae:3c:55:9a:e4:f5:ee:59:48:a5:2a: 93:4d:8d:02:ba:02:73:f6:07:36:2a:5a:99:4a:33:52:ce:36: ea:44:29:19:cb:d1:6f:4a:db:1f:d9:47:7e:8c:e7:2b:6a:7f: 11:43:57:f1:f6:7a:19:c1:b6:ff:81:37:71:3a:f6:14:d5:63: ab:9d:31:f7:bc:4c:0a:19:fb:36:d7:84:f2:1c:fd:c5:fc:8d: 83:b0:8f:ec:1b:9c:ae:57:4f:f1:96:f5:45:f5:c5:4e:8f:a0: ac:04:97:fa:87:2c:0d:5c:83:a9:d8:94:2f:d5:64:8d:ec:13: c6:b4:93:d2:29:f9:87:23:a0:90:7b:68:8c:d6:5c:fd:a3:97: 96:68:a7:e0:2a:22:8b:a9:d4:01:fc:f5:06:39:7f:63:6b:33: 8e:3f:6b:23:18:9c:c8:7c:0f:0c:c1:4c:73:3f:a3:c2:d7:ea: cb:2a:a8:5d:86:a1:0d:4a:5e:12:51:ba:6c:1e:1c:20:75:d6: 5f:62:5f:d3 证书查看 # 查看kube-api的cert文件 cat /etc/kubernetes/manifests/kube-apiserver.yaml | grep tls-cert-file # 查看certfile详情 openssl x509 -in ./apiserver.crt -text -noout # kube-api故障，排查问题 # 列出所有的容器 crictl ps -a crictl ps -a | grep kube-api crictl logs \u0026lt;container-id\u0026gt; CertificateSigningRequest # 有签名文件akshay.csr，先base64编码 cat akshay.csr | base64 -w 0 # 按照如下yaml，执行k apply创建csr # 查看csr，刚创建的状态是Pending k get certificatesigningrequests k get csr # 授权，授权后状态是Approved,Issued k certificate approve \u0026lt;csr-name\u0026gt; # 拒绝 csr kubectl certificate deny \u0026lt;csr-name\u0026gt; # 删除csr k delete csr \u0026lt;csr-name\u0026gt; # 查看csr详情 k get csr \u0026lt;csr-name\u0026gt; -o yaml --- apiVersion: certificates.k8s.io/v1 kind: CertificateSigningRequest metadata: name: akshay spec: groups: - system:authenticated request: \u0026lt;Paste the base64 encoded value of the CSR file\u0026gt; signerName: kubernetes.io/kube-apiserver-client usages: - client auth Kube Config Client-certificate（客户端证书）和client-key（客户端密钥）是在SSL/TLS通信中用于客户端身份验证的两个重要组件。\n客户端证书是一种数字证书，用于验证客户端的身份。它包含了客户端的公钥以及与之相关联的身份信息，通常由证书颁发机构（CA）签发。客户端证书可以被服务器用来验证客户端的身份，确保通信双方的合法性和安全性。\n客户端密钥是客户端证书中包含的私钥部分。私钥是一种加密密钥，用于对数据进行签名和解密。客户端使用私钥对数据进行签名，服务器使用客户端证书中的公钥对签名进行验证，从而确认客户端的身份。\n在SSL/TLS通信中，客户端证书和客户端密钥通常一起使用，以确保通信的安全性和完整性。客户端证书用于验证客户端的身份，客户端密钥用于生成数字签名以进行身份验证和数据加密。\n这三个文件名后缀分别代表以下含义：\n.crt：代表证书文件，包含了公钥和证书相关信息。 .csr：代表证书签名请求文件，包含了公钥和一些个人信息，用于向证书颁发机构申请签名。 .key：代表密钥文件，包含了与证书相关的私钥信息。 这三个文件之间的关联性在于：\n证书签名请求文件（.csr）是用来向证书颁发机构申请签名的，其中包含了公钥和一些个人信息。 证书文件（.crt）是由证书颁发机构签名后的证书，包含了公钥和证书相关信息。 密钥文件（.key）包含了与证书相关的私钥信息，用于与证书进行配对，以进行加密和解密操作。 这三个文件通常一起使用，以建立安全的通信连接和进行加密操作。\n# config默认文件路径 ls ~/.kube/config # 查看所有cluster k config view # 指定config文件 kubectl config view --kubeconfig \u0026lt;config-file-path\u0026gt; # 查看config中的current-context kubectl config current-context --kubeconfig \u0026lt;config-file-path\u0026gt; # 切换context kubectl config --kubeconfig=\u0026lt;config-file-path\u0026gt; use-context \u0026lt;new-context-name\u0026gt; # 将自定义的config文件替换~/.kube/config文件，即可设置为默认的config RBAC # 查看kube-api的authorization-mode kubectl describe pod kube-apiserver-controlplane -n kube-system | grep mode # 列出roles k get roles # 列出所有namespace的roles k get roles.rbac.authorization.k8s.io --all-namespaces --no-headers # 查看roles详情 k describe roles \u0026lt;role-name\u0026gt; # 列出rolebinding k get rolebindings --all-namespaces # 查看rolebinding详情 k describe rolebindings \u0026lt;rolebinding-name\u0026gt; -n kube-system # 查看config k config view # 指定config中的用户执行kubectl命令 k get pods --as \u0026lt;user-name\u0026gt; # 上述命令执行报错，用户无权限，需要创建role和rolebinding # 创建一个role，名为developer k create role developer --namespace=default --verb=list,create,delete --resource=pod --dry-run=client -o yaml # 创建rolebinding，将deveploer绑定到用户dev-user上 kubectl create rolebinding dev-user-binding --namespace=default --role=developer --user=dev-user # 编辑role的权限，编辑后无需重新binding k edit role \u0026lt;role-name\u0026gt; Cluster Role # 列出clusterrole k get clusterrole # 列出clusterrolebinding k get clusterrolebindings # 查看环境中cluster数量 k get clusterrole --no-headers | wc -l # 查看clusterrolebinding数量 k get clusterrolebindings.rbac.authorization.k8s.io --no-headers | wc -l # 查看所有与namspace无关的resource k api-resources --namespaced=false # 查看clusterrole详情 k describe clusterrole \u0026lt;clusterrole-name\u0026gt; # 查看clusterrolebinding详情 k describe clusterrolebindings.rbac.authorization.k8s.io \u0026lt;name\u0026gt; # 创建一个管理node的clusterrole k create clusterrole nodeadmin --resource=nodes --verb=get,watch,list,create,delete --dry-run=client -o yaml # 创建clusterrolebinding k create clusterrolebinding michella-binding --clusterrole nodeadmin --user=michelle --dry-run=client -o yaml # 测试是否有执行权限 kubectl auth can-i list nodes --as michelle # 需要给michelle用户增加权限，新建存储相关的clusterrole和binding k create clusterrole storage-admin --resource=persistentvolumes,storageclasses --verb=get,watch,list,create,delete --dry-run=client -o yaml k create clusterrolebinding michelle-storage-admin --clusterrole=storage-admin --user=michelle --dry-run=client -o yaml Service Account # 获取所有service account k get serviceaccounts k get sa # 查看service account详情 k describe sa \u0026lt;sa-name\u0026gt; # 查看pod的serviceaccount k get po web-dashboard-97c9c59f6-vmw8g -o yaml | grep -i account # 创建一个serviceaccount k create serviceaccount dashboard-sa # 用如下yaml为serviceaccount创建role和rolebinding赋予权限 # 为dashboard-sa这个service account创建token kubectl create token dashboard-sa # 编辑deployment的serviceaccount（默认是default） k edit deployments.apps web-dashboard # 或者 k set serviceaccount deploy/web-dashboard dashboard-sa --- kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: namespace: default name: pod-reader rules: - apiGroups: - \u0026#39;\u0026#39; resources: - pods verbs: - get - watch - list --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: read-pods namespace: default subjects: - kind: ServiceAccount name: dashboard-sa # Name is case sensitive namespace: default roleRef: kind: Role #this must be Role or ClusterRole name: pod-reader # this must match the name of the Role or ClusterRole you wish to bind to apiGroup: rbac.authorization.k8s.io Image Secret # 应用使用私有仓库的镜像 k create secret --help # 创建docker-registry类型的密钥 k create secret docker-registry private-reg-cred --docker-username=dock_user --docker-password=dock_passwd --docker-server=myprivateregistry.com:5000 --docker-email=dock_user@myprivateregistry.com apiVersion: apps/v1 kind: Deployment metadata: annotations: deployment.kubernetes.io/revision: \u0026#34;3\u0026#34; creationTimestamp: \u0026#34;2023-12-02T13:18:12Z\u0026#34; generation: 3 labels: app: web name: web namespace: default resourceVersion: \u0026#34;2598\u0026#34; uid: b375109f-b184-4cb1-9a80-425f1a940e3d spec: progressDeadlineSeconds: 600 replicas: 2 revisionHistoryLimit: 10 selector: matchLabels: app: web strategy: rollingUpdate: maxSurge: 25% maxUnavailable: 25% type: RollingUpdate template: metadata: creationTimestamp: null labels: app: web spec: containers: - image: myprivateregistry.com:5000/nginx:alpine imagePullPolicy: IfNotPresent name: nginx resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File dnsPolicy: ClusterFirst imagePullSecrets: - name: private-reg-cred restartPolicy: Always schedulerName: default-scheduler securityContext: {} terminationGracePeriodSeconds: 30 Security Context # 执行whoami查看容器内部的执行用户 kubectl exec \u0026lt;pod-name\u0026gt; -- whoami # 强制删除pod kubectl delete pod \u0026lt;pod-name\u0026gt; --force # 更新security context必须先删除再新建pod，可以用k replace命令 # 编辑如下yaml，容器内用user ID 1010执行sleep命令 --- apiVersion: v1 kind: Pod metadata: name: ubuntu-sleeper namespace: default spec: securityContext: runAsUser: 1010 containers: - command: - sleep - \u0026#34;4800\u0026#34; image: ubuntu name: ubuntu-sleeper securityContext: capabilities: add: [\u0026#34;SYS_TIME\u0026#34;] 不同level的context\napiVersion: v1 kind: Pod metadata: name: multi-pod spec: securityContext: runAsUser: 1001 containers: - image: ubuntu name: web command: [\u0026#34;sleep\u0026#34;, \u0026#34;5000\u0026#34;] securityContext: runAsUser: 1002 - image: ubuntu name: sidecar command: [\u0026#34;sleep\u0026#34;, \u0026#34;5000\u0026#34;] 编辑如下yaml，为容器增加SYS_TIME的能力\n--- apiVersion: v1 kind: Pod metadata: name: ubuntu-sleeper namespace: default spec: containers: - command: - sleep - \u0026#34;4800\u0026#34; image: ubuntu name: ubuntu-sleeper securityContext: capabilities: add: [\u0026#34;SYS_TIME\u0026#34;] Network Policy # 列出networkpolicy k get networkpolicies.networking.k8s.io k get netpol # 查看netpol详情 k describe netpol \u0026lt;netpol-name\u0026gt; # 使用netpol中对应的selector查询应用的pod k get pods --selector name=payroll # 或者 k get po --show-labels # 创建network policy使得Internal只能访问mysql和payroll # 注意同时放开了53端口，因为需要通过53端口访问DNS # 使用如下yaml实现 apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: internal-policy namespace: default spec: podSelector: matchLabels: name: internal policyTypes: - Egress - Ingress ingress: - {} egress: - to: - podSelector: matchLabels: name: mysql ports: - protocol: TCP port: 3306 - to: - podSelector: matchLabels: name: payroll ports: - protocol: TCP port: 8080 - ports: - port: 53 protocol: UDP - port: 53 protocol: TCP 存储Storage Persistent Volume Claim # 查看pod内的日志 kubectl exec \u0026lt;pod-name\u0026gt; -- cat /log/app.log # 为pod添加持久化的日志卷 kubectl get po webapp -o yaml \u0026gt; webapp.yaml # 配置hostpath类型的volume apiVersion: v1 kind: Pod metadata: name: webapp spec: containers: - name: event-simulator image: kodekloud/event-simulator env: - name: LOG_HANDLERS value: file volumeMounts: - mountPath: /log name: log-volume volumes: - name: log-volume hostPath: # directory location on host path: /var/log/webapp # this field is optional type: Directory 用如下yaml创建Persistent Volume\napiVersion: v1 kind: PersistentVolume metadata: name: pv-log spec: persistentVolumeReclaimPolicy: Retain accessModes: - ReadWriteMany capacity: storage: 100Mi hostPath: path: /pv/log 创建Persistent Volume Claim\nkind: PersistentVolumeClaim apiVersion: v1 metadata: name: claim-log-1 spec: accessModes: - ReadWriteOnce resources: requests: storage: 50Mi # 列出persistent volume k get persistentvolume k get pv # 列出persistent volume claim k get pvc k get persistentvolumeclaims # 列出多种资源 k get pv,pvc # pod中使用pvc apiVersion: v1 kind: Pod metadata: name: webapp spec: containers: - name: event-simulator image: kodekloud/event-simulator env: - name: LOG_HANDLERS value: file volumeMounts: - mountPath: /log name: log-volume volumes: - name: log-volume persistentVolumeClaim: claimName: claim-log-1 被pod使用中的PVC无法直接删除，需要等到pod删除后才能删掉PVC\nStorage Class # 列出storage class k get storageclasses.storage.k8s.io k get sc # 查看sc详情 k describe sc \u0026lt;sc-name\u0026gt; # 创建storage class，使用如下yaml --- apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: delayed-volume-sc provisioner: kubernetes.io/no-provisioner volumeBindingMode: WaitForFirstConsumer 注意WaitForFirstConsume模式的storage，pvc绑定pv时，不会立刻申请存储，而是处于PENDING状态，等到使用pvc的pod被调度时，才会实际上申请存储\n如下为一个使用pvc的yaml\n--- apiVersion: v1 kind: Pod metadata: name: nginx labels: name: nginx spec: containers: - name: nginx image: nginx:alpine volumeMounts: - name: local-persistent-storage mountPath: /var/www/html volumes: - name: local-persistent-storage persistentVolumeClaim: claimName: local-pvc 网络Networking 网络基本命令 # 查看node的internal ip地址 k get nodes -o wide # 查看ip地址对应的网口 ip a | grep \u0026lt;ip\u0026gt; # 查看网口的mac地址/状态 ip link show \u0026lt;interface-name\u0026gt; # 查看Containerd创建的网口(Container Network Interface) ip link | grep cni # 查看路由表 ip route list # 查看默认路由 # 默认路由：默认路由是指当目标网络不在路由表中时，数据包将被发送到的默认网关 ip route show default # 查看kube服务监听的port netstat -ntpl | grep kube # 查看etcd的tcp监听服务 netstat -ntpl | grep etcd # 查看etcd的所有链接（包含client） netstat -anp | grep etcd CNI # 查看kubelet的container runtime endpoint ps aux | grep kubelet | grep runtime # 查看cni的插件 ls /opt/cni/bin/ # 查看当前cluster配置的cni插件 ls /etc/cni/net.d/ 部署weave net # 部署weave-net k apply -f weave-daemonset-k8s.yaml # serviceaccount/weave-net created # clusterrole.rbac.authorization.k8s.io/weave-net created # clusterrolebinding.rbac.authorization.k8s.io/weave-net created # role.rbac.authorization.k8s.io/weave-net created # rolebinding.rbac.authorization.k8s.io/weave-net created # daemonset.apps/weave-net created apiVersion: v1 kind: List items: - apiVersion: v1 kind: ServiceAccount metadata: name: weave-net labels: name: weave-net namespace: kube-system - apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: weave-net labels: name: weave-net rules: - apiGroups: - \u0026#39;\u0026#39; resources: - pods - namespaces - nodes verbs: - get - list - watch - apiGroups: - extensions resources: - networkpolicies verbs: - get - list - watch - apiGroups: - \u0026#39;networking.k8s.io\u0026#39; resources: - networkpolicies verbs: - get - list - watch - apiGroups: - \u0026#39;\u0026#39; resources: - nodes/status verbs: - patch - update - apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: weave-net labels: name: weave-net roleRef: kind: ClusterRole name: weave-net apiGroup: rbac.authorization.k8s.io subjects: - kind: ServiceAccount name: weave-net namespace: kube-system - apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: name: weave-net namespace: kube-system labels: name: weave-net rules: - apiGroups: - \u0026#39;\u0026#39; resources: - configmaps resourceNames: - weave-net verbs: - get - update - apiGroups: - \u0026#39;\u0026#39; resources: - configmaps verbs: - create - apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: weave-net namespace: kube-system labels: name: weave-net roleRef: kind: Role name: weave-net apiGroup: rbac.authorization.k8s.io subjects: - kind: ServiceAccount name: weave-net namespace: kube-system - apiVersion: apps/v1 kind: DaemonSet metadata: name: weave-net labels: name: weave-net namespace: kube-system spec: # Wait 5 seconds to let pod connect before rolling next pod selector: matchLabels: name: weave-net minReadySeconds: 5 template: metadata: labels: name: weave-net spec: initContainers: - name: weave-init image: \u0026#39;weaveworks/weave-kube:2.8.1\u0026#39; command: - /home/weave/init.sh env: securityContext: privileged: true volumeMounts: - name: cni-bin mountPath: /host/opt - name: cni-bin2 mountPath: /host/home - name: cni-conf mountPath: /host/etc - name: lib-modules mountPath: /lib/modules - name: xtables-lock mountPath: /run/xtables.lock readOnly: false containers: - name: weave command: - /home/weave/launch.sh env: - name: IPALLOC_RANGE value: 10.32.1.0/24 - name: INIT_CONTAINER value: \u0026#34;true\u0026#34; - name: HOSTNAME valueFrom: fieldRef: apiVersion: v1 fieldPath: spec.nodeName image: \u0026#39;weaveworks/weave-kube:2.8.1\u0026#39; readinessProbe: httpGet: host: 127.0.0.1 path: /status port: 6784 resources: requests: cpu: 50m securityContext: privileged: true volumeMounts: - name: weavedb mountPath: /weavedb - name: dbus mountPath: /host/var/lib/dbus readOnly: true - mountPath: /host/etc/machine-id name: cni-machine-id readOnly: true - name: xtables-lock mountPath: /run/xtables.lock readOnly: false - name: weave-npc env: - name: HOSTNAME valueFrom: fieldRef: apiVersion: v1 fieldPath: spec.nodeName image: \u0026#39;weaveworks/weave-npc:2.8.1\u0026#39; #npc-args resources: requests: cpu: 50m securityContext: privileged: true volumeMounts: - name: xtables-lock mountPath: /run/xtables.lock readOnly: false hostNetwork: true dnsPolicy: ClusterFirstWithHostNet hostPID: false restartPolicy: Always securityContext: seLinuxOptions: {} serviceAccountName: weave-net tolerations: - effect: NoSchedule operator: Exists - effect: NoExecute operator: Exists volumes: - name: weavedb hostPath: path: /var/lib/weave - name: cni-bin hostPath: path: /opt - name: cni-bin2 hostPath: path: /home - name: cni-conf hostPath: path: /etc - name: cni-machine-id hostPath: path: /etc/machine-id - name: dbus hostPath: path: /var/lib/dbus - name: lib-modules hostPath: path: /lib/modules - name: xtables-lock hostPath: path: /run/xtables.lock type: FileOrCreate priorityClassName: system-node-critical updateStrategy: type: RollingUpdate # 查看weave的agent/peer k get pods --all-namespaces | grep weave # weave pod在每个节点上存在一个（包括master和work node） # 查看weave创建的网口 ip link | grep weave # 查看weave网口的ip地址段 ip addr show weave ip route list # 查看work node上weave net的默认网关，首先登录到work node ip route | gre weave Service Networking # 查看整个cluster的网络范围 ip addr | grep eth0 # 215: eth0@if216: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1450 qdisc noqueue state UP group default # inet 192.4.210.9/24 brd 192.4.210.255 scope global eth0 ipcalc -b 192.4.210.9 # 计算的cluster的地址范围192.4.210.0/24 # 查看cluster中pod的网络地址范围 # 若pod使用weave网络，使用如下查询方式 k logs -n kube-system weave-net-8v8hr | grep ipalloc-range # pod地址范围是10.244.0.0/16 # 查看service的网络地址范围 cat /etc/kubernetes/manifests/kube-apiserver.yaml | grep cluster-ip-range # --service-cluster-ip-range=10.96.0.0/12 # 查看kube-proxy的类型 k logs -n kube-system \u0026lt;kube-proxy-pod-name\u0026gt; CoreDNS # 查看cluster的DNS解决方案 k get pods -n kube-system | grep dns # 查看dns service k get service --all-namespaces | grep dns # 查看coredns的配置文件 k -n kube-system describe deployments.apps coredns | grep -A2 Args # 查看Corefile的注入方式 k get po -n kube-system coredns-5d78c9869d-5sxxz -o yaml k describe cm -n kube-system coredns # service的DNS规则如下：service.namespace.svc.cluster.local # web-service.payroll.svc.cluster.local # 查看DNS结果 kubectl exec -it hr -- nslookup mysql.payroll \u0026gt; /root/CKA/nslookup.out Ingress # 查看ingress kubectl get all -A | grep -i ingress k get ingress -A # 查看ingress详情 kubectl describe ingress \u0026lt;ingress-name\u0026gt; # 编辑ingress修改rules kubectl edit ingress # 创建ingress，注意如下命令缺少annotation，创建的yaml添加annotation才能正常工作 # pathType: Exact k create ingress -n critical-space test-ingress --rule=/pay=pay-service:8282 --dry-run=client -o yaml # pathType: Prefix k create ingress -n critical-space test-ingress --rule=/pay*=pay-service:8282 --dry-run=client -o yaml apiVersion: networking.k8s.io/v1 kind: Ingress metadata: annotations: nginx.ingress.kubernetes.io/rewrite-target: / nginx.ingress.kubernetes.io/ssl-redirect: \u0026#34;false\u0026#34; name: ingress-wear-watch namespace: app-space spec: rules: - http: paths: - backend: service: name: wear-service port: number: 8080 path: /wear pathType: Prefix - backend: service: name: video-service port: number: 8080 path: /stream pathType: Prefix 如下为cluster创建ingress controller\n# 创建ingress独立的namespace(便于隔离) k create namespace ingress-nginx # 创建configmap kubectl create configmap ingress-nginx-controller --namespace ingress-nginx # 创建service account k create sa ingress-nginx -n ingress-nginx k create sa ingress-nginx-admission -n ingress-nginx # 创建role，rolebinding，clusterrole，clusterrolebinding # 略 # ingress controller 的yaml如下 apiVersion: apps/v1 kind: Deployment metadata: labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/managed-by: Helm app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.1.2 helm.sh/chart: ingress-nginx-4.0.18 name: ingress-nginx-controller namespace: ingress-nginx spec: replicas: 1 minReadySeconds: 0 revisionHistoryLimit: 10 selector: matchLabels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx template: metadata: labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx spec: containers: - args: - /nginx-ingress-controller - --publish-service=$(POD_NAMESPACE)/ingress-nginx-controller - --election-id=ingress-controller-leader - --watch-ingress-without-class=true - --default-backend-service=app-space/default-http-backend - --controller-class=k8s.io/ingress-nginx - --ingress-class=nginx - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller - --validating-webhook=:8443 - --validating-webhook-certificate=/usr/local/certificates/cert - --validating-webhook-key=/usr/local/certificates/key env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: LD_PRELOAD value: /usr/local/lib/libmimalloc.so image: registry.k8s.io/ingress-nginx/controller:v1.1.2@sha256:28b11ce69e57843de44e3db6413e98d09de0f6688e33d4bd384002a44f78405c imagePullPolicy: IfNotPresent lifecycle: preStop: exec: command: - /wait-shutdown livenessProbe: failureThreshold: 5 httpGet: path: /healthz port: 10254 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 name: controller ports: - name: http containerPort: 80 protocol: TCP - containerPort: 443 name: https protocol: TCP - containerPort: 8443 name: webhook protocol: TCP readinessProbe: failureThreshold: 3 httpGet: path: /healthz port: 10254 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 1 resources: requests: cpu: 100m memory: 90Mi securityContext: allowPrivilegeEscalation: true capabilities: add: - NET_BIND_SERVICE drop: - ALL runAsUser: 101 volumeMounts: - mountPath: /usr/local/certificates/ name: webhook-cert readOnly: true dnsPolicy: ClusterFirst nodeSelector: kubernetes.io/os: linux serviceAccountName: ingress-nginx terminationGracePeriodSeconds: 300 volumes: - name: webhook-cert secret: secretName: ingress-nginx-admission --- apiVersion: v1 kind: Service metadata: creationTimestamp: null labels: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/managed-by: Helm app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx app.kubernetes.io/version: 1.1.2 helm.sh/chart: ingress-nginx-4.0.18 name: ingress-nginx-controller namespace: ingress-nginx spec: ports: - port: 80 protocol: TCP targetPort: 80 nodePort: 30080 selector: app.kubernetes.io/component: controller app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/name: ingress-nginx type: NodePort # 接着创建ingress，ingress资源是在namespace范围下的，所以ingress要和service同一个namespace k create ingress -n app-space --rule /wear*=wear-service:8080 --rule /watch*=video-service:8080 --annotation nginx.ingress.kubernetes.io/rewrite-target=/ --annotation nginx.ingress.kubernetes.io/ssl-redirect=false test-ingress --dry-run=client -o yaml apiVersion: networking.k8s.io/v1 kind: Ingress metadata: annotations: nginx.ingress.kubernetes.io/rewrite-target: / nginx.ingress.kubernetes.io/ssl-redirect: \u0026#34;false\u0026#34; creationTimestamp: null name: test-ingress namespace: app-space spec: rules: - http: paths: - backend: service: name: wear-service port: number: 8080 path: /wear pathType: Prefix - backend: service: name: video-service port: number: 8080 path: /watch pathType: Prefix status: loadBalancer: {} 部署K8S # 在每个节点上执行如下安装操作 # step1: 修改网络策略 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system # step2: 安装包 sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl sudo mkdir -m 755 /etc/apt/keyrings curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.27/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg echo \u0026#39;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.27/deb/ /\u0026#39; | sudo tee /etc/apt/sources.list.d/kubernetes.list sudo apt-get update # To see the new version labels sudo apt-cache madison kubeadm sudo apt-get install -y kubelet=1.27.0-2.1 kubeadm=1.27.0-2.1 kubectl=1.27.0-2.1 sudo apt-mark hold kubelet kubeadm kubectl Installing kubeadm | Kubernetes\n# step3: 查看kubelet版本 kubelet --version # step4: 使用kubeadm启动kubernetes集群 # step4-1: 启动controlplane # 查看eth0网口ip地址 ifconfig eth0 # 假设上一步eth0地址是192.17.132.9 kubeadm init --apiserver-cert-extra-sans=controlplane --apiserver-advertise-address 192.17.132.9 --pod-network-cidr=10.244.0.0/16 # 或者执行如下命令 IP_ADDR=$(ip addr show eth0 | grep -oP \u0026#39;(?\u0026lt;=inet\\s)\\d+(\\.\\d+){3}\u0026#39;) kubeadm init --apiserver-cert-extra-sans=controlplane --apiserver-advertise-address $IP_ADDR --pod-network-cidr=10.244.0.0/16 # 执行完毕后，配置kubeconfig mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.17.132.9:6443 --token b2134k.u3alyaj4iwkjhm6w \\ --discovery-token-ca-cert-hash sha256:23471ecdb6d52790d13880d333fa0a667cc249297ed26faa7b75171b84157c46 # Step 4-2: 将node01加入到cluster # kubeadm生成join token kubeadm token generate # 或 kubeadm token create --print-join-command # 生成如下命令，ssh登录到node01上执行 kubeadm join 192.17.132.9:6443 --token 2uh5xs.qoh26441ba0l4du4 --discovery-token-ca-cert-hash sha256:23471ecdb6d52790d13880d333fa0a667cc249297ed26faa7b75171b84157c46 # Step5: 安装Flannel网络 # 下载kube-flannel.yml curl -LO https://raw.githubusercontent.com/flannel-io/flannel/v0.20.2/Documentation/kube-flannel.yml # 编辑kube-flannel.yml # 定位到 args: - --ip-masq - --kube-subnet-mgr # 添加参数 - --iface=eth0 kubectl apply -f kube-flannel.yml # 网络创建成功后，node状态变成Ready controlplane ~ ➜ kubectl get nodes NAME STATUS ROLES AGE VERSION controlplane Ready control-plane 15m v1.27.0 node01 Ready \u0026lt;none\u0026gt; 15m v1.27.0 Trouble Shooting Application Failure：\ndns解析的service名称不对 service中selector没有选中工作的pod service的targetPort配置错误 db的用户名密码错误 service暴露的node端口错误 Control Plane Failure：\nkube-scheduler故障，修改/etc/kubernetes/manifests/下的yaml scale无响应，查看kube-controller故障 Work Node Failure:\n计算节点containerd服务或者kubelet服务停掉了，用systemctl命令手动启动 /var/lib/kubelet/config.yaml配置文件有问题 /etc/kubernetes/kubelet.conf中kube-api的端口配置 Network Failure:\n缺少网络插件Creating a cluster with kubeadm | Kubernetes\ncurl -L https://github.com/weaveworks/weave/releases/download/latest_release/weave-daemonset-k8s-1.11.yaml | kubectl apply -f -\n查看所有kube-proxy是否运行正常，查看关联的configMap是否正确，修改daemonset\nLighting Lab # json path定义输出 kubectl get deployments.apps -n admin2406 -o custom-columns=DEPLOYMENT:.metadata.name,CONTAINER_IMAGE:.spec.template.spec.containers[*].image,READY_REPLICAS:.status.readyReplicas,NAMESPACE:.metadata.namespace --sort-by=.metadata.name 参考 Kubectl Command Cheat Sheet - Learn Essential Kubernetes Commands\nKubectl Cheatsheet | Free Cheatsheet\nLF 认证考试攻略｜认证考试流程全介绍\u0026ndash;购买、注册及预约考试篇（建议收藏）-Linux Foundation开源软件学园\nCKA (Certified Kubernetes Administrator)\nKiller Shell - Exam Simulators\nLinux Foundation Certification Exam: Candidate Handbook (using PSI BRIDGE Proctoring platform) - T\u0026amp;C DOCS (Candidate Facing Resources)\n考试入口Certified Kubernetes Administrator China Exam (CKA-CN) - Exam | The Linux Foundation\nCKA考试心得分享 - 木二 - 博客园\nCKA考试经验总结 - 简书\nIntroduction to YAML - KodeKloud\n互联网最全cka真题解析-2022.9.9 - 知乎\n2023年CKA考试真题及注意事项 - jiayou111 - 博客园\nKubernetes CKA真题解析-20200402真题_check to see how many nodes are ready (not includi-CSDN博客\n","permalink":"https://blog.niuhemoon.win/posts/tech/cka-study-record/","summary":"\u003cp\u003e记录一下CKA考试的备考过程\u003c/p\u003e","title":"CKA备考笔记"},{"content":" 参加了一个LLM的应用比赛，赛题目标是编码优化prompt提高text2sql推理的正确率 给定的资源如下：\n所有数据库schema 一个100条记录的训练集（其实是基于spider数据集做了修改） 三个LLM的接口（Baichuan13B/LLama2/Code-LLama） text2sql正确率提高到了60%左右，在此记录一些心得\nprompt的组成包四个元素：\nInstruction（指令，必须） Context（上下文信息，可选） Input Data（输入，需要处理的数据，可选） Output Indicator（输出指引，规定输出的类型或格式，可选） 一个面向复杂任务的prompt的一般都包含Instruction，Context，Input Data，Output Indicator。 所以面向大语言模型的开发应用过程就是如下公式：\nLMM(Instruction + Context + Input Data + Output Indicator) = Output\n题目要求根据自然语言的Question，给出对应数据库的SQL Query语句\n做Prompt优化的核心步骤有：\n利用LLM的翻译能力将输入的中文Question转换成英文 解析数据库schema，格式化后加入prompt，其中不同table间的外键很关键，column的字段类型可有可无 few shot，给出数据库关联的三个案例（和问题数据库关联的案例有明显提升效果） chain of thought，指导LLM如何思考，注意构造sql语句的哪些步骤 诱导慢思考（Let\u0026rsquo;s think step by step） 多LLM交叉验证和单LLM self consistency，即多问几次，投票选择出现次数多的sql语句 后处理校验sql语句的正确性 当然更好的办法是对LLM进行预训练，Prompt优化或者LLM agent的提升效果有限\n","permalink":"https://blog.niuhemoon.win/posts/tech/text2sql-prompt-engineering/","summary":"参加了一个LLM的应用比赛，赛题目标是编码优化prompt提高text2sql推理的正确率 给定的资源如下： 所有数据库schema 一个100条记录的训练集（其实是基于spider数据集做了修改） 三个LLM的接口（Baichuan13B/LLama2/Code-LLama） text2","title":"text2sql Prompt 调优笔记"},{"content":"介绍 Xpath全称XML Path Language，功能上使用类似路径的语法来识别和导航XML文档中的节点，同时支持HTML语言。XPath是W3C的推荐标准\nNodes Xpath中有七种节点：\nelement attribute text namespace processing-instruction comment root nodes 句法 选中Nodes 表达式 描述 nodename 选中所有同名节点 / 从root node开始选择 // 从当前节点开始选择，不管层级关系 . 选择当前节点 .. 选择当前节点的父节点 @ 选择属性 举例如下\n表达式 效果 bookstore Selects all nodes with the name \u0026ldquo;bookstore\u0026rdquo; /bookstore Selects the root element bookstore bookstore/book Selects all book elements that are children of bookstore //book Selects all book elements no matter where they are in the document bookstore//book Selects all book elements that are descendant of the bookstore element, no matter where they are under the bookstore element //@lang Selects all attributes that are named lang Predicates 谓词 Path Expression Result /bookstore/book[1] Selects the first book element that is the child of the bookstore element. /bookstore/book[last()] Selects the last book element that is the child of the bookstore element /bookstore/book[last()-1] Selects the last but one book element that is the child of the bookstore element /bookstore/book[position()\u0026lt;3] Selects the first two book elements that are children of the bookstore element //title[@lang] Selects all the title elements that have an attribute named lang //title[@lang=\u0026lsquo;en\u0026rsquo;] Selects all the title elements that have a \u0026ldquo;lang\u0026rdquo; attribute with a value of \u0026ldquo;en\u0026rdquo; /bookstore/book[price\u0026gt;35.00] Selects all the book elements of the bookstore element that have a price element with a value greater than 35.00 /bookstore/book[price\u0026gt;35.00]/title Selects all the title elements of the book elements of the bookstore element that have a price element with a value greater than 35.00 选择未知节点 Wildcard Description * Matches any element node @* Matches any attribute node node() Matches any node of any kind Path Expression Result /bookstore/* Selects all the child element nodes of the bookstore element //* Selects all elements in the document //title[@*] Selects all title elements which have at least one attribute of any kind 选择多条路径 通过使用|或操作符，可以选择多条路径\nPath Expression Result //book/title | //book/price Selects all the title AND price elements of all book elements //title | //price Selects all the title AND price elements in the document /bookstore/book/title | //price Selects all the title elements of the book element of the bookstore element AND all the price elements in the document Axes Axes(轴)用来表示和当前节点之间的关系，用于定位树上当前节点的关联节点\nAxisName Result ancestor Selects all ancestors (parent, grandparent, etc.) of the current node ancestor-or-self Selects all ancestors (parent, grandparent, etc.) of the current node and the current node itself attribute Selects all attributes of the current node child Selects all children of the current node descendant Selects all descendants (children, grandchildren, etc.) of the current node descendant-or-self Selects all descendants (children, grandchildren, etc.) of the current node and the current node itself following Selects everything in the document after the closing tag of the current node following-sibling Selects all siblings after the current node namespace Selects all namespace nodes of the current node parent Selects the parent of the current node preceding Selects all nodes that appear before the current node in the document, except ancestors, attribute nodes and namespace nodes preceding-sibling Selects all siblings before the current node self Selects the current node 路径定位表达式 绝对路径以/开头 定位的语法如下：axisname::nodetest[predicate] Axisname轴名称 Nodetest节点选择 Predicate 谓词细化选择 Example Result child::book Selects all book nodes that are children of the current node attribute::lang Selects the lang attribute of the current node child::* Selects all element children of the current node attribute::* Selects all attributes of the current node child::text() Selects all text node children of the current node child::node() Selects all children of the current node descendant::book Selects all book descendants of the current node ancestor::book Selects all book ancestors of the current node ancestor-or-self::book Selects all book ancestors of the current node - and the current as well if it is a book node child::*/child::price Selects all price grandchildren of the current node 操作符 Xpath操作符可以返回如下类型的值：\nnode-set string number boolean Operator Description Example | Computes two node-sets //book | //cd + Addition 6 + 4 - Subtraction 6 - 4 * Multiplication 6 * 4 div Division 8 div 4 = Equal price=9.80 != Not equal price!=9.80 \u0026lt; Less than price\u0026lt;9.80 \u0026lt;= Less than or equal to price\u0026lt;=9.80 \u0026gt; Greater than price\u0026gt;9.80 \u0026gt;= Greater than or equal to price\u0026gt;=9.80 or or price=9.80 or price=9.70 and and price\u0026gt;9.00 and price\u0026lt;9.90 mod Modulus (division remainder) 5 mod 2 Functions函数 函数 作用 name() 获取node的名称//[starts-with(name(), \u0026lsquo;h\u0026rsquo;)] text() 获取node的文本//button[text()=\u0026ldquo;Submit\u0026rdquo;] lang(str) 获取字符串的语言 count() node计数//table[count(tr)=1] position() 计算位置//ol/li[position()=2] number() boolean() not() 取反button[not(starts-with(text(),\u0026ldquo;Submit\u0026rdquo;))] contains() 字符串包含font[contains(@class,\u0026ldquo;head\u0026rdquo;)] starts-with() font[starts-with(@class,\u0026ldquo;head\u0026rdquo;)] ends-with() font[ends-with(@class,\u0026ldquo;head\u0026rdquo;)] concat(x, y) substring(str, start, len) 浏览器使用示例 chrome浏览器有两种使用方法：\nDevtool-Elements, CTRL+F Devtool-Console, $x(xpath_syntax) 案例 解释 /bookstore/book/title 选择所有书的title /bookstore/book[1]/title 选择第一本书的title /bookstore/book/price[text()] 选择所有书的价格 /bookstore/book[price\u0026gt;35]/price 选择价格大于35的price节点 /bookstore/book[price\u0026gt;35]/title 选择价格大于35的title节点 $x(\u0026#39;//bookstore/book/title\u0026#39;) (4) [title, title, title, title] $x(\u0026#39;//bookstore/book[1]/title\u0026#39;) [title] $x(\u0026#39;//bookstore/book[position() \u0026gt; 2]/title\u0026#39;) (2) [title, title] $x(\u0026#39;//bookstore/book[price \u0026gt; 30]/title\u0026#39;) (2) [title, title] $x(\u0026#39;.//bookstore/book[1]/price\u0026#39;)[0].textContent \u0026#39;30.00\u0026#39; $x(\u0026#39;.//bookstore/book[1]/price[text()]\u0026#39;)[0].textContent \u0026#39;30.00\u0026#39; $x(\u0026#39;.//bookstore/book[1]/price/text()\u0026#39;)[0].textContent \u0026#39;30.00\u0026#39; $x(\u0026#39;.//bookstore/book[@id=\u0026#34;testid\u0026#34;]/title\u0026#39;)[0].textContent \u0026#39;Everyday Italian\u0026#39; $x(\u0026#39;.//bookstore/book[@class=\u0026#34;testclass\u0026#34;]/title\u0026#39;)[0].textContent \u0026#39;Harry Potter\u0026#39; $x(\u0026#39;.//bookstore/book[contains(@class, \u0026#34;test\u0026#34;)]/title\u0026#39;)[0].textContent \u0026#39;Harry Potter\u0026#39; Xpath测试html打开开发者工具可以试验 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e Everyday Italian Giada De Laurentiis 2005 30.00 Harry Potter J K. Rowling 2005 29.99 XQuery Kick Start James McGovern Per Bothner Kurt Cagle James Linn Vaidyanathan Nagarajan 2003 49.99 Learning XML Erik T. Ray 2003 39.95 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;bookstore\u0026gt; \u0026lt;book id=\u0026#34;testid\u0026#34; category=\u0026#34;cooking\u0026#34;\u0026gt; \u0026lt;title lang=\u0026#34;en\u0026#34;\u0026gt;Everyday Italian\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;Giada De Laurentiis\u0026lt;/author\u0026gt; \u0026lt;year\u0026gt;2005\u0026lt;/year\u0026gt; \u0026lt;price\u0026gt;30.00\u0026lt;/price\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book class=\u0026#34;testclass\u0026#34; category=\u0026#34;children\u0026#34;\u0026gt; \u0026lt;title lang=\u0026#34;en\u0026#34; href=\u0026#34;test.pdf\u0026#34;\u0026gt;Harry Potter\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;J K. Rowling\u0026lt;/author\u0026gt; \u0026lt;year\u0026gt;2005\u0026lt;/year\u0026gt; \u0026lt;price\u0026gt;29.99\u0026lt;/price\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book category=\u0026#34;web\u0026#34;\u0026gt; \u0026lt;title lang=\u0026#34;en\u0026#34; href=\u0026#34;/test\u0026#34;\u0026gt;XQuery Kick Start\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;James McGovern\u0026lt;/author\u0026gt; \u0026lt;author\u0026gt;Per Bothner\u0026lt;/author\u0026gt; \u0026lt;author\u0026gt;Kurt Cagle\u0026lt;/author\u0026gt; \u0026lt;author\u0026gt;James Linn\u0026lt;/author\u0026gt; \u0026lt;author\u0026gt;Vaidyanathan Nagarajan\u0026lt;/author\u0026gt; \u0026lt;year\u0026gt;2003\u0026lt;/year\u0026gt; \u0026lt;price\u0026gt;49.99\u0026lt;/price\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book category=\u0026#34;web\u0026#34;\u0026gt; \u0026lt;title lang=\u0026#34;en\u0026#34; href=\u0026#34;https://www.google.com\u0026#34;\u0026gt;Learning XML\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;Erik T. Ray\u0026lt;/author\u0026gt; \u0026lt;year\u0026gt;2003\u0026lt;/year\u0026gt; \u0026lt;price\u0026gt;39.95\u0026lt;/price\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;/bookstore\u0026gt; 参考 Xpath cheatsheet\nXPath Tutorial\n","permalink":"https://blog.niuhemoon.win/posts/tech/xpath-cheetsheet/","summary":"介绍 Xpath全称XML Path Language，功能上使用类似路径的语法来识别和导航XML文档中的节点，同时支持HTML语言。XPath是W3C的推荐标准 Nodes Xpath中有七种节点： element attribute text namespace processing-instruction comment root nodes 句法 选中Nodes 表达式 描述 nodename 选中所有同名节点 / 从root node开始选择 // 从当前节点开","title":"xpath基本使用"},{"content":" 2023 年 7 月:\n怨仇星域三部曲 2023 年 6 月:\n回忆爱玛侬 2023 年 5 月:\n山月记 2023 年 4 月:\n第三次浪潮 Where Wizards Stay Up Late A Philosophy of Software Design 2023 年 2 月：\n我每天只工作三小时 置身事内 程序员修炼之道 2023 年 1 月：\n二手时间 认知天性：让学习轻而易举的心理学规律 数字思维 ","permalink":"https://blog.niuhemoon.win/posts/read/%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%952023/","summary":"2023 年 7 月: 怨仇星域三部曲 2023 年 6 月: 回忆爱玛侬 2023 年 5 月: 山月记 2023 年 4 月: 第三次浪潮 Where Wizards Stay Up Late A Philosophy of Software Design 2023 年 2 月： 我每天只工作三小时 置身事内 程序员修炼之道 2023 年 1 月： 二手时间 认知天性：让学习轻而易举的心理学规律 数字思维","title":"阅读记录2023"},{"content":"《奈飞文化手册》 范珂译\n◆ 推荐序一 文化，奈飞成功的原动力\n奈飞的企业文化主要是由“自由”与“责任”这两个关键词构成的。我之前认为：“现代企业文化的核心就是要靠制度管人，而不是靠人管人。”但奈飞在这个基础上又进化了一步，它提出，现代企业文化的核心还是人管人，但这个管人的人不是企业的管理者，而是员工自己。“自由”与“责任”的核心就是要将权力还给员工，让他们能够在自由的环境中充分施展自己的能力，履行自己的责任。\n◆ 前言 自由与责任，奈飞文化的核心\n当我介绍我们在奈飞开发的管理方法时，我会对所有关于管理的基本假设发起挑战，管理并不是要在员工忠诚度、人员稳定和职业发展方面做工作，同时实施相关项目来提升员工的敬业度和幸福感。这里面没有一项是管理应该做的工作。我的一个极端主张是，管理者的本职工作是建立伟大的团队，按时完成那些让人觉得不可思议的工作。只有这一项工作是管理应该做的。\n◆ 成年人最渴望的奖励，就是成功\n今天的管理理念认为，如果想让员工提高生产力，就必须先用奖金来激励他们，然后让他们知道自己的行为是受到监控的，以便让他们保持做事的责任心。因此，很多公司都有部门目标、团队目标和个人目标，还有一套正式的年度绩效评估流程，用以测量绩效。这种结构的逻辑性非常强，也非常合理。但是，仅有这些是远远不够的。对员工说：“如果你做X，你就会得到奖励Y”，背后的假设是“系统是静态的”。但是，今天没有哪项业务是静态的。更为根本的是，尽管有奖励很不错，但是，没有哪种奖励能比为迎接挑战而做出重大贡献更具激励效果。\n你能够为员工做的最好的事情，就是只招聘那些高绩效的员工来和他们一起工作。这可远比桌上足球、免费寿司、一大笔签约奖金或者股票期权更有吸引力。\n◆ 培养基层员工的高层视角\n如何做到让每位员工都理解公司业务1．建立新员工大学，保持沟通的强节奏。2．双向沟通，为员工提供向所有管理者提问的机会。3．让每一位员工了解，他为客户带来的体验是如何直接影响公司利润的。4．如果只选择一门课程面向公司全员开授，请选择公司业务运作和客户服务的基本知识。5．最好的福利，是让员工有机会去更好地了解业务和客户。\n◆ 人前人后言行一致\n人力资源部门副总裁会把我叫到他的办公室，大声质问：“你是不是开工程师的玩笑了？”我说：“是的，不过，有没有搞错！他们抱怨浴缸里的水不够热，毛巾不够软，还有游泳池里的水太凉了。”副总裁就会责备我：“工程师是我们最重要的资源，你必须给予他们特殊对待！”我并不认同这一点。就像前面讲过的，我实在是厌倦了把工程师当作上帝一样对待。到了哈斯廷斯那里，一切都不一样了。在面试我时，他的第一个问题是：“你的人力资源理念是什么？”记住，我可是在太阳计算机系统和柏兰德两家公司工作过的，于是我用人力资源术语流利地回答道：“我认为每个人都应该有野心，坦诚，能够通过被赋能为企业做出贡献。”哈斯廷斯看着我说：“你说的是什么？你知道你刚才说的那番话毫无意义吗？那些词串起来，甚至都不能组成一句有逻辑的话！”我镇定自若地回答道：“嘿，你根本不了解我！”哈斯廷斯针锋相对：“如果我们像这样谈话，你觉得我能怎么了解你？告诉我，你会做什么来帮助公司成长？”\n给予反馈最重要的是要针对行为，而不是笼统地给一个人定性，比如“你不够专心。”反馈的内容必须是可操作的，反馈对象必须理解他们的行为需要做出哪些特定的改变。像“你做得不错，但是还不够”，这样的评论实际上是毫无意义的。你可以这么说：“我能看到你工作非常努力，我很欣赏这一点。但是，我也注意到，你在某些事情上花了太多时间，而这些时间本可以花在更为重要的事情上。”这样，你接下来就可以和对方更好地确定事情的优先顺序了。\n信任是建立在坦诚沟通的基础之上的，我发现当员工听到半真半假的话时就会开始冷嘲热讽。冷嘲热讽就像是癌细胞，它容易扩散、转移成牢骚和不满，并导致阿谀奉承和背后中伤等不良风气。\n传统观点认为，如果允许人们匿名，他们就会表现得更坦诚。但根据我的经验，情况并非如此。坦诚的人会坦诚地对待任何事情。而且，如果你不知道是谁给你的反馈，你怎么把他的评语和他的工作背景、他的上级以及他的性格特点结合起来呢？匿名反馈最大的问题就在于它传递出这样一个信息：人们只有在对方不知道自己是谁的时候才是最坦诚的。\n◆ 坚持你的观点，用事实为它辩护\n我们在奈飞提出了一个要求，即人们必须通过探求事实来完善自己的观点，并且以开放的心态去倾听那些他们并不认同，但以事实为依据的辩论。这个要求执行得很顺利，因为我们早期的员工都是数学家和工程师，科学方法就是他们的生命，他们依靠这些方法来发现事实，然后调整自己对问题的理解以及处理问题的方式。随着公司的壮大，我们有意培养员工对事实驱动和科学方法的痴迷，不只是在工程部，而是在全公司。你的公司也可以广泛推行这套行为准则，即便不是工程师的公司也可以。\n我们根据直觉采取了不少行动，在为团队寻找人才时，我会留意那些会分析数据，而且凭直觉就知道该如何忽略数据的人。”泰德还警告说，数据可以被当作一个挡箭牌，抵挡本该用主观判断来做出决定的责任。基于真实数据来做决定会令人们感到更自在，部分原因是：如果决定是错误的话，就可以把责任推到数据上面。\n◆ 不要让招聘成为一场数字游戏\n当时的美国国防部长唐纳德·拉姆斯菲尔德（Donald Rumsfeld）有一句名言：“你要带着你现有的军队，而不是你想有的或者你以后希望有的军队参加战争。”当我和管理者们讨论如何建立优秀团队时，我告诉他们要按照完全相反的方式来行事。你必须现在就招聘你未来希望拥有的团队成员。\n晋升员工并指导他们扮演新角色，对团队领导者来说是一件相当有满足感的事情，对团队绩效来说也是一件好事。但是，晋升和培养员工对于团队绩效来说，通常并不是最理想的方式。管理者不应该期望自己成为员工的职业规划者。在今天快速发展的商业环境中，试图扮演这种角色是很危险的。\n我相信，对于今天职场人士的最佳建议就是：保持灵活，不断学习新技能，不断考虑新机会，经常接受新挑战，这样可以保持工作的新鲜感和延展性。奈飞鼓励员工为自己的成长负责，利用好公司提供的大量机会，向那些优秀的同事和管理者学习，无论这样做是意味着在公司内部获得晋升还是在公司外部获得一个好机会。\n有时候，在某个时间段对一个组织来说是非常合适，也喜欢为这个组织工作的那些人，最好是跳槽去那些有类似挑战和环境的新组织。我告诉这位工程师：“没关系，你不必非得成为其中的一分子，也许你在一家50人的公司里会更快乐，也许那里才是你能找到最大乐趣的地方。”\n◆ 人才保留不是团队建设的目标\n正如奈飞最好的用人经理之一的约翰·辛库提曾经跟我说的：“知道什么时候让员工离开与引进一个拥有你所需技能的顶尖人才，是相辅相成的。他们就像一枚硬币的两面。如果你不是很擅长招聘优秀人才，那么在让优秀员工离开时，你的心里就不会好受。二者缺一，你都无法做好另外一项，也永远无法建立一支高绩效的团队。”\n最有竞争力的公司能够保持灵活，不断创新和增长，很大原因在于它们总在积极地引进新的人才。最好的员工则总是在寻找有挑战的新机会，尽管他们大多极度忠诚，但是他们中的很多人最终还是会到别处寻找机会。你永远也不会知道他们何时决定离开，通常你也没有办法阻止他们。\n员工在工作中的幸福不应该是美味沙拉、睡袋或桌球。工作中真实和持久的幸福源于和你认识的优秀人才一起深入地解决一个问题，源于客户喜爱你付出辛勤努力所创造的产品或服务。\n但谷歌在招聘方面做得更好，因为它的目标更大，它要把世界上所有的信息组织起来。还有比这个更大的目标吗？所以，谷歌尽可能多地招募那些聪明人，把他们放到一个拥有所有资源的环境中，让他们产出大量创意，然后把那些最顶级的创意利用起来。谷歌的领导者希望利用不同的方式推动公司的发展，因此人才数量对他们来说非常重要\n我有一个铁律，如果有招聘人员看见一个陌生人坐在那里等候面试，他们必须过去和他说：“嗨，我叫XX，您是哪一位？您是要面试吗？您在等谁？让我看看您今天的面试安排，我来帮您安排一下。”我知道招聘团队成员清楚地听到了这个规则，因为如果我在面试某个应聘者时迟到的话，我会说：“对不起，我希望有人已经跟您聊过了。”他们会说：“有6个人跟我聊过了。”面试的重要性高于用人经理事先预订的任何会议，这也是高管会议的与会者可能缺席或提前离开会议的唯一理由。候选人在评估你，就像你在评估他们一样，但人们很容易忘记这一点。\n◆ 薪酬与绩效评估流程无关，只与绩效有关\n根据我的经验，如果你有意招聘你能发现的最佳人选、给他们支付最高的薪水，你会发现，他们为业务增长带来的价值总是会大大超过他们的薪水。\n◆ 每10场比赛就做一次评估\n有很多次，在完成演讲之后，人们会走上前来向我征求职业发展意见。我告诉他们：你需要成为一个终身学习者。你需要不断获取新技能并积累新经验，但不是非得在同一家公司取得它们。事实上，有时候公司聘用你做某件事，你做完就完了。如果我雇用别人来整修我的车库，当他们干完活儿之后，我并不需要他们来整修我的后院。\n1．如果员工的表现不够好，及时告诉他们要么纠正过来，要么去一家新公司。2．不要把与工作不再匹配的员工归结为失败者。3．不要给员工无法实现的承诺，这只会让他们感觉自己被背叛了。4．积极地帮助离职员工找到新的好机会。\n","permalink":"https://blog.niuhemoon.win/posts/read/%E5%A5%88%E9%A3%9E%E6%96%87%E5%8C%96%E6%89%8B%E5%86%8C/","summary":"\u003cp\u003e\u003cstrong\u003e《奈飞文化手册》\u003c/strong\u003e\n范珂译\u003c/p\u003e","title":"奈飞文化手册"},{"content":"《世界观：现代人必须要懂的科学哲学和科学史（原书第2版）》 理查德·德威特（Richard DeWitt）\n◆ 第1章 世界观\n一个观点如果即使本身发生变化也不对其所在的观点体系产生实质性改变，那它就是一个典型的外围观点。\n总之，我们只能为我们所秉持的极小一部分观点拿出直接证据。对我们的大多数观点（也许是几乎所有观点）来说，我们之所以秉持这些观点，主要在于它们可以跟一个很大的、其中各个观点相互联结的观点集合拼合在一起。换句话说，我们之所以秉持这样的观点主要是因为它们可以跟我们的世界观拼合在一起。\n◆ 第2章 真理\n所以，总结一下，根据真理符合论，决定一个观点为真的因素是这个观点与独立、客观的现实相符合；决定一个观点为假的因素是这个观点没能与那样的现实相符合。\n在这里列出个人主义融贯论和以科学为基础的融贯论主要是为了说明在融贯论这个理论类别中还有许多不同的小类别。由于不同种类的融贯论的主要区别在于考虑了哪些人的观点，同时，存在很多不同的方法来解释具体考虑了哪些人的观点，因此我们必须明白，可能存在大量差异巨大的融贯论。\n从本质上讲，知觉表征论的核心是：感官为我们提供了外部世界各种物体的表征（对视觉来说，这些表征大致类似图画）。同样地，这是一个几乎所有人都认为理所当然的观点。不过，这个观点同时也有些有趣的推论，而这些推论却直接影响了真理符合论。这些推论中最重要的一个是，这个观点意味着我们每个人从某种意义上来说与这个世界都是隔绝的。更具体地说，我们没有办法确定自身感官所提供的表征是否准确。\n如果自身感官为我们提供了外部世界的表征，那么接下来一个合理的问题就是这些表征是否准确。正如我们刚刚讨论过的，要评估感官提供的表征是否准确，我们需要把这些表征和表征所代表的事物进行对比。然而，让我们再看一看图2-1中萨拉的意识图解。假设萨拉想评估她关于苹果的视觉表征是否正确，要达到这个目的，她需要把苹果的视觉表征与真正的苹果进行对比。但是，萨拉没有办法这么做。萨拉不能把苹果的视觉表征与真正的苹果进行对比的原因是她无法从自己的意识中走出来。从萨拉的角度来看，她所能运用的都在她的意识里。\n这个情形就像是为了评估恶魔塔照片的准确性而把照片和恶魔塔的地形图或者恶魔塔周围道路的地图进行对比。在这种情况下，对比是在两个表征之间进行的，而评估表征准确性所需要的对比，也就是表征与这个表征所代表的事物之间的对比，并没有进行。这个推论说明，我们根本没有办法评估感官给我们提供的表征是否准确，或者换句话说，我们没有办法确定现实到底是什么样子的\n总之，尽管我们都认为自己的体验来自于“正常”的现实，但我们并不能确定这些体验不是来自于某种《全面回忆》情境植入我们大脑中的现实。简言之，我们无法确定现实真正的样子。\n总结一下，个人主义融贯论似乎会陷入一种让人无法接受的相对主义。另一方面，团体融贯论似乎避免了相对主义的问题，但是同时又带来了几个新的、不容忽视的问题。所以，不管是真理融贯论还是真理符合论，对关于真理的核心问题，都无法提供让人完全满意的答案。\n甚至“我有一个身体”的观点也经不起测试，因为可能邪恶骗子正在往我没有实体的大脑中植入身体的图像。那有没有观点经得起这个测试呢？也就是说，是否存在可以让我们感到完全确定的观点？笛卡尔认为他找到了至少一个这样的观点，就是他的名言“Cogito，ergosum”，也就是“我思，故我在”。笛卡尔表示，这是一个可以让他感到完全确定的观点。\n◆ 第3章 经验事实和哲学性/概念性事实\n我猜测你之所以这样认为，是源于你看待这个世界的方式。我们大部分人无法想象物体在我们观察不到的时候就不再存在了。我们对自己所生活的这个世界有一个判断，那就是“组成这个世界的大部分物体是稳定的，即使在没有被观察到的时候，仍然保持存在”。对此，我们深信不疑，而这正是我们认为抽屉里有一支铅笔的根源。\n把事实与观点区分开来就意味着两者之间存在相当清晰的区别，也就意味着事实是事实，而观点仅仅是观点。然而，两者之间实际上没有这样一个明确的区别，至少在一个人的生命过程中或者一个人自身的世界观中不会有这样的区别（在这里，可以再考虑一下“书桌上的铅笔和抽屉里的铅笔”的例子）。从一个人自己的世界观来看，那些他感到深信不疑而又有强有力证据支撑的观点似乎就是事实。\n在我们所处的时代，事实只是对我们来说看起来像事实，它们看起来都差不多。只有经过仔细思考，有时在思考过程中还要克服极大的困难，然后我们才会发现自己所秉持的某些观点更偏向于以经验为基础，而另一些观点则更偏向于以哲学性/概念性观点为基础。\n◆ 第4章 证实与不证实证据和推理\n证实推理是一种归纳推理，而不证实推理则是一种演绎推理。证实推理的归纳推理性质和不证实推理的演绎推理性质都具有一些重要影响。要理解这些影响，我们首先需要明确归纳推理和演绎推理之间的不同之处。\n这就是归纳推理的特点：在一个好的归纳推理过程中，即使所有前提条件都是真的，所得出的结论也有可能是错的。相比之下，在一个好的演绎推理论证过程中，真的前提条件就保证了真的结论。也就是说，在一个好的演绎推理论证过程中，如果所有前提条件都是真的，那么其所得出的结论就一定是真的。\n证实推理模式和不证实推理模式是科学领域内外两个常见的推理模式。一方面，证实推理模式由于是一种归纳推理模式，因而无法在证明一个理论正确的同时保证这一正确性不受质疑。因此，对于一个科学理论来说，不管有多少可以证明其正确性的证据，这个理论是错误的这种可能性始终存在。除此之外，在实际的例子里，归纳得出的证据和归纳推理通常非常复杂且相互交织。证实推理模式及证据往往远没有它们乍看起来那么直接明确。另一方面，不证实推理模式是一种演绎推理。然而实际上，由不证实推理模式得出的证据往往同样很复杂。具体来说，通常不证实推理模式涉及大量辅助假设。因此，通过不证实推理模式得出的证据只能表明要么是所使用的理论不正确，要么就是一个或几个辅助假设不正确（经常出现的是后者）。因此，不证实推理模式及证据同样也远没有它们乍看起来那么直接明确。\n◆ 第5章 奎因-迪昂论点和对科学方法的意义\n笛卡尔这个方法的基本问题是，它不足以成为一个基础。简言之，在寻找关于这个世界的必定为真的起始点时，笛卡尔的问题与亚里士多德的问题是一样的，也就是，似乎不存在得到一致认可的、必定为真的起始点。尽管，一个人至少可以在“我存在”（至少作为一个思考主题存在）的主张上找到某些确定性，对这一观点可能有更多共识，但是这个观点同样太单薄了，无法成为进行知识构建的基础。\n◆ 第6章 哲学插曲：归纳的问题和困惑\n总之，每一天他们所处的世界都与前一天有一些不同。由于自己所处的世界始终在变化，这两人不知道每天会遇到什么。对他们来说，未来不会像过去一样。因此，他们无法对未来做出那种我们都认为是理所当然的归纳推理。（大概他们所能做出的唯一一种关于未来的归纳推理，就是未来不会继续像过去一样，而这当然并不是一个特别有帮助的推理结论。）所以，要理解休谟的归纳问题，应认识到的第一个关键点是：前面提到的那句话，也就是未来将继续像过去一样，是每一个关于未来的推理所必需的隐含前提，尽管通常都不为人察觉。\n总结一下，休谟的观点是每一个归纳推理都依赖于“未来将继续像过去一样”的隐含前提。但是，用来解释支撑这个隐含前提的主要（似乎也是唯一的）方法是循环的，因此，看起来这个关键的隐含前提无法得到足够支撑。所以，关于未来的推理依赖于一个无法得到支撑的假设，这些推理从逻辑上也就无法得到支撑。\n休谟的问题是，我们是否可以从逻辑上为我们关于未来的推理提供依据，而他的答案是：我们不可以。\n◆ 第8章 工具主义和现实主义\n对工具主义者来说，一个适当的理论可以给出预言和解释，至于这个理论是否反映或模拟现实世界，并不是一个重要的考量。而对现实主义者来说，事情恰恰相反，一个合理的理论必须不仅可以给出预言和解释，而且要反映现实事物的真实情况。\n真理符合论的支持者认为真理是符合现实的观点，而真理融贯论的支持者则认为当一个观点可以与一个整体的观点体系相融合，或者说是拼合在一起时，那么这个观点就是真理。因此，接下来的疑问就会是真理的符合论和融贯论是否与工具主义和现实主义紧密相连。\n◆ 第9章 亚里士多德世界观中的宇宙结构\n总的来说，目的论解释是从目标、目的或功能角度提出的解释，而机械论解释则是不使用目标、目的和功能的解释。\n◆ 第14章 哥白尼体系\n他认为有很多各种各样客观存在，但又没有实体的永恒“形式”。这些形式是知识的客观存在，也就是说，相对于仅仅得到一个信念或观点，当我们得到了知识时，我们的知识就是关于一个或多个这样客观存在，但又没有实体的永恒形式的。举个例子，当我们知道了毕达哥拉斯定理，或数学中的其他真理，我们所得到的知识并不是关于地球上某种物体的（比如，画在纸上的三角形），而是关于一个客观存在，但又没有实体的永恒形式的。\n◆ 第20章 新科学和牛顿世界观概述\n回到向地面下落的钢笔的例子，请注意钢笔和地球之间似乎不存在联系，并没有橡皮筋把地球和钢笔绑在一起，也没有细绳，什么都没有。然而，尽管如此，钢笔在被松开以后仍然向地球移动。从这个角度来看，重力听起来并不像是科学，而像是魔法。\n牛顿世界观也随时间推移而经历了发展，不过一个机械论的、像机器一样的宇宙一直保留了下来，并且成为这一世界观的核心观点。\n◆ 第21章 哲学插曲：什么是科学定律\n反映无例外的规律性似乎是科学定律的一个关键特点。\n◆ 第三部分 科学及世界观的新近发展\n与17世纪发生的情况一样，我们看到某些我们一直认为显而易见的经验事实，在运用了新近科学发展的视角后，都被证明是错误的哲学性/概念性事实。\n◆ 第23章 狭义相对论\n光速恒定原则是狭义相对论赖以为基础的基本原则之一\n◆ 第24章 广义相对论\n火星围绕太阳沿椭圆轨道运转并不是火星与太阳之间相互的吸引力或者说万有引力的结果。相反，与其他运动的物体一样，火星沿直线运动。然而，在一个弯曲的空间中，“直线”其实是测地线。正如我们在前面看到的，根据广义相对论，像太阳这样的物体会导致时空曲率。根据广义相对论方程式，这个曲率之大，会使火星运动所沿的测地线变成围绕太阳的一个椭圆形。换句话说，在广义相对论中，像火星和太阳这样的物体之间不存在吸引“力”。事实上，火星只是沿直线运动，但是由于时空曲率，这条直线变成了围绕太阳的一个椭圆形。\n◆ 第28章 演化的哲学与概念影响\n生命及其蕴含之力能，最初注入到寥寥几个或单个类型之中；当这一行星按照固定的引力法则循环运行之时，无数最美丽与最奇异的类型，即是从如此简单的开端演化而来、并依然在演化之中；生命如是之观，何等壮丽恢弘。（Darwin，1964\n◆ 第29章 世界观：总结思考\n我认为，相对论真正更重要的影响是，它深刻表明了在一些看起来显而易见的命题上，我们犯了多么严重的错误。或者换句话说，它表明了哲学性/概念性事实伪装成显而易见的经验事实是多么容易。举个例子，我认识的所有人在了解相对论之前都认为空间和时间对任何人来说都是相同的，而且把这当作一个显而易见的经验事实。\n再来梳理一下：在亚里士多德世界观中，宇宙被看作像一个生物有机体，各部分分别发挥其作用，从而共同实现天然的目标和目的；在牛顿世界观中，宇宙被看作像一台机器，各个部分通过推拉与其他部分发生相互作用，与机器里的零部件彼此发生相互作用的方式一样。这类隐喻既很有魅力，又很有用——这一点很容易理解，因为它们提供了一种方便而又简单的方式来总结对宇宙的整体观点。不过，新近的这些发现都有一个有趣的特点，那就是它们所主张的宇宙与我们经历过的任何事物都不一样。\n","permalink":"https://blog.niuhemoon.win/posts/read/%E4%B8%96%E7%95%8C%E8%A7%82/","summary":"\u003cp\u003e《世界观：现代人必须要懂的科学哲学和科学史（原书第2版）》\n理查德·德威特（Richard DeWitt）\u003c/p\u003e","title":"世界观"},{"content":" Tip\n文中操作基于Manjaro系统\n涉及软件:\ncalibre管理电子书 mega网盘 同步备份图书库 微信读书 手机便捷阅读 (web端同步，支持导出批注) okular 阅读pdf (功能强大，支持标注) zlib 下载电子书 (目前要用tor浏览器才能访问) 之前读了很多技术和非技术的书籍，非技术的书基本都是epub,mobi格式，技术类的基本是pdf格式。书籍零散，趁着元旦用calibre 整理一下。\n安装配置calibre # 安装calibre yay -Sy calibre 从豆瓣下载元数据和封面插件\nReleases · fugary/calibre-douban\ncalibre默认有两个用户:\n本地电子阅读器用户 (即直接双击calibre书籍条目阅读) 匿名的内容服务器用户 (calibre启动内容服务器，在网页上阅读) 默认这两个用户的批注是不互通的，需要合并批注的话，双击一本epub书，在首选项-杂项-与内容服务器用户同步书签/突出显示里进行配置\n安装并配置calibre-web calibre-web目前阅读功能较弱，胜在UI比较好看，主要用来从网页管理图书\nmkdir calibre-web \u0026amp;\u0026amp; cd calibre-web python3 -m venv ./venv source venv/bin/activate # install calibreweb pip install calibreweb # start calibreweb cps # open browser http://localhost:8083 calibre-web添加豆瓣源数据api\ncalibre-web-douban-api\n安装mega桌面同步calibre目录 mega网盘免费用户有50GB的空间，足够同步图书库做一个备份。国内可能网速不稳定需要挂梯子。 从mega官网下载源码包，并使用pacman安装。不推荐从yay源安装megasync，因为目前yay源的包有bug，无法正常使用。\n桌面应用程序- MEGA\n","permalink":"https://blog.niuhemoon.win/posts/read/calibre-usage/","summary":"使用calibre管理电子书","title":"calibre-usage"},{"content":"Tmux基本概念 ◎ Tmux基本概念 session 会话：可以理解成是一个特定的终端组合，通常将同一任务下的工作放到一个会话中。 window 窗口：一个会话可以包含多个窗口，一个窗口就相当于普通终端的一个标签，通常在不同的窗口中完成不同的工作。 pane 窗格：一个窗口可以被分割成多个小的窗格。 Tmux配置文件(可选) 全局配置 /etc/tmux.conf 用户配置 ~/.tmux.conf 开箱即用的配置文件:\n🇫🇷 Oh my tmux! ❤️\n笔者配置文件内容如下:\n# 开启鼠标 set -g mouse on Tmux基本操作 Tip\n本文中prefix是tmux的前缀快捷键，默认是Ctrl+b\n会话管理 # prefix + ? 查看帮助信息 # 新建会话tmux tmux new -s \u0026lt;session-name\u0026gt; tmux new-session -s \u0026lt;session-name\u0026gt; # 离开会话 # prefix + d tmux detach # 查看所有tmux会话 tmux list-session tmux ls # 接入会话 tmux attach -t \u0026lt;session-name\u0026gt; tmux a -t \u0026lt;session-name\u0026gt; # 杀死会话 tmux kill-session -t \u0026lt;session-name\u0026gt; # 切换会话 tmux switch -t \u0026lt;session-name\u0026gt; # 重命名会话 tmux rename-session -t \u0026lt;old-name\u0026gt; \u0026lt;new-name\u0026gt; # 重命名当前会话 tmux rename-session \u0026lt;new-name\u0026gt; 窗格管理 # 划分上下窗格prefix + \u0026#34; tmux split-window # 划分左右窗格prefix + % tmux split-window -h # 移动光标prefix + ←↑→↓ tmux select-pane -U # 光标切到上方窗格 tmux select-pane -D tmux select-pane -L tmux select-pane -R # 交换窗格位置 # 窗格上移 tumx swap-pane -U # 窗格下移 tumx swap-pane -D # 窗格转变为窗口 prefix + ! # 窗格全屏显示prefix + z, 再使用一次恢复原大小 # 调整窗格大小prefix + Ctrl + ←↑→↓ 窗口管理 # 新建窗口 tmux new-window tmux new-window -n \u0026lt;window-name\u0026gt; # 查看窗口列表 tmux list-window # 切换窗口 tmux select-window -t \u0026lt;window-name\u0026gt; # 重命名当前窗口 tmux rename-window \u0026lt;new-name\u0026gt; # 重命名指定窗口 tmux rename-window -t \u0026lt;old-name\u0026gt; \u0026lt;new-name\u0026gt; # 切换上一个窗口 prefix + p # 切换下一个窗口 prefix + n # 切换指定窗口 prefix + \u0026lt;number窗口编号\u0026gt; 其它快捷键 命令 说明 ? 列出所有快捷键；按 q 返回 d 脱离当前会话,可暂时返回 Shell 界面 s 选择并切换会话；在同时开启了多个会话时使用 [ 复制模式，光标移动到复制内容位置，空格键开始，方向键选择复制，回车确认，q/Esc 退出 ] 进入粘贴模式，粘贴之前复制的内容，按 q/Esc 退出 t 显示当前的时间 c 创建新窗口 \u0026amp; 关闭当前窗口 [0-9] 数字键切换到指定窗口 p 切换至上一窗口 n 切换至下一窗口 l 前后窗口间互相切换 w 通过窗口列表切换窗口 , 重命名当前窗口，便于识别 . 修改当前窗口编号，相当于重新排序 f 在所有窗口中查找关键词，便于窗口多了切换 \u0026quot; 将当前面板上下分屏 % 将当前面板左右分屏 x 关闭当前分屏 ! 将当前面板置于新窗口,即新建一个窗口,其中仅包含当前面板 q 显示面板编号 o 选择当前窗口中下一个面板 { 向前置换当前面板 } 向后置换当前面板 z 最大化当前所在面板 方向键 移动光标选择对应面板 page up 向上滚动屏幕，q 退出 page down 向下滚动屏幕，q 退出 alt+o 逆时针旋转当前窗口的面板 ctrl+o 顺时针旋转当前窗口的面板 ctrl+方向键 以 1 个单元格为单位移动边缘以调整当前面板大小 alt+方向键 以 5 个单元格为单位移动边缘以调整当前面板大小 参考 Tmux 简介与使用\nTmux 使用教程 - 阮一峰的网络日志\n","permalink":"https://blog.niuhemoon.win/posts/tech/tmux-usage/","summary":"tmux是将会话和窗口解绑的工具","title":"tmux-usage"},{"content":"记录hugo 一些常用的shortcode\nRaw 如下是一个使用svg绘制的钟表\nPlantuml Grpahvizo DOT Language (GraphViz) Example Chart Blockquote 花开花谢 白天黑夜\n一切自然 又不尽然\n春夏秋冬 经过才懂\n世间冷暖 无非自然\n李健 《懂得》 Imagecap 带标题的图片 ◎ Tmux基本概念 不带标题的图片 折叠内容 测试折叠内容 测试折叠内容\nprint(\u0026#39;hello\u0026#39;) RawHTML \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e Everyday Italian Giada De Laurentiis 2005 30.00 Harry Potter J K. Rowling 2005 29.99 XQuery Kick Start James McGovern Per Bothner Kurt Cagle James Linn Vaidyanathan Nagarajan 2003 49.99 Learning XML Erik T. Ray 2003 39.95 Music 基于meeting js\nspotify iframe\nNotice Warning\n告警\nInfo\n引言/通知\nNote\n记录\nTip\n提示\nBilibili \u003c!DOCTYPE HTML\u003e Gist Codepen See the Pen Draft Countdown by littlebookboy (@littlebookboy) on CodePen. Youtube Ref Theme Documentation - Extended Shortcodes - LoveIt\n","permalink":"https://blog.niuhemoon.win/posts/tech/hugo-shortcode-example/","summary":"\u003cp\u003e记录hugo 一些常用的shortcode\u003c/p\u003e","title":"hugo shortcode example"},{"content":"在manjaro上搭建minikube测试环境\n安装 minikube 安装依赖 sudo pacman -Sy libvirt qemu ebtables dnsmasq sudo usermod -a -G libvirt $(whoami) newgrp libvirt sudo systemctl start libvirtd.service sudo systemctl enable libvirtd.service sudo systemctl start virtlogd.service sudo systemctl enable virtlogd.service 装docker和kvm2 驱动 sudo pacman -Sy docker-machine yaourt -Sy docker-machine-driver-kvm2 装minikube yay -Sy minikube kubectl-bin minikube version whereis kubectl kubectl -h 装环境 注意关掉 vpn\nminikube start --vm-driver kvm2 --registry-mirror=https://dockerhub.azk8s.cn --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers minikube status kubectl cluster-info kubectl get nodes 参考 https://www.howtoforge.com/learning-kubernetes-locally-via-minikube-on-linux-manjaro-archlinux/\n","permalink":"https://blog.niuhemoon.win/posts/tech/install-minikube-on-manjaro/","summary":"\u003cp\u003e在manjaro上搭建minikube测试环境\u003c/p\u003e","title":"Manjaro 搭建 minikube 环境"},{"content":"安装 Tinygo 在 Ubuntu 上安装开发环境，其他环境见参考\n# x86_64 wget https://github.com/tinygo-org/tinygo/releases/download/v0.17.0/tinygo_0.17.0_amd64.deb sudo dpkg -i tinygo_0.17.0_amd64.deb # arm wget https://github.com/tinygo-org/tinygo/releases/download/v0.17.0/tinygo_0.17.0_arm.deb sudo dpkg -i tinygo_0.17.0_arm.deb 配置环境变量\nexport PATH=$PATH:/usr/local/tinygo/bin 验证安装成功\ntinygo version 安装 esp32 环境 # install dep sudo apt-get install git wget make libncurses-dev flex bison gperf pip3 install pyserial # install esp32 toolchain wget https://dl.espressif.com/dl/xtensa-esp32-elf-linux64-1.22.0-80-g6c4433a-5.2.0.tar.gz -P ~/ mkdir -p ~/esp cd ~/esp tar -xzf ~/xtensa-esp32-elf-linux64-1.22.0-80-g6c4433a-5.2.0.tar.gz # add env path export PATH=\u0026#34;$PATH:$HOME/esp/xtensa-esp32-elf/bin\u0026#34; # install esptool pip3 install esptool 烧录 esp32 程序 可以用 usb 连接 esp32，也可以 ttl 转 usb 线，我用的是 ttl-usb，将连接 esp 对应的 RX 和 TX 串口，自己使用串口线烧录时需要同时按住两个板载按键。\n烧录完成后，按 en 使能键，程序开始运行。\n# chmod /dev/ttyUSB0 sudo chmod 666 /dev/ttyUSB0 # flash example program tinygo flash -target=esp32-mini32 -port=/dev/ttyUSB0 examples/blinky1 example/blinky1 代码在/usr/local/lib/tinygo/src 目录下\n也可以编写自己的程序进行烧录，将下面程序保存在/tmp/blink/blink.go\npackage main // This is the most minimal blinky example and should run almost everywhere. import ( \u0026#34;machine\u0026#34; \u0026#34;time\u0026#34; ) func main() { led := machine.LED led.Configure(machine.PinConfig{Mode: machine.PinOutput}) for { led.Low() time.Sleep(time.Millisecond * 300) led.High() time.Sleep(time.Millisecond * 2000) } } 编译并烧录\ntinygo flash -target=esp32-mini32 -port=/dev/ttyUSB0 /tmp/blink/blink.go Tinygo 对 esp32 支持情况\n当前 tinygo 对 esp32 的支持还很不完善，比较鸡肋，不支持 goroutine，不支持网络和蓝牙等。相比 arduino 和 micropython，实用性不强。\nInterface Hardware Supported TinyGo Support GPIO YES YES UART YES YES SPI YES YES I2C YES Not Yet ADC YES Not Yet PWM YES Not Yet WiFi YES Not Yet Bluetooth YES Not Yet 参考 https://tinygo.org/getting-started/linux/\nhttps://docs.espressif.com/projects/esp-idf/en/release-v3.0/get-started/linux-setup.html#standard-setup-of-toolchain-for-linux\n","permalink":"https://blog.niuhemoon.win/posts/tech/tinygo-esp32/","summary":"\u003ch3 id=\"安装-tinygo\"\u003e安装 Tinygo\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在 Ubuntu 上安装开发环境，其他环境见参考\u003c/p\u003e\n\u003c/blockquote\u003e","title":"tinygo点亮esp32"},{"content":" 使用select语句和带缓冲区的channel来控制函数并发执行次数\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) // cocurrency number of the do func const cnum = 3 func main() { var jobs = make(chan bool, cnum) for { for i := 0; i \u0026lt; 10; i++ { go frqLimit(do, jobs, i) } time.Sleep(4e9) } } func frqLimit(f func(), jobChan chan bool, i int) { select { case jobChan \u0026lt;- true: f() \u0026lt;-jobChan default: fmt.Println(\u0026#34;job channel is full. pass \u0026#34;, i) } fmt.Println(\u0026#34;jobs\u0026#34;, i, \u0026#34;exit\u0026#34;) } func do() { time.Sleep(3e9) fmt.Println(\u0026#34;job done\u0026#34;) } ","permalink":"https://blog.niuhemoon.win/posts/tech/golang-frequency-limit/","summary":"使用select语句和带缓冲区的channel来控制函数并发执行次数 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) // cocurrency number of the do func const cnum = 3 func main() { var jobs = make(chan bool, cnum) for { for i := 0; i \u0026lt; 10; i++ { go frqLimit(do, jobs, i) } time.Sleep(4e9) } } func frqLimit(f func(), jobChan chan bool, i int) { select { case jobChan \u0026lt;- true: f() \u0026lt;-jobChan default: fmt.Println(\u0026#34;job channel is full. pass \u0026#34;, i) } fmt.Println(\u0026#34;jobs\u0026#34;, i, \u0026#34;exit\u0026#34;) } func do() { time.Sleep(3e9) fmt.Println(\u0026#34;job done\u0026#34;) }","title":"golang限制函数同时调用次数"},{"content":"Makefile基础 语法\n# 目标 ：依赖 # 根据依赖生成目标的命令 targets : prerequisites command 变量\nMakefile 允许使用等号自定义变量。\ntxt = Hello World test: @echo $(txt) 上面代码中，变量 txt 等于 Hello World。调用时，变量需要放在 $( ) 之中。\n调用Shell变量，需要在美元符号前，再加一个美元符号，这是因为Make命令会对美元符号转义。\ntest: @echo $$HOME 有时，变量的值可能指向另一个变量。\nv1 = $(v2) 上面代码中，变量 v1 的值是另一个变量 v2。这时会产生一个问题，v1 的值到底在定义时扩展（静态扩展），还是在运行时扩展（动态扩展）？如果 v2 的值是动态的，这两种扩展方式的结果可能会差异很大。\n为了解决类似问题，Makefile一共提供了四个赋值运算符 （=、:=、？=、+=），它们的区别请看StackOverflow。\nVARIABLE = value # 在执行时扩展，允许递归扩展。 VARIABLE := value # 在定义时扩展。 VARIABLE ?= value # 只有在该变量为空时才设置值。 VARIABLE += value # 将值追加到变量的尾端。 特殊变量\n$@ ： target文件名 $\u0026lt; ： 第一个dependencies文件 $? ： 所有比target文件更新的dependencies文件 $^ ： 所有的dependencies文件，不管文件修改时间如何。 跨平台\n让makefile支持跨平台，在不同平台作出不同的反应\n# Detect system OS. ifeq ($(OS),Windows_NT) detected_OS := Windows else detected_OS := $(shell sh -c \u0026#39;uname -s 2\u0026gt;/dev/null || echo not\u0026#39;) endif Go语言Makefile模板 -include .env PROJECTNAME=$(shell basename \u0026#34;$(PWD)\u0026#34;) # Binary package name for release BINARY=go_trans VERSION=0.0.3 # Go related variables. GOBASE=$(shell pwd) GOPATH :=$(shell echo ${GOPATH}) # Go binary store place. GOBIN=$(GOBASE)/bin GORELEASE=$(GOBASE)/release GOFILES=$(wildcard *.go) GOBUILD_RACE=go build -race -o GOBUILD=go build -o # Redirect error output to a file, so we can show it in development mode. STDERR=/tmp/.$(PROJECTNAME)-stderr.txt # PID file will keep the process id of the server PID=/tmp/.$(PROJECTNAME).pid # Make is verbose in Linux. Make it silent. MAKEFLAGS += --silent .PHONY: help all: help help: Makefile @echo @echo \u0026#34; Choose a command run in \u0026#34;$(PROJECTNAME)\u0026#34;:\u0026#34; @echo @sed -n \u0026#39;s/^##//p\u0026#39; $\u0026lt; | column -t -s \u0026#39;:\u0026#39; | sed -e \u0026#39;s/^/ /\u0026#39; @echo go-compile: clean-bin go-get go-build go-build: @echo \u0026#34; \u0026gt; Building binary...\u0026#34; @GOOS=linux GOARCH=amd64 $(GOBUILD) $(GOBIN)/$(PROJECTNAME) @echo \u0026#34; \u0026gt; Building done.\u0026#34; go-race-check: go-get @echo \u0026#34; \u0026gt; Race check start...\u0026#34; @GOOS=linux GOARCH=amd64 $(GOBUILD_RACE) $(GOBIN)/$(PROJECTNAME)_tmp @echo \u0026#34; \u0026gt; Race check done.\u0026#34; @-rm $(GOBIN)/$(PROJECTNAME)_tmp go-generate: @echo \u0026#34; \u0026gt; Generating dependency files...\u0026#34; @GOPATH=$(GOPATH) GOBIN=$(GOBIN) go generate $(generate) go-get: @echo \u0026#34; \u0026gt; Checking if there is any missing dependencies...\u0026#34; #@GOPATH=$(GOPATH) GOBIN=$(GOBIN) go get $(get) go-install: @GOPATH=$(GOPATH) GOBIN=$(GOBIN) go install $(GOFILES) clean-bin: @echo \u0026#34; \u0026gt; Cleaning build cache...\u0026#34; @-rm $(GOBIN)/* 2\u0026gt; /dev/null clean-release: @echo \u0026#34; \u0026gt; Cleaning release file...\u0026#34; @-rm $(GORELEASE)/* 2\u0026gt; /dev/null ## test: Run all test. test: echo \u0026#34;Test Not Implement.\u0026#34; ## install: Install missing dependencies. Runs `go get` internally. e.g; make install get=github.com/foo/bar install: go-get stop: stop-server start-server: stop-server @echo \u0026#34; \u0026gt; $(PROJECTNAME) is available at $(ADDR)\u0026#34; @-$(GOBIN)/$(PROJECTNAME) 2\u0026gt;\u0026amp;1 \u0026amp; echo $$! \u0026gt; $(PID) @cat $(PID) | sed \u0026#34;/^/s/^/ \\\u0026gt; PID: /\u0026#34; stop-server: @-touch $(PID) @-kill `cat $(PID)` 2\u0026gt; /dev/null || true @-rm $(PID) restart-server: stop-server start-server ## compile: Compile the x86_64 Linux binary without race check. compile: @-touch $(STDERR) @-rm $(STDERR) @-$(MAKE) go-compile 2\u0026gt; $(STDERR) @cat $(STDERR) | sed -e \u0026#39;1s/.*/\\nError:\\n/\u0026#39; | sed \u0026#39;s/make\\[.*/ /\u0026#39; | sed \u0026#34;/^/s/^/ /\u0026#34; 1\u0026gt;\u0026amp;2 ## clean: Clean build files and release file. clean: clean-bin clean-release ## race: Race check. race: @-touch $(STDERR) @-rm $(STDERR) @-$(MAKE) go-race-check 2\u0026gt; $(STDERR) @cat $(STDERR) | sed -e \u0026#39;1s/.*/\\nError:\\n/\u0026#39; | sed \u0026#39;s/make\\[.*/ /\u0026#39; | sed \u0026#34;/^/s/^/ /\u0026#34; 1\u0026gt;\u0026amp;2 ## release: Release arm64 and x86_64 linux binary package. release: clean-release @echo \u0026#34; \u0026gt; Creating release file...\u0026#34; # Build for arm linux @CGO_ENABLED=0 GOOS=linux GOARCH=arm64 $(GOBUILD) $(GORELEASE)/$(BINARY)-arm64-liunx-$(VERSION) # Build for x86_64 linux @CGO_ENABLED=0 GOOS=linux GOARCH=amd64 $(GOBUILD) $(GORELEASE)/$(BINARY)-x86-64-linux-$(VERSION) 参考 跟我一起写Makefile\nhttps://github.com/crossoverJie/btb/blob/master/Makefile Makefiles for Go Developers\ngo-makefile-example\nMake 命令教程\n一个为go准备的优秀makefile\nGNU make\nmakefile跨平台\n","permalink":"https://blog.niuhemoon.win/posts/tech/golang-makefile/","summary":"Makefile基础 语法 # 目标 ：依赖 # 根据依赖生成目标的命令 targets : prerequisites command 变量 Makefile 允许使用等号自定义变量。 txt = Hello World test: @echo $(txt) 上面代码中，变量 txt 等于 Hello World。调用时，变量需要放在 $( ) 之中。 调用Shell变量，需要在美元符号前，再加一个美元符号，这是因为Make命令会对美元符号转义。 test: @echo $$HOME 有","title":"Go语言和Makefile"},{"content":"简介 Typescript 可以在代码编写写做类型检查，可以编写更健壮的代码。\n安装 npm config set registry https://registry.npm.taobao.org sudo npm install -g typescript # 安装REPL sudo npm install -g tsun 基本概念 联合类型\n表示取值是多种类型中的一种，当 TypeScript 不确定一个联合类型的变量到底是哪个类型的时候，我们只能访问此联合类型的所有类型里共有的属性或方法\nlet myFavoriteNumber: string | number; myFavoriteNumber = \u0026#34;seven\u0026#34;; myFavoriteNumber = 7; 接口\nTypeScript 中的接口是一个非常灵活的概念，除了可用于对类的一部分行为进行抽象以外，也常用于对「对象的形状（Shape）」进行描述。 接口是一个类型，不是一个真正的值，它在编译结果中会被删除\n//？可选属性 interface Person { name: string; age?: number; } let tom: Person = { name: \u0026#34;Tom\u0026#34;, }; let tom: Person1 = { name: \u0026#34;Tom\u0026#34;, age: 25, }; //接口可以继承 interface ApiError extends Error { code: number; } 接口可以定义任意类型，但是当同时存在可选类型和任意类型，可选类型需要是任意类型的子集\ninterface Person { name: string; age?: number; //任意类型为联合类型 [propName: string]: string | number; } let tom: Person = { name: \u0026#34;Tom\u0026#34;, age: 25, gender: \u0026#34;male\u0026#34;, }; 接口属性只读，意味着，只有在创建对象时可被赋值，其后无法修改，而且只读属性必须在对象初始化时进行赋值。\ninterface Person { readonly id: number; name: string; age?: number; [propName: string]: any; } let tom: Person = { id: 89757, name: \u0026#34;Tom\u0026#34;, gender: \u0026#34;male\u0026#34;, }; 数组\n习惯性的将数组中的元素类型保持相同\nlet fibonacci: number[] = [1, 1, 2, 3, 5]; //泛型 let fibonacci: Array\u0026lt;number\u0026gt; = [1, 1, 2, 3, 5]; //接口表示数组 //用接口表示数组通常用来标识类型 interface NumberArray { //索引是数字，类型是数字 [index: number]: number; } let fibonacci: NumberArray = [1, 1, 2, 3, 5]; interface IArguments { [index: number]: any; length: number; callee: Function; } 函数\n在 JavaScript 中，有两种常见的定义函数的方式——函数声明（Function Declaration）和函数表达式（Function Expression）; 函数声明和函数表达式的词法环境和执行上下文是不一样的，函数声明会做类型提升。\n// 函数声明（Function Declaration） function sum(x, y) { return x + y; } // 函数表达式（Function Expression） let mySum = function (x, y) { return x + y; }; 可以手动给函数表达式添加类型，也可以使用类型推断 在 TypeScript 的类型定义中，=\u0026gt; 用来表示函数的定义，左边是输入类型，需要用括号括起来，右边是输出类型。 在 ES6 中，=\u0026gt; 叫做箭头函数，应用十分广泛\nlet mySum: (x: number, y: number) =\u0026gt; number = function ( x: number, y: number ): number { return x + y; }; 可选参数用？标识，必须接在必需参数的后面\nfunction buildName(firstName: string, lastName?: string) { if (lastName) { return firstName + \u0026#34; \u0026#34; + lastName; } else { return firstName; } } let tomcat = buildName(\u0026#34;Tom\u0026#34;, \u0026#34;Cat\u0026#34;); let tom = buildName(\u0026#34;Tom\u0026#34;); ES6 中允许给参数添加默认值，Typescript 将添加默认值的参数识别为可选参数，并且添加默认值后，就不受「可选参数必须接在必需参数后面」的限制了 默认值参数在必需参数前的话，需要传一个 undefined 进去占位，因此推荐将默认值参数放在后面\nfunction buildName(firstName: string = \u0026#34;Tom\u0026#34;, lastName: string) { return firstName + \u0026#34; \u0026#34; + lastName; } let tomcat = buildName(\u0026#34;Tom\u0026#34;, \u0026#34;Cat\u0026#34;); //如果默认值参数在必需参数前边，必须传入undefined console.log(buildName(undefined, \u0026#34;cat\u0026#34;)); function buildName1(firstName: string, lastName: string = \u0026#34;Man\u0026#34;) { return firstName + \u0026#34; \u0026#34; + lastName; } console.log(buildName(\u0026#34;good\u0026#34;)); 剩余 rest 参数（不定长参数） rest 参数只能是最后一个参数\n//items是一个数组 function push(array, ...items) { items.forEach(function (item) { array.push(item); }); } let a: any[] = []; push(a, 1, 2, 3); 函数重载允许一个函数接受不同数量或类型的参数时，作出不同的处理。 Typescript 会从最前面的函数定义开始匹配\n//前声明（定义）后实现，将精确的声明写在前面 function reverse(x: number): number; function reverse(x: string): string; function reverse(x: number | string): number | string { if (typeof x === \u0026#34;number\u0026#34;) { return Number(x.toString().split(\u0026#34;\u0026#34;).reverse().join(\u0026#34;\u0026#34;)); } else if (typeof x === \u0026#34;string\u0026#34;) { return x.split(\u0026#34;\u0026#34;).reverse().join(\u0026#34;\u0026#34;); } } 类型断言\n值 as 类型 类型断言只会影响 TypeScript 编译时的类型，类型断言语句在编译结果中会被删除 它不会真的影响到变量的类型。 应用场景:\n将一个联合类型断言为其中一个类型，欺骗 tsc 编译器，可能导致运行时出错 将一个父类断言为更加具体的子类 将任何一个类型断言为 any 将 any 断言为一个具体的类型 限制： typescript 是结构类型系统，不关心定义时的类型关系，只比较最终结构有什么关系\n联合类型可以被断言为其中一个类型 父类可以被断言为子类 任何类型都可以被断言为 any any 可以被断言为任何类型 要使得 A 能够被断言为 B，只需要 A 兼容 B 或 B 兼容 A 即可 //类型比较 //下面两种Cat的定义是等价的 interface Animal { name: string; } interface Cat { name: string; run(): void; } interface Cat extends Animal { run(): void; } //联合类型断言 interface Cat { name: string; run(): void; } interface Fish { name: string; swim(): void; } function isFish(animal: Cat | Fish) { if (typeof (animal as Fish).swim === \u0026#34;function\u0026#34;) { return true; } return false; } //子类断言 interface ApiError extends Error { code: number; } interface HttpError extends Error { statusCode: number; } function isApiError(error: Error) { if (typeof (error as ApiError).code === \u0026#34;number\u0026#34;) { return true; } return false; } //确保代码无误后，绕过类型检查 //在类型的严格性和开发的便利性之间掌握平衡 (window as any).foo = 1; //明确类型，后续有了代码补全，提高可维护性 function getCacheData(key: string): any { return (window as any).cache[key]; } interface Cat { name: string; run(): void; } const tom = getCacheData(\u0026#34;tom\u0026#34;) as Cat; tom.run(); 类型声明比类型断言约束更严格，如 animal 断言为 Cat，只需要满足 Animal 兼容 Cat 或 Cat 兼容 Animal 即可 animal 赋值给 tom，需要满足 Cat 兼容 Animal 才行 可以用泛型替代类型断言\nfunction getCacheData\u0026lt;T\u0026gt;(key: string): T { return (window as any).cache[key]; } interface Cat { name: string; run(): void; } const tom = getCacheData\u0026lt;Cat\u0026gt;(\u0026#34;tom\u0026#34;); tom.run(); 声明文件\n常用的声明语法\ndeclare var 声明全局变量 declare const 声明全局常量 declare function 声明全局方法 declare class 声明全局类 declare enum 声明全局枚举类型 declare namespace 声明（含有子属性的）全局对象 interface 和 type 声明全局类型 export 导出变量 export namespace 导出（含有子属性的）对象 export default ES6 默认导出 export = commonjs 导出模块 export as namespace UMD 库声明全局变量 declare global 扩展全局变量 declare module 扩展模块 /// \u0026lt;reference /\u0026gt; 三斜线指令 类型别名\n类型 c 语言 typedef，在 typescript 中用 type 创建类型别名\ntype Name = string; type NameResolver = () =\u0026gt; string; type NameOrResolver = Name | NameResolver; function getName(n: NameOrResolver): Name { if (typeof n === \u0026#34;string\u0026#34;) { return n; } else { return n(); } } 字面量类型\n约束取值只能是某几个值中的一个\ntype EventNames = \u0026#34;click\u0026#34; | \u0026#34;scroll\u0026#34; | \u0026#34;mousemove\u0026#34;; function handleEvent(ele: Element, event: EventNames) { // do something } handleEvent(document.getElementById(\u0026#34;hello\u0026#34;), \u0026#34;scroll\u0026#34;); // 没问题 handleEvent(document.getElementById(\u0026#34;world\u0026#34;), \u0026#34;dblclick\u0026#34;); // 报错，event 不能为 \u0026#39;dblclick\u0026#39; 元组\n数组合并了相同类型的对象，而元组（Tuple）合并了不同类型的对象; 可以对元组中的单个元素赋值； 当直接对元组类型的变量进行初始化或者赋值的时候，需要提供所有元组类型中指定的项; 当添加越界的元素时，它的类型会被限制为元组中每个类型的联合类型\nlet tom: [string, number] = [\u0026#34;Tom\u0026#34;, 25]; let tom: [string, number]; tom[0] = \u0026#34;Tom\u0026#34;; tom[1] = 25; tom[0].slice(1); tom[1].toFixed(2); tom = [\u0026#34;Tom\u0026#34;, 25]; tom.push(\u0026#34;male\u0026#34;); 枚举\n枚举（Enum）类型用于取值被限定在一定范围内的场景\nenum Days { Sun, Mon, Tue, Wed, Thu, Fri, Sat, } console.log(Days[\u0026#34;Sun\u0026#34;] === 0); // true console.log(Days[\u0026#34;Mon\u0026#34;] === 1); // true console.log(Days[\u0026#34;Tue\u0026#34;] === 2); // true console.log(Days[\u0026#34;Sat\u0026#34;] === 6); // true console.log(Days[0] === \u0026#34;Sun\u0026#34;); // true console.log(Days[1] === \u0026#34;Mon\u0026#34;); // true console.log(Days[2] === \u0026#34;Tue\u0026#34;); // true console.log(Days[6] === \u0026#34;Sat\u0026#34;); // true 类\n传统方法中，JavaScript 通过构造函数实现类的概念，通过原型链实现继承。而在 ES6 中，我们终于迎来了 class 使用 class 定义类，使用 constructor 定义构造函数。 通过 new 生成新实例的时候，会自动调用构造函数。 使用 extends 关键字实现继承，子类中使用 super 关键字来调用父类的构造函数和方法。 使用 getter 和 setter 可以改变属性的赋值和读取行为： 使用 static 修饰符修饰的方法称为静态方法，它们不需要实例化，而是直接通过类来调用，不可以通过实例来调用：\nES6 中实例的属性只能通过构造函数中的 this.xxx 来定义，ES7 提案中可以直接在类里面定义 ES7 提案中，可以使用 static 定义一个静态属性，静态属性属于类； 当构造函数修饰为 private 时，该类不允许被继承或者实例化; 当构造函数修饰为 protected 时，该类只允许被继承，不允许被实例化； 类属性/方法的访问限定符如下:\npublic 修饰的属性或方法是公有的，可以在任何地方被访问到，默认所有的属性和方法都是 public 的 private 修饰的属性或方法是私有的，不能在声明它的类的外部访问 protected 修饰的属性或方法是受保护的，它和 private 类似，区别是它在子类中也是允许被访问的 class Animal { private _name: string; age = 23; static num = 42; constructor(name) { this._name = name; } get name() { return \u0026#34;get \u0026#34; + this._name; } //name是public的，但是_name是私有的 //不能在set name中再对name赋值，会造成死循环 set name(value) { if (value === \u0026#34;Dog\u0026#34;) { console.log(\u0026#34;Animal cannot be dog\u0026#34;); return; } this._name = value; console.log(\u0026#34;setter: \u0026#34; + value); } sayHi() { console.log(`My name is ${this._name}`); } static isAnimal(a) { return a instanceof Animal; } } class Cat extends Animal { constructor(name) { super(name); // 调用父类的 constructor(name) console.log(this.name); } //函数重写 sayHi() { return \u0026#34;Meow, \u0026#34; + super.sayHi(); // 调用父类的 sayHi() } } let a = new Animal(\u0026#34;Jack\u0026#34;); Animal.isAnimal(a); // true let c = new Cat(\u0026#34;Tom\u0026#34;); // Tom console.log(c.sayHi()); // Meow, My name is Tom 参数属性 修饰符和 readonly 还可以使用在构造函数参数中，等同于类中定义该属性同时给该属性赋值 只读属性关键字，只允许出现在属性声明或索引签名或构造函数中 注意如果 readonly 和其他访问修饰符同时存在的话，需要写在其后面。 abstract 用于定义抽象类和其中的抽象方法。 抽象类不允许被实例化，抽象类中的抽象方法必须被子类实现\nabstract class Animal { //public readonly name; public constructor(public readonly name: string) { this.name = name; } //abstract method public abstract eat(); } class Cat extends Animal { public eat() { console.log(`${this.name} is eating.`); } } let a = new Cat(\u0026#34;Tom\u0026#34;); console.log(a.name); // Tom 类和接口\n实现（implements）是面向对象中的一个重要概念。一般来讲，一个类只能继承自另一个类，有时候不同类之间可以有一些共有的特性，这时候就可以把特 性提取成接口（interfaces），用 implements 关键字来实现。这个特性大大提高了面向对象的灵活性。\n接口中所有属性和方法都要求是 public 一个类可以实现一个或者多个接口 接口之间可以是继承关系 接口可以继承类（不推荐），本质上还是接口继承接口，因为在创建类的时候，会创建一个同名的接口类型 创建类时自动生成的类型中包含了除了构造函数的实例属性和实例方法，会保留访问限定符， 如果类属性是 private，将导致该类型的对象无法被初始化，生成的接口类型中不包括：\n静态类型和静态方法 构造函数 interface Alarm { alert(): void; } interface Light { lightOn(): void; lightOff(): void; } class Car implements Alarm, Light { alert() { console.log(\u0026#34;Car alert\u0026#34;); } lightOn() { console.log(\u0026#34;Car light on\u0026#34;); } lightOff() { console.log(\u0026#34;Car light off\u0026#34;); } } 接口继承类（晦涩）\nclass Point { x: number; y: number; constructor(x: number, y: number) { this.x = x; this.y = y; } } interface PointInstanceType { x: number; y: number; } // 等价于 interface Point3d extends PointInstanceType interface Point3d extends Point { z: number; } let point3d: Point3d = { x: 1, y: 2, z: 3 }; 泛型\n泛型（Generics）是指在定义函数、接口或类的时候，不预先指定具体的类型，而在使用的时候再指定类型的一种特性\nfunction createArray\u0026lt;T\u0026gt;(length: number, value: T): Array\u0026lt;T\u0026gt; { let result: T[] = []; for (let i = 0; i \u0026lt; length; i++) { result[i] = value; } return result; } createArray\u0026lt;string\u0026gt;(3, \u0026#34;x\u0026#34;); // [\u0026#39;x\u0026#39;, \u0026#39;x\u0026#39;, \u0026#39;x\u0026#39;] //多个类型参数 function swap\u0026lt;T, U\u0026gt;(tuple: [T, U]): [U, T] { return [tuple[1], tuple[0]]; } swap([7, \u0026#34;seven\u0026#34;]); // [\u0026#39;seven\u0026#39;, 7] 泛型约束，可以使用其他类型约束，也可以在类型参数之间进行约束\nfunction copyFields\u0026lt;T extends U, U\u0026gt;(target: T, source: U): T { for (let id in source) { target[id] = (\u0026lt;T\u0026gt;source)[id]; } return target; } let x = { a: 1, b: 2, c: 3, d: 4 }; copyFields(x, { b: 10, d: 20 }); 参考 Typescript 入门教程\n深入理解Typescript\n","permalink":"https://blog.niuhemoon.win/posts/tech/typescript-doc/","summary":"简介 Typescript 可以在代码编写写做类型检查，可以编写更健壮的代码。 安装 npm config set registry https://registry.npm.taobao.org sudo npm install -g typescript # 安装REPL sudo npm install -g tsun 基本概念 联合类型 表示取值是多种类型中的一种，当 TypeScript 不确定一个联合类型的变量到底是哪个类型的时候，我们只能访问此联合类型的所有类型里共有的属性或方法 let myFavoriteNumber: string | number; myFavoriteNumber = \u0026#34;seven\u0026#34;; myFavoriteNumber = 7; 接口 TypeScript 中的","title":"Typescript基础"},{"content":"CheatSheet Docker 核心架构：\n客户端 Client 服务器 Docker daemon 镜像 Image Registry 容器 Container 容器基本技术：\ncgroup 资源限额 namespace 资源隔离 Mount UTS IPC PID Network User Docker 采用 C/S 架构，客户端向服务器发送请求，服务器负责构建、运行和分发容器。客户端和服务器可以运行在同一个 host 上，客户端也可以通过 socket 或者 REST API 和远程服务器通信。docker 客户端是和服务器通信的命令行工具。服务器负责创建、运行、监控容器，构建、存储镜像。镜像是一个只读模板，通过镜像可以创建容器。容器就是镜像运行的实例。Registry 是存放镜像的仓库。\n构建镜像并启动容器 镜像管理\n# pull an image from a registry docker pull myimage:1.0 # retag a local image with new name and tag docker tag myimage:1.0 myrepo/myimage:2.0 # push an image to a registry docker push myrepo/myimage:2.0 # 查看本地镜像 docker images # list all images locally stored docker image ls # delete an image from local image store docker image rm alpine:3.4 从镜像启动容器\n# 后台从镜像启动容器，并指定Host和容器的端口映射 docker run -d -p 8000:80 \u0026lt;image\u0026gt; # 进入容器，附加到前台进程 docker attach \u0026lt;容器\u0026gt; # 离开容器 Ctrl+p Ctrl+q # 进入容器，新开一个终端 docker exec -it \u0026lt;容器\u0026gt; bash # 退出容器 exit # 启动exit的容器 docker start \u0026lt;容器\u0026gt; # 停止容器 docker stop \u0026lt;容器\u0026gt; # rum a container from alpine:3.9 image # name the running container \u0026#34;web\u0026#34; # expose port 5000 externally mapped to port 80 inside the container docker container run --name web -p 5000:80 alpine:3.9 # stop a running container through SIGTERM docker container stop web # stop a running container through SIGKILL docker container kill web # delete all running and stopped containers docker container rm -f $(docker ps -aq) # print the last 100 lines of a container\u0026#39;s logs docker container logs --tail 100 web 构建镜像\n# 查看容器 docker ps -a docker container ls -a # 构建镜像 # 1.运行容器 # 2.修改容器 # 3.将容器保存为新镜像 docker commit \u0026lt;镜像\u0026gt; # 从dockerfile构建镜像 docker build -t \u0026lt;image_name\u0026gt; -f \u0026lt;Dockerfile路径\u0026gt; # build an image from Dockerfile in the current directory and tag the image docker build -t myimage:1.0 . # 查看镜像分层 docker history \u0026lt;image\u0026gt; docker 网络 Docker 容器和主机之间网络：\nbridge host none 自定义 网络相关的命令：\nbrctl show # 显示网桥 ip r # 查看路由表 iptables-save # 查看路由 # 查看docker网桥 docker network inspect bridge # 查看docker网络 docker network ls # 以某种网络配置从镜像启动容器 docker run --network=host -it \u0026lt;镜像\u0026gt; bash 镜像的备份与恢复 docker save 导出镜像到本地文件 # Usage $ docker save [OPTIONS] IMAGE [IMAGE...] # 导出golang镜像 $ sudo docker save --output golang.tar golang:1.2 docker load 从本地文件导入文件到镜像库 # Usage $ docker load [OPTIONS] # 导入golang镜像 $ sudo docker load --input golang.tar docker export 导出容器快照到本地文件 # Usage $ docker export [OPTIONS] CONTAINER # 导出hello容器快照 $ sudo docker export --output hello.tar docker import 从容器快照文件中再导入为镜像 # Usage $ docker import [OPTIONS] URL|- [REPOSITORY[:TAG]] # 导入hello快照，并制定镜像标签为hello:1.0 $ cat hello.tar | sudo docker import - hello:1.0 容器监控 # 查看所有容器 docker container ls # 查看容器内进程 docker container top \u0026lt;容器\u0026gt; # 查看容器资源状态 # 1. 所有容器 docker container stats # 2. 特定容器 docker container stats \u0026lt;容器...\u0026gt; 工具\nSysdig Weave Scope cAdvisor Prometheus 容器日志 docker 默认将容器日志发送到 STDOUT 和 STDERR， 此外，docker 还提供了多种 logging driver，帮助从容器中提取运行日志， 默认的 logging driver 是 json-file，将容器日志保存在 json file 中， 可以在 host 目录的/var/lib/docker/containers/目录下找到日志的 json 文件\n一些系统的日志方案\nELK Graylog # 打印容器所有日志 docker logs \u0026lt;容器\u0026gt; # 持续打印日志 docker logs -f \u0026lt;容器\u0026gt; 参考 Docker 从入门到实践\nDocker 快速入门\nDocker 入门教程\n每天 5 分钟玩转 Docker\n","permalink":"https://blog.niuhemoon.win/posts/tech/docker-tutorial/","summary":"CheatSheet Docker 核心架构： 客户端 Client 服务器 Docker daemon 镜像 Image Registry 容器 Container 容器基本技术： cgroup 资源限额 namespace 资源隔离 Mount UTS IPC PID Network User Docker 采用 C/S 架构，客户端向服务器发送请求，服务器负责构建、运行和分发容器。客户端和服务器可以运行在同一个 host 上，客户端也可以通过 socket 或者 REST API 和远程服务器通信。docker 客户端是和服务器通信的命令","title":"docker基本使用"},{"content":"命令行 # 从文件中执行sql语句 sqlite\u0026gt; .read cars.sql # 打开test.db数据库文件，如果文件不存在，创建 sqlite3 test.db # 元命令 # 显示可用表 .tables sqlite\u0026gt; .mode column sqlite\u0026gt; .headers on sqlite\u0026gt; SELECT * FROM Friends; Id Name Sex ---------- ---------- ---------- 1 Jane F 2 Thomas M 3 Franklin M 4 Elisabeth F 5 Mary F 6 Lucy F 7 Jack M 本示例说明如何在 sqlite 的列模式下格式化数据。 .headers命令也已用于显示列标题。 默认情况下，标题是隐藏的。 .width命令调整列的大小。 （此 meta 命令仅与列模式下的表有关。） sqlite\u0026gt; SELECT Name, Title FROM Authors NATURAL JOIN Books; Name Title ----------- ---------- Jane Austen Emma Leo Tolstoy War and Pe Joseph Hell Catch XII Charles Dic David Copp Joseph Hell Good as Go Leo Tolstoy Anna Karen 列宽不足以正确显示所有数据。 sqlite\u0026gt; .width 15 18 sqlite\u0026gt; SELECT Name, Title FROM Authors NATURAL JOIN Books; Name Title --------------- ------------------ Jane Austen Emma Leo Tolstoy War and Peace Joseph Heller Catch XII Charles Dickens David Copperfield Joseph Heller Good as Gold Leo Tolstoy Anna Karenia SQL 在这里，我们更改列宽。 第一列为 15 个字符，第二列为 18 个字符。 .show命令列出了各种设置。 其中包括输出模式，列表模式中使用的分隔符以及标题是否打开。 .schema命令显示表的结构。 它提供了 DDL SQL 来创建表。 sqlite\u0026gt; .schema Cars CREATE TABLE Cars(Id INTEGER PRIMARY KEY, Name TEXT, Price INTEGER); SQL .schema命令显示表的结构。 它提供了 DDL SQL 来创建表。 可以使用.prompt命令更改sqlite3的提示。 sqlite\u0026gt; .prompt \u0026#34;\u0026gt; \u0026#34; \u0026#34;. \u0026#34; \u0026gt; SELECT * FROM Cars . LIMIT 2; Id Name Price ---------- ---------- ---------- 1 Audi 52642 2 Mercedes 57127 \u0026gt; SQL 有两个提示。 一个是主提示，另一个是继续提示。 默认的主提示是sqlite\u0026amp;gt;，默认的继续提示是...\u0026amp;gt;。 我们可以从 Shell 执行 SQL 命令。 $ sqlite3 test.db \u0026#34;SELECT * FROM Cars;\u0026#34; 我们将使用.dump命令转储该表。 sqlite\u0026gt; .output cars2.sql sqlite\u0026gt; .dump Cars SQL 我们还可以将输出重定向到文件。 .output命令会将输出重定向到cars2.sql文件。 sqlite\u0026gt; .tables Authors Cars Friends Reservations Books Customers Orders sqlite\u0026gt; DROP TABLE Cars; sqlite\u0026gt; .tables Authors Customers Orders Books Friends Reservations sqlite\u0026gt; .read cars.sql sqlite\u0026gt; .tables Authors Cars Friends Reservations Books Customers Orders sqlite\u0026gt; SELECT * FROM Cars WHERE Id=1; Id Name Price ---------- ---------- ---------- 1 Audi 52642 在这里，我们得到 SELECT 语句的输出。 默认情况下，输出模式为 line，分隔符为|。\n使用案例 1、输入\u0026quot; sqlite3 + 数据库名.db \u0026quot; (如： \u0026quot; sqlite3 collect.db \u0026ldquo;) 打开数据库\n2、可输入 \u0026quot; .table \u0026quot; 查看数据库中存在哪些表\n3、可输入\u0026rdquo; .schema \u0026rsquo; 查看建表语句\n4、通过 SQL 查询语句 \u0026quot; select _ from 表名 \u0026quot; （如：\u0026quot; select _ from Book \u0026ldquo;）\n参考 sqlite 教程\n","permalink":"https://blog.niuhemoon.win/posts/tech/sqlite3-tutorial/","summary":"命令行 # 从文件中执行sql语句 sqlite\u0026gt; .read cars.sql # 打开test.db数据库文件，如果文件不存在，创建 sqlite3 test.db # 元命令 # 显示可用表 .tables sqlite\u0026gt; .mode column sqlite\u0026gt; .headers on sqlite\u0026gt; SELECT * FROM Friends; Id Name Sex ---------- ---------- ---------- 1 Jane F 2 Thomas M 3 Franklin M 4 Elisabeth F 5 Mary F 6 Lucy F 7 Jack M 本示例说明如何在 sqlite 的列模式下格式化数据。 .headers命令也已用于显示列标题。 默认情况下","title":"sqlite3入门"},{"content":"快捷键 awk 是 linux 上用于文本处理的脚本语言，你可以实现：\n定义变量 使用字符串和算术运算符 使用控制流程和循环 生成格式化的输出 用法：awk [POSIX 或 GNU 风格选项] [--] \u0026#39;程序\u0026#39; 文件 ... POSIX 选项：\tGNU 长选项：(标准) -f 脚本文件\t--file=脚本文件 -F fs\t--field-separator=fs -v var=val\t--assign=var=val 使用变量 $0 整行 $1 第一列字段 $2 第二列字段 $n 第 n 列字段 空格或者制表符是默认的列分隔符 可以通过-F 指定分隔符\nawk -F: \u0026#39;{print $1}\u0026#39; /etc/passwd cat /etc/passwd | awk -F: \u0026#39;{print $1}\u0026#39; 使用脚本文件 将 awk 脚本保存在 testfile 文件中\n{print $1 \u0026#34; home at \u0026#34; $6} 然后执行文件\nawk -F: -f testfile /etc/passwd 预处理和后处理 保存 testfile 如下\nBEGIN { print \u0026#34;Users and thier corresponding home\u0026#34; print \u0026#34; UserName \\t HomePath\u0026#34; print \u0026#34;___________ \\t __________\u0026#34; FS=\u0026#34;:\u0026#34; } { print $1 \u0026#34; \\t \u0026#34; $6 } END { print \u0026#34;The end\u0026#34; } 执行脚本\nawk -f testfile /etc/passwd 内置变量 一些内置变量如下\nFS 指定 field 段分隔符 OFS [Output Filed Separator]输出分隔符 ORS [Output Record Separator] 输出行分隔符 FIELDWIDTHS 按段长度分割 RS [Record Separator]记录分隔符，默认是换行符 指定输出分隔符\nawk \u0026#39;BEGIN{FS=\u0026#34;:\u0026#34;; OFS=\u0026#34;-\u0026#34;} {print $1,$6,$7}\u0026#39; /etc/passwd 使用长度分割\n素材如下，保存为 testrecord：\n1235.96521 927-8.3652 36257.8157 awk \u0026#39;BEGIN{FIELDWIDTHS=\u0026#34;3 4 3\u0026#34;}{print $1,$2,$3}\u0026#39; testrecord 输出如下：\n123 5.96 521 927 -8.3 652 362 57.8 157 使用 Record Separator 素材如下，保存为 testrecord：\nPerson Name 123 High Street (222) 466-1234 Another person 487 High Street (523) 643-8754 awk \u0026#39;BEGIN{FS=\u0026#34;\\n\u0026#34;; RS=\u0026#34;\u0026#34;} {print $1,$3}\u0026#39; testrecord 输出如下：\nPerson Name (222) 466-1234 Another person (523) 643-8754 参考 30 Examples For Awk Command In Text Processing\n","permalink":"https://blog.niuhemoon.win/posts/tech/awk-usage/","summary":"快捷键 awk 是 linux 上用于文本处理的脚本语言，你可以实现： 定义变量 使用字符串和算术运算符 使用控制流程和循环 生成格式化的输出 用法：awk [POSIX 或 GNU 风格选项] [--] \u0026#39;程序\u0026#39; 文件 ... POSIX 选项： GNU 长选项：(标准) -f 脚本文件 --file=脚本文件 -F fs --field-separator=fs -v var=val --assign=var=val 使用变量 $0 整行 $1 第一列字段 $2 第二列字","title":"awk基本使用"},{"content":"# 创建目录并进入 function mkdircd () { mkdir -p \u0026#34;$@\u0026#34; \u0026amp;\u0026amp; eval cd \u0026#34;\\\u0026#34;\\$$#\\\u0026#34;\u0026#34;; } 查找文件 # 找到大于100M的文件 find / -type f -size +100M # 找到文件名中含有mail的文件/文件夹 find /etc -name \u0026#34;*mail*\u0026#34; # 找到修改时间在60天之前的文件 find . -mtime +60 # 找到修改时间在2天内的文件 find . -mtime -2 # 批量显示TS后缀且大于100M文件的详情 find . -type f -name \u0026#39;*.TS\u0026#39; -size +100M -exec ls -l {} \\; # 批量删除TS后缀且大于100M的文件 find . -type f -name \u0026#39;*.TS\u0026#39; -size +100M -exec rm -f {} \\; # 查找修改时间60天前的文件并打包 find /home/jsmith -type f -mtime +60 | xargs tar -cvf /tmp/`date \u0026#39;+%d%m%Y\u0026#39;_archive.tar` 输出重定向 # 标准输出重定向，只显示error信息 ./shell-script.sh \u0026gt; /dev/null # 标准错误信息重定向 ./shell-script.sh 2\u0026gt; /dev/null # 标准错误和输出都重定向 ./shell-script.sh \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 # 将所有大写转化为小写 tr A-Z a-z \u0026lt; department.txt # 将所有小写转化为大写 tr a-z A-Z \u0026lt; employee.txt xargs 基本使用 # 删除log文件 find ~ -name \u0026#39;*.log\u0026#39; -print0 | xargs -0 rm -f find /etc -name \u0026#34;*.conf\u0026#34; | xargs ls -l cat url-list.txt | xargs wget -c find / -name *.jpg -type f -print | xargs tar -cvzf images.tar.gz ls *.jpg | xargs -n1 -i cp {} /external-harddrive/directory 文件中截取列 # 以:分割，第一列 cut -d: -f 1 /etc/passwd # 以:分割，第1和第3列 cut -d: -f 1,3 /etc/passwd # 截取每行前边1-8个字符 cut -c 1-8 /etc/passwd 后台运行 nohup ./backup.sh \u0026amp; screen -S backup # 以特定间隔时间执行命令 watch df -h sed 基础 # thegeekstuff.txt # Instruction Guides 1. Linux Sysadmin, Linux Scripting etc. 2. Databases - Oracle, mySQL etc. 3. Security (Firewall, Network, Online Security etc) 4. Storage in Linux 5. Productivity (Too many technologies to explore, not much time available) # Additional FAQS 6. Windows- Sysadmin, reboot etc. # 将第一个Linux替换为Linux-Unix sed \u0026#39;s/Linux/Linux-Unix/\u0026#39; thegeekstuff.txt # 将所有Linux替换为Linux-Unix sed \u0026#39;s/Linux/Linux-Unix/g\u0026#39; thegeekstuff.txt # 将第2个出现的Linux替换为Linux-Unix sed \u0026#39;s/Linux/Linux-Unix/2\u0026#39; thegeekstuff.txt # 输出修改行并写入指定的output文件 sed -n \u0026#39;s/Linux/Linux-Unix/gpw output\u0026#39; thegeekstuff.txt # 行正则匹配到-，则从-到行尾的字符被替换为空 sed \u0026#39;/\\-/s/\\-.*//g\u0026#39; thegeekstuff.txt # 删除每行的后3个字符 sed \u0026#39;s/...$//\u0026#39; thegeekstuff.txt # 直接修改源文件，去除#开头的注释 sed -e \u0026#39;s/#.*//\u0026#39; thegeekstuff.txt # 直接修改源文件，去除#开头的注释并去除空行 sed -e \u0026#39;s/#.*//;/^$/d\u0026#39; thegeekstuff.txt # 去除html的箭头标签 sed -e \u0026#39;s/\u0026lt;[^\u0026gt;]*\u0026gt;//g\u0026#39; # 同时显示多个文件的日志 tail -f /var/log/syslog -f /var/log/auth.log # 修改命令行提示符号 export PS1=\u0026#34;\\u@\\h \\w\u0026gt; \u0026#34; # 修改系统时间 date {mmddhhmiyyyy.ss} # Jan 31st 2009, 10:19 p.m, 53 seconds date 013122192009.53 date +%Y%m%d -s \u0026#34;20090131\u0026#34; date +%T -s \u0026#34;22:19:53\u0026#34; date -s \u0026#34;01/31/2009 22:19:53\u0026#34; # 显示时间 date +\u0026#34;%d-%m-%Y\u0026#34; 01-01-2009 date +\u0026#34;%d/%m/%Y\u0026#34; # 01/01/2009 date +\u0026#34;%A,%B %d %Y\u0026#34; # Thursday,January 01 2009 压缩和解压 zip var-log-files.zip /var/log/* zip -r var-log-dir.zip /var/log/ unzip var-log.zip unzip -v var-log.zip unzip -l var-log.zip unzip -t var-log.zip zip -P mysecurepwd var-log-protected.zip /var/log/* unzip var-log-protected.zip tar [options] [tar-archive-name] [other-file-names] # 压缩文件 tar cvf /tmp/my_home_directory.tar /home/jsmith # 显示压缩文件目录 tar tvf /tmp/my_home_directory.tar # 提取压缩文件 tar xvf /tmp/my_home_directory.tar # 指定提取目录 tar xvfz /tmp/my_home_directory.tar.gz -C /home/ramesh # gzip压缩文件(*.tar.gz) tar cvfz /tmp/my_home_directory.tar.gz /home/jsmith tar xvfz /tmp/my_home_directory.tar.gz tar tvfz /tmp/my_home_directory.tar.gz # bzip压缩文件(*.tar.bz2) tar cvfj /tmp/my_home_directory.tar.bz2 /home/jsmith tar xvfj /tmp/my_home_directory.tar.bz2 tar tvfj /tmp/my_home_directory.tar.bz2 命令行历史 # CTRL+r 查找匹配历史 # CTRL+p 上一条命令 history -c # 清除历史 # 忽略重复命令 export HISTCONTROL=ignoredups # 忽略以空格开头的命令 export HISTCONTROL=ignorespace # 不记录历史 export HISTSIZE=0 系统管理 # 创建swap分区 dd if=/dev/zero of=/home/swap-fs bs=1M count=512 ls -l /home/swap-fs mkswap /home/swap-fs swapon /home/swap-fs # edit in /etc/fstab /home/swap-fs swap swap defaults 0 0 # 生成ssh公钥 ssh-keygen ssh-copy-id -i ~/.ssh/id_rsa.pub remote-host # 定时任务管理 crontab -e {minute} {hour} {day-of-month} {month} {day-of-week} {full-path-to-shell-script} # run at 00:01am 1 0 * * * /root/bin/backup.sh # run at weekday 11:59pm 59 11 * * 1,2,3,4,5 /root/bin/backup.sh 59 11 * * 1-5 /root/bin/backup.sh # run every 5 minute */5 * * * * /root/bin/check-status.sh # run at 13:10pm on lst of every month 10 13 1 * * /root/bin/full-backup.sh # run at 11:00pm every weekday 0 23 * * 1-5 /root/bin/incremental-backup.sh # 同步文件 rsync options source destination # sync two directory in a local computer # -z enable compression # -v verbose # -r recursive # -a archive mode:will preserve symbolic link/permission/timestamp/owner/group rsync -zvr /var/opt/installation/inventory/ /root/temp # sync one file rsync -v /var/lib/rpm/Pubkeys /root/temp/ # sync to remote machine rsync -avz /root/temp/ thegeekstuff@192.168.200.10:/home/thegeekstuff/temp/ # sync from remote to local rsync -avz thegeekstuff@192.168.200.10:/var/lib/rpm /root/temp # netcat命令nc # 从server1拷贝文件到server2 # 1. 在server2(102.168.200.27)上监听 nc -l 2222 \u0026gt; 1234.txt # 2. 在server1上开启传输 nc -w 1 102.168.200.27 2222 \u0026lt; abc.txt # 网络拷贝硬盘 # 1. server2(102.168.200.27)监听 nc -l -p 2222 | dd of=/dev/sda # 2. server1执行传输 dd if=/dev/sda | nc 102.168.200.27 2222 # nc端口扫描 # 扫描20-30端口 nc -v -w 1 192.168.200.29 -z 20-30 系统性能监控 ps axl ps aux ps axuf ps U niuhe netstat -tap netstat --route # 路由表 sar lsof ","permalink":"https://blog.niuhemoon.win/posts/tech/linux-101-hackers/","summary":"# 创建目录并进入 function mkdircd () { mkdir -p \u0026#34;$@\u0026#34; \u0026amp;\u0026amp; eval cd \u0026#34;\\\u0026#34;\\$$#\\\u0026#34;\u0026#34;; } 查找文件 # 找到大于100M的文件 find / -type f -size +100M # 找到文件名中含有mail的文件/文件夹 find /etc -name \u0026#34;*mail*\u0026#34; # 找到修改时间在60天之前的文件 find . -mtime +60 # 找到修改时间在2天内的文件 find . -mtime -2 # 批量显示TS后缀且大于100M文件的详情 find . -type f -name \u0026#39;*.TS\u0026#39; -size +100M -exec ls -l {} \\; # 批","title":"linux 101 Hackers 笔记"},{"content":"快捷键 CTRL+B 打开/收起侧边栏目\nCTRL+` 打开内置终端\nCTRL+, 打开设置\nCTRL+p 快速搜索并打开文件\nCTRL+TAB 在已经打开的标签页中跳转\nCTRL+\\ 将标签页移动到右侧分割栏\nCTRL+w 关闭标签页\nCTRL+f 查找内容\nCTRL+h 查找并替换\nCTRL+SHIFT+f 全局搜索\nCTRL+SHIFT+p 命令面板\nCTRL+/ 注释/解除注释\nCTRL+HOME/END 跳转到文件首/尾\nCTRL+c/v 复制或剪切当前光标行/在当前光标行或下一行粘贴\nCTRL+SHIFT+箭头上下箭头 多个光标用于列编辑\nALT+CLICK 获取多个编辑的光标\nCTRL+d 选中单词\nCTRL+SHIFT+l 选中所有该选中的内容\nF2 重命名变量\nCTRL+CLICK 代码跳转\nCTRL+k z 进入/推出 zen 模式\n官方常用快捷键 General Ctrl+Shift+P, F1 Show Command Palette Ctrl+P Quick Open, Go to File\u0026hellip; Ctrl+Shift+N New window/instance Ctrl+W Close window/instance Ctrl+, User Settings Ctrl+K Ctrl+S Keyboard Shortcuts Basic editing Ctrl+X Cut line (empty selection) Ctrl+C Copy line (empty selection) Alt+ ↓ / ↑ Move line down/up Ctrl+Shift+K Delete line Ctrl+Enter / Insert line below/ above Ctrl+Shift+Enter Ctrl+Shift+\\ Jump to matching bracket Ctrl+] / Ctrl+[ Indent/Outdent line Home / End Go to beginning/end of line Ctrl+ Home / End Go to beginning/end of file Ctrl+ ↑ / ↓ Scroll line up/down Alt+ PgUp / PgDn Scroll page up/down Ctrl+Shift+ [ / ] Fold/unfold region Ctrl+K Ctrl+ [ / ] Fold/unfold all subregions Ctrl+K Ctrl+0 / Fold/Unfold all regions Ctrl+K Ctrl+J Ctrl+K Ctrl+C Add line comment Ctrl+K Ctrl+U Remove line comment Ctrl+/ Toggle line comment Ctrl+Shift+A Toggle block comment Alt+Z Toggle word wrap Rich languages editing Ctrl+Space Trigger suggestion Ctrl+Shift+Space Trigger parameter hints Ctrl+Shift+I Format document Ctrl+K Ctrl+F Format selection F12 Go to Definition Ctrl+Shift+F10 Peek Definition Ctrl+K F12 Open Definition to the side Ctrl+. Quick Fix Shift+F12 Show References F2 Rename Symbol Ctrl+K Ctrl+X Trim trailing whitespace Ctrl+K M Change file language Multi-cursor and selection Alt+Click Insert cursor* Shift+Alt+ ↑ / ↓ Insert cursor above/below Ctrl+U Undo last cursor operation Shift+Alt+I Insert cursor at end of each line selected Ctrl+L Select current line Ctrl+Shift+L Select all occurrences of current selection Ctrl+F2 Select all occurrences of current word Shift+Alt + → Expand selection Shift+Alt + ← Shrink selection Shift+Alt + drag mouse Column (box) selection Display F11 Toggle full screen Shift+Alt+0 Toggle editor layout (horizontal/vertical) Ctrl+ = / - Zoom in/out Ctrl+B Toggle Sidebar visibility Ctrl+Shift+E Show Explorer / Toggle focus Ctrl+Shift+F Show Search Ctrl+Shift+G Show Source Control Ctrl+Shift+D Show Debug Ctrl+Shift+X Show Extensions Ctrl+Shift+H Replace in files Ctrl+Shift+J Toggle Search details Ctrl+Shift+C Open new command prompt/terminal Ctrl+K Ctrl+H Show Output panel Ctrl+Shift+V Open Markdown preview Ctrl+K V Open Markdown preview to the side Ctrl+K Z Zen Mode (Esc Esc to exit) Search and replace Ctrl+F Find Ctrl+H Replace F3 / Shift+F3 Find next/previous Alt+Enter Select all occurrences of Find match Ctrl+D Add selection to next Find match Ctrl+K Ctrl+D Move last selection to next Find match Navigation Ctrl+T Show all Symbols Ctrl+G Go to Line\u0026hellip; Ctrl+P Go to File\u0026hellip; Ctrl+Shift+O Go to Symbol\u0026hellip; Ctrl+Shift+M Show Problems panel F8 Go to next error or warning Shift+F8 Go to previous error or warning Ctrl+Shift+Tab Navigate editor group history Ctrl+Alt+- Go back Ctrl+Shift+- Go forward Ctrl+M Toggle Tab moves focus Editor management Ctrl+W Close editor Ctrl+K F Close folder Ctrl+\\ Split editor Ctrl+ 1 / 2 / 3 Focus into 1st, 2nd, 3rd editor group Ctrl+K Ctrl + ← Focus into previous editor group Ctrl+K Ctrl + → Focus into next editor group Ctrl+Shift+PgUp Move editor left Ctrl+Shift+PgDn Move editor right Ctrl+K ← Move active editor group left/up Ctrl+K → Move active editor group right/down File management Ctrl+N New File Ctrl+O Open File\u0026hellip; Ctrl+S Save Ctrl+Shift+S Save As\u0026hellip; Ctrl+W Close Ctrl+K Ctrl+W Close All Ctrl+Shift+T Reopen closed editor Ctrl+K Enter Keep preview mode editor open Ctrl+Tab Open next Ctrl+Shift+Tab Open previous Ctrl+K P Copy path of active file Ctrl+K R Reveal active file in Explorer Ctrl+K O Show active file in new window/instance Debug F9 Toggle breakpoint F5 Start / Continue F11 / Shift+F11 Step into/out F10 Step over Shift+F5 Stop Ctrl+K Ctrl+I Show hover Integrated terminal Ctrl+` Show integrated terminal Ctrl+Shift+` Create new terminal Ctrl+Shift+C Copy selection Ctrl+Shift+V Paste into active terminal Ctrl+Shift+ ↑ / ↓ Scroll up/down Shift+ PgUp / PgDn Scroll page up/down Shift+ Home / End Scroll to top/bottom Keyboard shortcuts for Linux The Alt+Click gesture may not work on some Linux distributions. You can change the modifier key for the Insert cursor command to Ctrl+Click with the \u0026rsquo;editor.multiCursorModifier\u0026rsquo; setting\n导入/导出扩展 //导出扩展名 code --list-extensions \u0026gt;\u0026gt; vs_code_extensions_list.txt cat vs_code_extensions_list.txt | xargs -n 1 code --install-extension //删除所有扩展 code --list-extensions | xargs -n 1 code --uninstall-extension 2gua.rainbow-brackets Angular.ng-template cyrilletuzi.angular-schematics davidbabel.vscode-simpler-icons dbaeumer.vscode-eslint doggy8088.angular-extension-pack donjayamanne.githistory eamodio.gitlens EditorConfig.EditorConfig EFanZh.graphviz-preview esbenp.prettier-vscode formulahendry.auto-rename-tag golang.go Gruntfuggly.todo-tree humao.rest-client infinity1207.angular2-switcher jebbs.plantuml johnpapa.Angular2 krizzdewizz.refactorix MariusAlchimavicius.json-to-ts Mikael.Angular-BeastCode mikeburgh.xml-format ms-azuretools.vscode-docker ms-mssql.mssql ms-python.python ms-toolsai.jupyter ms-vscode-remote.remote-containers ms-vscode-remote.remote-ssh ms-vscode-remote.remote-ssh-edit ms-vscode.cpptools ms-vscode.typescript-javascript-grammar ms-vscode.vscode-typescript-tslint-plugin msjsdiag.debugger-for-chrome nhoizey.gremlins obenjiro.arrr oderwat.indent-rainbow PKief.material-icon-theme quicktype.quicktype shd101wyy.markdown-preview-enhanced steoates.autoimport stringham.move-ts tht13.html-preview-vscode twxs.cmake wayou.vscode-todo-highlight xabikos.JavaScriptSnippets ","permalink":"https://blog.niuhemoon.win/posts/tech/vscode-shortcut/","summary":"快捷键 CTRL+B 打开/收起侧边栏目 CTRL+` 打开内置终端 CTRL+, 打开设置 CTRL+p 快速搜索并打开文件 CTRL+TAB 在已经打开的标签页中跳转 CTRL+\\ 将标签页移动到右侧分割栏 CTRL+w 关闭标签页 CTRL+f 查找内容 CTRL+h 查找并替换 CTRL+SHIFT+f 全局搜索 CTRL+SHIFT+p 命令面板 CTRL+/ 注释/解除注释 CTRL+HOME/END 跳转到文件首/尾 CTRL+c/v 复制或剪切当前光标行/在当前光标行或下一行粘贴 CTRL+SHIFT+","title":"vscode 快捷键和插件记录"},{"content":"创建虚拟机 1、界面或命令行通过RESTful API向keystone获取认证信息。\n2、keystone通过用户请求认证信息，并生成auth-token返回给对应的认证请求。\n3、界面或命令行通过RESTful API向nova-api发送一个boot instance的请求（携带auth-token）。\n4、nova-api接受请求后向keystone发送认证请求，查看token是否为有效用户和token。\n5、keystone验证token是否有效，如有效则返回有效的认证和对应的角色（注：有些操作需要有角色权限才能操作）。\n6、通过认证后nova-api和数据库通讯。\n7、初始化新建虚拟机的数据库记录。\n8、nova-api通过rpc.call向nova-scheduler请求是否有创建虚拟机的资源(Host ID)。\n9、nova-scheduler进程侦听消息队列，获取nova-api的请求。\n10、nova-scheduler通过查询nova数据库中计算资源的情况，并通过调度算法计算符合虚拟机创建需要的主机。\n11、对于有符合虚拟机创建的主机，nova-scheduler更新数据库中虚拟机对应的物理主机信息。\n12、nova-scheduler通过rpc.cast向nova-compute发送对应的创建虚拟机请求的消息。\n13、nova-compute会从对应的消息队列中获取创建虚拟机请求的消息。\n14、nova-compute通过rpc.call向nova-conductor请求获取虚拟机消息。（Flavor）\n15、nova-conductor从消息队队列中拿到nova-compute请求消息。\n16、nova-conductor根据消息查询虚拟机对应的信息。\n17、nova-conductor从数据库中获得虚拟机对应信息。\n18、nova-conductor把虚拟机信息通过消息的方式发送到消息队列中。\n19、nova-compute从对应的消息队列中获取虚拟机信息消息。\n20、nova-compute通过keystone的RESTfull API拿到认证的token，并通过HTTP请求glance-api获取创建虚拟机所需要镜像。\n21、glance-api向keystone认证token是否有效，并返回验证结果。\n22、token验证通过，nova-compute获得虚拟机镜像信息(URL)。\n23、nova-compute通过keystone的RESTfull API拿到认证k的token，并通过HTTP请求neutron-server获取创建虚拟机所需要的网络信息。\n24、neutron-server向keystone认证token是否有效，并返回验证结果。\n25、token验证通过，nova-compute获得虚拟机网络信息。\n26、nova-compute通过keystone的RESTfull API拿到认证的token，并通过HTTP请求cinder-api获取创建虚拟机所需要的持久化存储信息。\n27、cinder-api向keystone认证token是否有效，并返回验证结果。\n28、token验证通过，nova-compute获得虚拟机持久化存储信息。\n29、nova-compute根据instance的信息调用配置的虚拟化驱动来创建虚拟机。\n以Nova为例，nova/compute目录并不是一定在nova-compute节点上运行，而主要是和compute相关(虚拟机操作相关）的功能实现，同样的，scheduler目录代码并不全在scheduler服务节点运行，但主要是和调度相关的代码。不过目录结构遵循一定的规律。\n通常一个OpenStack项目的代码目录都会包含api.py、rpcapi.py、manager.py，这三个是最重要的模块。\napi.py： 通常是供其它组件调用的封装库。换句话说，该模块通常并不会由本模块调用。比如compute目录的api.py，通常由nova-api服务的controller调用。可以简单认为是供其他服务调用的sdk。 rpcapi.py：这个是RPC请求的封装，或者说是RPC封装的client端，该模块封装了RPC请求调用。 manager.py： 这个才是真正服务的功能实现，也是RPC的server端，即处理RPC请求的入口，实现的方法通常和rpcapi实现的方法一一对应。 关机流程\nAPI节点 nova-api接收用户请求 -\u0026gt; nova-api调用compute/api.py -\u0026gt; compute/api调用compute/rpcapi.py -\u0026gt; rpcapi.py向目标计算节点发起stop_instance()RPC请求 计算节点 收到stop_instance()请求 -\u0026gt; 调用compute/manager.py的callback方法stop_instance() -\u0026gt; 调用libvirt关机虚拟机\n前面提到OpenStack项目的目录结构是按照功能划分的，而不是服务组件，因此并不是所有的目录都能有对应的组件。仍以Nova为例:\nnova/cmd：这是服务的启动脚本，即所有服务的main函数。看服务怎么初始化，就从这里开始。 nova/db: 封装数据库访问，目前支持的driver为sqlalchemy。 nova/conf：Nova所有配置项声明都放在这个目录。 nova/locale: 本地化处理。 nova/image: 封装Glance接口。 nova/network: 封装Neutron接口。 nova/volume: 封装Cinder接口。 nova/virt: 这是支持的所有虚拟化驱动实现，即compute driver实现，主流的如libvirt、hyperv、ironic、vmwareapi等。 nova/objects: 对象模型，封装了所有Nova对象的CURD操作，相对以前直接调用db的model更安全，并且支持版本控制。 nova/policies： API policy集合。 nova/tests: 测试代码，如单元测试、功能测试。 nova/hacking: Nova代码规范定义的一些规则。 nova \u0026ndash;debug boot \u0026ndash;image 81e58b1a-4732-4255-b4f8-c844430485d2 \u0026ndash;flavor 1 yikun\ncontroller的index方法对应list操作、show方法对应get操作、create对应创建操作、delete对应删除操作、update对应更新操作等。\nopenstack-nova-compute.service 两个职责，其一，是守护进程，负责基于各种虚拟化技术Hypervisior实现创建和终止虚拟机；其二，整合了计算资源CPU，存储，网络三类资源部署管理虚拟机，实现计算能力的交付。\nCell V2的设计思想是，由API、Super Conductor去访问上层的全局数据库（nova_api数据库），而底下的cell中的组件，只需要关心cell中的逻辑即可\n首先，api中进行第一次Quota检测，主要方法就是收集地下各个cell数据库中的资源信息，然后和api数据库中的quota上限进行对比。例如，一个用户可以创建10个虚拟机，在cell1中有2个，cell2中有7个，再创建一个虚拟机时，会搜集cell1和cell2中的虚拟机个数之和（9个），然后加上变化（新增一个），与总配额进行比较。 二次检测（cell v2在super conductor里做）。由于在并发场景下，可能出现同时检测发现满足，之后进行创建，就会造成配额的超分，针对这个问题，社区目前给出的方案是，在创建虚拟机记录之后，再进行recheck，如果发现超额了，会将超额分配的虚拟机标记为ERROR，不再继续往下走了。 在Cell v2场景，虚拟机的创建记录已经需要写入的子cell中，因此，conductor需要做的事，包括一下几个步骤：\n进行调度，选出host。 根据host，通过host_mappings找到对应的cell 在对应的cell db中创建虚拟机记录，并且记录instances_mappings信息 通过cell_mappings来查找对应的cell的mq，然后投递到对应的cell中的compute 完成这些操作时，需要牵扯到3个关键的数据结构，我们来简单的看一下：\nhost_mappings：记录了host和cell的映射信息 instances_mappings：记录了虚拟机和cell的映射信息 cell_mappings：记录了cell和cell对应的mq的映射信息 与Cell v1不太相同，在目前的设计中，认为scheduler能看到的应该是底下能够提供资源的具体的所有的Resource Provider（对于计算资源来说，就是所有的计算节点），而不是整个cell，也就是说所有cell中的资源scheduler都可以看到，而子cell就负责创建就好了。因此，在super conductor中，需要做一些transfer的事情，这样也就不必在像cell v1那样，在子cell里还得搞个scheduler去做调度。\n通过Placement获取可用的备选资源，参考Placement Allocation Requests的实现。 在Ocata版本时，Resource Providers - Scheduler Filters in DB这个BP就已经在调度前加了一步，获取备选节点。从BP的标题就可以看出，设计者想通过Placement服务提供的新的一套机制，来做过滤。原因是之前的调度需要在scheduler维护每一个compute节点的hoststate信息，然后调度的时候，再一个个去查，这太低效了，尤其是在计算节点数目比较多的时候。因此，增加了一个“预过滤”的流程，通过向Placement查询，Placement服务直接通过SQL去查一把，把满足条件（比如CPU充足、RAM充足等）先获取到。 而原来获取备选节点的时候，只支持获取单一的Resource Provider，这个BP增强了获取备选资源的能力，用于后续支持更复杂的请求，比如共享资源、嵌套资源的Provider查询。后面，Placement还会陆续支持更多的请求，比如对一些非存量不可计数的资源的支持。这样留给后面Filter\u0026amp;Weight的压力就小一些了，再往后，会不会完全取代Filter呢？我想，现有的各种过滤都可以通过Placement支持后，完全有可能的。 Scheduler通过Placement来claim资源。参考Scheduler claiming resources to the Placement API的实现。 在最早的时候，claim资源是由compute来做的，现在相当于提前到scheduler去搞了。有什么好处呢？我们先看看原来的问题： 调度时刻和真正的去compute节点去claim资源的时刻之间是由一段时间的，在资源不是那么充足的环境，就会造成在scheduler调度的时候，资源还没刷新，所以调度时候成功了，但是真正下来的时候，才发现compute实际已经没有资源了，然后又“跨越半个地球”去做重调度，无形地增加了系统的负载。 而且增加了创建的时长（哦，哪怕创建失败呢？），你想想，用户创了那么久的虚拟机，最后你告诉我调度失败了，用户不太能忍。 所以这个BP就把Claim资源放在调度处了，我上一个调度请求处理完，马上就告诉placement，这资源老子用了，其他人不要动了。OK，世界终于清净了，能拿到资源的拿到了，拿不到资源的马上也知道自己拿不到了，大大增强了调度的用户体验。 2.4 Placement 恩，在调度的时候，已经介绍过这个服务了，在虚拟机创建的流程中，比较常用的接口就是获取备选资源和claim资源。 Placement目标很宏伟，大致的作用就是：资源我来管，要资源问我要，用了资源告诉我。后面准备用一篇文章整体介绍一下Placement。（yep，这个Flag我立下了，会写的）\nservice的详细信息主要包括如下几项： binary, host, zone, status, state 其中： binary，可以理解为service的名称，类似于nova-compute； host是service所在的主机名称； zone是service所属的AZ，其实就是service所在的主机所属的aggregate，只是aggregate的概念不对外呈现，所以用户看到的是AZ。其实，在Nova内部，AZ是AG的metadata而已。\nzone的确定，涉及到两个配置项，对于非计算节点，zone的名称依赖于配置项internal_service_availability_zone（默认是internal）； 对于计算节点，如果不属于任何AG，或者所属的AG没有AZ的metadata信息，默认的zone依赖于配置项default_availability_zone（默认是nova）。 status是服务disable属性的体现，该属性可以直接通过API修改; state是服务真实的状态，是通过servicegroup api获取。每个服务在启动时会加入servicegroup，以db后端为例，会在服务中启动定时器，更新service表中的report_count的值，同时也会刷新更新时间，后续会根据这个更新时间确定服务的死活；\n当然，查询service信息也支持过滤条件，比如： 1、查询某个host相关的service； 2、按binary名称查询service；\n其实Nova中没有host这个独立的资源（数据库对象），但是Nova却有针对host的API操作，其实，在内部实现中，就是通过前面的service信息，间接组装返回host信息。\n租户：配额\n与此同时，虚拟机state或task_state发生变化时，也会向外部发送通知。 前提是配置项notify_on_state_change要配置为vm_state或vm_and_task_state。 Nova中的虚拟机每个操作（启动、停止、暂停、恢复等等），都会在db中保存相关的操作记录，给用户提供查询。利用这个功能，用户对自己的虚拟机整个生命周期的过程和状态都会了如指掌，便于用户的管理。参见这里。示例如下：\n在内部实现中，nova-api层会记录action开始的记录，在nova-compute层，则会添加event开始和结束的信息，action和event根据request id（一次消息请求的标识）关联。\n先说通知，虚拟机操作异常时，一般都会发送error通知，通知中包含异常的函数名称、异常时函数的参数以及异常信息。 再说db，虚拟机操作异常时，无论是在conductor, scheduler还是compute层，除了会发送通知外，还会记录异常信息到数据库（instance_faults表），当查询虚拟机信息时，会返回虚拟机的异常信息。 一个hypervisor，是创建虚拟机能够调度到的最小单元。\napi.py提供对外访问的接口，可以从这开始入手跟踪各个功能实现。 rpcapi.py封装RPC请求调用，大多数是异步调用。 manager.py各种RPC调用的实现，基本和rpcapi.py中调用的名称一一对应。 此外还有一点，Openstack的目录结构是根据功能划分的，比如Nova中compute目录不一定都是在nova-compute节点上运行，而是所有和虚拟机创建相关的功能都在这里。\n从配置文件可以明显的看出，nova-api对应的文件是nova/cmd/api.py的main()函数：\nvm_state\npower_state\ntask_state\n_record_action_start notify_about_instance_action elevated\n@startuml title: 创建虚拟机 participant \u0026#34;API\u0026#34; as api note left of api nova/api/openstack/compute/servers.py end note participant \u0026#34;Scheduler\u0026#34; as sch database \u0026#34;Database\u0026#34; as db #Green participant \u0026#34;Condutor(super)\u0026#34; as pconductor participant \u0026#34;Placement\u0026#34; as placement box \u0026#34;internal service\u0026#34; participant \u0026#34;Compute\u0026#34; as compute participant \u0026#34;Libvirt\u0026#34; as virt end box participant \u0026#34;Conductor(cell)\u0026#34; as ccondutor participant \u0026#34;Neutron\u0026#34; as neutron participant \u0026#34;Cinder\u0026#34; as cinder participant \u0026#34;Glance\u0026#34; as glance autonumber \u0026#34;\u0026lt;b\u0026gt; [00]\u0026#34; [-\u0026gt; api++ : 创建虚拟机 api -\u0026gt; api : validate schema api -\u0026gt; api : get context api -\u0026gt; api : get server_dict api -\u0026gt; api : gen create_kwargs api -\u0026gt; api : policy check api -\u0026gt; api : provision instance api -\u0026gt; glance : 获取镜像信息 api -\u0026gt; api : policy校验 api -\u0026gt; api : 配额校验 api -\u0026gt; api : 添加Group hnote left #FFAAAA vm_state: Building task_state: Scheduling end note api -\u0026gt; db : 创建instance db -\u0026gt; api : create success [\u0026lt;- api : return 202 deactivate api api -\u0026gt; pconductor ++: schedule \u0026amp; build pconductor -\u0026gt; sch : select_destination sch -\u0026gt; placement : get allocation candidates placement -\u0026gt; sch : alloc_reqs.provider_summarys sch -\u0026gt; sch : Filter \u0026amp; weighter sch -\u0026gt; placement : claim Resources placement -\u0026gt; sch : hello sch -\u0026gt; pconductor : return host pconductor -\u0026gt; pconductor : in target cell DB中创建instance pconductor -\u0026gt; pconductor : 配额校验 recheck pconductor -\u0026gt; pconductor : 刷新instance cell 信息 pconductor -\u0026gt; pconductor : 删除build request() pconductor -\u0026gt; compute : 在指定cell中创建虚拟机 hnote left #FFAAAA vm_state: Building task_state: None end note compute -\u0026gt; neutron : 创建网络 hnote left #FFAAAA vm_state: Building task_state: Networking end note compute -\u0026gt; cinder : 构建块设备 hnote left #FFAAAA vm_state: Building task_state: Block Device Mapping end note compute -\u0026gt; compute : spawn() hnote left #FFAAAA vm_state: Building task_state: Spawning end note compute -\u0026gt; glance : 下载镜像 compute -\u0026gt; compute : 生成xml compute -\u0026gt; compute : 刷新虚拟机状态 hnote left #FFAAAA vm_state: Building task_state: None end note @enduml @startuml title: Lock虚拟机 participant \u0026#34;API\u0026#34; as api database \u0026#34;Database\u0026#34; as db #Green autonumber \u0026#34;\u0026lt;b\u0026gt; [00]\u0026#34; [-\u0026gt; api : lock api -\u0026gt; api : get_context api -\u0026gt; api : authorize action [lock] policy api -\u0026gt; db : get instance by id db -\u0026gt; api : done api -\u0026gt; api : check policy api -\u0026gt; db : instance.locked = True\\n locked_by=owner or admin\\n record locked reason db -\u0026gt; api : done [\u0026lt;- api : response @enduml @startuml title: Pause虚拟机 participant \u0026#34;API\u0026#34; as api database \u0026#34;Database\u0026#34; as db #Green box \u0026#34;internal service\u0026#34; participant \u0026#34;Compute\u0026#34; as compute participant \u0026#34;Libvirt\u0026#34; as virt end box autonumber \u0026#34;\u0026lt;b\u0026gt; [00]\u0026#34; [-\u0026gt; api++ : pause instance api -\u0026gt; api : authorize context api -\u0026gt; db++ : get instance by uuid return done api -\u0026gt; api : check policy api -\u0026gt; api : check instance lock api -\u0026gt; api : check instance cell api -\u0026gt; api : ensure instance state is ACTIVE api -\u0026gt; db++ : task_state = PAUSING return done api -\u0026gt; api : record pause action api -\u0026gt; compute++ : pause_instance compute -\u0026gt; compute : notify : pause.start compute -\u0026gt; virt++ : pause virt -\u0026gt; virt : get domain virt -\u0026gt; virt : domain.suspend() return done compute -\u0026gt; db++ : vm_state = PAUSE\\n task_state = None return done compute -\u0026gt; compute : notify: pause.end [\u0026lt;- api : response @enduml @startuml title: Rename虚拟机 participant \u0026#34;API\u0026#34; as api database \u0026#34;Database\u0026#34; as db #Green autonumber \u0026#34;\u0026lt;b\u0026gt; [00]\u0026#34; [-\u0026gt; api : update name activate api api -\u0026gt; api : validate schema api -\u0026gt; api : get context api -\u0026gt; api : authorize [update] policy api -\u0026gt; api : get update_dict[\u0026#34;display_name\u0026#34;] api -\u0026gt; db++ : get server by id return done api -\u0026gt; db : update(update_dict) db -\u0026gt; db : save [\u0026lt;- api : responee @enduml @startuml title: Suspend虚拟机 participant \u0026#34;API\u0026#34; as api database \u0026#34;Database\u0026#34; as db #Green box \u0026#34;internal service\u0026#34; participant \u0026#34;Compute\u0026#34; as compute participant \u0026#34;Libvirt\u0026#34; as virt end box autonumber \u0026#34;\u0026lt;b\u0026gt; [00]\u0026#34; [-\u0026gt; api++ : suspend instance api -\u0026gt; api : authorize context api -\u0026gt; db++ : get instance by uuid return done api -\u0026gt; api : check policy api -\u0026gt; api : check instance lock api -\u0026gt; api : check instance cell api -\u0026gt; api : ensure instance state is ACTIVE api -\u0026gt; db++ : task_state = SUSPANDING return done api -\u0026gt; api : record action : suspand api -\u0026gt; compute++ : suspand_instance compute -\u0026gt; compute : notify : suspand.start compute -\u0026gt; virt++ : suspand virt -\u0026gt; virt : get instance guest virt -\u0026gt; virt : detach pci device virt -\u0026gt; virt : detach sriow ports virt -\u0026gt; virt : guest.save_memory_state() return done compute -\u0026gt; db++ : vm_state = SUSPENDED\\n task_state = None return done compute -\u0026gt; compute : notify: suspend.end [\u0026lt;- api : response @enduml @startuml hide empty description [*] --\u0026gt; State1 State1 --\u0026gt; [*] vm_state:powering\\n task_state:good\\n nihao State1 : this is another string State1 -\u0026gt; State2 State2 --\u0026gt; [*] @enduml @startuml title: Unlock虚拟机 participant \u0026#34;API\u0026#34; as api database \u0026#34;Database\u0026#34; as db #Green autonumber \u0026#34;\u0026lt;b\u0026gt; [00]\u0026#34; [-\u0026gt; api : lock api -\u0026gt; api : get_context api -\u0026gt; api : authorize action [unlock] policy api -\u0026gt; db : get instance by id db -\u0026gt; api : done api -\u0026gt; api : check policy api -\u0026gt; db : query instance.locked db -\u0026gt; api : done api -\u0026gt; db : instance.locked = False\\n locked_by=None\\n clear locked reason db -\u0026gt; api : done [\u0026lt;- api : response @enduml @startuml title: Unpause虚拟机 participant \u0026#34;API\u0026#34; as api database \u0026#34;Database\u0026#34; as db #Green box \u0026#34;internal service\u0026#34; participant \u0026#34;Compute\u0026#34; as compute participant \u0026#34;Libvirt\u0026#34; as virt end box autonumber \u0026#34;\u0026lt;b\u0026gt; [00]\u0026#34; [-\u0026gt; api++ : unpause instance api -\u0026gt; api : authorize context api -\u0026gt; db++ : get instance by uuid return done api -\u0026gt; api : check policy api -\u0026gt; api : check instance lock api -\u0026gt; api : check instance cell api -\u0026gt; api : ensure instance state is PAUSED api -\u0026gt; db++ : task_state = UNPAUSING return done api -\u0026gt; api : record action : unpause api -\u0026gt; compute++ : unpause_instance compute -\u0026gt; compute : notify : unpause.start compute -\u0026gt; virt++ : unpause virt -\u0026gt; virt : get domain virt -\u0026gt; virt : domain.resume() return done compute -\u0026gt; db++ : vm_state = ACTIVE\\n task_state = None return done compute -\u0026gt; compute : notify: unpause.end [\u0026lt;- api : response @enduml 参考 Openstack虚拟机启动方式\nOpenstack源码学习笔记\nOpenstack词汇表\nOpenstack从硬盘启动实例\nNova虚拟机创建流程分析\nNova创建虚拟机流程分析\n如何阅读openstack源码\n虚拟机创建的50个步骤和100个知识点\nOpenstack源码学习之热迁移\n","permalink":"https://blog.niuhemoon.win/posts/tech/create-instance/","summary":"创建虚拟机 1、界面或命令行通过RESTful API向keystone获取认证信息。 2、keystone通过用户请求认证信息，并生成auth-token返回给对应的认证请求。 3、界面或命令行通过RESTful API向nova-api发送一个boot instance的请求（携带aut","title":"openstack创建虚拟机"},{"content":" 不同命令的功能有重复和交集\nOpenstack篇 Openstack每个组件都有其命令，openstack社区为了方便使用，将所有组件的命令进行了统一，以openstack开头\n# 查看所有openstack服务 openstack service list # 查看openstack服务状态 openstack-service status # 重启本节点所有openstack服务 openstack-service restart # openstack服务URL列表查询 # endpoint表示一个服务在哪可被访问的URL和端口号列表 openstack endpoint list # 查询domain，domain是一个keystone验证实体 openstack domain list # 查看nova服务列表 openstack compute service list # 查看网络服务列表 openstack network agent list # ======================================================= # 项目（租户）列表查询 openstack project list # 查看租户详情 openstack project show \u0026lt;project_id/name\u0026gt; # 创建租户 openstack project create --description \u0026#39;Admin Project\u0026#39; \u0026lt;租户名\u0026gt; # 删除租户 openstack project delete \u0026lt;租户id/name\u0026gt; # 禁用启用租户 openstack project set \u0026lt;租户id/name\u0026gt; --disable/enable # 更新租户名称 openstack project set \u0026lt;租户id/name\u0026gt; --name \u0026lt;new name\u0026gt; # ======================================================== # 查看某一个项目下所有用户user openstack user list --project=\u0026lt;project_id/name\u0026gt; # 查看所有用户 openstack user list # 查看用户详情 openstack user show \u0026lt;user_name/id\u0026gt; # 创建用户 openstack user create --domain \u0026lt;域名\u0026gt; --project \u0026lt;项目/租户名\u0026gt; --password \u0026lt;密码\u0026gt; \u0026lt;用户名\u0026gt; # 删除用户 openstack user delete \u0026lt;用户名\u0026gt; # 禁用启用某一个用户 openstack user set \u0026lt;user_name/id\u0026gt; --disable/enable # 更新用户名称 openstack user set \u0026lt;user_name/id\u0026gt; --name \u0026lt;new name\u0026gt; # 查询某一用户与项目、角色的关系 openstack role assignment list --user=用户名 # ======================================================= # 角色查询 # 一个角色包括一组权利和特权，角色访问控制提供预定义的用户可操作列表，如开启或停止虚机，重置密码等。在身份验证服务和计算服务中均被支持。 openstack role list # 角色详情查询 opensatck role show \u0026lt;role_name/id\u0026gt; # 创建角色 openstack role create \u0026lt;role_name\u0026gt; # 分配角色，将项目和用户加入到角色中 openstack role add --user \u0026lt;用户名\u0026gt; --project \u0026lt;项目名\u0026gt; \u0026lt;角色名\u0026gt; # 删除角色 openstack role remove --user \u0026lt;用户名\u0026gt; --project \u0026lt;项目名\u0026gt; \u0026lt;角色名\u0026gt; # ====================================================== # 列出所有的镜像 openstack image list # 查看某一个镜像信息 openstack image show \u0026lt;image_id\u0026gt; # 设置镜像标签 openstack image set --tag \u0026lt;标签名\u0026gt; \u0026lt;image_name/id\u0026gt; # 创建镜像 # 格式化类型包括raw、qcow2、vmdk等 openstack image create \u0026lt;镜像名\u0026gt; --file \u0026lt;镜像文件名\u0026gt; --disk-format \u0026lt;格式化类型\u0026gt; --container-format bare --public # openstack image create “test1” --file cirros-0.5.1-x86_64-disk.img --disk-format qcow2 --container-format bare --public # 查看安全组信息 openstack group list # 查看flavor类型 openstack flavor list # 查询网络信息 openstack network list # 查看端口信息（虚拟网络） openstack port list # 创建虚拟机 openstack server create --image \u0026lt;image_id/name\u0026gt; --flavor \u0026lt;flavor_id/name\u0026gt; --nic net-id=\u0026lt;net_id\u0026gt; \u0026lt;instance_name\u0026gt; # 创建虚拟机帮助 openstack server create --help # ================================================== # 查看openstack环境主机列表 openstack host list # 查看某个host主机资源情况 openstack host show \u0026lt;host_name\u0026gt; # 查看虚拟机列表 openstack server list # 查看虚拟机详情 openstack server show \u0026lt;instance_id\u0026gt; # 虚拟机暂停 openstack server pause \u0026lt;instance_id\u0026gt; # 虚拟机从暂停中恢复 openstack server unpause \u0026lt;instance_id\u0026gt; # 虚拟机重启 openstack server reboot \u0026lt;instance_id\u0026gt; # 虚拟机删除 openstack server delete \u0026lt;instance_id\u0026gt; Nova篇 # 查看openstack版本 nova-manage version # 查看命令帮助信息 nova help \u0026lt;command\u0026gt; # 返回nova服务所在的host信息 # 在电子通信领域，host和node的区别在于，host是向外提供某种服务，而node只需要是连接到网络的设备 # 运行有nova服务的主机被认为是host nova host-list # 查看host具体资源信息 nova host-describe \u0026lt;host_name\u0026gt; # 查看nova服务和状态 nova service-list # ======================================= # 查看计算节点 nova hypervisor-list # 查看计算节点详情 nova hypervisor-show \u0026lt;hypervisor ID\u0026gt; # 查看计算节点上的虚拟机 nova hypervisor-servers \u0026lt;hypervisor ID\u0026gt; # ====================================== # 列出所有flavor(模板) nova flavor-list # 创建flavor，模板ID建议为auto nova flavor-create --is-public true \u0026lt;模板名称\u0026gt; \u0026lt;模板ID\u0026gt; \u0026lt;内存(MB)\u0026gt; \u0026lt;磁盘(GB)\u0026gt; \u0026lt;VCPUS\u0026gt; # 显示flavro详情 nova flavor-show \u0026lt;模板ID\u0026gt; # 删除flavor nova flavor-delet \u0026lt;模板ID\u0026gt; # ======================================= # 查看虚拟机列表 nova list nova list --all-te # 查看虚拟机详情 nova show \u0026lt;instance_id\u0026gt; # 查看虚拟机控制台日志 nova console-log \u0026lt;instance_id\u0026gt; # 查看密钥对列表 nova keypair-list # 查看镜像列表 nova image-list # 查看浮动ip列表 nova floating-ip-list # 查看安全组列表 nova secgroup-list # ===================================== # 查看浮动ip列表 nova-manage floating list # 数据库同步 nova-manage db sync nova-manage api_db sync nova-manage placement sync # 查看数据库版本 nova-manage db version # nova组件更新检查 nova-status upgrade check # ==================================== nova suspend \u0026lt;instance_id\u0026gt; nova resume \u0026lt;instance_id\u0026gt; nova start \u0026lt;instance_id\u0026gt; nova stop \u0026lt;instance_id\u0026gt; nova delete \u0026lt;instance_id\u0026gt; nova reboot \u0026lt;instance_id\u0026gt; # 硬重启 nova reboot --hard \u0026lt;instance_id\u0026gt; # 进入救援模式 nova rescue \u0026lt;instance_id\u0026gt; # 使用指定镜像进入救援模式 nova rescue --image \u0026lt;image_id\u0026gt; \u0026lt;instance_id\u0026gt; # 重启虚拟机，由救援模式进入正常模式 nova unrescue \u0026lt;instance_id\u0026gt; # 重置虚拟机状态 nova reset-state \u0026lt;instance_id\u0026gt; # 指定节点热迁移 nova live-migration \u0026lt;instance_id\u0026gt; \u0026lt;compute_node_id\u0026gt; # 调整虚拟机资源 nova resize \u0026lt;instance_id\u0026gt; \u0026lt;flavor_id\u0026gt; --poll # 确认调整虚拟机资源 nova resize-confirm \u0026lt;instance_id\u0026gt; # 资源调整失败回滚 nova resize-revert \u0026lt;instance_id\u0026gt; # 通过快照创建一个镜像 nova image-create \u0026lt;instance_id\u0026gt; \u0026lt;image_name\u0026gt; # =================================== # 从镜像创建虚拟机 nova boot --image cirros --flavor 1 --nic net-name=net1 vm1 # 从卷(块设备)创建虚拟机 # 1. 从镜像生成volumn cinder create --image-id \u0026lt;image_id\u0026gt; --name \u0026lt;volume_name\u0026gt; \u0026lt;size_in_gb\u0026gt; # 2. 从volumn创建虚拟机 nova boot --flavor \u0026lt;flavor_id\u0026gt; source=volumn,,id=卷ID,dest=volume,shutdown=preserve,bootindex=0 虚拟机名称 # ================================== # 挂载云硬盘 nova volume-attach \u0026lt;instance_id\u0026gt; \u0026lt;volume_name\u0026gt; /dev/sdb # 卸载云硬盘 nova volume-detach \u0026lt;instance_id\u0026gt; \u0026lt;volume_name\u0026gt; Neutron篇 # 列出当前租户网络 neutron net-list # 列出所有租户网络 neutron net-list --all-te # 查看网络详情 neutron net-show \u0026lt;net_id\u0026gt; # 删除一个网络 neutron net-delete \u0026lt;net_id\u0026gt; # 查看所有agent neutron agent-list # 查看所有租户拥有的port # port是虚拟网口，是路由器和虚拟机挂接网络的着附点 neutron port-list # 查看port详情 neutron port-show \u0026lt;port_id\u0026gt; # 查看安全组 neutron security-group-rule-list Glance篇 # 列出全部镜像 glance image-list # 查看image具体信息 glance show \u0026lt;image ID\u0026gt; # 上传镜像 glance image-create --visibility public --container-format docker/bare --disk-format raw/qcow2 --name xxx --file /root/xxx --progress glance image-create --name \u0026#34;CentOS7.0\u0026#34; --disk-format qcow2 --container-format bare --progress \u0026lt;/opt/images/centos_7-x86_64_xiandian.qcow2 Cinder篇 # 显示存储列表 cinder list # 显示存储卷类型列表 cinder type-list # 创建存储卷 cinder create --display-name VOLNAME SIZE（SIZE的单位为GB） Ceilmeter篇 # 查看监控资源 ceilometer meter-list #查看告警列表 ceilometer alarm-list # 删除一个告警 ceilometer alarm-delete -a ALARM_ID # 获取某一个告警信息 ceilometer alarm-state-get ALARM_ID 服务状态 systemctl list-units | grep openstack systemctl status httpd.service # 查看Apache的http服务日志 cd /etc/httpd/logs tail -f \u0026lt;日志文件\u0026gt; 参考 Openstack常用命令\nOpenstack官方常用命令手册\nOpenstack命令行操作虚拟机\nNova命令行官方参考\nOpenstack用户指南\n","permalink":"https://blog.niuhemoon.win/posts/tech/openstack-command-tutorial/","summary":"不同命令的功能有重复和交集 Openstack篇 Openstack每个组件都有其命令，openstack社区为了方便使用，将所有组件的命令进行了统一，以openstack开头 # 查看所有openstack服务 openstack service list # 查看openstack服务状态 openstack-service status # 重启本节点所有openstack","title":"Openstack命令行基础"},{"content":"环境搭建和准备 # 查看cpu是否支持硬件虚拟化 grep -E -c \u0026#34;vmx|svm\u0026#34; /proc/cpuinfo sudo apt install -y qemu qemu-kvm libvirt-daemon bridge-utils virt-manager virtinst # if centos # yum install -y kvm virt-manager libvirt libvirt-python python-virtinst virt-install qemu-kvm lsmod | grep -i kvm sudo systemctl status libvirtd.service # 如果服务未启动 sudo systemctl enable libvirtd --now # 配置网桥使得libvirt可以从外部访问 cat /etc/netplan/00-installer-config.yaml # 可选，GUI管理工具 sudo apt-get install virt-manager python-spice-client-gtk 下载调试镜像： 从官方地址下载cirros镜像，用来调试虚拟机，用户名和密码如下\nuser:cirros pass:cubswin:) # 不同版本密码不同 通常将cirros镜像放置到/var/lib/libvirt/boot路径下\n可以查看镜像信息\nqemu-img info cirros-0.5.0-x86_64-disk.img 至此，vrish学习的基本环境就搭建完成\nLibvirt基本概念 virsh命令大概分组\nDomain Management（域管理） Domain Monitoring（域监控） Host and Hypervisor（主机及虚拟化） Interface（网卡接口） Network Filter（网络防火墙） Networking（网络） Node Device（节点设备驱动）存在 Secret Snapshot（快照） Storage Pool（存储池或存储策略） Storage Volume（存储卷） Virsh itself（virsh shell自身相关） 定义过的或者能够被libvirt感知到的虚机的配置文件都在/etc/libvirt目录下\n虚拟机文件和其它的相关文件都保存在 /var/lib/libvirt/ 下\n镜像的默认路径是 /var/lib/libvirt/boot/。\n上图时一个libvirt虚拟机的生命周期图，虚拟机分为两种：\n持久性的 短暂性的 持久性虚拟机会一直存在，直到被删除；\n短暂性的虚拟机只有在虚拟机被关机或重启前存在\n虚拟机常用命令 virsh和qemu的命令非常多，下面罗列一些常用的命令\nvirsh help\t# 查看帮助信息 virsh version\t# 查看qemu版本 virsh help \u0026lt;特定命令\u0026gt;\t# 查看特定命令帮助信息 virsh \u0026lt;特定命令\u0026gt; --help\t# 查看特定命令帮助信息 virsh nodeinfo\t# 查看宿主机信息 virsh uri # 查看当前主机hyperviso的连接路径； virsh connect \u0026lt;hypervisor uri\u0026gt;\t# 连接到特定hypervisor,默认qemu:///system virsh sysinfo\t# 查看hypervisro信息 virsh start \u0026lt;虚拟机名称\u0026gt; # 启动一个之前已经定义define过的虚拟机（domain) virsh shutdown \u0026lt;虚拟机名称\u0026gt;\t# 关闭虚拟机,类似虚拟机内执行关机 virsh reboot \u0026lt;虚拟机名称\u0026gt;\t# 重启虚拟机 virsh destroy \u0026lt;虚拟机名称\u0026gt;\t# 强制关闭虚拟机，类似于断电 virsh suspend \u0026lt;虚拟机名称\u0026gt; # 挂起虚拟机，将当前状态保存在内存中 virsh resume \u0026lt;虚拟机名称\u0026gt;\t# 恢复虚拟机挂起状态，从内存中恢复虚拟机状态 virsh save \u0026lt;虚拟机名称\u0026gt; \u0026lt;img镜像文件名\u0026gt;\t# 暂停虚拟机，将虚拟机状态保存在磁盘镜像文件中 virsh restore \u0026lt;img镜像文件名\u0026gt;\t#重新载入暂停的虚拟机 virsh autostart \u0026lt;虚拟机名称\u0026gt;\t# 虚拟机随着物理机启动自动启动 virsh autostart \u0026lt;虚拟机名称\u0026gt; --disable\t# 禁止开机启动 virsh dominfo \u0026lt;虚拟机名称\u0026gt;\t# 查看虚拟机domain信息 virsh domblklist \u0026lt;虚拟机名称\u0026gt;\t# 列出虚拟机所有块存储设备 virsh console \u0026lt;虚拟机名称\u0026gt;\t# 控制台连接虚拟机 virsh dumpxml \u0026lt;虚拟机名称\u0026gt;\t# 查看虚拟机xml文件 virsh edit \u0026lt;虚拟机名称\u0026gt;\t# 编辑虚拟机xml文件 virsh managedsave \u0026lt;虚拟机名称\u0026gt;\t# 保存状态save并关闭虚拟机，下次启动会恢复到之前保存的状态 virsh start \u0026lt;虚拟机名称\u0026gt;\t# 启动并恢复managedsave保存的状态 virsh reset \u0026lt;虚拟机名称\u0026gt;\t# 对虚拟机执行强制重启，类似重置电源按钮 virsh create \u0026lt;虚拟机xml文件\u0026gt; # 从xml文件中创建domain，创建完成后会自动启动； # 一个xml对应一个domain虚拟机 virsh define \u0026lt;虚拟机xml文件\u0026gt;\t# 从xml文件定义define新的domain，不会自动启动 virsh undefine \u0026lt;虚拟机名称\u0026gt;\t# 对于运行中的持久性虚拟机，将状态转换为暂时的，关机后virsh无法感知其存在 # 对于非活动的虚拟机，undefine后virsh将无法感知其存在 # undefine后磁盘依然存在，只是删除虚拟机的配置文件/etc/libvirt/qemu virsh undefine \u0026lt;虚拟机名称\u0026gt; --remove-all-storage\t# 删除虚拟机并删除所有磁盘文件 virsh snapshot-create-as \u0026lt;虚拟机名称\u0026gt; --name \u0026lt;快照名称\u0026gt; # 从命令行创建快照 virsh snapshot-create \u0026lt;虚拟机名称\u0026gt;\t# 从xml文件创建快照 virsh snapshot-list \u0026lt;虚拟机名称\u0026gt;\t# 查看虚拟机快照列表 virsh snapshot-parent \u0026lt;虚拟机名称\u0026gt; --current\t# 查看当前快照的上一级快照 virsh snapshot-edit \u0026lt;虚拟机名称\u0026gt; --snapshotname \u0026lt;快照名\u0026gt;\t# 编辑快照 virsh snapshot-revert \u0026lt;虚拟机名称\u0026gt; --snapshotname \u0026lt;快照名\u0026gt;\t# 恢复快照 virsh snapshot-delete \u0026lt;虚拟机名称\u0026gt; --snapshotname \u0026lt;快照名\u0026gt;\t# 删除快照 virsh list\t# 查看活动虚拟机状态 virsh list --all\t# 查看所有虚拟机状态 virsh setvcpus \u0026lt;虚拟机名称\u0026gt; 4 --maximum --config # 设置最大vcpu数（只能用--config，下次运行生效） virsh setvcpus \u0026lt;虚拟机名称\u0026gt; 4 --config # 下次启动使用vcpu数 virsh vcpuinfo \u0026lt;虚拟机名称\u0026gt; # 查看vcpu信息 virsh vcpupin \u0026lt;虚拟机名称\u0026gt;\t# 查询域 vcpu亲和性,即vcpu和物理cpu之间关系 virsh maxvcpus\t# 显示本机vcpu最大值 virsh setmaxmem \u0026lt;虚拟机名称\u0026gt; [--size] 2G --current # 设置最大内存限制值 virsh setmem \u0026lt;虚拟机名称\u0026gt; [--size] 2G --current # 设置内存分配 virsh domblklist cirros\t# 查看虚拟机的存储块设备 创建磁盘文件 #qcow2是文件类型，test1-add1.qcow2是磁盘文件，5G是大小 qemu-img create -f qcow2 /var/lib/libvirt/images/test1-add1.qcow2 5G qemu-img info \u0026lt;虚拟机镜像\u0026gt;\t# 查看镜像信息 virt-install \u0026lt;命令行\u0026gt; # 通过命令行指定来创建虚拟机 virsh attach-disk \u0026lt;虚拟机名称\u0026gt; virsh attach-device \u0026lt;虚拟机名称\u0026gt; /etc/libvirt/qemu/test2-add.xml --persistent\t# 从XML文件附加设备 virsh detach-device \u0026lt;虚拟机名称\u0026gt; /etc/libvirt/qemu/test2-add.xml --persistent\t# 卸载设备 虚拟机操作实践 实验1：修改虚拟机vcpu 修改虚拟机的最大vcpu数量，可以修改maximum config 和current config的值\n# 查看vcpu配置 ➜ ~ virsh vcpucount cirros maximum config 2\t# 指定下次重启虚拟机后可用的最大vcpu数量 maximum live 2\t# 指定运行/暂停状态下虚拟机可用的最大vcpu数量,重启后和maximum config一致 current config 2\t# 下次重启时虚拟机使用的vcpu数量 current live 2\t# 正在运行的虚拟机vcpu实际数量 通过修改xml文件修改vcpu数量\nvirsh edit cirros # \u0026lt;vcpu placement=\u0026#39;static\u0026#39;\u0026gt;2\u0026lt;/vcpu\u0026gt; # 修改为 \u0026lt;vcpu placement=\u0026#39;static\u0026#39;\u0026gt;3\u0026lt;/vcpu\u0026gt; 关闭并重新启动虚拟机\nvirsh shutdown cirros virsh list --all # 确认已经是shut off状态 virsh start cirros 再次查看vcpu数量，发现已经改变\n➜ ~ virsh vcpucount cirros maximum config 3 maximum live 3 current config 3 current live 3 同样方式，修改xml文件，恢复为2个vcpu，执行virsh reboot 后并没释放vcpu\n➜ ~ virsh vcpucount cirros maximum config 2 maximum live 3 current config 2 current live 3 必须执行shutdown或者destory，然后重新start才能改变运行时的vcpu\n➜ ~ virsh vcpucount cirros maximum config 2 maximum live 2 current config 2 current live 2 还可以通过命令行修改vcpu的各个配置值\n➜ ~ virsh setvcpus cirros 3 --maximum --config ➜ ~ virsh vcpucount cirros maximum config 3 maximum live 2 current config 2 current live 2 ➜ ~ virsh setvcpus cirros 3 --config # 修改current config ➜ ~ virsh vcpucount cirros maximum config 3 maximum live 2 current config 3 current live 2 # 重启虚拟机使其生效 ➜ ~ virsh shutdown cirros ➜ ~ virsh start cirros ➜ ~ virsh vcpucount cirros maximum config 3 maximum live 3 current config 3 current live 3 在宿主机上无法设置vcpu的current live小于current config，只能在虚拟机内部执行chcpu指令来修改，使得vcpu离线\n也可以将最大可用vcpu设置较大，方便后续在虚拟机运行时可以动态调整vcpu的数量\n➜ ~ virsh setvcpus cirros 5 --maximum --config ➜ ~ virsh setvcpus cirros 2 --config ➜ ~ virsh shutdown cirros ➜ ~ virsh start cirros ➜ ~ virsh vcpucount cirros maximum config 5 maximum live 5 current config 2 current live 2 ➜ ~ virsh setvcpus cirros 3\t# 动态调整vcpu数量，调整范围[current config，比maximum config] ➜ ~ virsh vcpucount cirros maximum config 5 maximum live 5 current config 2 current live 3 ➜ ~ virsh setvcpus cirros 2\t➜ ~ virsh vcpucount cirros maximum config 5 maximum live 5 current config 2 current live 2 ➜ ~ virsh vcpuinfo cirros\t# 查看vcpu运行状态 实验2：修改虚拟机的内存 通过修改xml配置文件并重新启动虚拟机\n# 修改项，修改完成后 \u0026lt;memory unit=\u0026#39;KiB\u0026#39;\u0026gt;462144\u0026lt;/memory\u0026gt;\t# 启动后最大允许可用内存 \u0026lt;currentMemory unit=\u0026#39;KiB\u0026#39;\u0026gt;262144\u0026lt;/currentMemory\u0026gt;# 启动时使用的内存大小 在最大可用内存范围内，可以在虚拟机运行时调整内存使用\n虚拟机最大内存只能在虚拟机关闭状态更改，重启后生效\n使用virsh setmaxmem命令，和直接修改xml文件等效\n➜ ~ virsh dominfo cirros | grep memory # 虚拟机启动时显示的used memory不准确 Max memory: 462144 KiB Used memory: 262144 KiB ➜ ~ virsh setmem cirros 300000 ➜ ~ virsh dominfo cirros | grep memory Max memory: 462144 KiB Used memory: 300000 KiB ➜ ~ virsh shutdown cirros ➜ ~ virsh setmaxmem cirros 700000 实验3：调整虚拟机的磁盘 虚拟机支持在虚拟机开机时动态挂载新的磁盘\n➜ ~ qemu-img create -f qcow2 -o size=20M,preallocation=metadata /var/lib/libvirt/boot/second.qcow2 Formatting \u0026#39;/var/lib/libvirt/boot/second.qcow2\u0026#39;, fmt=qcow2 size=20971520 cluster_size=65536 preallocation=metadata lazy_refcounts=off refcount_bits=16 ➜ ~ qemu-img info /var/lib/libvirt/boot/second.qcow2 image: /var/lib/libvirt/boot/second.qcow2 file format: qcow2 virtual size: 20 MiB (20971520 bytes) disk size: 260 KiB cluster_size: 65536 Format specific information: compat: 1.1 lazy refcounts: false refcount bits: 16 corrupt: false virsh attach-disk cirros /images/cirros/second.qcow2 vda --targetbus virtio # 卸载磁盘（前提时没有分区或者挂载 virsh detach-disk 26 vda 也可以手动修改xml文件，然后重启虚拟机\n# 首先创建一个qcow2磁盘或者raw磁盘 # dd命令创建一个非稀疏的磁盘 dd if=/dev/zero of=/vm-images/vm1-add.img bs=1M count=1024 # 在xml文件中加入一个新的xml段 \u0026lt;disk type=\u0026#39;file\u0026#39; device=\u0026#39;disk\u0026#39;\u0026gt; \u0026lt;driver name=\u0026#39;qemu\u0026#39; type=\u0026#39;raw\u0026#39; cache=\u0026#39;none\u0026#39; io=\u0026#39;threads\u0026#39;/\u0026gt; \u0026lt;source file=\u0026#39;/vm-images/vm1-add.img\u0026#39;/\u0026gt; \u0026lt;target dev=\u0026#39;vdb\u0026#39; bus=\u0026#39;virtio\u0026#39;/\u0026gt; \u0026lt;address type=\u0026#39;pci\u0026#39; domain=\u0026#39;0x0000\u0026#39; bus=\u0026#39;0x00\u0026#39; slot=\u0026#39;0x06\u0026#39; function=\u0026#39;0x0\u0026#39;/\u0026gt; \u0026lt;/disk\u0026gt; 实验4：创建虚拟机 virt-install --name=cirros --ram=256 --vcpus=1 --disk path=/var/lib/libvirt/boot/cirros-0.5.0-x86_64-disk.img,format=qcow2 --import --network network:default --vnc --vncport=5920 # 也可以通过xml文件来创建 实验5：复制虚拟机 可以通过命令行复制一个虚拟机，也可以通过拷贝并修改配置文件和存储卷文件进行复制\n# 通过virt-clone命令复制 # virt-clone -o \u0026lt;虚拟机名称\u0026gt; -n \u0026lt;新虚拟机名称\u0026gt; -f /var/lib/libvirt/images/test4.qcow2 # qcow2磁盘不需要预先创建，创建完成后需要进虚拟机手动改变ip地址和用户名 ➜ ~ virt-clone -o cirros -n cirros1 -f /var/lib/libvirt/boot/cirros1.qcow2 # 自动生产不一样的mac地址和uuid ➜ ~ diff cirros.xml cirros1.xml \u0026lt; \u0026lt;name\u0026gt;cirros\u0026lt;/name\u0026gt; \u0026lt; \u0026lt;uuid\u0026gt;874fe199-47ea-45d1-a25d-98d0535dddb3\u0026lt;/uuid\u0026gt; --- \u0026gt; \u0026lt;name\u0026gt;cirros1\u0026lt;/name\u0026gt; \u0026gt; \u0026lt;uuid\u0026gt;fba2f776-432d-4870-a7ec-bbf73fa1b086\u0026lt;/uuid\u0026gt; 39c39 \u0026lt; \u0026lt;source file=\u0026#39;/var/lib/libvirt/boot/cirros-0.5.0-x86_64-disk.img\u0026#39;/\u0026gt; --- \u0026gt; \u0026lt;source file=\u0026#39;/var/lib/libvirt/boot/cirros1.qcow2\u0026#39;/\u0026gt; 63c63 \u0026lt; \u0026lt;mac address=\u0026#39;52:54:00:fa:5c:d3\u0026#39;/\u0026gt; --- \u0026gt; \u0026lt;mac address=\u0026#39;52:54:00:29:8d:06\u0026#39;/\u0026gt; 81c81 \u0026lt; \u0026lt;graphics type=\u0026#39;vnc\u0026#39; port=\u0026#39;5921\u0026#39; autoport=\u0026#39;no\u0026#39;\u0026gt; --- \u0026gt; \u0026lt;graphics type=\u0026#39;vnc\u0026#39; port=\u0026#39;-1\u0026#39; autoport=\u0026#39;yes\u0026#39;\u0026gt; #virt-clone -f指定的文件不要事先创建，如果有多个磁盘文件就用多个-f选项 如 virt-clone -o \u0026lt;虚拟机名称\u0026gt; -n \u0026lt;新虚拟机名称\u0026gt; -f /home/lib/libvirt/images/test4.qcow2 -f /mnt/images/test4-add1.qcow2 可以手动复制xml文件和磁盘镜像来复制\n➜ qemu cp cirros.xml cirros3.xml # 修改xml文件中的domain name和mac地址等信息 ➜ qemu vim cirros3.xml ➜ qemu cd /var/lib/libvirt/boot # 在define新的克隆虚拟机之前准备好所需的磁盘 ➜ boot cp cirros-0.5.0-x86_64-disk.img cirros3.img ➜ boot qemu-img info cirros3.img image: cirros3.img file format: qcow2 virtual size: 112 MiB (117440512 bytes) disk size: 198 MiB cluster_size: 65536 Snapshot list: ID TAG VM SIZE DATE VM CLOCK 1 1603292226 101 MiB 2020-10-21 22:57:06 94:39:31.435 Format specific information: compat: 1.1 lazy refcounts: false refcount bits: 16 corrupt: false ➜ ~ virsh define /etc/libvirt/qemu/cirros3.xml Domain cirros3 defined from /etc/libvirt/qemu/cirros3.xml ➜ ~ virsh list --all Id Name State -------------------------- 2 cirros running - cirros3 shut off ➜ ~ virsh start cirros3 Domain cirros3 started # 此时，一个新的克隆虚拟机就创建完成 # 需要手动修改IP和hostname 实验6：误删虚拟机恢复 # 误删除虚拟机 ➜ ~ virsh undefine cirros1 Domain cirros1 has been undefined ➜ ~ virsh dominfo cirros1 Id: 1 Name: cirros1 UUID: fba2f776-432d-4870-a7ec-bbf73fa1b086 OS Type: hvm State: running CPU(s): 2 CPU time: 41.7s Max memory: 700416 KiB Used memory: 262144 KiB Persistent: no\t# 已经变为非持久化的，无法重新启动 Autostart: disable Managed save: no Security model: apparmor Security DOI: 0 Security label: libvirt-fba2f776-432d-4870-a7ec-bbf73fa1b086 (enforcing) ➜ ~ virsh shutdown cirros1 # 关机后再也启动不了了 ➜ ~ ls /etc/libvirt/qemu # cirros1的xml文件已经不存在 ➜ ~ ls /var/lib/libvirt/boot # cirros1的qcow2镜像仍然存在 # 需要在关闭虚拟机之前，重新定义define一个配置文件即可恢复 virsh dumpxml centos-C \u0026gt; /etc/libvirt/qemu/centos-C.xml virsh define /etc/libvirt/qemu/centos-C.xml # 如果是在关闭着的服务器上执行的virsh undefine centos-C 删除命令，则会把对应的配置文件清空，虚拟机再也启动不了，重新定义也不行 对于 参考 在 Ubuntu 的 KVM 中安装 Windows 系统\nvirsh使用总结\nkvm管理和基础命令\nkvm命令总结和虚机器备份迁移\nHow to Install KVM on Ubuntu 20.04 LTS Server (Focal Fossa)\nLibvirt虚拟机生命周期\nModify cpu number ","permalink":"https://blog.niuhemoon.win/posts/tech/virsh-tutorial/","summary":"环境搭建和准备 # 查看cpu是否支持硬件虚拟化 grep -E -c \u0026#34;vmx|svm\u0026#34; /proc/cpuinfo sudo apt install -y qemu qemu-kvm libvirt-daemon bridge-utils virt-manager virtinst # if centos # yum install -y kvm virt-manager libvirt libvirt-python python-virtinst virt-install qemu-kvm lsmod | grep -i kvm sudo systemctl status libvirtd.service # 如果服务未启动 sudo systemctl enable libvirtd --now # 配置网桥使得libvirt可以从外部访问 cat /etc/netplan/00-installer-config.yaml # 可选，GUI管理工具 sudo apt-get install virt-manager python-spice-client-gtk 下载调试镜像： 从官方地址下载cirros镜像，用来调试虚","title":"Virsh命令和虚拟机"},{"content":" Tcpdump是一个linux命令行的抓包工具，可以抓取TCP/IP和其他数据包，如UDP,ARP,ICMP，可以使用过滤器过滤出想要的包。\n抓取特定接口上的包 当使用tcpdump不加任何参数，将分析所有接口上的数据包。\nsudo tcpdump 可以使用-i选项指定特定接口\n可以使用-c选项限制数据包的个数\nsudo tcpdump -i wlp2s0 -c 10 抓取特定主机的数据包 可以使用-host选项指定和特定主机相关的数据包\nsudo tcpdump -i ens160 -c 5 -ttttnnvvS host 14.249.62.219 通过指定端口抓包 可以指定接口的端口进行抓包，也可以抓取特定接口以外的数据包\n# 抓取22端口数据包 sudo tcpdump -i ens160 -c 5 -nn port 22 # 抓取22端口以外数据包 sudo tcpdump -i ens160 -nn not port 22 # 指定端口号的范围 sudo tcpdump -i ens160 -c 3 -nns 0 portrange 20-23 抓取特定代理的数据包 sudo tcpdump -i ens160 -c 5 -nn tcp 保存抓包日志 使用-s选项来指定每个数据包保存的长度，默认保存68个字节，剩余字节被忽略，指定0表示完整保存。\nsudo tcpdump -i ens160 -c 5 -nn tcp -w packets-record.pcap -s 0 读取tcpdump记录文件 更常用的是使用wireshark软件分析\nsudo tcpdump -r packets-record.pcap 过滤特定源头的数据包 使用src选项指定来自特定源IP的数据包\n使用dst选项指定特定目的IP的数据包\nsudo tcpdump src 100.9.8.40 sudo tcpdump dst 14.249.62.219 抓取特定网段的数据包 使用-net选项指定incoming/outgoing特定网段的数据包\nsudu tcpdump net 192.169.0.0/24 指定数据包格式 # 16进制格式 sudo tcpdump -X -i eth0 # Ascii码格式 sudo tcpdump -A -i eth0 抓取IPV6包 sudo tcpdump -nn ip6 proto 6 过滤Http的User Agent 从http请求头中过滤出user agent和host信息\nsudo tcpdump -nn -A -s1500 -l | egrep -i \u0026#39;User-Agent:|Host:\u0026#39; 过滤cookie信息\nsudo tcpdump -nn -A -s0 -l | egrep -i \u0026#39;Set-Cookie|Host:|Cookie:\u0026#39; 列出可选的接口 sudo tcpdump -D 循环写入抓包文件 对于长时间的抓包，为了防止单个文件过大，每30分钟（1800秒）写入一个新文件，文件大小限制为100M，文件个数的24个\nsudo tcpdump -i ens160 -w /tmp/network-%H-%M.pcap -W 24 -G 1800 -C 100 Tcpdump选项 -i \u0026lt;interface\u0026gt;: 监听特定接口 -n: Don’t resolve hostnames. You can use -nn to don’t resolve hostnames or port names. -t: Print human-readable timestamp on each dump line, -tttt: Give maximally human-readable timestamp output. -X: 以ascii和十六进制两种格式显示数据包内容 -v, -vv, -vvv: 增加获取数据包的数量 -c N: 只获取N个数据包然后停止 -s: Define the snaplength (size) of the capture in bytes. Use -s0 to get everything, unless you are intentionally capturing less. -S: 打印绝对序列号 -q: 显示较少的协议信息 -w \u0026lt;file name\u0026gt;: 将原始数据包写入文件 逻辑运算符号 Tcpdump支持更精确的过滤，使用and/or/not这种逻辑运算。\n抓取来自 10.20.0.0/16 网段，并且目的地址是10.30.0.0/16 网段的数据包，使用便于阅读的时间戳， 不求解主机名和端口号，反向输出并使用绝对序号。\nCapture traffic coming from 10.20.0.0/16 and going to the network 10.30.0.0/16 with showing human-readable timestamps (tt), with no resolution of hostnames or port numbers (nn), verbose output (vv) and using absolute sequence numbers (S):\n$ sudo -ttnnvvS tcpdump src net 10.20.0.0/16 and dst net 10.30.0.0/16 Display traffic from source 192.168.0.10 which is not UDP protocol:\n$ sudo tcpdump src 192.168.0.10 and src net and not udp To capture arp or ping traffic for a specific host and save the output to a file named packetfile.txt:\n$ sudo tcpdump -nnti eth0 arp or icmp and host 192.168.0.1 -w packetfile.txt Tcpdump 输出格式 截取一行输出，分析其输出的格式\n10:31:13.440803 IP Ubuntu.ssh \u0026gt; 117.6.129.86.50736: Flags [P.], seq 188:400, ack 1, win 501, options [nop,nop,TS val 468736347 ecr 335665367], length 212 其中:\n10:31:13.401128 - 本地数据包被抓取的时间\nIP - 表示数据包是IPV4协议的\nUbuntu.ssh - 标识源IP地址或者主机名 ，.ssh 表示端口，这里时22端口\n117.6.129.86.50376 - 表示数据包的目的IP地址 ，使用.分割端口号\n标志位：\n[P.] - This is TCP flags field.\n[.] - ACK (Acknowledgment).\n[S] - SYN (Start Connection).\n[P] - PSH (Push Data).\n[F] - FIN (Finish Connection).\n[R] - RST (Reset Connection).\n[S.] - SYN-ACK (SynAcK Packet).\nseq 188:400 - 序列号表示该数据包包含序列是188-400字节的数据\nwin 501 - 窗口大小，表示接受缓冲区中可用的字节\noptions [nop,nop,TS val 468736347 ecr 335665367] - These are TCP options such as the MSS (Maximum Segment Size) or Window Scale. You can refer more about TCP protocol options.\nlength 212 - 表示数据包中payload数据的字节\n参考 Tcpdump基本使用\n","permalink":"https://blog.niuhemoon.win/posts/tech/tcpdump-usage/","summary":"Tcpdump是一个linux命令行的抓包工具，可以抓取TCP/IP和其他数据包，如UDP,ARP,ICMP，可以使用过滤器过滤出想要的包。 抓取特定接口上的包 当使用tcpdump不加任何参数，将分析所有接口上的数据包。 sudo tcpdump 可以使用-i选项指定特定接口 可以使用-c选项限制数据包的个","title":"tcpdump的基本使用【译】"},{"content":"简介 Linux上对系统进行性能检测的工具非常多，本文介绍一些常用工具的使用\n性能观测工具\n▪ 首先学习的Basic Tool有如下： uptime、top(htop)、mpstat、isstat、vmstat、free、ping、nicstat、dstat。\n▪ 高级的命令如下： sar、netstat、pidstat、strace、tcpdump、blktrace、iotop、slabtop、sysctl、/proc。\n性能观测工具sar\nsar\n# install sudo apt install sysstat # usage sar -u 2 3 sar -u -f /var/log/sa/sa05 sar -P ALL 1 1 sar -r 1 3 sar -W 1 3 top\n交互模式的一些快捷操作: 全局命令: \u0026lt;回车/空格\u0026gt; ?, =, A, B, d, G, h, I, k, q, r, s, W, Z 统计区的命令: l, m, t, 1 任务区的命令： 外观: b, x, y, z 内容: c, f, H, o, S, u 大小: #, i, n 排序: \u0026lt;, \u0026gt;, F, O, R 色彩方案: \u0026lt;Ret\u0026gt;, a, B, b, H, M, q, S, T, w, z, 0 - 7 窗口命令: -, _, =, +, A, a, G, g, w Press \u0026#39;h\u0026#39; or \u0026#39;?\u0026#39; for help with Windows, Type \u0026#39;q\u0026#39; or \u0026lt;Esc\u0026gt; to continue 如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了！！！！！\n9. netstat - 显示开放的端口和连接 它是Linux管理员使用来显示各种网络信息的工具，如查看什么端口开放和什么网络连接已经建立以及何种进程运行在该连接之上。同时它也显示了不同程序间打开的Unix套接字的信息。作为大多数Linux发行版本的一部分，netstat的许多命令在netstat和它的不同输出中有详细的描述。最为常用的如下：\nnetstat | head -20 netstat -r netstat -rC netstat -i netstat -ie netstat -s netstat -g netstat -tapn vmstat是虚拟内存(virtual memory statistics)的缩写，作为一个内存监控工具，它收集和显示关于内存，进程，终端和分页和I/O阻塞的概括信息。作为一个开源程序，它可以在大部分Linux发行版本中找到，包括Solaris和FreeBSD。它用来诊断大部分的内存性能问题和其他相关问题。\n让我们看下如何了解vmstat提供的信息：\n----------------------------- procs部分的解释 r 列表示运行和等待cpu时间片的进程数，如果长期大于1，说明cpu不足，需要增加cpu。 b 列表示在等待资源的进程数，比如正在等待I``/O``、或者内存交换等。 ----------------------------- cpu部分的解释 us 列显示了用户方式下所花费 CPU 时间的百分比。us的值比较高时，说明用户进程消耗的cpu时间多，但是如果长期大于50%，需要考虑优化用户的程序。 sy 列显示了内核进程所花费的cpu时间的百分比。这里us + sy的参考值为80%，如果us+sy 大于 80%说明可能存在CPU不足。 wa 列显示了IO等待所占用的CPU时间的百分比。这里wa的参考值为30%，如果wa超过30%，说明IO等待严重，这可能是磁盘大量随机访问造成的，也可能磁盘或者 ``磁盘访问控制器的带宽瓶颈造成的(主要是块操作)。 id` `列显示了cpu处在空闲状态的时间百分比 ----------------------------- system部分的解释 in 列表示在某一时间间隔中观测到的每秒设备中断数。 cs列表示每秒产生的上下文切换次数，如当 cs 比磁盘 I/O 和网络信息包速率高得多，都应进行进一步调查。 ----------------------------- memory部分的解释 swpd 切换到内存交换区的内存数量(k表示)。如果swpd的值不为0，或者比较大，比如超过了100m，只要si、so的值长期为0，系统性能还是正常 free 当前的空闲页面列表中内存数量(k表示) buff 作为buffer cache的内存数量，一般对块设备的读写才需要缓冲。 cache: 作为page cache的内存数量，一般作为文件系统的cache，如果cache较大，说明用到cache的文件较多，如果此时IO中bi比较小，说明文件系统效率比较好。 ----------------------------- swap部分的解释 si 由内存进入内存交换区数量。 so由内存交换区进入内存数量。 ----------------------------- IO部分的解释 bi 从块设备读入数据的总量（读磁盘）（每秒kb）。 bo 块设备写入数据的总量（写磁盘）（每秒kb） Procs procs有 r列和b列。r列代表等待访问CPU的进程数量。而b列意味着睡眠进程的数量。在这些列的下面，是它们的值。从上面的截图中，我门有2个进程正在等待访问CPU，0个睡眠进程。\nMemory memory有swpd、 free、 buff 和 cache 这些列。这些信息和命令free -m相同。swpd列显示了有多少内存已经被交换到了交换文件或者磁盘。free列显示了未分配的可用内存。buff列显示了使用中的内存。cache列显示了有多少内存可以被交换到交换文件或者磁盘上如果一些应用需要他们。\nSwap swap显示了从交换系统上发送或取回了多少内存。si列告诉我们每秒有多少内存被从swap移到真实内存中（In）。so列告诉我们每秒有多少内存被从真实内存移到swap中（Out）。\nI/O io依据块的读写显示了每秒输入输出的活动。bi列告诉我们收到的块数量，bo列告诉我们发送的块数量。\nSystem system显示了每秒的系统操作数量。in列显示了系统每秒被中断的数量。cs列显示了系统为了处理所以任务而上下文切换的数量。\nCPU CPU告诉了我们CPU资源的使用情况。us列显示了处理器在非内核程序消耗的时间。sy列显示了处理器在内核相关任务上消耗的时间。id列显示了处理器的空闲时间。wa列显示了处理器在等待IO操作完成以继续处理任务上的时间。\nss是iproute2包的一部分。iproute2是用来替代一整套标准的Unix网络工具组件，它曾经用来完成网络接口配置，路由表和管理ARP表任务。ss工具用来记录套接字统计信息，它可以显示类似netstat一样的信息，同时也能显示更多TCP和状态信息。一些例子如下：\nss -tnap ss -tnap6 ss -tnap ss -s ss -tn -o state established -p lsof命令，意为“list open files”, 用于在许多类Unix系统中显示所有打开的文件及打开它们的进程。在大部分Linux发行版和其他类Linux操作系统中系统管理员用它来检查不同的进程打开了哪些文件。\n# lsof +p process_id # lsof | less # lsof –u username # lsof /etc/passwd # lsof –i TCP:ftp # lsof –i TCP:80 缓冲区与特定的块设备关联，并覆盖文件系统元数据的缓存以及跟踪运行中的页面。缓存仅包含驻留的文件数据。也就是说，缓冲区记住目录中的内容，文件权限是什么，并跟踪从特定块设备写入或读取的内存。缓存仅包含文件本身的内容。\n“缓冲区”表示有多少RAM专用于缓存磁盘块。“缓存”类似于“缓冲区”，只是这次它缓存文件读取中的页面。\n引用答案（供参考）：\n简短答案：高速缓存是页面高速缓存的大小。缓冲区是内存中块I / O缓冲区的大小。缓存的事项；缓冲区在很大程度上无关紧要。\n长答案：缓存是Linux页面缓存的大小减去交换缓存中的内存，它由SwapCached表示（因此总页面缓存大小为Cached + SwapCached）。Linux通过页面缓存执行所有文件I / O。写操作的实现是简单地将页面缓存中的相应页面标记为脏。然后，刷新程序线程会定期将所有脏页写回到磁盘。通过从页面缓存返回数据来实现读取。如果数据尚未在高速缓存中，则首先填充它。在现代Linux系统上，“缓存”可以轻松达到数GB。它只会响应内存压力而缩小。系统将清除页面缓存以及将数据交换到磁盘上，以根据需要提供更多的内存。\n缓冲区是内存中的块I / O缓冲区。他们是相对短暂的。在Linux内核版本2.4之前，Linux具有单独的页面和缓冲区高速缓存。从2.4开始，页面和缓冲区高速缓存是统一的，缓冲区是未在页面高速缓存中表示的原始磁盘块，即不是文件数据。因此，“缓冲区”度量标准的重要性最低。在大多数系统上，缓冲区通常只有几十兆字节。\n它并不像这样简单，但是可能有助于理解：\n缓冲区用于存储文件元数据（权限，位置等）。每个内存页面都在此处跟踪。\n缓存用于存储实际文件内容。\niostat\n解释说明： avg-cpu: 总体cpu使用情况统计信息，对于多核cpu，这里为所有cpu的平均值 %user: 在用户级别运行所使用的CPU的百分比. %``nice``: ``nice``操作所使用的CPU的百分比. %sys: 在系统级别(kernel)运行所使用CPU的百分比. %iowait: CPU等待硬件I``/O``时,所占用CPU百分比. %idle: CPU空闲时间的百分比. Device段:各磁盘设备的IO统计信息 tps: 每秒钟发送到的I``/O``请求数. Blk_read ``/s``: 每秒读取的block数. Blk_wrtn``/s``: 每秒写入的block数. Blk_read: 读入的block总数. Blk_wrtn: 写入的block总数. iostat -x -k -d 1\n解释说明： rrqm``/s``: 每秒对该设备的读请求被合并次数，文件系统会对读取同块(block)的请求进行合并 wrqm``/s``: 每秒对该设备的写请求被合并次数 r``/s``: 每秒完成的读次数 w``/s``: 每秒完成的写次数 rkB``/s``: 每秒读数据量(kB为单位) wkB``/s``: 每秒写数据量(kB为单位) avgrq-sz:平均每次IO操作的数据量(扇区数为单位) avgqu-sz: 平均等待处理的IO请求队列长度 await: 平均每次IO请求等待时间(包括等待时间和处理时间，毫秒为单位) svctm: 平均每次IO请求的处理时间(毫秒为单位) %util: 采用周期内用于IO操作的时间比率，即IO队列非空的时间比率 如果 %util 接近 100%，说明产生的I``/O``请求太多，I``/O``系统已经满负荷，该磁盘可能存在瓶颈。 idle小于70% IO压力就较大了,一般读取速度有较多的wait。 同时可以结合vmstat 查看查看b参数(等待资源的进程数)和wa参数(IO等待所占用的CPU时间的百分比,高过30%时IO压力高) 在Linux系统中，为了提高文件系统性能，内核利用一部分物理内存分配出缓冲区，用于缓存系统操作和数据文件，当内核收到读写的请求时，内核先去缓存区找是否有请求的数据，有就直接返回，如果没有则通过驱动程序直接操作磁盘。 缓存机制优点：减少系统调用次数，降低CPU上下文切换和磁盘访问频率。 CPU上下文切换：CPU给每个进程一定的服务时间，当时间片用完后，内核从正在运行的进程中收回处理器，同时把进程当前运行状态保存下来，然后加载下一个任务，这个过程叫做上下文切换。实质上就是被终止运行进程与待运行进程的进程切换。\nSwap用途：Swap意思是交换分区，通常我们说的虚拟内存，是从硬盘中划分出的一个分区。当物理内存不够用的时候，内核就会释放缓存区（buffers/cache）里一些长时间不用的程序，然后将这些程序临时放到Swap中，也就是说如果物理内存和缓存区内存不够用的时候，才会用到Swap。 swap清理：swapoff -a \u0026amp;\u0026amp; swapon -a 注意：这样清理有个前提条件，空闲的内存必须比已经使用的swap空间大\n1. 查看内存使用情况，发现swap虚拟内存空间竟然为0 # free -m 2. 建虚拟内存磁盘卷。做法如下： # dd if=/dev/zero of=/opt/swap bs=1024 count=2048000 # mkswap /opt/swap # swapon /opt/swap 再次查看内容，发现swap虚拟内存就有了 # free -m 3. 如果想取消文件虚拟内存，即删除swap，做法如下：（当然根据系统配置，也可以保留swap，以后继续用）。 # swapoff /opt/swap # rm /opt/swap 4. swap开机挂载 # vim /etc/fstab /opt/swap swap swap defaults 0 0 上面挂载参数分别为： 设备文件或伪文件系统 挂载点 文件系统类型 挂载选项 备份频率 开机自检次序 6. 移动虚拟内存空间 如果当前的虚存所在的磁盘空间不够，可以首先关闭虚存服务，将其移动到别的磁盘，再启用即可。 # swapoff -v /swap/swapadd # mv /swap/swapadd /mnt/swap # swapon /swap/swapadd 释放缓存区内存的方法 1）清理pagecache（页面缓存） [root@backup ~]# echo 1 \u0026gt; /proc/sys/vm/drop_caches 或者 # sysctl -w vm.drop_caches=1 2）清理dentries（目录缓存）和inodes [root@backup ~]# echo 2 \u0026gt; /proc/sys/vm/drop_caches 或者 # sysctl -w vm.drop_caches=2 3）清理pagecache、dentries和inodes [root@backup ~]# echo 3 \u0026gt; /proc/sys/vm/drop_caches 或者 # sysctl -w vm.drop_caches=3 上面三种方式都是临时释放缓存的方法，要想永久释放缓存，需要在/etc/sysctl.conf文件中配置：vm.drop_caches=1/2/3，然后sysctl -p生效即可！ 另外，可以使用sync命令来清理文件系统缓存，还会清理僵尸(zombie)对象和它们占用的内存 [root@backup ~]# sync 温馨提示： 上面操作在大多数情况下都不会对系统造成伤害，只会有助于释放不用的内存。 但是如果在执行这些操作时正在写数据，那么实际上在数据到达磁盘之前就将它从文件缓存中清除掉了，这可能会造成很不好的影响。 那么如果避免这种事情发生呢？ 因此，这里不得不提一下/proc/sys/vm/vfs_cache_pressure这个文件，告诉内核，当清理inoe/dentry缓存时应该用什么样的优先级。 [root@backup ~]# cat /proc/sys/vm/vfs_cache_pressure 100 vfs_cache_pressure=100 这个是默认值，内核会尝试重新声明dentries和inodes，并采用一种相对于页面缓存和交换缓存比较\u0026#34;合理\u0026#34;的比例。 减少vfs_cache_pressure的值，会导致内核倾向于保留dentry和inode缓存。 增加vfs_cache_pressure的值，（即超过100时），则会导致内核倾向于重新声明dentries和inodes 总之，vfs_cache_pressure的值： 小于100的值不会导致缓存的大量减少 超过100的值则会告诉内核你希望以高优先级来清理缓存。 其实无论vfs_cache_pressure的值采用什么值，内核清理缓存的速度都是比较低的。 如果将此值设置为10000，系统将会将缓存减少到一个合理的水平。 测试硬盘写入速度\n[root@redhat73 ~]# dd if=/dev/zero of=/home/linshi.a bs=1024000000 count=2 2+0 records in 2+0 records out 2048000000 bytes (2.0 GB) copied, 4.67577 s, 438 MB/s 写入一个2GB的文件，用时4.67577秒，平均438 MB/s [root@localhost home]# free -h total used free shared buff/cache available Mem: 974M 56M 818M 580K 99M 787M Swap: 2.0G 37M 2.0G # 参数解释 -m 以MB为单位输出 -g 以GB为单位输出 -h 以人类可读的单位输出，自动转换KB、MB或者GB为单位 -s N 每N秒打印一次 -c N 打印N次后退出 # 输出说明（Mem代表物理内存、Swap代表虚拟内存） total 表示系统的总内存 used 表示应用程序已经使用的内存 free 表示当前还没有被使用的内存 shared 表示共享链接库使用的内存 buff/cache 表示系统的page cache和buffer使用到的内存 available 表示应用程序还可以申请到的内存 怎么判断是否需要加内存： 1.swap使用有多少 2.available剩余是多少，而不是看free cache是Linux系统为了提高系统运行效率而将一些程序或文件写入到cache，可提高程序运行和加载速度，如果程序需要会马上释放。所以判断系统内存是否足够和是否需要增加的时候不能简单的看free Cache Pages: A cache is the part of the memory which transparently stores data so that future requests for that data can be served faster. This memory is utilized by the kernel to cache disk data and improve i/o performance. 系统当前使用到的内存是：used + buff/cache，used中包含了shared。 所以total = used + buff/cache + free = 56 + 99 + 818 = 973 available（787） \u0026lt;= free + buff/cache（818 + 99 = 917），为什么是小于呢？因为系统的一些page或cache是不能回收的。 # 查看CPU信息 # 总核数 = 物理CPU个数 X 每颗物理CPU的核数 # 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数 # 查看物理CPU个数 cat /proc/cpuinfo| grep \u0026#34;physical id\u0026#34;| sort| uniq| wc -l # 查看每个物理CPU中core的个数(即核数) cat /proc/cpuinfo| grep \u0026#34;cpu cores\u0026#34;| uniq # 查看逻辑CPU的个数 cat /proc/cpuinfo| grep \u0026#34;processor\u0026#34;| wc -l # 查看CPU信息（型号） cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 性能测评工具\n性能调优工具\n参考 用十条命令在一分钟内检查Linux服务器性能\n你值得拥有 —— 25 个 Linux 性能监控工具\nTop命令详解\ngglsof命令入门\nLinux缓存机制\n30个实例详解TOP命令\nlsof命令行神器入门\n超全整理！Linux性能分析工具汇总合集\n","permalink":"https://blog.niuhemoon.win/posts/tech/linux-peformence-test/","summary":"简介 Linux上对系统进行性能检测的工具非常多，本文介绍一些常用工具的使用 性能观测工具 ▪ 首先学习的Basic Tool有如下： uptime、top(htop)、mpstat、isstat、vmstat、free、ping、nicstat、dstat。 ▪ 高级的命令如下： sar、net","title":"Linux性能测试"},{"content":"Core Dump文件 凡事皆有两面性，OS在出Core的同时，虽然会终止掉当前进程，但是也会保留下第一手的现场数据，OS仿佛是一架被按下快门的相机，而照片就是产出的Core文件。里面含有当进程被终止时内存、CPU寄存器等信息，可以供后续开发人员进行调试。\nGdb可以附着在特定进程上调试，但是为了不影响运行中的进程，可以通过生成 core file 的方式来保存进程的当前信息。\n实验环境配置 环境是Ubuntu20.04\n# 新开一个Shell的时候，ulimit选项都恢复了默认选项，需要重新设置该值 # 查看shell进程资源 ulimit -a # 查看core文件大小限制 ulimit -c # 修改core文件大小限制 ulimit -c unlimited # 查看修改是否生效 ulimit -c # 设置core_pattern # core_pattern文件中定义了当产生core dump后对core文件进行什么操作 cat /proc/sys/kernel/core_pattern # 需要修改core_pattern文件使得core文件保存在磁盘上 # 方法1 # 暂停apport服务 sudo service apport stop cat /proc/sys/kernel/core_pattern # 生成core文件后恢复apport服务 sudo service apport start # 方法2 mkdir /var/cores echo \u0026#34;/var/cores/core.%e.%p\u0026#34; \u0026gt; /proc/sys/kernel/core_pattern # 方法3 vim /etc/sysctl.conf # 在最后一行添加kernel.core_uses_pid = 1 sysctl -p # 阅读core文件头\treadelf -h core 安装Python-dbg\nsudo apt install gdb python3-dbg GDB调试Python代码 实验1：直接调试core dump文件 将如下代码保存为explode.py\nimport os def my_exploding_func(): my_local_var = \u0026#39;hi\u0026#39; number = 4 number2 = 5 number4 = number+3 os.abort() my_exploding_func() 执行代码，产生core dump文件\npython explode.py 同样的Python版本执行gdb调试\n# 读取core文件 gdb `which python` core 可以使用一些常见的命令调试\n#0 __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:50 50\t../sysdeps/unix/sysv/linux/raise.c: 没有那个文件或目录. (gdb) py-list 3 def my_exploding_func(): 4 my_local_var = \u0026#39;hi\u0026#39; 5 number = 4 6 number2 = 5 7 number4 = number+3 \u0026gt;8 os.abort() 9 10 my_exploding_func() (gdb) py-bt Traceback (most recent call first): \u0026lt;built-in method abort of module object at remote 0x7f08dfc7d360\u0026gt; File \u0026#34;explode.py\u0026#34;, line 8, in my_exploding_func os.abort() File \u0026#34;explode.py\u0026#34;, line 10, in \u0026lt;module\u0026gt; my_exploding_func() 实验2:主动生成core dump文件 如下代码保存为test.py\nimport time def do(x): time.sleep(10) def main(): for x in range(10000): do(x) if __name__ == \u0026#39;__main__\u0026#39;: main() 运行该代码后找到PID\nps -ef | grep \u0026#34;python test.py\u0026#34; 主动生成core dump文件,不影响进程继续运行\ngdb python PID generate-core-file 所有gdb命令都支持使用，同时还有安装python-dbg支持的命令\n在gdb调试命令行中输入\n# py + TAB键位弹出常用命令 py-bt py-list py-up py-bt-full py-locals python py-down py-print python-interactive # help + 命令显示帮助信息 help py-bt 参考 gdb Debugging Full Example Linux上Core Dump文件的形成和分析\nLinux上coredump实验\nGDB调试Python命令\nDebuggin with gdb\n","permalink":"https://blog.niuhemoon.win/posts/tech/gdb-debug-python/","summary":"Core Dump文件 凡事皆有两面性，OS在出Core的同时，虽然会终止掉当前进程，但是也会保留下第一手的现场数据，OS仿佛是一架被按下快门的相机，而照片就是产出的Core文件。里面含有当进程被终止时内存、CPU寄存器等信息，可以供后续开发人员进行调试。 Gdb可以附着在特定进程上调试，但","title":"GDB调试Python代码"},{"content":" 有两种常用的方法可以使得代码并行执行，多线程和多进程 。因为Cython解释器的实现不是线程安全的，具有GIL锁，同一时刻，只有一个线程可以获得解释器的锁。因此，Python利用多核心的CPU只能通过多进程，而多线程只适用于IO密集型的程序。\n多进程基础 创建并开启进程 可以使用multiprocessing.Process()来创建进程，它接受两个参数：\ntarget，一个可调用的函数，当进程开始时会执行 args，一个元组，提供目标函数的参数 使用process.start()来开始执行一个进程\n调用process.join()来告诉程序等待进程结束再执行后续代码，主进程将会被阻塞\nfrom multiprocessing import Process import os def square_numbers(): for i in range(1000): result = i * i if __name__ == \u0026#34;__main__\u0026#34;: processes = [] num_processes = os.cpu_count() # number of CPUs on the machine. Usually a good choise for the number of processes # create processes and asign a function for each process for i in range(num_processes): process = Process(target=square_numbers) processes.append(process) # start all processes for process in processes: process.start() # wait for all processes to finish # block the main programm until these processes are finished for process in processes: process.join() 进程间分享数据 因为进程的内存空间不同，需要特殊的共享内存对象来分享数据。\n数据可以保存在共享内存变量中，使用Value或者Array\nValue(type, value)创建一个ctype对象 Array(type, value)创建一个ctype类型的列表 如下程序演示年race condition资源竟态，每次执行结果都不一样，例如当两个进程读取同一个值，并对其执行+1操作，然后写会原有地址，其结果并不是预想的加2。\nfrom multiprocessing import Process, Value, Array import time def add_100(number): for _ in range(100): time.sleep(0.001) number.value += 1 def add_100_array(numbers): for _ in range(100): time.sleep(0.01) for i in range(len(numbers)): numbers[i] += 1 if __name__ == \u0026#34;__main__\u0026#34;: shared_number = Value(\u0026#39;i\u0026#39;, 0) print(\u0026#39;Value at beginning:\u0026#39;, shared_number.value) shared_array = Array(\u0026#39;d\u0026#39;, [0.0, 100.0, 200.0]) print(\u0026#39;Array at beginning:\u0026#39;, shared_array[:]) process1 = Process(target=add_100, args=(shared_number,)) process2 = Process(target=add_100, args=(shared_number,)) process3 = Process(target=add_100_array, args=(shared_array,)) process4 = Process(target=add_100_array, args=(shared_array,)) process1.start() process2.start() process3.start() process4.start() process1.join() process2.join() process3.join() process4.join() print(\u0026#39;Value at end:\u0026#39;, shared_number.value) print(\u0026#39;Array at end:\u0026#39;, shared_array[:]) print(\u0026#39;end main\u0026#39;) \u0026#34;\u0026#34;\u0026#34; Value at beginning: 0 Array at beginning: [0.0, 100.0, 200.0] Value at end: 144 Array at end: [134.0, 237.0, 339.0] end main \u0026#34;\u0026#34;\u0026#34; 可以使用锁避免资源竟态 锁（也称为互斥锁）是一种同步机制，用于在存在许多执行进程/线程的环境中强制限制对资源的访问。锁具有两种状态：锁定和解锁。 如果状态为锁定，则在再次解除锁定状态之前，不允许其他并发进程/线程进入此代码段。\n# import Lock from multiprocessing import Lock from multiprocessing import Process, Value, Array import time def add_100(number, lock): for _ in range(100): time.sleep(0.001) # lock the state lock.acquire() number.value += 1 # unlock the state lock.release() def add_100_array(numbers, lock): for _ in range(100): time.sleep(0.01) for i in range(len(numbers)): lock.acquire() numbers[i] += 1 lock.release() if __name__ == \u0026#34;__main__\u0026#34;: # create a lock lock1 = Lock() lock2 = Lock() shared_number = Value(\u0026#39;i\u0026#39;, 0) print(\u0026#39;Value at beginning:\u0026#39;, shared_number.value) shared_array = Array(\u0026#39;d\u0026#39;, [0.0, 100.0, 200.0]) print(\u0026#39;Array at beginning:\u0026#39;, shared_array[:]) # pass the lock to the target function process1 = Process(target=add_100, args=(shared_number, lock1)) process2 = Process(target=add_100, args=(shared_number, lock1)) process3 = Process(target=add_100_array, args=(shared_array, lock2)) process4 = Process(target=add_100_array, args=(shared_array, lock2)) process1.start() process2.start() process3.start() process4.start() process1.join() process2.join() process3.join() process4.join() print(\u0026#39;Value at end:\u0026#39;, shared_number.value) print(\u0026#39;Array at end:\u0026#39;, shared_array[:]) print(\u0026#39;end main\u0026#39;) \u0026#34;\u0026#34;\u0026#34; Value at beginning: 0 Array at beginning: [0.0, 100.0, 200.0] Value at end: 200 Array at end: [200.0, 300.0, 400.0] end main \u0026#34;\u0026#34;\u0026#34; 在上下文管理器中使用锁 使用上下文管理器管理锁的获取和释放更加安全\ndef add_100(number, lock): for _ in range(100): time.sleep(0.01) with lock: number.value += 1 多进程使用队列通信 使用队列的操作是进程安全的。多进程队列实现了队列的所有方法。done()和join()除外。\nq.get():移除队首第一个元素，默认情况，会阻塞直到有元素可用 q.put(item)将元素压到队尾，默认情况，阻塞直到队列有空的槽 q.empty()如果队列为空，返回True q.close()表明当前进程不会有新的数据放到队列中了 # communicate between processes with the multiprocessing Queue # Queues are thread and process safe from multiprocessing import Process, Queue import time def square(numbers, queue): for i in numbers: time.sleep(0.01) queue.put(i*i) def make_negative(numbers, queue): for i in numbers: time.sleep(0.01) queue.put(i*-1) if __name__ == \u0026#34;__main__\u0026#34;: numbers = range(1, 6) q = Queue() p1 = Process(target=square, args=(numbers,q)) p2 = Process(target=make_negative, args=(numbers,q)) p1.start() p2.start() p1.join() p2.join() # order might not be sequential while not q.empty(): print(q.get()) print(\u0026#39;end main\u0026#39;) \u0026#34;\u0026#34;\u0026#34; 1 -1 4 -2 9 -3 16 -4 25 -5 end main \u0026#34;\u0026#34;\u0026#34; 进程池 进程池对象控制一些工作进程worker，可以支持超时和回调以实现异步处理，也有一些并行的map实现。它可以自动管理多个处理器，并将数据分成小块，在多个处理器上并行处理。\n重要的函数包括：\nmap(func, iterable[, chunksize])将可迭代对象切分成小块，作为独立任务提交到进程池，并行处理。函数将会阻塞，直到返回结果。 close()阻止更多任务添加到进程池，一旦任务完成，worker进程将退出 join()等待工作进程退出，在调用join()之前需要调用close()或者terminate() apply(func, args)调用func函数，参数是args。阻塞直到返回结果，func函数只在进程池中一个worker中执行 有map_async()和apply_async()这种非阻塞的异步函数 from multiprocessing import Pool import random import time def cube(number): print(\u0026#34;Hi\u0026#34;) time.sleep(random.randint(1,2)) return number * number * number if __name__ == \u0026#34;__main__\u0026#34;: numbers = range(10) p = Pool() # by default this allocates the maximum number of available # processors for this task --\u0026gt; os.cpu_count() result = p.map(cube, numbers) # or # result = [p.apply(cube, args=(i,)) for i in numbers] p.close() p.join() print(result) 多线程基础 Python多线程相对比较鸡肋，其使用和多进程类似\n创建并开始线程 使用threading库实现\nfrom threading import Thread def square_numbers(): for i in range(1000): result = i * i if __name__ == \u0026#34;__main__\u0026#34;: threads = [] num_threads = 10 # create threads and asign a function for each thread for i in range(num_threads): thread = Thread(target=square_numbers) threads.append(thread) # start all threads for thread in threads: thread.start() # wait for all threads to finish # block the main thread until these threads are finished for thread in threads: thread.join() 线程间共享数据 线程间可以通过全局变量来共享数据，因为线程间是共享内存空间的\nfrom threading import Thread import time # all threads can access this global variable database_value = 0 def increase(): global database_value # needed to modify the global value # get a local copy (simulate data retrieving) local_copy = database_value # simulate some modifying operation local_copy += 1 time.sleep(0.1) # write the calculated new value into the global variable database_value = local_copy if __name__ == \u0026#34;__main__\u0026#34;: print(\u0026#39;Start value: \u0026#39;, database_value) t1 = Thread(target=increase) t2 = Thread(target=increase) t1.start() t2.start() t1.join() t2.join() print(\u0026#39;End value:\u0026#39;, database_value) print(\u0026#39;end main\u0026#39;) \u0026#34;\u0026#34;\u0026#34; Start value: 0 End value: 1 end main \u0026#34;\u0026#34;\u0026#34; 使用锁处理资源竟态 # import Lock from threading import Thread, Lock import time database_value = 0 def increase(lock): global database_value # lock the state lock.acquire() local_copy = database_value local_copy += 1 time.sleep(0.1) database_value = local_copy # unlock the state lock.release() if __name__ == \u0026#34;__main__\u0026#34;: # create a lock lock = Lock() print(\u0026#39;Start value: \u0026#39;, database_value) # pass the lock to the target function t1 = Thread(target=increase, args=(lock,)) # notice the comma after lock since args must be a tuple t2 = Thread(target=increase, args=(lock,)) t1.start() t2.start() t1.join() t2.join() print(\u0026#39;End value:\u0026#39;, database_value) print(\u0026#39;end main\u0026#39;) 使用上下文管理器\ndef increase(lock): global database_value with lock: local_copy = database_value local_copy += 1 time.sleep(0.1) database_value = local_copy 多线程消息队列通信 对队列的操作是线程安全的\nfrom threading import Thread, Lock, current_thread from queue import Queue def worker(q, lock): while True: value = q.get() # blocks until the item is available # do stuff... with lock: # prevent printing at the same time with this lock print(f\u0026#34;in {current_thread().name} got {value}\u0026#34;) # ... # For each get(), a subsequent call to task_done() tells the queue # that the processing on this item is complete. # If all tasks are done, q.join() can unblock q.task_done() if __name__ == \u0026#39;__main__\u0026#39;: q = Queue() num_threads = 10 lock = Lock() for i in range(num_threads): t = Thread(name=f\u0026#34;Thread{i+1}\u0026#34;, target=worker, args=(q, lock)) t.daemon = True # dies when the main thread dies t.start() # fill the queue with items for x in range(20): q.put(x) q.join() # Blocks until all items in the queue have been gotten and processed. print(\u0026#39;main done\u0026#39;) \u0026#34;\u0026#34;\u0026#34; in Thread1 got 0 in Thread2 got 1 in Thread2 got 11 in Thread2 got 12 in Thread2 got 13 in Thread2 got 14 in Thread2 got 15 in Thread2 got 16 in Thread2 got 17 in Thread2 got 18 in Thread2 got 19 in Thread8 got 5 in Thread4 got 9 in Thread1 got 10 in Thread5 got 2 in Thread6 got 3 in Thread9 got 6 in Thread7 got 4 in Thread10 got 7 in Thread3 got 8 main done \u0026#34;\u0026#34;\u0026#34; Python标准库自带的一些小工具 # 查看包安装路径 python -m site # 开启简单的http server python -m http.server # base64编码和解码 echo \u0026#34;hello\u0026#34; | python -m base64 # top level await console python -m asyncio # 查看tokenize和ast结果 python -m tokenize cgi.py pythono -m ast cgi.py # json美化输出 echo \u0026#39;{\u0026#34;foo\u0026#34;: \u0026#34;bar\u0026#34;}\u0026#39; | python -m json.tool # 显示日历 python -m calendar 参考 Python多线程和多进程 CLI tools hidden in the Python standard library | Simon Willison’s TILs\n","permalink":"https://blog.niuhemoon.win/posts/tech/python-advanced-3/","summary":"有两种常用的方法可以使得代码并行执行，多线程和多进程 。因为Cython解释器的实现不是线程安全的，具有GIL锁，同一时刻，只有一个线程可以获得解释器的锁。因此，Python利用多核心的CPU只能通过多进程，而多线程只适用于IO密集型的程序。 多进程基础 创建并开启进程 可以使用mult","title":"Python进阶下"},{"content":"生成器Generator def countdown(num): print(\u0026#39;Starting\u0026#39;) while num \u0026gt; 0: yield num num -= 1 # this will not print \u0026#39;Starting\u0026#39; cd = countdown(3) # this will print \u0026#39;Starting\u0026#39; and the first value print(next(cd)) # will print the next values print(next(cd)) print(next(cd)) # this will raise a StopIteration print(next(cd)) 迭代器使用方式\n# you can iterate over a generator object with a for in loop cd = countdown(3) for x in cd: print(x) # you can use it for functions that take iterables as input cd = countdown(3) sum_cd = sum(cd) print(sum_cd) cd = countdown(3) sorted_cd = sorted(cd) print(sorted_cd) 生成器表达式\n# generator expression mygenerator = (i for i in range(1000) if i % 2 == 0) print(sys.getsizeof(mygenerator), \u0026#34;bytes\u0026#34;) # list comprehension mylist = [i for i in range(1000) if i % 2 == 0] print(sys.getsizeof(mylist), \u0026#34;bytes\u0026#34;) # 120bytes # 4272 bytes 生成器概念 类可以实现生成器作为一个可迭代对象，它需要实现__iter__方法和__next__方法，使得类对象可迭代。此外，还需要注意记录迭代次数，以及最后raise一个StopIteration异常。\nclass firstn: def __init__(self, n): self.n = n self.num = 0 def __iter__(self): return self def __next__(self): if self.num \u0026lt; self.n: cur = self.num self.num += 1 return cur else: raise StopIteration() firstn_object = firstn(1000000) print(sum(firstn_object)) 装饰器Decorators 装饰器的典型使用场景有：\n计算函数执行时间 用于调试，打印出函数的参数和调用信息 作为函数的参数校验 以插件的形式注册函数 降低代码执行速度来测试网络，如使用sleep函数 缓存代码执行结果Memoization 附加信息或者更新状态 装饰器就是一个语法糖，如下装饰器就类似target = somedecorator(target)\n装饰器一个特性就是将被装饰函数替换为其他函数\n@somedecorator def target(): print(\u0026#34;running target\u0026#34;) 简单装饰器模板\nimport functools def my_decorator(func): @functools.wraps(func)\t# 保持被装饰函数的属性 def wrapper(*args, **kwargs): # Do something before result = func(*args, **kwargs) # Do something after return result return wrapper 带参数的装饰器函数，可以认为是两层函数，在简单装饰器外部套一个函数来扩展装饰器的行为。\n即两层闭包，一个持有外部环境变量的函数就是闭包。\ndef repeat(num_times): def decorator_repeat(func): @functools.wraps(func) def wrapper(*args, **kwargs): for _ in range(num_times): result = func(*args, **kwargs) return result return wrapper return decorator_repeat @repeat(num_times=3) def greet(name): print(f\u0026#34;Hello {name}\u0026#34;) greet(\u0026#39;Alex\u0026#39;) # 输出 \u0026#34;\u0026#34;\u0026#34; Hello Alex Hello Alex Hello Alex \u0026#34;\u0026#34;\u0026#34; 层叠装饰器 装饰器的执行顺序是decorator(func)，从外到内执行，如果有多个装饰器堆叠在一起，按照decorator2(docorator1(func))的执行顺序。\n其更清晰的执行顺序是：\nfunc = decorator1(func) func = decorator2(func) func() 多个装饰器装饰函数时，有个规律是从下到上包裹（装饰）函数，在装饰的过程中执行装饰器函数和内部闭包wrapper函数之间代码，闭包函数知识作为一个对象被返回，在装饰过程中并不执行。\n而在执行被装饰函数的过程中，从上到下执行wrapper函数内部的代码。\n如下代码多个装饰器，其装饰的顺序和wrapper执行的顺序相反。\n# 装饰过程 say_hello = start_end_decorator_2(start_end_decorator_1(say_hello)) say_hello() 多装饰器实验\nimport functools # a decorator function that prints debug information about the wrapped function def start_end_decorator_2(func): print(\u0026#39;Start decorator2\u0026#39;) @functools.wraps(func) def wrapper2(*args, **kwargs): print(\u0026#39;Exec wrapper 2\u0026#39;) result = func(*args, **kwargs) print(\u0026#39;End wrapper 2\u0026#39;) return result return wrapper2 def start_end_decorator_1(func): print(\u0026#39;Start decorator1\u0026#39;) @functools.wraps(func) def wrapper1(*args, **kwargs): print(\u0026#39;Exec wrapper 1\u0026#39;) result = func(*args, **kwargs) print(\u0026#39;End wrapper 1\u0026#39;) return result return wrapper1 @start_end_decorator_2 @start_end_decorator_1 def say_hello(name): greeting = f\u0026#39;Hello {name}\u0026#39; print(greeting) return greeting \u0026#34;\u0026#34;\u0026#34; 相当于 func = start_end_decorator_1(func) 此时func是下面这个wrapper1函数 def wrapper1(*args, **kwargs): print(\u0026#39;Exec wrapper 1\u0026#39;) result = func(*args, **kwargs) print(\u0026#39;End wrapper 1\u0026#39;) return result 再经过下一个装饰器start_end_decorator_2 func再次被替换 func = start_end_decorator_2(start_end_decorator_1(func)) \u0026#34;\u0026#34;\u0026#34; say_hello(name=\u0026#39;Alex\u0026#39;) # exec result \u0026#34;\u0026#34;\u0026#34; Start decorator1 Start decorator2 Exec wrapper 2 Exec wrapper 1 Hello Alex End wrapper 1 End wrapper 2 \u0026#34;\u0026#34;\u0026#34; 装饰器执行时间 装饰器需要区分导入时和运行时，\n装饰器一个特性就是装饰的过程在import时执行，当import代码时，装饰器立刻执行，将被装饰函数变为另一个函数。\nregistry = [] def register(func): print(\u0026#34;running register(%s)\u0026#34; % func) registry.append(func) return func @register def f1(): print(\u0026#34;running f1\u0026#34;) @register def f2(): print(\u0026#34;running f2\u0026#34;) def f3(): print(\u0026#34;running f3\u0026#34;) def main(): print(\u0026#34;running main\u0026#34;) print(\u0026#34;registry -\u0026gt;\u0026#34;, registry) f1() f2() f3() if __name__ == \u0026#34;__main__\u0026#34;: main() # import该模块的输出如下 \u0026#34;\u0026#34;\u0026#34; running register(\u0026lt;function f1 at 0x7f4105056af0\u0026gt;) running register(\u0026lt;function f2 at 0x7f4105056c10\u0026gt;) \u0026#34;\u0026#34;\u0026#34; # 执行main函数的输出如下 # 在运行时，被装饰函数才开始执行 \u0026#34;\u0026#34;\u0026#34; running register(\u0026lt;function f1 at 0x7f65b62d70d0\u0026gt;) running register(\u0026lt;function f2 at 0x7f65b62d7160\u0026gt;) running main registry -\u0026gt; [\u0026lt;function f1 at 0x7f65b62d70d0\u0026gt;, \u0026lt;function f2 at 0x7f65b62d7160\u0026gt;] running f1 running f2 running f3 \u0026#34;\u0026#34;\u0026#34; 类装饰器 可以使用类作为装饰器，因此，需要首先实现魔法方法__call__，使得对象是callable可调用的，类装饰器典型用处是保存状态，如函数被调用次数。我们使用functools.update_wrapper()而不是functools.wraps来持久化被装饰器函数信息。\nimport functools class CountCalls: # the init needs to have the func as argument and stores it def __init__(self, func): functools.update_wrapper(self, func) self.func = func self.num_calls = 0 # extend functionality, execute function, and return the result def __call__(self, *args, **kwargs): self.num_calls += 1 print(f\u0026#34;Call {self.num_calls} of {self.func.__name__!r}\u0026#34;) return self.func(*args, **kwargs) @CountCalls def say_hello(num): print(\u0026#34;Hello!\u0026#34;) say_hello(5) say_hello(5) # result \u0026#34;\u0026#34;\u0026#34; Call 1 of \u0026#39;say_hello\u0026#39; Hello! Call 2 of \u0026#39;say_hello\u0026#39; Hello! \u0026#34;\u0026#34;\u0026#34; Context Managers 上下文管理器用于资源管理，允许你方便的分配和释放资源\nPython内置的关键字with用于处理上下文管理器，上下文管理器典型的用途有：\n打开和关闭文件 打开和关闭数据库连接 获得和释放锁 from threading import Lock lock = Lock() # error-prone: lock.acquire() # do stuff # lock should always be released! lock.release() # Better: with lock: # do stuff 实现一个上下文管理器类 为了支持with关键字，需要在类中实现__enter__和__exit__方法，当Python执行到with语句，会执行__enter__方法，此时应该获取资源并返回，而当离开上下文环境时，将执行__exit__方法，此时应该释放资源。\nclass ManagedFile: def __init__(self, filename): print(\u0026#39;init\u0026#39;, filename) self.filename = filename def __enter__(self): print(\u0026#39;enter\u0026#39;) self.file = open(self.filename, \u0026#39;w\u0026#39;) return self.file def __exit__(self, exc_type, exc_value, exc_traceback): if self.file: self.file.close() print(\u0026#39;exit\u0026#39;) with ManagedFile(\u0026#39;notes.txt\u0026#39;) as f: print(\u0026#39;doing stuff...\u0026#39;) f.write(\u0026#39;some todo...\u0026#39;) 处理异常 当异常产生时，Python将异常类型、值和traceback信息传递给__exit__方法，它可以处理该异常。如果__exit__方法返回了除True之外的任何值，则由with语句引发异常。\nclass ManagedFile: def __init__(self, filename): print(\u0026#39;init\u0026#39;, filename) self.filename = filename def __enter__(self): print(\u0026#39;enter\u0026#39;) self.file = open(self.filename, \u0026#39;w\u0026#39;) return self.file def __exit__(self, exc_type, exc_value, exc_traceback): if self.file: self.file.close() print(\u0026#39;exc:\u0026#39;, exc_type, exc_value) print(\u0026#39;exit\u0026#39;) # No exception with ManagedFile(\u0026#39;notes.txt\u0026#39;) as f: print(\u0026#39;doing stuff...\u0026#39;) f.write(\u0026#39;some todo...\u0026#39;) print(\u0026#39;continuing...\u0026#39;) print() # Exception is raised, but the file can still be closed with ManagedFile(\u0026#39;notes2.txt\u0026#39;) as f: print(\u0026#39;doing stuff...\u0026#39;) f.write(\u0026#39;some todo...\u0026#39;) f.do_something() print(\u0026#39;continuing...\u0026#39;) 也可以在__exit__方法中处理异常，并返回True\nclass ManagedFile: def __init__(self, filename): print(\u0026#39;init\u0026#39;, filename) self.filename = filename def __enter__(self): print(\u0026#39;enter\u0026#39;) self.file = open(self.filename, \u0026#39;w\u0026#39;) return self.file def __exit__(self, exc_type, exc_value, exc_traceback): if self.file: self.file.close() if exc_type is not None: print(\u0026#39;Exception has been handled\u0026#39;) print(\u0026#39;exit\u0026#39;) return True with ManagedFile(\u0026#39;notes2.txt\u0026#39;) as f: print(\u0026#39;doing stuff...\u0026#39;) f.write(\u0026#39;some todo...\u0026#39;) f.do_something() print(\u0026#39;continuing...\u0026#39;) 用生成器实现一个上下文管理器 与其写一个类，也可以写一个生成器函数，并用contextlib.contextmanager来装饰它。\n为了实现这个目的，函数必须在try语句段中yield资源，而在finally语句中实现类似__exit__的功能，即释放资源。\nfrom contextlib import contextmanager @contextmanager def open_managed_file(filename): f = open(filename, \u0026#39;w\u0026#39;) try: yield f finally: f.close() with open_managed_file(\u0026#39;notes.txt\u0026#39;) as f: f.write(\u0026#39;some todo...\u0026#39;) 生成器首先获取资源，然后暂时挂起执行流程，并yeild返回资源，资源可以被调用者使用，当调用着离开with上下文，生成器接着执行后续的finally语句，释放资源。\nPython中的解引用 Python中的*号具有多种作用：\nUse *args for variable-length arguments Use **kwargs for variable-length keyword arguments Use *, followed by more function parameters to enforce keyword-only arguments def my_function(*args, **kwargs): for arg in args: print(arg) for key in kwargs: print(key, kwargs[key]) my_function(\u0026#34;Hey\u0026#34;, 3, [0, 1, 2], name=\u0026#34;Alex\u0026#34;, age=8) # Parameters after \u0026#39;*\u0026#39; or \u0026#39;*identifier\u0026#39; are keyword-only parameters and may only be passed using keyword arguments. def my_function2(name, *, age): print(name) print(age) # my_function2(\u0026#34;Michael\u0026#34;, 5) --\u0026gt; this would raise a TypeError my_function2(\u0026#34;Michael\u0026#34;, age=5) Python函数传参以及深拷贝浅拷贝 在Python中，赋值语句obj_b = obj_a不产生真正的对象拷贝，只创建一个新的变量和obj_a具有相同的引用，因此当你想要产生可变对象的真正的拷贝，并在不影响原来对象的情况下修改拷贝对象时，需要格外小心。\n可以使用copy模块产生真正的拷贝，然而，对于混合/嵌套对象，浅拷贝和深拷贝有重要的区别，\n浅拷贝\n只有一层深，对于比一层深的嵌套对象是源对象的引用，因此修改会导致源对象的更改\n深拷贝\n一份完全独立的拷贝，递归产生源对象中所有嵌套对象的拷贝\n赋值操作 会产生源对象的一个引用，修改会导致源对象的变更\nlist_a = [1, 2, 3, 4, 5] list_b = list_a list_a[0] = -10 print(list_a) print(list_b) \u0026#34;\u0026#34;\u0026#34; [-10, 2, 3, 4, 5] [-10, 2, 3, 4, 5] \u0026#34;\u0026#34;\u0026#34; 浅拷贝 浅拷贝只有一层深度，修改第一层不会影响源对象，使用copy.copy()方法或者对象特定的拷贝方法或者拷贝构造函数\nimport copy list_a = [1, 2, 3, 4, 5] list_b = copy.copy(list_a) # not affects the other list list_b[0] = -10 print(list_a) print(list_b) 但是在嵌套对象中，修改第二层或者更深层次的数据时，会影响到源对象，因为在第二层时拷贝的是引用，而不是值。\nimport copy list_a = [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]] list_b = copy.copy(list_a) # affects the other! list_a[0][0]= -10 print(list_a) print(list_b) \u0026#34;\u0026#34;\u0026#34; [[-10, 2, 3, 4, 5], [6, 7, 8, 9, 10]] [[-10, 2, 3, 4, 5], [6, 7, 8, 9, 10]] \u0026#34;\u0026#34;\u0026#34; 对于列表，类似的浅拷贝方法还有\n# shallow copies list_b = list(list_a) list_b = list_a[:] list_b = list_a.copy() 深拷贝 深拷贝是一份完全独立的克隆，使用copy.deepcopy方法实现\nimport copy list_a = [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]] list_b = copy.deepcopy(list_a) # not affects the other list_a[0][0]= -10 print(list_a) print(list_b) \u0026#34;\u0026#34;\u0026#34; [[-10, 2, 3, 4, 5], [6, 7, 8, 9, 10]] [[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]] \u0026#34;\u0026#34;\u0026#34; 对象的深拷贝和浅拷贝 可以使用copy模块实现对特定对象的深拷贝或者浅拷贝\n赋值只拷贝对象引用 class Person: def __init__(self, name, age): self.name = name self.age = age # Only copies the reference p1 = Person(\u0026#39;Alex\u0026#39;, 27) p2 = p1 p2.age = 28 print(p1.age) print(p2.age) \u0026#34;\u0026#34;\u0026#34; 28 28 \u0026#34;\u0026#34;\u0026#34; 浅拷贝拷贝一层 # shallow copy import copy p1 = Person(\u0026#39;Alex\u0026#39;, 27) p2 = copy.copy(p1) p2.age = 28 print(p1.age) print(p2.age) \u0026#34;\u0026#34;\u0026#34; 27 28 \u0026#34;\u0026#34;\u0026#34; 深拷贝可以完整拷贝 class Company: def __init__(self, boss, employee): self. boss = boss self.employee = employee # shallow copy will affect nested objects boss = Person(\u0026#39;Jane\u0026#39;, 55) employee = Person(\u0026#39;Joe\u0026#39;, 28) company = Company(boss, employee) company_clone = copy.copy(company) company_clone.boss.age = 56 print(company.boss.age) print(company_clone.boss.age) \u0026#34;\u0026#34;\u0026#34; 56 56 \u0026#34;\u0026#34;\u0026#34; # deep copy will not affect nested objects boss = Person(\u0026#39;Jane\u0026#39;, 55) employee = Person(\u0026#39;Joe\u0026#39;, 28) company = Company(boss, employee) company_clone = copy.deepcopy(company) company_clone.boss.age = 56 print(company.boss.age) print(company_clone.boss.age) \u0026#34;\u0026#34;\u0026#34; 55 56 \u0026#34;\u0026#34;\u0026#34; 函数传参 在C语言中传参有显式的值传递和地址传递，在Python中也有类似的机制。\nPython中数据类型存在可变和不可变的区别，即mutable和immutable。\n对于可变类型，例如列表，由于传递的是列表的引用，列表可以在一个方法中被修改\n# immutable objects -\u0026gt; no change def foo(x): x = 5 # x += 5 also no effect since x is immutable and a new variable must be created var = 10 print(\u0026#39;var before foo():\u0026#39;, var) foo(var) print(\u0026#39;var after foo():\u0026#39;, var) \u0026#34;\u0026#34;\u0026#34; var before foo(): 10 var after foo(): 10 \u0026#34;\u0026#34;\u0026#34; 可变对象 # mutable objects -\u0026gt; change def foo(a_list): a_list.append(4) my_list = [1, 2, 3] print(\u0026#39;my_list before foo():\u0026#39;, my_list) foo(my_list) print(\u0026#39;my_list after foo():\u0026#39;, my_list) \u0026#34;\u0026#34;\u0026#34; my_list before foo(): [1, 2, 3] my_list after foo(): [1, 2, 3, 4] \u0026#34;\u0026#34;\u0026#34; 重新绑定一个可变对象的引用 # Rebind a mutable reference -\u0026gt; no change def foo(a_list): # 赋值操作产生一个新的局部变量 a_list = [50, 60, 70] # a_list is now a new local variable within the function a_list.append(50) my_list = [1, 2, 3] print(\u0026#39;my_list before foo():\u0026#39;, my_list) foo(my_list) print(\u0026#39;my_list after foo():\u0026#39;, my_list) 区分+=和= # another example with rebinding references: def foo(a_list): a_list += [4, 5] # this chanches the outer variable def bar(a_list): a_list = a_list + [4, 5] # this rebinds the reference to a new local variable my_list = [1, 2, 3] print(\u0026#39;my_list before foo():\u0026#39;, my_list) foo(my_list) print(\u0026#39;my_list after foo():\u0026#39;, my_list) my_list = [1, 2, 3] print(\u0026#39;my_list before bar():\u0026#39;, my_list) bar(my_list) print(\u0026#39;my_list after bar():\u0026#39;, my_list) \u0026#34;\u0026#34;\u0026#34; my_list before foo(): [1, 2, 3] my_list after foo(): [1, 2, 3, 4, 5] my_list before bar(): [1, 2, 3] my_list after bar(): [1, 2, 3] \u0026#34;\u0026#34;\u0026#34; 参考 Python-Notebook\nPython中的*号\n闭包概念\nPython装饰器\n","permalink":"https://blog.niuhemoon.win/posts/tech/python-advanced-2/","summary":"生成器Generator def countdown(num): print(\u0026#39;Starting\u0026#39;) while num \u0026gt; 0: yield num num -= 1 # this will not print \u0026#39;Starting\u0026#39; cd = countdown(3) # this will print \u0026#39;Starting\u0026#39; and the first value print(next(cd)) # will print the next values print(next(cd)) print(next(cd)) # this will raise a StopIteration print(next(cd)) 迭代器使用方式 # you can iterate over a generator object with a for in loop cd = countdown(3) for x in cd: print(x) # you can use it for functions that take iterables as input cd = countdown(3) sum_cd = sum(cd) print(sum_cd) cd = countdown(3) sorted_cd = sorted(cd) print(sorted_cd) 生成器表达式 # generator expression mygenerator = (i for i in range(1000) if i % 2 == 0) print(sys.getsizeof(mygenerator), \u0026#34;bytes\u0026#34;) # list comprehension mylist","title":"Python进阶中"},{"content":" Ubuntn 上一直以来对中文输入法的支持都不是很完善，在升级到 20.04 版本之后，系统默认自带的是 ibus 输入法，刚刚上手使用之后不是很好用。在尝试安装 fcitx 和搜狗输入法之后，因为搜狗输入法和 Pycharm 等 IDE 冲突，会导致软件卡死，而且资源占用较高。还是切换回了 ibus 输入法。\n在简单调教之后，发现 ibus 还是很好用的。\n打开 Ibus 首选项\n勾选将每个输入记录为新词汇，然后会记录用户的输入历史，方便导出并转移\n启用模糊拼音和词典同样可以提高词汇匹配的准确程度 对于用户数据可以定期备份或者清除 当修改配置后，需要重启 ibus 服务使其生效。使用下面命令行重启 ibus\nibus-daemon -r -d -x 随着日常使用之后，ibus 会根据你的输入记录，优化其输入法。\n","permalink":"https://blog.niuhemoon.win/posts/tech/ibus-input/","summary":"Ubuntn 上一直以来对中文输入法的支持都不是很完善，在升级到 20.04 版本之后，系统默认自带的是 ibus 输入法，刚刚上手使用之后不是很好用。在尝试安装 fcitx 和搜狗输入法之后，因为搜狗输入法和 Pycharm 等 IDE 冲突，会导致软件卡死，而且资源占用较高。还是切换回了 ibus 输入法。 在简单调教之后，发现 ibus 还是很好用的。 打开 Ibus 首选项","title":"Ubuntu20_04上使用ibus中文输入法"},{"content":"基础 1.1 字符匹配 字符 说明 \\ 转义符 \\d [0-9]。表示是一位数字。 \\D [^0-9]。表示除数字外的任意字符。 \\w [0-9a-zA-Z_]。表示数字、大小写字母和下划线。 \\W [^0-9a-za-z_]。非单词字符。 \\s [\\t\\v\\n\\r\\f]。表示空白符，包括空格、水平制表符、 垂直制表符、换行符、回车符、换页符。 \\S [^\\t\\v\\n\\r\\f]。非空白符。 . [^\\n\\r\\u2028\\u2029]。通配符，表示几乎任意字符。 换行符、回车符、行分隔符和段分隔符除外。 \\uxxxx 查找以十六进制数 xxxx 规定的 Unicode 字符。 \\f 匹配一个换页符 (U+000C)。 \\n 匹配一个换行符 (U+000A)。 \\r 匹配一个回车符 (U+000D)。 \\t 匹配一个水平制表符 (U+0009)。 \\v 匹配一个垂直制表符 (U+000B)。 \\0 匹配 NULL（U+0000）字符， 不要在这后面跟其它小数，因为 \\0 是一个 八进制转义序列。 [\\b] 匹配一个退格(U+0008)。（不要和\\b 混淆了。） [abc] any of a, b, or c [^abc] not a, b, or c [a-g] character between a \u0026amp; g 1.2 位置匹配 字符 说明 \\b 是单词边界，具体就是\\w 和\\W 之间的位置，也包括\\w 和 ^ 之间的位置， 也包括\\w 和 之间的位置。 \\B 是\\b 的反面的意思，非单词边界。例如在字符串中所有位置中，扣掉\\b， 剩下的都是\\B 的。 ^abc$ 字符串开始、结束的位置 1.3 组 字符 说明 (abc) capture group，捕获组 \\n backreference to group #n，分组引用，引用第 n 个捕获组匹配的内容, 其中 n 是正整数 (?:abc) non-capturing group，非捕获组 1.4 先行断言 字符 说明 a(?=b) positive lookahead，先行断言，a 只有在 b 前面才匹配 a(?!b) negative lookahead，先行否定断言，a 只有不在 b 前面才匹配 1.5 后行断言 字符 说明 (?\u0026lt;=b)a positive lookbehind，后行断言，a 只有在 b 后面才匹配 (?\u0026lt;!b)a negative lookbehind，后行否定断言，a 只有不在 b 后面才匹配 1.6 量词和分支 字符 说明 a* 0 or more a+ 1 or more a? 0 or 1 a{5} exactly five a{2,} two or more a{1,3} between one \u0026amp; three a+? a{2,}? match as few as possible，惰性匹配，就是尽可能少的匹配 以下都是惰性匹配： {m,n}? {m,}? ?? +? *?\n1.7 分支 字符 说明 ab|cd match ab or cd，匹配\u0026rsquo;ab\u0026rsquo;或者\u0026rsquo;cd\u0026rsquo;字符子串 1.8 修饰符 字符 说明 i 执行对大小写不敏感的匹配。 g 执行全局匹配（查找所有匹配而非在找到第一个匹配后停止）。 m 执行多行匹配。 u 开启\u0026quot;Unicode 模式\u0026quot;，用来正确处理大于\\uFFFF 的 Unicode 字符。也就是说，会正确处理四个字节的 UTF-16 编码。 s 允许 . 匹配换行符。 y y 修饰符的作用与 g 修饰符类似，也是全局匹配，后一次匹配都从上一次匹配成功的下一个位置开始。不同之处在于，g 修饰符只要剩余位置中存在匹配就可，而 y 修饰符确保匹配必须从剩余的第一个位置开始，这也就是\u0026quot;粘连\u0026quot;的涵义 2. 运算符优先级 运算符 描述 \\ 转义符 (), (?:), (?=), [] 圆括号和方括号 *, +, ?, {n}, {n,}, {n,m} 限定符 ^, $, \\任何元字符、任何字符 定位点和序列（即：位置和顺序） | 替换，\u0026ldquo;或\u0026quot;操作 字符具有高于替换运算符的优先级，使得\u0026quot;m|food\u0026quot;匹配\u0026quot;m\u0026quot;或\u0026quot;food\u0026rdquo;。若要匹配\u0026quot;mood\u0026quot;或\u0026quot;food\u0026quot;，请使用括号创建子表达式，从而产生\u0026quot;(m|f)ood\u0026quot;。 使用案例 一、20 个最常用的正则表达式 #1 . 校验密码强度：密码的强度必须是包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间 ^(?=.*\\\\d)(?=.*[a-z])(?=.*[A-Z]).{8,10}$ #2. 校验中文：字符串仅能是中文 ^[\\\\u4e00-\\\\u9fa5]{0,}$ # 3. 由数字、26个英文字母或下划线组成的字符串： ^\\\\w+$ #4. 校验E-Mail 地址：同密码一样，下面是E-mail地址合规性的正则检查语句。 [\\\\w!#$%\u0026amp;\u0026#39;*+/=?^_`{|}~-]+(?:\\\\.[\\\\w!#$%\u0026amp;\u0026#39;*+/=?^_`{|}~-]+)*@(?:[\\\\w](?:[\\\\w-]*[\\\\w])?\\\\.)+[\\\\w](?:[\\\\w #5. 校验身份证号码：下面是身份证号码的正则校验。15 或 18位。 #15位 ^[1-9]\\\\d{7}((0\\\\d)|(1[0-2]))(([0|1|2]\\\\d)|3[0-1])\\\\d{3}$ #18位 ^[1-9]\\\\d{5}[1-9]\\\\d{3}((0\\\\d)|(1[0-2]))(([0|1|2]\\\\d)|3[0-1])\\\\d{3}([0-9]|X)$ #6. 校验日期：“yyyy-mm-dd“ 格式的日期校验，已考虑平闰年。 ^(?:(?!0000)[0-9]{4}-(?:(?:0[1-9]|1[0-2])-(?:0[1-9]|1[0-9]|2[0-8])|(?:0[13-9]|1[0-2])-(?:29|30)|(?:0[13578]|1[02])-31)|(?:[0-9]{2}(?:0[48]|[2468][048]|[13579][26])|(?:0[48]|[2468][048]|[13579][26])00)-02-29)$ #7. 校验金额：金额校验，精确到2位小数。 ^[0-9]+(.[0-9]{2})?$ #8. 校验手机号：下面是国内 13、15、18开头的手机号正则表达式。 ^(13[0-9]|14[5|7]|15[0|1|2|3|5|6|7|8|9]|18[0|1|2|3|5|6|7|8|9])\\\\d{8}$ #9. 判断IE的版本：IE目前还没被完全取代，很多页面还是需要做版本兼容，下面是IE版本检查的表达式。 ^.*MSIE [5-8](?:\\\\.[0-9]+)?(?!.*Trident\\\\/[5-9]\\\\.0).*$ #10. 校验IP-v4地址：IP4 正则语句 \\\\b(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\b #11. 校验IP-v6地址：IP6 正则语句。 (([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])) #12. 检查URL的前缀：应用开发中很多时候需要区分请求是HTTPS还是HTTP，通过下面的表达式可以取出一个url的前缀然后再逻辑判断。 if (!s.match(/^[a-zA-Z]+:\\\\/\\\\//)) { s = \u0026#39;http://\u0026#39; + s; } #13. 提取URL链接：下面的这个表达式可以筛选出一段文本中的URL。 ^(f|ht){1}(tp|tps):\\\\/\\\\/([\\\\w-]+\\\\.)+[\\\\w-]+(\\\\/[\\\\w- ./?%\u0026amp;=]*)? #14. 文件路径及扩展名校验：下面的这个表达式可以筛选出一段文本中的URL。 ^(f|ht){1}(tp|tps):\\\\/\\\\/([\\\\w-]+\\\\.)+[\\\\w-]+(\\\\/[\\\\w- ./?%\u0026amp;=]*)? #14. 文件路径及扩展名校验：验证文件路径和扩展名 ^([a-zA-Z]\\\\:|\\\\\\\\)\\\\\\\\([^\\\\\\\\]+\\\\\\\\)*[^\\\\/:*?\u0026#34;\u0026lt;\u0026gt;|]+\\\\.txt(l)?$ #15. 提取Color Hex Codes：有时需要抽取网页中的颜色代码，可以使用下面的表达式。 \\\\#([a-fA-F]|[0-9]){3,6} #16. 提取网页图片：假若你想提取网页中所有图片信息，可以利用下面的表达式。 \\\\\u0026lt; *[img][^\\\\\u0026gt;]*[src] *= *[\\\\\u0026#34;\\\\\u0026#39;]{0,1}([^\\\\\u0026#34;\\\\\u0026#39;\\\\ \u0026gt;]*) #17. 提取页面超链接：提取html中的超链接。 (\u0026lt;;a\\\\s*(?!.*\\\\brel=)[^\u0026gt;;]*)(href=\u0026#34;https?://)((?!(?:(?:www\\\\.)?\u0026#39;.implode(\u0026#39;|(?:www\\\\.)?\u0026#39;, $follow_list) #18. 精炼CSS：通过下面的表达式，可以搜索相同属性值的CSS，从而达到精炼代码的目的。 ^\\\\s*[a-zA-Z\\\\-]+\\\\s*[:]{1}\\\\s[a-zA-Z0-9\\\\s.#]+[;]{1} #19. 抽取注释：如果你需要移除HMTL中的注释，可以使用如下的表达式。 \u0026lt;!--(.*?)--\u0026gt; #20. 匹配HTML标签：通过下面的表达式可以匹配出HTML中的标签。 \u0026lt;/?\\\\w+((\\\\s+\\\\w+(\\\\s*=\\\\s*(?:\u0026#34;.*?\u0026#34;|\u0026#39;.*?\u0026#39;|[\\\\^\u0026#39;\u0026#34;\u0026gt;\\\\s]+))?)+\\\\s*|\\\\s*)/?\u0026gt; 二、校验数字表达式 1 数字：^[0-9]*$ 2 n位的数字：^\\d{n}$ 3 至少n位的数字：^\\d{n,}$ 4 m-n位的数字：^\\d{m,n}$ 5 零和非零开头的数字：^(0|[1-9][0-9]*)$ 6 非零开头的最多带两位小数的数字：^([1-9][0-9]*)+(.[0-9]{1,2})?$ 7 带1-2位小数的正数或负数：^(\\-)?\\d+(\\.\\d{1,2})?$ 8 正数、负数、和小数：^(\\-|\\+)?\\d+(\\.\\d+)?$ 9 有两位小数的正实数：^[0-9]+(.[0-9]{2})?$ 10 有1~3位小数的正实数：^[0-9]+(.[0-9]{1,3})?$ 11 非零的正整数：^[1-9]\\d*$ 或 ^([1-9][0-9]*){1,3}$ 或 ^\\+?[1-9][0-9]*$ 12 非零的负整数：^\\-[1-9][]0-9\u0026#34;*$ 或 ^-[1-9]\\d*$ 13 非负整数：^\\d+$ 或 ^[1-9]\\d*|0$ 14 非正整数：^-[1-9]\\d*|0$ 或 ^((-\\d+)|(0+))$ 15 非负浮点数：^\\d+(\\.\\d+)?$ 或 ^[1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*|0?\\.0+|0$ 16 非正浮点数：^((-\\d+(\\.\\d+)?)|(0+(\\.0+)?))$ 或 ^(-([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*))|0?\\.0+|0$ 17 正浮点数：^[1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*$ 或 ^(([0-9]+\\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\\.[0-9]+)|([0-9]*[1-9][0-9]*))$ 18 负浮点数：^-([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*)$ 或 ^(-(([0-9]+\\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\\.[0-9]+)|([0-9]*[1-9][0-9]*)))$ 19 浮点数：^(-?\\d+)(\\.\\d+)?$ 或 ^-?([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*|0?\\.0+|0)$ 三、校验字符的表达式 1 汉字：^[\\u4e00-\\u9fa5]{0,}$ 2 英文和数字：^[A-Za-z0-9]+$ 或 ^[A-Za-z0-9]{4,40}$ 3 长度为3-20的所有字符：^.{3,20}$ 4 由26个英文字母组成的字符串：^[A-Za-z]+$ 5 由26个大写英文字母组成的字符串：^[A-Z]+$ 6 由26个小写英文字母组成的字符串：^[a-z]+$ 7 由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$ 8 由数字、26个英文字母或者下划线组成的字符串：^\\w+$ 或 ^\\w{3,20}$ 9 中文、英文、数字包括下划线：^[\\u4E00-\\u9FA5A-Za-z0-9_]+$ 10 中文、英文、数字但不包括下划线等符号：^[\\u4E00-\\u9FA5A-Za-z0-9]+$ 或 ^[\\u4E00-\\u9FA5A-Za-z0-9]{2,20}$ 11 可以输入含有^%\u0026amp;\u0026#39;,;=?$\\\u0026#34;等字符：[^%\u0026amp;\u0026#39;,;=?$\\x22]+ 12 禁止输入含有~的字符：[^~\\x22]+ 四、特殊需求表达式 1 Email地址：^\\w+([-+.]\\w+)*@\\w+([-.]\\w+)*\\.\\w+([-.]\\w+)*$ 2 域名：[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(/.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+/.? 3 InternetURL：[a-zA-z]+://[^\\s]* 或 ^http://([\\w-]+\\.)+[\\w-]+(/[\\w-./?%\u0026amp;=]*)?$ 4 手机号码：^(13[0-9]|14[5|7]|15[0|1|2|3|5|6|7|8|9]|18[0|1|2|3|5|6|7|8|9])\\d{8}$ 5 电话号码(\u0026#34;XXX-XXXXXXX\u0026#34;、\u0026#34;XXXX-XXXXXXXX\u0026#34;、\u0026#34;XXX-XXXXXXX\u0026#34;、\u0026#34;XXX-XXXXXXXX\u0026#34;、\u0026#34;XXXXXXX\u0026#34;和\u0026#34;XXXXXXXX)：^(\\(\\d{3,4}-)|\\d{3.4}-)?\\d{7,8}$ 6 国内电话号码(0511-4405222、021-87888822)：\\d{3}-\\d{8}|\\d{4}-\\d{7} 7 身份证号(15位、18位数字)：^\\d{15}|\\d{18}$ 8 短身份证号码(数字、字母x结尾)：^([0-9]){7,18}(x|X)?$ 或 ^\\d{8,18}|[0-9x]{8,18}|[0-9X]{8,18}?$ 9 帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]{4,15}$ 10 密码(以字母开头，长度在6~18之间，只能包含字母、数字和下划线)：^[a-zA-Z]\\w{5,17}$ 11 强密码(必须包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间)：^(?=.*\\d)(?=.*[a-z])(?=.*[A-Z]).{8,10}$ 12 日期格式：^\\d{4}-\\d{1,2}-\\d{1,2} 13 一年的12个月(01～09和1～12)：^(0?[1-9]|1[0-2])$ 14 一个月的31天(01～09和1～31)：^((0?[1-9])|((1|2)[0-9])|30|31)$ 15 钱的输入格式： 16 1.有四种钱的表示形式我们可以接受:\u0026#34;10000.00\u0026#34; 和 \u0026#34;10,000.00\u0026#34;, 和没有 \u0026#34;分\u0026#34; 的 \u0026#34;10000\u0026#34; 和 \u0026#34;10,000\u0026#34;：^[1-9][0-9]*$ 17 2.这表示任意一个不以0开头的数字,但是,这也意味着一个字符\u0026#34;0\u0026#34;不通过,所以我们采用下面的形式：^(0|[1-9][0-9]*)$ 18 3.一个0或者一个不以0开头的数字.我们还可以允许开头有一个负号：^(0|-?[1-9][0-9]*)$ 19 4.这表示一个0或者一个可能为负的开头不为0的数字.让用户以0开头好了.把负号的也去掉,因为钱总不能是负的吧.下面我们要加的是说明可能的小数部分：^[0-9]+(.[0-9]+)?$ 20 5.必须说明的是,小数点后面至少应该有1位数,所以\u0026#34;10.\u0026#34;是不通过的,但是 \u0026#34;10\u0026#34; 和 \u0026#34;10.2\u0026#34; 是通过的：^[0-9]+(.[0-9]{2})?$ 21 6.这样我们规定小数点后面必须有两位,如果你认为太苛刻了,可以这样：^[0-9]+(.[0-9]{1,2})?$ 22 7.这样就允许用户只写一位小数.下面我们该考虑数字中的逗号了,我们可以这样：^[0-9]{1,3}(,[0-9]{3})*(.[0-9]{1,2})?$ 23 8.1到3个数字,后面跟着任意个 逗号+3个数字,逗号成为可选,而不是必须：^([0-9]+|[0-9]{1,3}(,[0-9]{3})*)(.[0-9]{1,2})?$ 24 备注：这就是最终结果了,别忘了\u0026#34;+\u0026#34;可以用\u0026#34;*\u0026#34;替代如果你觉得空字符串也可以接受的话(奇怪,为什么?)最后,别忘了在用函数时去掉去掉那个反斜杠,一般的错误都在这里 25 xml文件：^([a-zA-Z]+-?)+[a-zA-Z0-9]+\\\\.[x|X][m|M][l|L]$ 26 中文字符的正则表达式：[\\u4e00-\\u9fa5] 27 双字节字符：[^\\x00-\\xff] (包括汉字在内，可以用来计算字符串的长度(一个双字节字符长度计2，ASCII字符计1)) 28 空白行的正则表达式：\\n\\s*\\r (可以用来删除空白行) 29 HTML标记的正则表达式：\u0026lt;(\\S*?)[^\u0026gt;]*\u0026gt;.*?\u0026lt;/\\1\u0026gt;|\u0026lt;.*? /\u0026gt; (网上流传的版本太糟糕，上面这个也仅仅能部分，对于复杂的嵌套标记依旧无能为力) 30 首尾空白字符的正则表达式：^\\s*|\\s*$或(^\\s*)|(\\s*$) (可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式) 31 腾讯QQ号：[1-9][0-9]{4,} (腾讯QQ号从10000开始) 32 中国邮政编码：[1-9]\\d{5}(?!\\d) (中国邮政编码为6位数字) 33 IP地址：\\d+\\.\\d+\\.\\d+\\.\\d+ (提取IP地址时有用) 34 IP地址：((?:(?:25[0-5]|2[0-4]\\\\d|[01]?\\\\d?\\\\d)\\\\.){3}(?:25[0-5]|2[0-4]\\\\d|[01]?\\\\d?\\\\d)) 排除特定字符串 # 不以com结尾的 ^.*?(?\u0026lt;!com)$ # 以com结尾 ^.*?(?\u0026lt;=com)$ ^.*?com$ # 不包含helloworld的字符串 ^(?!.*helloworld).*$ 匹配测试工具 在线验证工具 https://regexr.com/ https://www.debuggex.com/ https://deerchao.cn/tools/wegester/ https://regex101.com/ 正则可视化工具 https://jex.im/regulex/#!flags=\u0026amp;re=%5E(a%7Cb)*%3F%24 https://regexper.com/ 参考 正则表达式引擎执行原理\n如何匹配 3 的倍数\n实现一个正则表达式\n正则表达式 30 分钟入门\nPython 正则表达式\nPython 正则表达式指南\n利用正则表达式排除特定字符串\n一文掌握开发利器：正则表达式\nJavascript 正则 cheatsheet\nPython 正则 cheatsheet\n","permalink":"https://blog.niuhemoon.win/posts/tech/re-usage/","summary":"基础 1.1 字符匹配 字符 说明 \\ 转义符 \\d [0-9]。表示是一位数字。 \\D [^0-9]。表示除数字外的任意字符。 \\w [0-9a-zA-Z_]。表示数字、大小写字母和下划线。 \\W [^0-9a-za-z_]。非单词字符。 \\s [\\t\\v\\n\\r\\f]。表示空白符，包括空格、水平制表符、 垂直制表符、换行符","title":"正则表达式基本使用"},{"content":" 本文主要介绍PlantUML绘图环境的搭建以及时序图的绘制，主要以Linux平台为例。\n安装 若安装时序图和活动图以外的图形，需要安装graphviz\nsudo apt install graphviz VScode安装插件\nPlantUML Markdown Preview Enhanced 插件支持的文件名后缀是：.wsd, .pu, .puml, .plantuml, .iuml\n编辑文件完成后，按快捷键ALT+D预览\nCtrl+Shift+p可以选择导出图片\n需要java\nsudo apt install default-jre 浏览器插件支持PlantUML\nPlantUML Viewer插件可以打开UML文本并预览\n时序图示例 你可以用-\u0026gt;来绘制参与者之间传递的消息， 而不必显式地声明参与者。\n@startuml 用户 -\u0026gt; 认证中心: 登录操作 认证中心 -\u0026gt; 缓存: 存放(key=token+ip,value=token)token 用户 \u0026lt;- 认证中心 : 认证成功返回token 用户 -\u0026gt; 认证中心: 下次访问头部携带token认证 认证中心 \u0026lt;- 缓存: key=token+ip获取token 其他服务 \u0026lt;- 认证中心: 存在且校验成功则跳转到用户请求的其他服务 其他服务 -\u0026gt; 用户: 信息 @enduml 也可以通过关键字声明参与者\n@startuml actor Foo1 boundary Foo2 control Foo3 entity Foo4 database Foo5 collections Foo6 Foo1 -\u0026gt; Foo2 : To boundary Foo1 -\u0026gt; Foo3 : To control Foo1 -\u0026gt; Foo4 : To entity Foo1 -\u0026gt; Foo5 : To database Foo1 -\u0026gt; Foo6 : To collections @enduml @startuml title: 序列图sequence(示例) participant A participant B participant C participant D participant E note left of A: A左侧说明 note over D: 覆盖D的说明 note right of F: F右侧说明 A -\u0026gt;x B: 丢失的消息 B -\u0026gt; C: 实线箭头 C -\u0026gt;\u0026gt; D: 实线细箭头 D -\\ E: 实线半箭头 E -\\\\ F: 实线半箭头 F --/ E: 虚线半箭头 E --\u0026gt;o D: 虚线箭头加圈 D --\\o C: 虚线半箭头加圈 C \u0026lt;--\u0026gt; B: 实线双向箭头 A --\u0026gt; A: 自己到自己 @enduml 参考 PlantUML官网\n浏览器插件\n时序图示例\n","permalink":"https://blog.niuhemoon.win/posts/tech/plantuml-sequence/","summary":"\u003cblockquote\u003e\n\u003cp\u003e本文主要介绍PlantUML绘图环境的搭建以及时序图的绘制，主要以Linux平台为例。\u003c/p\u003e\n\u003c/blockquote\u003e","title":"PlantUML画时序图"},{"content":"Git版本控制 尽管 Git 的接口有些丑陋，但是它的底层设计和思想却是非常优雅的。丑陋的接口只能靠死记硬背，而优雅的底层设计则非常容易被人理解。因此，我们将通过一种自底向上的方式像您介绍 Git。我们会从数据模型开始，最后再学习它的接口。一旦您搞懂了 Git 的数据模型，再学习其接口并理解这些接口是如何操作数据模型的就非常容易了。\nGit 的数据模型 进行版本控制的方法很多。Git 拥有一个经过精心设计的模型，这使其能够支持版本控制所需的所有特性，例如维护历史记录、支持分支和促进协作。\n快照 Git 将顶级目录中的文件和文件夹作为集合，并通过一系列快照来管理其历史记录。在Git的术语里，文件被称作Blob对象（数据对象），也就是一组数据。目录则被称之为“树”，它将名字与Blob对象或树对象进行映射（使得目录中可以包含其他目录）。快照则是被追踪的最顶层的树。例如，一个树看起来可能是这样的：\n\u0026lt;root\u0026gt; (tree) | +- foo (tree) | | | + bar.txt (blob, contents = \u0026#34;hello world\u0026#34;) | +- baz.txt (blob, contents = \u0026#34;git is wonderful\u0026#34;) 这个顶层的树包含了两个元素，一个名为 “foo” 的树(它本身包含了一个blob对象 “bar.txt”)，以及一个对blob对象 “baz.txt”。\n历史记录建模：关联快照 版本控制系统和快照有什么关系呢？线性历史记录是一种最简单的模型，它包含了一组按照时间顺序线性排列的快照。不过处于种种原因，Git 并没有采用这样的模型。\n在 Git 中，历史记录是一个由快照组成的有向无环图。有向无环图，听上去似乎是什么高大上的数学名词。不过不要怕，您只需要知道这代表 Git 中的每个快照都有一系列的“父辈”，也就是其之前的一系列快照。注意，快照具有多个“父辈”而非一个，因为某个快照可能由多个父辈而来。例如，经过合并后的两条分支。\n在 Git 中，这些快照被称为“提交”。通过可视化的方式来表示这些历史提交记录时，看起来差不多是这样的：\no \u0026lt;-- o \u0026lt;-- o \u0026lt;-- o ^ \\ --- o \u0026lt;-- o 上面是一个 ASCII 码构成的简图，其中的 o 表示一次提交（快照）。\n箭头指向了当前提交的父辈（这是一种“在。。。之前”，而不是“在。。。之后”的关系）。在第三次提交之后，历史记录分岔成了两条独立的分支。这可能因为此时需要同时开发两个不同的特性，它们之间是相互独立的。开发完成后，这些分支可能会被合并并创建一个新的提交，这个新的提交会同时包含这些特性。新的提交会创建一个新的历史记录，看上去像这样（最新的合并提交用粗体标记）：\no \u0026lt;\u0026ndash; o \u0026lt;\u0026ndash; o \u0026lt;\u0026ndash; o \u0026lt;\u0026mdash;- o ^ / \\ v \u0026mdash; o \u0026lt;\u0026ndash; o\nGit 中的提交是不可改变的。但这并不代表错误不能被修改，只不过这种“修改”实际上是创建了一个全新的提交记录。而引用（参见下文）则被更新为指向这些新的提交。\n数据模型及其伪代码表示 以伪代码的形式来学习 Git 的数据模型，可能更加清晰：\n// 文件就是一组数据 type blob = array\u0026lt;byte\u0026gt; // 一个包含文件和目录的目录 type tree = map\u0026lt;string, tree | file\u0026gt; // 每个提交都包含一个父辈，元数据和顶层树 type commit = struct { parent: array\u0026lt;commit\u0026gt; author: string message: string snapshot: tree } 这是一种简洁的历史模型。\n对象和内存寻址 Git 中的对象可以是 blob、树或提交：\ntype object = blob | tree | commit Git 在储存数据时，所有的对象都会基于它们的SHA-1 hash进行寻址。\nobjects = map\u0026lt;string, object\u0026gt; def store(object): id = sha1(object) objects[id] = object def load(id): return objects[id] Blobs、树和提交都一样，它们都是对象。当它们引用其他对象时，它们并没有真正的在硬盘上保存这些对象，而是仅仅保存了它们的哈希值作为引用。\n例如，above例子中的树（可以通过git cat-file -p 698281bc680d1995c5f4caaf3359721a5a58d48d 来进行可视化），看上去是这样的：\n100644 blob 4448adbf7ecd394f42ae135bbeed9676e894af85 baz.txt 040000 tree c68d233a33c5c06e0340e4c224f0afca87c8ce87 foo 树本身会包含一些指向其他内容的指针，例如baz.txt (blob) 和 foo (树)。如果我们用git cat-file -p 4448adbf7ecd394f42ae135bbeed9676e894af85，即通过哈希值查看 baz.txte 的内容，会得到以下信息：\ngit is wonderful 引用 现在，所有的快照都可以通过它们的 SHA-1 哈希值来标记了。但这也太不方便了，谁也记不住一串 40 位的十六进制字符。\n针对这一问题，Git 的解决方法是给这些哈希值赋予人类可读的名字，也就是引用（references）。引用是指向提交的指针。与对象不同的是，它是可变的（引用可以被更新，指向新的提交）。例如，master 引用通常会指向主分支的最新一次提交。\nreferences = map\u0026lt;string, string\u0026gt; def update_reference(name, id): references[name] = id def read_reference(name): return references[name] def load_reference(name_or_id): if name_or_id in references: return load(references[name_or_id]) else: return load(name_or_id) 这样，Git 就可以使用诸如 “master” 这样人类刻度的名称来表示历史记录中某个特定的提交，而不需要在使用一长串十六进制字符了。\n有一个细节需要我们注意， 通常情况下，我们会想要知道“我们当前所在位置”，并将其标记下来。这样当我们创建新的快照的时候，我们就可以知道它的相对位置（如何设置它的“父辈”）。在 Git 中，我们当前的位置有一个特殊的索引，它就是”HEAD”。\n仓库 最后，我们可以粗略地给出 Git 仓库的定义了：对象 和 引用。\n在硬盘上，Git 仅存储对象和引用：因为其数据模型仅包含这些东西。所有的 git 命令都对应着对提交树的操作，例如增加对象，增加或删除引用。\n当您输入某个指令时，请思考一些这条命令是如何对底层的图数据结构进行操作的。另一方面，如果您希望修改提交树，例如“丢弃未提交的修改和将 ‘master’ 引用指向提交5d83f9e 时，有什么命令可以完成该操作（针对这个具体问题，您可以使用git checkout master; git reset --hard 5d83f9e）\n暂存区 Git 中还包括一个和数据模型完全不相关的概念，但它确是创建提交的接口的一部分。\n就上面介绍的快照系统来说，您也许会期望它的实现里包括一个 “创建快照” 的命令，该命令能够基于当前工作目录的当前状态创建一个全新的快照。有些版本控制系统确实是这样工作的，但 Git 不是。我们希望简洁的快照，而且每次从当前状态创建快照可能效果并不理想。例如，考虑如下场景，您开发了两个独立的特性，然后您希望创建两个独立的提交，其中第一个提交仅包含第一个特性，而第二个提交仅包含第二个特性。或者，假设您在调试代码时添加了很多打印语句，然后您仅仅希望提交和修复 bug 相关的代码而丢弃所有的打印语句。\nGit 处理这些场景的方法是使用一种叫做 “暂存区（staging area）”的机制，它允许您指定下次快照中要包括那些改动。\nGit 的命令行接口 为了避免重复信息，我们将不会详细解释以下命令行。强烈推荐您阅读Pro Git 中文版或可以观看本讲座的视频来学习。\n基础 git help \u0026lt;command\u0026gt;: 获取 git 命令的帮助信息 git init: 创建一个新的 git 仓库，其数据会存放在一个名为 .git 的目录下 git status: 显示当前的仓库状态 git add \u0026lt;filename\u0026gt;: 添加文件到暂存区 git commit: 创建一个新的提交 如何编写 良好的提交信息! git log: 显示历史日志 git log --all --graph --decorate: 可视化历史记录（有向无环图） git diff \u0026lt;filename\u0026gt;: 显示与上一次提交之间的差异 git diff \u0026lt;revision\u0026gt; \u0026lt;filename\u0026gt;: 显示某个文件两个版本之间的差异 git checkout \u0026lt;revision\u0026gt;: 更新 HEAD 和目前的分支 分支和合并 git branch: 显示分支 git branch \u0026lt;name\u0026gt;: 创建分支 git checkout -b \u0026lt;name\u0026gt;: 创建分支并切换到该分支 相当于 git branch \u0026lt;name\u0026gt;; git checkout \u0026lt;name\u0026gt; git merge \u0026lt;revision\u0026gt;: 合并到当前分支 git mergetool: 使用工具来处理合并冲突 git rebase: 将一系列补丁变基（rebase）为新的基线 远端操作 git remote: 列出远端 git remote add \u0026lt;name\u0026gt; \u0026lt;url\u0026gt;: 添加一个远端 git push \u0026lt;remote\u0026gt; \u0026lt;local branch\u0026gt;:\u0026lt;remote branch\u0026gt;: 将对象传送至远端并更新远端引用 git branch --set-upstream-to=\u0026lt;remote\u0026gt;/\u0026lt;remote branch\u0026gt;: 创建本地和远端分支的关联关系 git fetch: 从远端获取对象/索引 git pull: 相当于 git fetch; git merge git clone: 从远端下载仓库 撤销 git commit --amend: 编辑提交的内容或信息 git reset HEAD \u0026lt;file\u0026gt;: 恢复暂存的文件 git checkout -- \u0026lt;file\u0026gt;: 丢弃修改 Git 高级操作 git config: Git 是一个 高度可定制的 工具 列出所有config文件里的设置项\ngit config --system -l # 系统级的配置 /etc文件加下 git config --global -l # 用户级的配置 /home/用户名/的文件下 git config --local -l # 仓库/项目级 ./.git/目录下 git config user.name \u0026#39;你的姓名\u0026#39; git config user.email \u0026#39;你的email\u0026#39; 删除配置文件中的配置项\ngit config --unset user.name 查看配置文件中的配置项\ngit config --get user.name 定义指令别名\n# git config alias.指令别名 \u0026#39;标准指令\u0026#39; git config alias.con \u0026#39;config -l\u0026#39; git con git config --unset alias.con 创建.gitignore文件 vi .gitignore .gitignore文件规定了git系统该忽略哪些文件\n/images *.txt !requirements.txt 如以上配置规定了git忽略\n/images目录下的所有文件 除了requirements.txt外的所有txt文件 git clone --shallow: 克隆仓库，但是不包括版本历史信息 git add -p: 交互式暂存 git rebase -i: 交互式变基 git blame: 查看最后修改某行的人 git stash: 暂时移除工作目录下的修改内容 git bisect: 通过二分查找搜索历史记录 .gitignore: 指定 故意不追踪的文件 杂项 图形用户界面: Git 的 图形用户界面客户端 有很多，但是我们自己并不使用这些图形用户界面的客户端，我们选择使用命令行接口 Shell 集成: 将 Git 状态集成到您的 shell 中会非常方便。(zsh,bash)。Oh My Zsh这样的框架中一般以及集成了这一功能 编辑器集成: 和上面一条类似，将 Git 集成到编辑器中好处多多。fugitive.vim 是 Vim 中集成 GIt 的常用插件 工作流:我们已经讲解了数据模型与一些基础命令，但还没讨论到进行大型项目时的一些惯例 ( 有很多 不同的 处理方法) GitHub: Git 并不等同于 GitHub。 在 GitHub 中您需要使用一个被称作拉取请求（pull request）的方法来像其他项目贡献代码 Other Git 提供商: GitHub 并不是唯一的。还有像GitLab 和 BitBucket这样的平台。 资源 Pro Git ，强烈推荐！学习前五章的内容可以教会您流畅使用 Git 的绝大多数技巧，因为您已经理解了 Git 的数据模型。后面的章节提供了很多有趣的高级主题。（Pro Git 中文版）； Oh Shit, Git!?! ，简短的介绍了如何从 Git 错误中恢复； Git for Computer Scientists ，简短的介绍了 Git 的数据模型，与本文相比包含较少量的伪代码以及大量的精美图片； Git from the Bottom Up详细的介绍了 Git 的实现细节，而不仅仅局限于数据模型。好奇的同学可以看看； How to explain git in simple words； Learn Git Branching 通过基于浏览器的游戏来学习 Git ； 参考 课程列表\n","permalink":"https://blog.niuhemoon.win/posts/tech/coding-tools-git/","summary":"Git版本控制 尽管 Git 的接口有些丑陋，但是它的底层设计和思想却是非常优雅的。丑陋的接口只能靠死记硬背，而优雅的底层设计则非常容易被人理解。因此，我们将通过一种自底向上的方式像您介绍 Git。我们会从数据模型开始，最后再学习它的接口。一旦您搞懂了 Git 的数据模型，再学习其接口并理解这些接口","title":"编程工具之Git"},{"content":"Vim编辑器 编辑模式 Vim的设计以大多数时间都花在阅读、浏览和进行少量编辑改动为基础，因此它具有多种操作模式：\n正常模式：在文件中四处移动光标进行修改 插入模式：插入文本 替换模式：替换文本 可视化（一般，行，块）模式：选中文本块 命令模式：用于执行命令 在不同的操作模式下， 键盘敲击的含义也不同。比如，x 在插入模式会插入字母x，但是在正常模式 会删除当前光标所在下的字母，在可视模式下则会删除选中文块。\n在默认设置下，Vim会在左下角显示当前的模式。 Vim启动时的默认模式是正常模式。通常你会把大部分 时间花在正常模式和插入模式。\n你可以按下 \u0026lt;ESC\u0026gt; （逃脱键） 从任何其他模式返回正常模式。 在正常模式，键入 i 进入插入 模式， R 进入替换模式， v 进入可视（一般）模式， V 进入可视（行）模式， \u0026lt;C-v\u0026gt; （Ctrl-V, 有时也写作 ^V）进入可视（块）模式， : 进入命令模式。\n因为你会在使用 Vim 时大量使用 \u0026lt;ESC\u0026gt; 键，可以考虑把大小写锁定键重定义成逃脱键 （MacOS 教程 ）。\n基本操作 插入文本 在正常模式， 键入 i 进入插入模式。 现在 Vim 跟很多其他的编辑器一样， 直到你键入\u0026lt;ESC\u0026gt; 返回正常模式。 你只需要掌握这一点和上面介绍的所有基知识就可以使用 Vim 来编辑文件了 （虽然如果你一直停留在插入模式内不一定高效）。\n缓存， 标签页， 窗口 Vim 会维护一系列打开的文件，称为 “缓存”。 一个 Vim 会话包含一系列标签页，每个标签页包含 一系列窗口 （分隔面板）。每个窗口显示一个缓存。 跟网页浏览器等其他你熟悉的程序不一样的是， 缓存和窗口不是一一对应的关系； 窗口只是视角。 一个缓存可以在 多个 窗口打开，甚至在同一 个标签页内的多个窗口打开。这个功能其实很好用， 比如在查看同一个文件的不同部分的时候。\nVim 默认打开一个标签页，这个标签也包含一个窗口。\n命令行 在正常模式下键入 : 进入命令行模式。 在键入 : 后，你的光标会立即跳到屏幕下方的命令行。 这个模式有很多功能， 包括打开， 保存， 关闭文件， 以及 退出 Vim。\n:q 退出 （关闭窗口） :w 保存 （写） :wq 保存然后退出 :e {文件名} 打开要编辑的文件 :ls 显示打开的缓存 :help {标题} 打开帮助文档 :help :w 打开 :w 命令的帮助文档 :help w 打开 w 移动的帮助文档 Vim 的接口其实是一种编程语言 Vim 最重要的设计思想是 Vim 的界面本身是一个程序语言。 键入操作 （以及他们的助记名） 本身是命令， 这些命令可以组合使用。 这使得移动和编辑更加高效，特别是一旦形成肌肉记忆。\n移动 多数时候你会在正常模式下，使用移动命令在缓存中导航。在 Vim 里面移动也被成为 “名词”， 因为它们指向文字块。\n基本移动: hjkl （左， 下， 上， 右） 词： w （下一个词）， b （词初）， e （词尾） 行： 0 （行初）， ^ （第一个非空格字符）， $ （行尾） 屏幕： H （屏幕首行）， M （屏幕中间）， L （屏幕底部） 翻页： Ctrl-u （上翻）， Ctrl-d （下翻） 文件： gg （文件头）， G （文件尾） 行数： :{行数}\u0026lt;CR\u0026gt; 或者 {行数}G ({行数}为行数) 杂项： % （找到配对，比如括号或者 /* */ 之类的注释对） 查找： f{字符}， t{字符}， F{字符}， T{字符} 查找/到 向前/向后 在本行的{字符} , / ; 用于导航匹配 搜索: /{正则表达式}, n / N 用于导航匹配 选择 可视化模式:\n可视化 可视化行 可视化块 可以用移动命令来选中。\n编辑 所有你需要用鼠标做的事， 你现在都可以用键盘：采用编辑命令和移动命令的组合来完成。 这就是 Vim 的界面开始看起来像一个程序语言的时候。Vim 的编辑命令也被称为 “动词”， 因为动词可以施动于名词。\ni 进入插入模式 但是对于操纵/编辑文本，不单想用退格键完成 O / o 在之上/之下插入行 d{移动命令} 删除 {移动命令} 例如， dw 删除词, d$ 删除到行尾, d0 删除到行头。 c{移动命令} 改变 {移动命令} 例如， cw 改变词 比如 d{移动命令} 再 i x 删除字符 （等同于 dl） s 替换字符 （等同于 xi） 可视化模式 + 操作 选中文字, d 删除 或者 c 改变 u 撤销, \u0026lt;C-r\u0026gt; 重做 y 复制 / “yank” （其他一些命令比如 d 也会复制） p 粘贴 更多值得学习的: 比如 ~ 改变字符的大小写 计数 你可以用一个计数来结合“名词” 和 “动词”， 这会执行指定操作若干次。\n3w 向前移动三个词 5j 向下移动5行 7dw 删除7个词 修饰语 你可以用修饰语改变 “名词” 的意义。修饰语有 i， 表示 “内部” 或者 “在内“， 和 a， 表示 ”周围“。\nci( 改变当前括号内的内容 ci[ 改变当前方括号内的内容 da' 删除一个单引号字符窗， 包括周围的单引号 自定义 Vim Vim 由一个位于 ~/.vimrc 的文本配置文件 （包含 Vim 脚本命令）。 你可能会启用很多基本 设置。\n我们提供一个文档详细的基本设置， 你可以用它当作你的初始设置。 我们推荐使用这个设置因为 它修复了一些 Vim 默认设置奇怪行为。 在 这儿 下载我们的设置， 然后将它保存成 ~/.vimrc.\nVim 能够被重度自定义， 花时间探索自定义选项是值得的。 你可以参考其他人的在 GitHub 上共享的设置文件， 比如， 你的授课人的 Vim 设置 (Anish, Jon (uses neovim), Jose)。 有很多好的博客文章也聊到了这个话题。 尽量不要复制粘贴别人的整个设置文件， 而是阅读和理解它， 然后采用对你有用的部分。\n扩展 Vim Vim 有很多扩展插件。 跟很多互联网上已经过时的建议相反， 你 不 需要在 Vim 使用一个插件 管理器（从 Vim 8.0 开始）。 你可以使用内置的插件管理系统。 只需要创建一个 ~/.vim/pack/vendor/start/ 的文件夹， 然后把插件放到这里 （比如通过 git clone）。\n以下是一些我们最爱的插件：\nctrlp.vim: 模糊文件查找 ack.vim: 代码搜索 nerdtree: 文件浏览器 vim-easymotion: 魔术操作 我们尽量避免在这里提供一份冗长的插件列表。 你可以查看讲师们的开源的配置文件 (Anish, Jon, Jose) 来看看我们使用的其他插件。 浏览 Vim Awesome 来了解一些很棒的插件。 这个话题也有很多博客文章： 搜索 “best Vim plugins”。\nVim 进阶 这里我们提供了一些展示这个编辑器能力的例子。我们无法把所有的这样的事情都教给你， 但是你 可以在使用中学习。 一个好的对策是: 当你在使用你的编辑器的时候感觉 “一定有更好的方法来做这个”， 那么很可能真的有： 上网搜寻一下。\n搜索和替换 :s （替换） 命令 （文档）。\n%s/foo/bar/g 在整个文件中将 foo 全局替换成 bar %s/\\[.*\\](\\(.*\\))/\\1/g 将有命名的 Markdown 链接替换成简单 URLs 多窗口 用 :sp / :vsp 来分割窗口 同一个缓存可以在多个窗口中显示。 宏 q{字符} 来开始在寄存器 {字符} 中录制宏 q 停止录制 @{字符} 重放宏 宏的执行遇错误会停止 {计数}@{字符} 执行一个宏 {计数} 次 宏可以递归 首先用 q{字符}q 清除宏 录制该宏， 用 @{字符} 来递归调用该宏 （在录制完成之前不会有任何操作） 例子： 将 xml 转成 json (file) 一个有 “name” / “email” 键对象的数组 用一个 Python 程序？ 用 sed / 正则表达式 g/people/d %s/\u0026lt;person\u0026gt;/{/g %s/\u0026lt;name\u0026gt;\\(.*\\)\u0026lt;\\/name\u0026gt;/\u0026quot;name\u0026quot;: \u0026quot;\\1\u0026quot;,/g … Vim 命令 / 宏 Gdd, ggdd 删除第一行和最后一行 格式化最后一个元素的宏 （寄存器 e） 跳转到有 \u0026lt;name\u0026gt; 的行 qe^r\u0026quot;f\u0026gt;s\u0026quot;: \u0026quot;\u0026lt;ESC\u0026gt;f\u0026lt;C\u0026quot;\u0026lt;ESC\u0026gt;q 格式化一个人的宏 跳转到有 \u0026lt;person\u0026gt; 的行 qpS{\u0026lt;ESC\u0026gt;j@eA,\u0026lt;ESC\u0026gt;j@ejS},\u0026lt;ESC\u0026gt;q 格式化一个人然后转到另外一个人的宏 跳转到有 \u0026lt;person\u0026gt; 的行 qq@pjq 执行宏到文件尾 999@q 手动移除最后的 , 然后加上 [ 和 ] 分隔符 扩展资料 vimtutor 是一个 Vim 安装时自带的教程 Vim Adventures 是一个学习使用 Vim 的游戏 Vim Tips Wiki Vim Advent Calendar 有很多 Vim 小技巧 Vim Golf 是用 Vim 的用户界面作为程序语言的 code golf Vi/Vim Stack Exchange Vim Screencasts Practical Vim （书） 参考 课程列表\n","permalink":"https://blog.niuhemoon.win/posts/tech/coding-tools-vim/","summary":"Vim编辑器 编辑模式 Vim的设计以大多数时间都花在阅读、浏览和进行少量编辑改动为基础，因此它具有多种操作模式： 正常模式：在文件中四处移动光标进行修改 插入模式：插入文本 替换模式：替换文本 可视化（一般，行，块）模式：选中文本块 命令模式：用于执行命令 在不同的操作模式下， 键盘敲击的含义也","title":"编程工具之Vim"},{"content":"最后一节课，我们回答学生提出的问题:\n学习操作系统相关内容的推荐，比如进程，虚拟内存，中断，内存管理等 你会优先学习的工具有那些？ 使用 Python VS Bash脚本 VS 其他语言? source script.sh 和 ./script.sh 有什么区别? 各种软件包和工具存储在哪里？引用过程是怎样的? /bin 或 /lib 是什么？ 我应该用 apt-get install 还是 pip install 去下载软件包呢? 用于提高代码性能，简单好用的性能分析工具有哪些? 你使用那些浏览器插件? 有哪些有用的数据整理工具？ Docker和虚拟机有什么区别? 不同操作系统的优缺点是什么，我们如何选择（比如选择最适用于我们需求的Linux发行版)? 使用 Vim 编辑器 VS Emacs 编辑器? 机器学习应用的提示或技巧? 还有更多的 Vim 小窍门吗？ 2FA是什么，为什么我需要使用它? 对于不同的 Web 浏览器有什么评价? 参考 学习操作系统相关内容的推荐，比如进程，虚拟内存，中断，内存管理等 首先，不清楚你是不是真的需要了解这些更底层的话题。 当你开始编写更加底层的代码，比如实现或修改内核的时候，这些内容是很重要的。除了其他课程中简要介绍过的进程和信号量之外，大部分话题都不相关。\n学习资源：\nMIT\u0026rsquo;s 6.828 class - 研究生阶段的操作系统课程（课程资料是公开的）。 现代操作系统 第四版（Modern Operating Systems 4th ed） - 作者是Andrew S. Tanenbaum 这本书对上述很多概念都有很好的描述。 FreeBSD的设计与实现（The Design and Implementation of the FreeBSD Operating System） - 关于FreeBSD OS 不错的资源(注意，FreeBSD OS 不是 Linux)。 其他的指南例如 用 Rust 写操作系统 这里用不同的语言逐步实现了内核，主要用于教学的目的。 你会优先学习的工具有那些？ 值得优先学习的内容：\n多去使用键盘，少使用鼠标。这一目标可以通过多加利用快捷键，更换界面等来实现。 学好编辑器。作为程序员你大部分时间都是在编辑文件，因此值得学好这些技能。 学习怎样去自动化或简化工作流程中的重复任务。因为这会节省大量的时间。 学习像 Git 之类的版本控制工具并且知道如何与 GitHub 结合，以便在现代的软件项目中协同工作。 使用 Python VS Bash脚本 VS 其他语言? 通常来说，Bash 脚本对于简短的一次性脚本有效，比如当你想要运行一系列的命令的时候。但是Bash 脚本有一些比较奇怪的地方，这使得大型程序或脚本难以用 Bash 实现：\nBash 可以获取简单的用例，但是很难获得全部可能的输入。例如，脚本参数中的空格会导致Bash 脚本出错。 Bash 对于代码重用并不友好。因此，重用你先前已经写好的代码很困难。通常 Bash 中没有软件库的概念。 Bash 依赖于一些像 $? 或 $@ 的特殊字符指代特殊的值。其他的语言却会显式地引用，比如 exitCode 或 sys.args。 因此，对于大型或者更加复杂的脚本我们推荐使用更加成熟的脚本语言例如 Python 和 Ruby。 你可以找到很多用这些语言编写的，用来解决常见问题的在线库。 如果你发现某种语言实现了你所需要的特定功能库，最好的方式就是直接去使用那种语言。\nsource script.sh 和 ./script.sh 有什么区别? 这两种情况 script.sh 都会在bash会话中被读取和执行，不同点在于那个会话执行这个命令。 对于 source 命令来说，命令是在当前的bash会话种执行的，因此当 source 执行完毕，对当前环境的任何更改（例如更改目录或是定义函数）都会留存在当前会话中。 单独运行 ./script.sh 时，当前的bash会话将启动新的bash会话（实例），并在新实例中运行命令 script.sh。 因此，如果 script.sh 更改目录，新的bash会话（实例）会更改目录，但是一旦退出并将控制权返回给父bash会话，父会话仍然留在先前的位置（不会有目录的更改）。 同样，如果 script.sh 定义了要在终端中访问的函数，需要用 source 命令在当前bash会话中定义这个函数。否则，如果你运行 ./script.sh，只有新的bash会话（进程）才能执行定义的函数，而当前的shell不能。\n各种软件包和工具存储在哪里？引用过程是怎样的? /bin 或 /lib 是什么？ 根据你在命令行中运行的程序，这些包和工具会全部在 PATH 环境变量所列出的目录中查找到， 你可以使用 which 命令(或是 type 命令)来检查你的shell在哪里发现了特定的程序。 一般来说，特定种类的文件存储有一定的规范，文件系统，层次结构标准（Filesystem, Hierarchy Standard）可以查到我们讨论内容的详细列表。\n/bin - 基本命令二进制文件 /sbin - 基本的系统二进制文件，通常是root运行的 /dev - 设备文件，通常是硬件设备接口文件 /etc - 主机特定的系统配置文件 /home - 系统用户的家目录 /lib - 系统软件通用库 /opt - 可选的应用软件 /sys - 包含系统的信息和配置(第一堂课介绍的) /tmp - 临时文件( /var/tmp ) 通常在重启之间删除 /usr/ - 只读的用户数据 /usr/bin - 非必须的命令二进制文件 /usr/sbin - 非必须的系统二进制文件，通常是由root运行的 /usr/local/bin - 用户编译程序的二进制文件 /var -变量文件 像日志或缓存 我应该用 apt-get install 还是 pip install 去下载软件包呢? 这个问题没有普遍的答案。这与使用系统程序包管理器还是特定语言的程序包管理器来安装软件这一更笼统的问题相关。需要考虑的几件事：\n常见的软件包都可以通过这两种方法获得，但是小众的软件包或较新的软件包可能不在系统程序包管理器中。在这种情况下，使用特定语言的程序包管理器是更好的选择。 同样，特定语言的程序包管理器相比系统程序包管理器有更多的最新版本的程序包。 当使用系统软件包管理器时，将在系统范围内安装库。如果出于开发目的需要不同版本的库，则系统软件包管理器可能不能满足你的需要。对于这种情况，大多数编程语言都提供了隔离或虚拟环境，因此你可以用特定语言的程序包管理器安装不同版本的库而不会发生冲突。对于 Python，可以使用 virtualenv，对于 Ruby，使用 RVM 。 根据操作系统和硬件架构，其中一些软件包可能会附带二进制文件或者软件包需要被编译。例如，在树莓派（Raspberry Pi）之类的ARM架构计算机中，在软件附带二进制文件和软件包需要被编译的情况下，使用系统包管理器比特定语言包管理器更好。这在很大程度上取决于你的特定设置。 你应该仅使用一种解决方案，而不同时使用两种方法，因为这可能会导致难以解决的冲突。我们的建议是尽可能使用特定语言的程序包管理器，并使用隔离的环境（例如 Python 的 virtualenv）以避免影响全局环境。 用于提高代码性能，简单好用的性能分析工具有哪些? 性能分析方面相当有用和简单工具是print timing。你只需手动计算代码不同部分之间花费的时间。通过重复执行此操作，你可以有效地对代码进行二分法搜索，并找到花费时间最长的代码段。\n对于更高级的工具， Valgrind 的 Callgrind可让你运行程序并计算所有的时间花费以及所有调用堆栈（即哪个函数调用了另一个函数）。然后，它会生成带注释的代码版本，其中包含每行花费的时间。但是，它会使程序运行速度降低一个数量级，并且不支持线程。其他的， perf 工具和其他特定语言的采样性能分析器可以非常快速地输出有用的数据。Flamegraphs 是对采样分析器结果的可视化工具。你还可以使用针对特定编程语言或任务的工具。例如，对于 Web 开发而言，Chrome 和 Firefox 内置的开发工具具有出色的性能分析器。\n有时，代码中最慢的部分是系统等待磁盘读取或网络数据包之类的事件。在这些情况下，需要检查根据硬件性能估算的理论速度是否不偏离实际数值，也有专门的工具来分析系统调用中的等待时间，包括用于用户程序内核跟踪的eBPF 。如果需要低级的性能分析， bpftrace 值得一试。\n你使用那些浏览器插件? 我们钟爱的插件主要与安全性与可用性有关：\nuBlock Origin - 是一个用途广泛（wide-spectrum）的拦截器，它不仅可以拦截广告，还可以拦截第三方的页面，也可以拦截内部脚本和其他种类资源的加载。如果你打算花更多的时间去配置，前往中等模式（medium mode）或者 强力模式（hard mode）。在你调整好设置之前一些网站会停止工作，但是这些配置会显著提高你的网络安全水平。另外， 简易模式（easy mode）作为默认模式已经相当不错了，可以拦截大部分的广告和跟踪，你也可以自定义规则来拦截网站对象。 Stylus - 是Stylish的分支（不要使用Stylish，它会窃取浏览记录)），这个插件可让你将自定义CSS样式加载到网站。使用Stylus，你可以轻松地自定义和修改网站的外观。可以删除侧边框，更改背景颜色，更改文字大小或字体样式。这可以使你经常访问的网站更具可读性。此外，Stylus可以找到其他用户编写并发布在userstyles.org中的样式。大多数常用的网站都有一个或几个深色主题样式。 全页屏幕捕获 - 内置于 Firefox 和 Chrome 扩展程序中。这些插件提供完整的网站截图，通常比打印要好用。 多账户容器 - 该插件使你可以将Cookie分为“容器”，从而允许你以不同的身份浏览web网页并且/或确保网站无法在它们之间共享信息。 密码集成管理器 - 大多数密码管理器都有浏览器插件，这些插件帮你将登录凭据输入网站的过程不仅方便，而且更加安全。与简单复制粘贴用户名和密码相比，这些插件将首先检查网站域是否与列出的条目相匹配，以防止冒充网站的网络钓鱼窃取登录凭据。 有哪些有用的数据整理工具？ 在数据整理那一节课程中，我们没有时间讨论一些数据整理工具，包括分别用于JSON和HTML数据的专用解析器， jq 和 pup。Perl语言是另一个更高级的可以用于数据整理管道的工具。另一个技巧是使用 column -t 命令，可以将空格文本（不一定对齐）转换为对齐的文本。\n一般来说，vim和Python是两个不常规的数据整理工具。对于某些复杂的多行转换，vim宏是非常有用的工具。你可以记录一系列操作，并根据需要重复执行多次，例如，在编辑的讲义(去年 视频)中，有一个示例是使用vim宏将XML格式的文件转换为JSON。\n对于通常以CSV格式显示的表格数据， Python pandas库是一个很棒的工具。不仅因为它能让复杂操作的定义（如分组依据，联接或过滤器）变得非常容易，而且还便于根据不同属性绘制数据。它还支持导出多种表格格式，包括 XLS，HTML 或 LaTeX。另外，R语言(一种有争议的不好的语言）具有很多功能，可以计算数据的统计数字，这在管道的最后一步中非常有用。 ggplot2是R中很棒的绘图库。\nDocker和虚拟机有什么区别? Docker 基于容器这个更为概括的概念。关于容器和虚拟机之间最大的不同是，虚拟机会执行整个的 OS 栈，包括内核（即使这个内核和主机内核相同）。与虚拟机不同，容器避免运行其他内核实例，而是与主机分享内核。在Linux环境中，有LXC机制来实现，并且这能使一系列分离的主机像是在使用自己的硬件启动程序，而实际上是共享主机的硬件和内核。因此容器的开销小于完整的虚拟机。\n另一方面，容器的隔离性较弱而且只有在主机运行相同的内核时才能正常工作。例如，如果你在macOS 上运行 Docker，Docker 需要启动 Linux虚拟机去获取初始的 Linux内核，这样的开销仍然很大。最后，Docker 是容器的特定实现，它是为软件部署而定制的。基于这些，它有一些奇怪之处：例如，默认情况下，Docker 容器在重启之间不会有以任何形式的存储。\n不同操作系统的优缺点是什么，我们如何选择（比如选择最适用于我们需求的Linux发行版)? 关于Linux发行版，尽管有相当多的版本，但大部分发行版在大多数使用情况下的表现是相同的。 可以使用任何发行版去学习 Linux 与 UNIX 的特性和其内部工作原理。 发行版之间的根本区别是发行版如何处理软件包更新。 某些版本，例如 Arch Linux 采用滚动更新策略，用了最前沿的软件包（bleeding-edge），但软件可能并不稳定。另外一些发行版（如Debian，CentOS 或 Ubuntu LTS）其更新策略要保守得多，因此更新的内容会更稳定，但会牺牲一些新功能。我们建议你使用 Debian 或 Ubuntu 来获得简单稳定的台式机和服务器体验。\nMac OS 是介于 Windows 和 Linux 之间的一个操作系统，它有很漂亮的界面。但是，Mac OS 是基于BSD 而不是 Linux，因此系统的某些部分和命令是不同的。 另一种值得体验的是 FreeBSD。虽然某些程序不能在 FreeBSD 上运行，但与 Linux 相比，BSD 生态系统的碎片化程度要低得多，并且说明文档更加友好。 除了开发Windows应用程序或需要使用某些Windows系统更好支持的功能（例如对游戏的驱动程序支持）外，我们不建议使用 Windows。\n对于双系统，我们认为最有效的是 macOS 的 bootcamp，长期来看，任何其他组合都可能会出现问题，尤其是当你结合了其他功能比如磁盘加密。\n使用 Vim 编辑器 VS Emacs 编辑器? 我们三个都使用 vim 作为我们的主要编辑器。但是 Emacs 也是一个不错的选择，你可以两者都尝试，看看那个更适合你。Emacs 不使用 vim 的模式编辑，但是这些功能可以通过 Emacs 插件像Evil 或 Doom Emacs来实现。 Emacs的优点是可以用Lisp语言进行扩展（Lisp比vim默认的脚本语言vimscript要更好用）。\n机器学习应用的提示或技巧? 课程的一些经验可以直接用于机器学习程序。 就像许多科学学科一样，在机器学习中，你需要进行一系列实验，并检查哪些数据有效，哪些无效。 你可以使用 Shell 轻松快速地搜索这些实验结果，并且以合理的方式汇总。这意味着需要在限定时间内或使用特定数据集的情况下，检查所有实验结果。通过使用JSON文件记录实验的所有相关参数，使用我们在本课程中介绍的工具，这件事情可以变得极其简单。 最后，如果你不使用集群提交你的 GPU 作业，那你应该研究如何使该过程自动化，因为这是一项非常耗时的任务，会消耗你的精力。\n还有更多的 Vim 小窍门吗？ 更多的窍门：\n插件 - 花时间去探索插件。有很多不错的插件修复了vim的缺陷或者增加了能够与现有vim工作流结合的新功能。关于这部分内容，资源是VimAwesome 和其他程序员的dotfiles。 标记 - 在vim里你可以使用 m\u0026lt;X\u0026gt; 为字母 X 做标记，之后你可以通过 '\u0026lt;X\u0026gt; 回到标记位置。这可以让你快速定位到文件内或文件间的特定位置。 导航 - Ctrl+O 和 Ctrl+I 命令可以使你在最近访问位置前后移动。 撤销树 - vim 有不错的更改跟踪机制，不同于其他的编辑器，vim存储变更树，因此即使你撤销后做了一些修改，你仍然可以通过撤销树的导航回到初始状态。一些插件比如 gundo.vim 和 undotree 通过图形化来展示撤销树。 时间撤销 - :earlier 和 :later 命令使得你可以用时间而非某一时刻的更改来定位文件。 持续撤销 - 是一个默认未被开启的vim的内置功能，它在vim启动之间保存撤销历史，需要配置在 .vimrc 目录下的undofile 和 undodir，vim会保存每个文件的修改历史。 热键（Leader Key） - 热键是一个用于用户自定义配置命令的特殊按键。这种模式通常是按下后释放这个按键（通常是空格键）并与其他的按键组合去实现一个特殊的命令。插件也会用这些按键增加它们的功能，例如，插件UndoTree使用 \u0026lt;Leader\u0026gt; U 去打开撤销树。 高级文本对象 - 文本对象比如搜索也可以用vim命令构成。例如，d/\u0026lt;pattern\u0026gt; 会删除下一处匹配 pattern 的字符串，cgn 可以用于更改上次搜索的关键字。 2FA是什么，为什么我需要使用它? 双因子验证（Two Factor Authentication 2FA）在密码之上为帐户增加了一层额外的保护。为了登录，你不仅需要知道密码，还必须以某种方式“证明”可以访问某些硬件设备。最简单的情形是可以通过接收手机的 SMS 来实现（尽管 SMS 2FA 存在 已知问题）。我们推荐使用YubiKey之类的U2F方案。\n对于不同的 Web 浏览器有什么评价? 2020的浏览器现状是，大部分的浏览器都与 Chrome 类似，因为它们都使用同样的引擎(Blink)。 Microsoft Edge 同样基于 Blink，至于 Safari 基于 WebKit(与Blink类似的引擎)，这些浏览器仅仅是更糟糕的 Chorme 版本。不管是在性能还是可用性上，Chorme 都是一款很不错的浏览器。如果你想要替代品，我们推荐 Firefox。Firefox 与 Chorme 的在各方面不相上下，并且在隐私方面更加出色。 有一款目前还没有完成的叫 Flow 的浏览器，它实现了全新的渲染引擎，有望比现有引擎速度更快。\n参考 课程列表\n","permalink":"https://blog.niuhemoon.win/posts/tech/coding-tools-qa/","summary":"最后一节课，我们回答学生提出的问题: 学习操作系统相关内容的推荐，比如进程，虚拟内存，中断，内存管理等 你会优先学习的工具有那些？ 使用 Python VS Bash脚本 VS 其他语言? source script.sh 和 ./script.sh 有什么区别? 各种软件包和工具存储在哪里？引用过程是怎样的? /bin 或 /lib 是什么？ 我应该用 apt-get install 还是 pip install 去下载软件包呢? 用于提","title":"编程工具之问答"},{"content":"安全和密码 熵(Entropy) 度量了不确定性并可以用来决定密码的强度。\n熵的单位是 比特。对于一个均匀分布的随机离散变量，熵等于log_2(所有可能的个数，即n)。 扔一次硬币的熵是1比特。掷一次（六面）骰子的熵大约为2.58比特。\n对称加密与非对称加密\n当你运行ssh-keygen命令，它会生成一个非对称密钥对：公钥和私钥(public_key, private_key)。 生成过程中使用的随机数由系统提供的熵决定。这些熵可以来源于硬件事件(hardware events)等。 公钥最终会被分发，它可以直接明文存储。 但是为了防止泄露，私钥必须加密存储。ssh-keygen命令会提示用户输入一个密码，并将它输入密钥生成函数 产生一个密钥。最终，ssh-keygen使用对称加密算法和这个密钥加密私钥。\n在实际运用中，当服务器已知用户的公钥（存储在.ssh/authorized_keys文件中，一般在用户HOME目录下），尝试连接的客户端可以使用非对称签名来证明用户的身份——这便是挑战应答方式。 简单来说，服务器选择一个随机数字发送给客户端。客户端使用用户私钥对这个数字信息签名后返回服务器。 服务器随后使用.ssh/authorized_keys文件中存储的用户公钥来验证返回的信息是否由所对应的私钥所签名。这种验证方式可以有效证明试图登录的用户持有所需的私钥。\n大杂烩 修改键位映射 作为一名程序员，键盘是你的主要输入工具。它像计算机里的其他部件一样是可配置的，而且值得你在这上面花时间。\n一个很常见的配置是修改键位映射。通常这个功能由在计算机上运行的软件实现。当某一个按键被按下，软件截获键盘发出的按键事件（keypress event）并使用另外一个事件取代。比如：\n将 Caps Lock 映射为 Ctrl 或者 Escape：Caps Lock 使用了键盘上一个非常方便的位置而它的功能却很少被用到，所以我们（讲师）非常推荐这个修改； 将 PrtSc 映射为播放/暂停：大部分操作系统支持播放/暂停键； 交换 Ctrl 和 Meta 键（Windows 的徽标键或者 Mac 的 Command 键）。 你也可以将键位映射为任意常用的指令。软件监听到特定的按键组合后会运行设定的脚本。\n打开一个新的终端或者浏览器窗口； 输出特定的字符串，比如：一个超长邮件地址或者 MIT ID； 使计算机或者显示器进入睡眠模式。 甚至更复杂的修改也可以通过软件实现：\n映射按键顺序，比如：按 Shift 键五下切换大小写锁定； 区别映射单点和长按，比如：单点 Caps Lock 映射为 Escape，而长按 Caps Lock 映射为 Ctrl； 对不同的键盘或软件保存专用的映射配置。 下面是一些修改键位映射的软件：\nmacOS - karabiner-elements, skhd 或者 BetterTouchTool Linux - xmodmap 或者 Autokey Windows - 控制面板，AutoHotkey 或者 SharpKeys QMK - 如果你的键盘支持定制固件，QMK 可以直接在键盘的硬件上修改键位映射。保留在键盘里的映射免除了在别的机器上的重复配置。 守护进程 即便守护进程（daemon）这个词看上去有些陌生，你应该已经大约明白它的概念。大部分计算机都有一系列在后台保持运行，不需要用户手动运行或者交互的进程。这些进程就是守护进程。以守护进程运行的程序名一般以 d 结尾，比如 SSH 服务端 sshd，用来监听传入的 SSH 连接请求并对用户进行鉴权。\nLinux 中的 systemd（the system daemon）是最常用的配置和运行守护进程的方法。运行 systemctl status 命令可以看到正在运行的所有守护进程。这里面有很多可能你没有见过，但是掌管了系统的核心部分的进程：管理网络、DNS解析、显示系统的图形界面等等。用户使用 systemctl 命令和 systemd 交互来enable（启用）、disable（禁用）、start（启动）、stop（停止）、restart（重启）、或者status（检查）配置好的守护进程及系统服务。\nsystemd 提供了一个很方便的界面用于配置和启用新的守护进程或系统服务。下面的配置文件使用了守护进程来运行一个简单的 Python 程序。文件的内容非常直接所以我们不对它详细阐述。systemd 配置文件的详细指南可参见 freedesktop.org。\n## /etc/systemd/system/myapp.service [Unit] ## 配置文件描述 Description=My Custom App ## 在网络服务启动后启动该进程 After=network.target [Service] ## 运行该进程的用户 User=foo ## 运行该进程的用户组 Group=foo ## 运行该进程的根目录 WorkingDirectory=/home/foo/projects/mydaemon ## 开始该进程的命令 ExecStart=/usr/bin/local/python3.7 app.py ## 在出现错误时重启该进程 Restart=on-failure [Install] ## 相当于Windows的开机启动。即使GUI没有启动，该进程也会加载并运行 WantedBy=multi-user.target ## 如果该进程仅需要在GUI活动时运行，这里应写作： # WantedBy=graphical.target # graphical.target在multi-user.target的基础上运行和GUI相关的服务 如果你只是想定期运行一些程序，可以直接使用 cron。它是一个系统内置的，用来执行定期任务的守护进程。\nFUSE 现在的软件系统一般由很多模块化的组件构建而成。你使用的操作系统可以通过一系列共同的方式使用不同的文件系统上的相似功能。比如当你使用 touch 命令创建文件的时候，touch 使用系统调用（system call）向内核发出请求。内核再根据文件系统，调用特有的方法来创建文件。这里的问题是，UNIX 文件系统在传统上是以内核模块的形式实现，导致只有内核可以进行文件系统相关的调用。\nFUSE（用户空间文件系统）允许运行在用户空间上的程序实现文件系统调用，并将这些调用与内核接口联系起来。在实践中，这意味着用户可以在文件系统调用中实现任意功能。\nFUSE 可以用于实现如：一个将所有文件系统操作都使用 SSH 转发到远程主机，由远程主机处理后返回结果到本地计算机的虚拟文件系统。这个文件系统里的文件虽然存储在远程主机，对于本地计算机上的软件而言和存储在本地别无二致。sshfs就是一个实现了这种功能的 FUSE 文件系统。\n一些有趣的 FUSE 文件系统包括：\nsshfs：使用 SSH 连接在本地打开远程主机上的文件 rclone：将 Dropbox、Google Drive、Amazon S3、或者 Google Cloud Storage 一类的云存储服务挂载为本地文件系统 gocryptfs：覆盖在加密文件上的文件系统。文件以加密形式保存在磁盘里，但该文件系统挂载后用户可以直接从挂载点访问文件的明文 kbfs：分布式端到端加密文件系统。在这个文件系统里有私密（private），共享（shared），以及公开（public）三种类型的文件夹 borgbackup：方便用户浏览删除重复数据后的压缩加密备份 备份 任何没有备份的数据都可能在一个瞬间永远消失。复制数据很简单，但是可靠地备份数据很难。下面列举了一些关于备份的基础知识，以及一些常见做法容易掉进的陷阱。\n首先，复制存储在同一个磁盘上的数据不是备份，因为这个磁盘是一个单点故障（single point of failure）。这个磁盘一旦出现问题，所有的数据都可能丢失。放在家里的外置磁盘因为火灾、抢劫等原因可能会和源数据一起丢失，所以是一个弱备份。推荐的做法是将数据备份到不同的地点存储。\n同步方案也不是备份。即使方便如 Dropbox 或者 Google Drive，当数据在本地被抹除或者损坏，同步方案可能会把这些“更改”同步到云端。同理，像 RAID 这样的磁盘镜像方案也不是备份。它不能防止文件被意外删除、损坏、或者被勒索软件加密。\n有效备份方案的几个核心特性是：版本控制，删除重复数据，以及安全性。对备份的数据实施版本控制保证了用户可以从任何记录过的历史版本中恢复数据。在备份中检测并删除重复数据，使其仅备份增量变化可以减少存储开销。在安全性方面，作为用户，你应该考虑别人需要有什么信息或者工具才可以访问或者完全删除你的数据及备份。最后一点，不要盲目信任备份方案。用户应该经常检查备份是否可以用来恢复数据。\n备份不限制于备份在本地计算机上的文件。云端应用的重大发展使得我们很多的数据只存储在云端。当我们无法登录这些应用，在云端存储的网络邮件，社交网络上的照片，流媒体音乐播放列表，以及在线文档等等都会随之丢失。用户应该有这些数据的离线备份，而且已经有项目可以帮助下载并存储它们。\n如果想要了解更多具体内容，请参考本课程2019年关于备份的课堂笔记。\nAPI（应用程序接口） 关于如何使用计算机有效率地完成 本地 任务，我们这堂课已经介绍了很多方法。这些方法在互联网上其实也适用。大多数线上服务提供的 API（应用程序接口）让你可以通过编程方式来访问这些服务的数据。比如，美国国家气象局就提供了一个可以从 shell 中获取天气预报的 API。\n这些 API 大多具有类似的格式。它们的结构化 URL 通常使用 api.service.com 作为根路径，用户可以访问不同的子路径来访问需要调用的操作，以及添加查询参数使 API 返回符合查询参数条件的结果。\n以美国天气数据为例，为了获得某个地点的天气数据，你可以发送一个 GET 请求（比如使用curl）到https://api.weather.gov/points/42.3604,-71.094。返回中会包括一系列用于获取特定信息（比如小时预报、气象观察站信息等）的 URL。通常这些返回都是JSON格式，你可以使用jq等工具来选取需要的部分。\n有些需要认证的 API 通常要求用户在请求中加入某种私密令牌（secret token）来完成认证。请阅读你想访问的 API 所提供的文档来确定它请求的认证方式，但是其实大多数 API 都会使用 OAuth。OAuth 通过向用户提供一系列仅可用于该 API 特定功能的私密令牌进行校验。因为使用了有效 OAuth 令牌的请求在 API 看来就是用户本人发出的请求，所以请一定保管好这些私密令牌。否则其他人就可以冒用你的身份进行任何你可以在这个 API 上进行的操作。\nIFTTT 这个网站可以将很多 API 整合在一起，让某 API 发生的特定事件触发在其他 API 上执行的任务。IFTTT 的全称If This Then That 足以说明它的用法，比如在检测到用户的新推文后，自动发布在其他平台。但是你可以对它支持的 API 进行任意整合，所以试着来设置一下任何你需要的功能吧！\n常见命令行标志参数及模式 命令行工具的用法千差万别，阅读 man 页面可以帮助你理解每种工具的用法。即便如此，下面我们将介绍一下命令行工具一些常见的共同功能。\n大部分工具支持 --help 或者类似的标志参数（flag）来显示它们的简略用法。\n会造成不可撤回操作的工具一般会提供“空运行”（dry run）标志参数，这样用户可以确认工具真实运行时会进行的操作。这些工具通常也会有“交互式”（interactive）标志参数，在执行每个不可撤回的操作前提示用户确认。\n--version 或者 -V 标志参数可以让工具显示它的版本信息（对于提交软件问题报告非常重要）。\n基本所有的工具支持使用 --verbose 或者 -v 标志参数来输出详细的运行信息。多次使用这个标志参数，比如 -vvv，可以让工具输出更详细的信息（经常用于调试）。同样，很多工具支持 --quiet 标志参数来抑制除错误提示之外的其他输出。\n大多数工具中，使用 - 代替输入或者输出文件名意味着工具将从标准输入（standard input）获取所需内容，或者向标准输出（standard output）输出结果。\n会造成破坏性结果的工具一般默认进行非递归的操作，但是支持使用“递归”（recursive）标志函数（通常是 -r）。\n有的时候你可能需要向工具传入一个 看上去 像标志参数的普通参数，比如：\n使用 rm 删除一个叫 -r 的文件； 在通过一个程序运行另一个程序的时候（ssh machine foo），向内层的程序（foo）传递一个标志参数。 这时候你可以使用特殊参数 -- 让某个程序 停止处理 -- 后面出现的标志参数以及选项（以 - 开头的内容）：\nrm -- -r 会让 rm 将 -r 当作文件名； ssh machine --for-ssh -- foo --for-foo 的 -- 会让 ssh 知道 --for-foo 不是 ssh 的标志参数。 窗口管理器 大部分人适应了 Windows、macOS、以及 Ubuntu 默认的“拖拽”式窗口管理器。这些窗口管理器的窗口一般就堆在屏幕上，你可以拖拽改变窗口的位置、缩放窗口、以及让窗口堆叠在一起。这种堆叠式（floating/stacking）管理器只是窗口管理器中的一种。特别在 Linux 中，有很多种其他的管理器。\n平铺式（tiling）管理器就是一个常见的替代。顾名思义，平铺式管理器会把不同的窗口像贴瓷砖一样平铺在一起而不和其他窗口重叠。这和 tmux 管理终端窗口的方式类似。平铺式管理器按照写好的布局显示打开的窗口。如果只打开一个窗口，它会填满整个屏幕。新开一个窗口的时候，原来的窗口会缩小到比如三分之二或者三分之一的大小来腾出空间。打开更多的窗口会让已有的窗口进一步调整。\n就像 tmux 那样，平铺式管理器可以让你在完全不使用鼠标的情况下使用键盘切换、缩放、以及移动窗口。它们值得一试！\nVPN VPN 现在非常火，但我们不清楚这是不是因为一些好的理由。你应该了解 VPN 能提供的功能和它的限制。使用了 VPN 的你对于互联网而言，最好的情况下也就是换了一个网络供应商（ISP）。所有你发出的流量看上去来源于 VPN 供应商的网络而不是你的“真实”地址，而你实际接入的网络只能看到加密的流量。\n虽然这听上去非常诱人，但是你应该知道使用 VPN 只是把原本对网络供应商的信任放在了 VPN 供应商那里——网络供应商 能看到的，VPN 供应商 也都能看到。如果相比网络供应商你更信任 VPN 供应商，那当然很好。反之，则连接VPN的价值不明确。机场的不加密公共热点确实不可以信任，但是在家庭网络环境里，这个差异就没有那么明显。\n你也应该了解现在大部分包含用户敏感信息的流量已经被 HTTPS 或者 TLS 加密。这种情况下你所处的网络环境是否“安全”不太重要：供应商只能看到你和哪些服务器在交谈，却不能看到你们交谈的内容。\n这一切的大前提都是“最好的情况”。曾经发生过 VPN 提供商错误使用弱加密或者直接禁用加密的先例。另外，有些恶意的或者带有投机心态的供应商会记录和你有关的所有流量，并很可能会将这些信息卖给第三方。找错一家 VPN 经常比一开始就不用 VPN 更危险。\nMIT 向有访问校内资源需求的成员开放自己运营的 VPN。如果你也想自己配置一个 VPN，可以了解一下 WireGuard 以及 Algo。\nMarkdown 你在职业生涯中大概率会编写各种各样的文档。在很多情况下这些文档需要使用标记来增加可读性，比如：插入粗体或者斜体内容，增加页眉、超链接、以及代码片段。\n在不使用 Word 或者 LaTeX 等复杂工具的情况下，你可以考虑使用 Markdown 这个轻量化的标记语言（markup language）。你可能已经见过 Markdown 或者它的一个变种。很多环境都支持并使用 Markdown 的一些子功能。\nMarkdown 致力于将人们编写纯文本时的一些习惯标准化。比如：\n用*包围的文字表示强调（斜体），或者用**表示特别强调（粗体）；\n以#开头的行是标题，#的数量表示标题的级别，比如：##二级标题；\n以-开头代表一个无序列表的元素。一个数字加.（比如1.）代表一个有序列表元素；\n反引号 `（backtick）包围的文字会以代码字体显示。如果要显示一段代码，可以在每一行前加四个空格缩进，或者使用三个反引号包围整个代码片段：\n就像这样 如果要添加超链接，将 需要显示 的文字用方括号包围，并在后面紧接着用圆括号包围链接：[显示文字](指向的链接)。\nMarkdown 不仅容易上手，而且应用非常广泛。实际上本课程的课堂笔记和其他资料都是使用 Markdown 编写的。点击这个链接可以看到本页面的原始 Markdown 内容。\nHammerspoon (macOS 桌面自动化) Hammerspoon 是面向 macOS 的一个桌面自动化框架。它允许用户编写和操作系统功能挂钩的 Lua 脚本，从而与键盘、鼠标、窗口、文件系统等交互。\n下面是 Hammerspoon 的一些示例应用：\n绑定移动窗口到的特定位置的快捷键 创建可以自动将窗口整理成特定布局的菜单栏按钮 在你到实验室以后，通过检测所连接的 WiFi 网络自动静音扬声器 在你不小心拿了朋友的充电器时弹出警告 从用户的角度，Hammerspoon 可以运行任意 Lua 代码，绑定菜单栏按钮、按键、或者事件。Hammerspoon 提供了一个全面的用于和系统交互的库，因此它能没有限制地实现任何功能。你可以从头编写自己的 Hammerspoon 配置，也可以结合别人公布的配置来满足自己的需求。\n资源 Getting Started with Hammerspoon：Hammerspoon 官方教程 Sample configurations：Hammerspoon 官方示例配置 Anish\u0026rsquo;s Hammerspoon config：Anish 的 Hammerspoon 配置 开机引导以及 Live USB 在你的计算机启动时，BIOS 或者 UEFI 会在加载操作系统之前对硬件系统进行初始化，这被称为引导（booting）。你可以通过按下计算机提示的键位组合来配置引导，比如 Press F9 to configure BIOS. Press F12 to enter boot menu。在 BIOS 菜单中你可以对硬件相关的设置进行更改，也可以在引导菜单中选择从硬盘以外的其他设备加载操作系统——比如 Live USB。\nLive USB 是包含了完整操作系统的闪存盘。Live USB 的用途非常广泛，包括：\n作为安装操作系统的启动盘； 在不将操作系统安装到硬盘的情况下，直接运行 Live USB 上的操作系统； 对硬盘上的相同操作系统进行修复； 恢复硬盘上的数据。 Live USB 通过在闪存盘上 写入 操作系统的镜像制作，而写入不是单纯的往闪存盘上复制 .iso 文件。你可以使用 UNetbootin 、Rufus 等 Live USB 写入工具制作。\nDocker, Vagrant, VMs, Cloud, OpenStack 虚拟机（Virtual Machine）以及如容器化（containerization）等工具可以帮助你模拟一个包括操作系统的完整计算机系统。虚拟机可以用于创建独立的测试或者开发环境，以及用作安全测试的沙盒。\nVagrant 是一个构建和配置虚拟开发环境的工具。它支持用户在配置文件中写入比如操作系统、系统服务、需要安装的软件包等描述，然后使用 vagrant up 命令在各种环境（VirtualBox，KVM，Hyper-V等）中启动一个虚拟机。Docker 是一个使用容器化概念的类似工具。\n租用云端虚拟机可以享受以下资源的即时访问：\n便宜、常开、且有公共IP地址的虚拟机用来托管网站等服务 有大量 CPU、磁盘、内存、以及 GPU 资源的虚拟机 超出用户可以使用的物理主机数量的虚拟机 相比物理主机的固定开支，虚拟机的开支一般按运行的时间计算。所以如果用户只需要在短时间内使用大量算力，租用1000台虚拟机运行几分钟明显更加划算。 受欢迎的 VPS 服务商有 Amazon AWS，Google Cloud，以及 DigitalOcean。\nMIT CSAIL 的成员可以使用 CSAIL OpenStack instance 申请免费的虚拟机用于研究。\n交互式记事本编程 交互式记事本可以帮助开发者进行与运行结果交互等探索性的编程。现在最受欢迎的交互式记事本环境大概是 Jupyter。它的名字来源于所支持的三种核心语言：Julia、Python、R。Wolfram Mathematica 是另外一个常用于科学计算的优秀环境。\nGitHub GitHub 是最受欢迎的开源软件开发平台之一。我们课程中提到的很多工具，从 vim 到 Hammerspoon，都托管在 Github 上。向你每天使用的开源工具作出贡献其实很简单，下面是两种贡献者们经常使用的方法：\n创建一个议题（issue）。 议题可以用来反映软件运行的问题或者请求新的功能。创建议题并不需要创建者阅读或者编写代码，所以它是一个轻量化的贡献方式。高质量的问题报告对于开发者十分重要。在现有的议题发表评论也可以对项目的开发作出贡献。 使用拉取请求（pull request）提交代码更改。由于涉及到阅读和编写代码，提交拉取请求总的来说比创建议题更加深入。拉取请求是请求别人把你自己的代码拉取（且合并）到他们的仓库里。很多开源项目仅允许认证的管理者管理项目代码，所以一般需要复刻（fork）这些项目的上游仓库（upstream repository），在你的 Github 账号下创建一个内容完全相同但是由你控制的复刻仓库。这样你就可以在这个复刻仓库自由创建新的分支并推送修复问题或者实现新功能的代码。完成修改以后再回到开源项目的 Github 页面创建一个拉取请求。 提交请求后，项目管理者会和你交流拉取请求里的代码并给出反馈。如果没有问题，你的代码会和上游仓库中的代码合并。很多大的开源项目会提供贡献指南，容易上手的议题，甚至专门的指导项目来帮助参与者熟悉这些项目。\n参考 课程列表\n","permalink":"https://blog.niuhemoon.win/posts/tech/coding-tools-foobar/","summary":"安全和密码 熵(Entropy) 度量了不确定性并可以用来决定密码的强度。 熵的单位是 比特。对于一个均匀分布的随机离散变量，熵等于log_2(所有可能的个数，即n)。 扔一次硬币的熵是1比特。掷一次（六面）骰子的熵大约为2.58比特。 对称加密与非对称加密 当你运行ssh-keygen命令，","title":"编程工具之杂烩"},{"content":"代码不能完全按照您的想法运行，它只能完全按照您的写法运行，这是编程界的一条金科玉律。\n让您的写法符合您的想法是非常困难的。在这节课中，我们会传授给您一些非常有用技术，帮您处理代码中的 bug 和程序性能问题。\n调试代码 打印调试法与日志 \u0026ldquo;最有效的 debug 工具就是细致的分析，配合恰当位置的打印语句\u0026rdquo; — Brian Kernighan, Unix 新手入门。\n调试代码的第一种方法往往是在您发现问题的地方添加一些打印语句，然后不断重复此过程直到您获取了足够的信息并找到问题的根本原因。\n另外一个方法是使用日志，而不是临时添加打印语句。日志较普通的打印语句有如下的一些优势：\n您可以将日志写入文件、socket 或者甚至是发送到远端服务器而不仅仅是标准输出； 日志可以支持严重等级（例如 INFO, DEBUG, WARN, ERROR等)，这使您可以根据需要过滤日志； 对于新发现的问题，很可能您的日志中已经包含了可以帮助您定位问题的足够的信息。 这里 是一个包含日志的例程序：\n$ python logger.py # Raw output as with just prints $ python logger.py log # Log formatted output $ python logger.py log ERROR # Print only ERROR levels and above $ python logger.py color # Color formatted output 有很多技巧可以使日志的可读性变得更好，我最喜欢的一个是技巧是对其进行着色。到目前为止，您应该已经知道，以彩色文本显示终端信息时可读性更好。但是应该如何设置呢？\nls 和 grep 这样的程序会使用 ANSI escape codes，它是一系列的特殊字符，可以使您的 shell 改变输出结果的颜色。例如，执行 echo -e \u0026quot;\\e[38;2;255;0;0mThis is red\\e[0m\u0026quot; 会打印红色的字符串：This is red 。下面这个脚本向您展示了如何在终端中打印多种颜色。\n#!/usr/bin/env bash for R in $(seq 0 20 255); do for G in $(seq 0 20 255); do for B in $(seq 0 20 255); do printf \u0026#34;\\e[38;2;${R};${G};${B}m█\\e[0m\u0026#34;; done done done 第三方日志系统 如果您正在构建大型软件系统，您很可能会使用到一些依赖，有些依赖会作为程序单独运行。如 Web 服务器、数据库或消息代理都是此类常见的第三方依赖。\n和这些系统交互的时候，阅读它们的日志是非常必要的，因为仅靠客户端侧的错误信息可能并不足以定位问题。\n幸运的是，大多数的程序都会将日志保存在您的系统中的某个地方。对于 UNIX 系统来说，程序的日志通常存放在 /var/log。例如， NGINX web 服务器就将其日志存放于/var/log/nginx。\n目前，系统开始使用 system log，您所有的日志都会保存在这里。大多数的（但不是全部）Linux 系统都会使用 systemd，这是一个系统守护进程，它会控制您系统中的很多东西，例如哪些服务应该启动并运行。systemd 会将日志以某种特殊格式存放于/var/log/journal，您可以使用 journalctl 命令显示这些消息。\n类似地，在 macOS 系统中是 /var/log/system.log，但是有更多的工具会使用系统日志，它的内容可以使用 log show 显示。\n对于大多数的 UNIX 系统，您也可以使用dmesg 命令来读取内核的日志。\n如果您希望将日志加入到系统日志中，您可以使用 logger 这个 shell 程序。下面这个例子显示了如何使用 logger并且如何找到能够将其存入系统日志的条目。\n不仅如此，大多数的编程语言都支持向系统日志中写日志。\nlogger \u0026#34;Hello Logs\u0026#34; # On macOS log show --last 1m | grep Hello # On Linux journalctl --since \u0026#34;1m ago\u0026#34; | grep Hello 正如我们在数据整理那节课上看到的那样，日志的内容可以非常的多，我们需要对其进行处理和过滤才能得到我们想要的信息。\n如果您发现您需要对 journalctl 和 log show 的结果进行大量的过滤，那么此时可以考虑使用它们自带的选项对其结果先过滤一遍再输出。还有一些像 lnav 这样的工具，它为日志文件提供了更好的展现和浏览方式。\n调试器 当通过打印已经不能满足您的调试需求时，您应该使用调试器。\n调试器是一种可以允许我们和正在执行的程序进行交互的程序，它可以做到：\n当到达某一行时将程序暂停； 一次一条指令地逐步执行程序； 程序崩溃后查看变量的值； 满足特定条件是暂停程序； 其他高级功能。 很多编程语言都有自己的调试器。Python 的调试器是pdb.\n下面对pdb 支持对命令进行简单对介绍：\nl(ist) - 显示当前行附近的11行或继续执行之前的显示； s(tep) - 执行当前行，并在第一个可能的地方停止 n(ext) - 继续执行直到当前函数的下一条语句或者 return 语句； b(reak) - 设置断点（基于传入对参数）； p(rint) - 在当前上下文对表达式求值并打印结果。还有一个命令是pp ，它使用 pprint 打印； r(eturn) - 继续执行直到当前函数返回； q(uit) - 退出调试器。 让我们使用pdb 来修复下面的 Python 代码（参考讲座视频）\ndef bubble_sort(arr): n = len(arr) for i in range(n): for j in range(n): if arr[j] \u0026gt; arr[j+1]: arr[j] = arr[j+1] arr[j+1] = arr[j] return arr print(bubble_sort([4, 2, 1, 8, 7, 6])) 注意，因为 Python 是一种解释型语言，所以我们可以通过 pdb shell 执行命令。 ipdb 是一种增强型的 pdb ，它使用IPython 作为 REPL并开启了 tab 补全、语法高亮、更好的回溯和更好的内省，同时还保留了pdb 模块相同的接口。\n对于更底层的编程语言，您可能需要了解一下 gdb ( 以及它的改进版 pwndbg) 和 lldb。\n它们都对类 C 语言的调试进行了优化，它允许您探索任意进程及其机器状态：寄存器、堆栈、程序计数器等。\n专门工具 即使您需要调试的程序是一个二进制的黑盒程序，仍然有一些工具可以帮助到您。当您的程序需要执行一些只有操作系统内核才能完成的操作时，它需要使用 系统调用。有一些命令可以帮助您追踪您的程序执行的系统调用。在 Linux 中可以使用strace ，在 macOS 和 BSD 中可以使用 dtrace。dtrace 用起来可能有些别扭，因为它使用的是它自有的 D 语言，但是我们可以使用一个叫做 dtruss 的封装使其具有和 strace (更多信息参考 这里)类似的接口\n下面的例子展现来如何使用 strace 或 dtruss 来显示ls 执行时，对stat 系统调用进行追踪对结果。若需要深入了解 strace，这篇文章 值得一读。\n# On Linux sudo strace -e lstat ls -l \u0026gt; /dev/null 4 # On macOS sudo dtruss -t lstat64_extended ls -l \u0026gt; /dev/null 有些情况下，我们需要查看网络数据包才能定位问题。像 tcpdump 和 Wireshark 这样的网络数据包分析工具可以帮助您获取网络数据包的内容并基于不同的条件进行过滤。\n对于 web 开发， Chrome/Firefox 的开发者工具非常方便，功能也很强大：\n源码 -查看任意站点的 HTML/CSS/JS 源码； 实时地修改 HTML, CSS, JS 代码 - 修改网站的内容、样式和行为用于测试（从这一点您也能看出来，网页截图是不可靠的）； Javascript shell - 在 JS REPL中执行命令； 网络 - 分析请求的时间线； 存储 - 查看 Cookies 和本地应用存储。 静态分析 有些问题是您不需要执行代码就能发现的。例如，仔细观察一段代码，您就能发现某个循环变量覆盖了某个已经存在的变量或函数名；或是有个变量在被读取之前并没有被定义。 这种情况下 静态分析 工具就可以帮我们找到问题。静态分析会将程序的源码作为输入然后基于编码规则对其进行分析并对代码的正确性进行推理。\n下面这段 Python 代码中存在几个问题。 首先，我们的循环变量foo 覆盖了之前定义的函数foo。最后一行，我们还把 bar 错写成了baz，因此当程序完成sleep (一分钟后)后，执行到这一行的时候便会崩溃。\nimport time def foo(): return 42 for foo in range(5): print(foo) bar = 1 bar *= 0.2 time.sleep(60) print(baz) 静态分析工具可以发现此类的问题。当我们使用pyflakes 分析代码的似乎，我们会得到与这两处 bug 相关的错误信息。mypy 则是另外一个工具，它可以对代码进行类型检查。这里，mypy 会经过我们bar 起初是一个 int ，然后变成了 float。这些问题都可以在不允许代码的情况下被发现。\n在 shell 工具那一节课的时候，我们介绍了 shellcheck，这是一个类似的工具，但它是应用于 shell 脚本的。\n$ pyflakes foobar.py foobar.py:6: redefinition of unused \u0026#39;foo\u0026#39; from line 3 foobar.py:11: undefined name \u0026#39;baz\u0026#39; $ mypy foobar.py foobar.py:6: error: Incompatible types in assignment (expression has type \u0026#34;int\u0026#34;, variable has type \u0026#34;Callable[[], Any]\u0026#34;) foobar.py:9: error: Incompatible types in assignment (expression has type \u0026#34;float\u0026#34;, variable has type \u0026#34;int\u0026#34;) foobar.py:11: error: Name \u0026#39;baz\u0026#39; is not defined Found 3 errors in 1 file (checked 1 source file) 大多数的编辑器和 IDE 都支持在编辑界面显示这些工具的分析结果、高亮有警告和错误的位置。 这个过程通常成为 code linting 。风格检查或安全检查的结果同样也可以进行相应的显示。\n在 vim 中，有 ale 或 syntastic 可以帮助您做同样的事情。 在 Python 中， pylint 和 pep8 是两种用于进行风格检查的工具，而 bandit 工具则用于检查安全相关的问题。\n对于其他语言的开发者来说，静态分析工具可以参考这个列表：Awesome Static Analysis (您也许会对 Writing 一节感兴趣) 。对于 linters 则可以参考这个列表： Awesome Linters。\n对于风格检查和代码格式化，还有以下一些工具可以作为补充：用于 Python 的 black、用于 Go 语言的 gofmt、用于 Rust 的 rustfmt 或是用于 JavaScript, HTML 和 CSS 的 prettier 。这些工具可以自动格式化您的代码，这样代码风格就可以与常见的风格保持一致。 尽管您可能并不想对代码进行风格控制，标准的代码风格有助于方便别人阅读您的代码，也可以方便您阅读它的代码。\n性能分析 即使您的代码能够向您期望的一样运行，但是如果它消耗了您全部的 CPU 和内存，那么它显然也不是个好程序。算法课上我们通常会介绍大O标记法，但却没交给我们如何找到程序中的热点。 鉴于 过早的优化是万恶之源，您需要学习性能分析和监控工具，它们会帮助您找到程序中最耗时、最耗资源的部分，这样您就可以有针对性的进行性能优化。\n计时 和调试代码类似，大多数情况下我们只需要打印两处代码之间的时间即可发现问题。下面这个例子中，我们使用了 Python 的 time模块。\nimport time, random n = random.randint(1, 10) * 100 ### 获取当前时间 start = time.time() ### 执行一些操作 print(\u0026#34;Sleeping for {} ms\u0026#34;.format(n)) time.sleep(n/1000) ### 比较当前时间和起始时间 print(time.time() - start) # Output # Sleeping for 500 ms ### 0.5713930130004883 不过，执行时间（wall clock time）也可能会误导您，因为您的电脑可能也在同时运行其他进程，也可能在此期间发生了等待。 对于工具来说，需要区分真实时间、用户时间和系统时间。通常来说，用户时间+系统时间代表了您的进程所消耗的实际 CPU （更详细的解释可以参照这篇文章）。\n真实时间 - 从程序开始到结束流失掉到真实时间，包括其他进程到执行时间以及阻塞消耗的时间（例如等待 I/O或网络）； User - CPU 执行用户代码所花费的时间； Sys - CPU 执行系统内核代码所花费的时间。 例如，试着执行一个用于发起 HTTP 请求的命令并在其前面添加 time 前缀。网络不好的情况下您可能会看到下面的输出结果。请求花费了 2s 才完成，但是进程仅花费了 15ms 的 CPU 用户时间和 12ms 的 CPU 内核时间。\n$ time curl https://missing.csail.mit.edu \u0026amp;\u0026gt; /dev/null` real 0m2.561s user 0m0.015s sys 0m0.012s 性能分析工具（profilers） CPU 大多数情况下，当人们提及性能分析工具的时候，通常指的是 CPU 性能分析工具。 CPU 性能分析工具有两种： 追踪分析器（tracing）及采样分析器（sampling）。 追踪分析器 会记录程序的每一次函数调用，而采样分析器则只会周期性的监测（通常为每毫秒）您的程序并记录程序堆栈。它们使用这些记录来生成统计信息，显示程序在哪些事情上花费了最多的时间。如果您希望了解更多相关信息，可以参考这篇 介绍性的文章。\n大多数的编程语言都有一些基于命令行都分析器，我们可以使用它们来分析代码。它们通常可以集成在 IDE 中，但是本节课我们会专注于这些命令行工具本身。\n在 Python 中，我们使用 cProfile 模块来分析每次函数调用所消耗都时间。 在下面的例子中，我们实现了一个基础的 grep 命令：\n#!/usr/bin/env python import sys, re def grep(pattern, file): with open(file, \u0026#39;r\u0026#39;) as f: print(file) for i, line in enumerate(f.readlines()): pattern = re.compile(pattern) match = pattern.search(line) if match is not None: print(\u0026#34;{}: {}\u0026#34;.format(i, line), end=\u0026#34;\u0026#34;) if __name__ == \u0026#39;__main__\u0026#39;: times = int(sys.argv[1]) pattern = sys.argv[2] for i in range(times): for file in sys.argv[3:]: grep(pattern, file) 我们可以使用下面的命令来对这段代码进行分析。通过它的输出我们可以直到，IO 消耗了大量的时间，编译正则表达式也比较耗费时间。因为正则表达式只需要编译一次，我们可以将其移动到 for 循环外面来改进性能。\n$ python -m cProfile -s tottime grep.py 1000 \u0026#39;^(import|\\s*def)[^,]*$\u0026#39; *.py [omitted program output] ncalls tottime percall cumtime percall filename:lineno(function) 8000 0.266 0.000 0.292 0.000 {built-in method io.open} 8000 0.153 0.000 0.894 0.000 grep.py:5(grep) 17000 0.101 0.000 0.101 0.000 {built-in method builtins.print} 8000 0.100 0.000 0.129 0.000 {method \u0026#39;readlines\u0026#39; of \u0026#39;_io._IOBase\u0026#39; objects} 93000 0.097 0.000 0.111 0.000 re.py:286(_compile) 93000 0.069 0.000 0.069 0.000 {method \u0026#39;search\u0026#39; of \u0026#39;_sre.SRE_Pattern\u0026#39; objects} 93000 0.030 0.000 0.141 0.000 re.py:231(compile) 17000 0.019 0.000 0.029 0.000 codecs.py:318(decode) 1 0.017 0.017 0.911 0.911 grep.py:3(\u0026lt;module\u0026gt;) [omitted lines] 关于 Python 的 cProfile 分析器（以及其他一些类似的一些分析器），需要注意的是它显示的是每次函数调用的时间。看上去可能快到反直觉，尤其是如果您在代码里面使用了第三方的函数库，因为内部函数调用也会被看作函数调用。\n更加符合直觉的显示分析信息的方式是包括每行代码的执行时间，这也是行分析器的工作。例如，下面这段 Python 代码会向本课程的网站发起一个请求，然后解析响应返回的页面中的全部 URL：\n#!/usr/bin/env python import requests from bs4 import BeautifulSoup ### 这个装饰器会告诉行分析器 ### 我们想要分析这个函数 @profile def get_urls(): response = requests.get(\u0026#39;https://missing.csail.mit.edu\u0026#39;) s = BeautifulSoup(response.content, \u0026#39;lxml\u0026#39;) urls = [] for url in s.find_all(\u0026#39;a\u0026#39;): urls.append(url[\u0026#39;href\u0026#39;]) if __name__ == \u0026#39;__main__\u0026#39;: get_urls() 如果我们使用 Python 的 cProfile 分析器，我们会得到超过2500行的输出结果，即使对其进行排序，我仍然搞不懂时间到底都花在哪了。如果我们使用 line_profiler，它会基于行来显示时间：\n$ kernprof -l -v a.py Wrote profile results to urls.py.lprof Timer unit: 1e-06 s Total time: 0.636188 s File: a.py Function: get_urls at line 5 Line ### Hits Time Per Hit % Time Line Contents ============================================================== 5 @profile 6 def get_urls(): 7 1 613909.0 613909.0 96.5 response = requests.get(\u0026#39;https://missing.csail.mit.edu\u0026#39;) 8 1 21559.0 21559.0 3.4 s = BeautifulSoup(response.content, \u0026#39;lxml\u0026#39;) 9 1 2.0 2.0 0.0 urls = [] 10 25 685.0 27.4 0.1 for url in s.find_all(\u0026#39;a\u0026#39;): 11 24 33.0 1.4 0.0 urls.append(url[\u0026#39;href\u0026#39;]) 内存 像 C 或者 C++ 这样的语言，内存泄漏会导致您的程序在使用完内存后不去释放它。为了应对内存类的 Bug，我们可以使用类似 Valgrind 这样的工具来检查内存泄漏问题。\n对于 Python 这类具有垃圾回收机制的语言，内存分析器也是很有用的，因为对于某个对象来说，只要有指针还指向它，那它就不会被回收。\n下面这个例子及其输出，展示了 memory-profiler 是如何工作的（注意装饰器和 line-profiler 类似）。\n@profile def my_func(): a = [1] * (10 ** 6) b = [2] * (2 * 10 ** 7) del b return a if __name__ == \u0026#39;__main__\u0026#39;: my_func() $ python -m memory_profiler example.py Line ### Mem usage Increment Line Contents ============================================== 3 @profile 4 5.97 MB 0.00 MB def my_func(): 5 13.61 MB 7.64 MB a = [1] * (10 ** 6) 6 166.20 MB 152.59 MB b = [2] * (2 * 10 ** 7) 7 13.61 MB -152.59 MB del b 8 13.61 MB 0.00 MB return a 事件分析 在我们使用strace调试代码的时候，您可能会希望忽略一些特殊的代码并希望在分析时将其当作黑盒处理。perf 命令将 CPU 的区别进行了抽象，它不会报告时间和内存的消耗，而是报告与您的程序相关的系统事件。\n例如，perf 可以报告不佳的缓存局部性（poor cache locality）、大量的页错误（page faults）或活锁（livelocks）。下面是关于常见命令的简介：\nperf list - 列出可以被 pref 追踪的事件； perf stat COMMAND ARG1 ARG2 - 收集与某个进程或指令相关的事件； perf record COMMAND ARG1 ARG2 - 记录命令执行的采样信息并将统计数据储存在perf.data中； perf report - 格式化并打印 perf.data 中的数据。 可视化 使用分析器来分析真实的程序时，由于软件的复杂性，其输出结果中将包含大量的信息。人类是一种视觉动物，非常不善于阅读大量的文字。因此很多工具都提供了可视化分析器输出结果的功能。\n对于采样分析器来说，常见的显示 CPU 分析数据的形式是 火焰图，火焰图会在 Y 轴显示函数调用关系，并在 X 轴显示其耗时的比例。火焰图同时还是可交互的，您可以深入程序的某一具体部分，并查看其栈追踪（您可以尝试点击下面的图片）。\n调用图和控制流图可以显示子程序之间的关系，它将函数作为节点并把函数调用作为边。将它们和分析器的信息（例如调用次数、耗时等）放在一起使用时，调用图会变得非常有用，它可以帮助我们分析程序的流程。 在 Python 中您可以使用 pycallgraph 来生成这些图片。\n资源监控 有时候，分析程序性能的第一步是搞清楚它所消耗的资源。程序变慢通常是因为它所需要的资源不够了。例如，没有足够的内存或者网络连接变慢的时候。\n有很多很多的工具可以被用来显示不同的系统资源，例如 CPU 占用、内存使用、网络、磁盘使用等。\n通用监控 - 最流行的工具要数 htop,了，它是 top的改进版。htop 可以显示当前运行进程的多种统计信息。htop 有很多选项和快捷键，常见的有：\u0026lt;F6\u0026gt; 进程排序、 t 显示树状结构和 h 打开或折叠线程。 还可以留意一下 glances ，它的实现类似但是用户界面更好。如果需要合并测量全部的进程， dstat 是也是一个非常好用的工具，它可以实时地计算不同子系统资源的度量数据，例如 I/O、网络、 CPU 利用率、上下文切换等等； I/O 操作 - iotop 可以显示实时 I/O 占用信息而且可以非常方便地检查某个进程是否正在执行大量的磁盘读写操作； 磁盘使用 - df 可以显示每个分区的信息，而 du 则可以显示当前目录下每个文件的磁盘使用情况（ disk usage）。-h 选项可以使命令使用对人类（human）更加友好的格式显示数据；ncdu是一个交互性更好的 du ，它可以让您在不同目录下导航、删除文件和文件夹； 内存使用 - free 可以显示系统当前空闲的内存。内存也可以使用 htop 这样的工具来显示； 打开文件 - lsof 可以列出被进程打开的文件信息。 当我们需要查看某个文件是被哪个进程打开的时候，这个命令非常有用；. 网络连接和配置 - ss le帮助我们监控网络包的收发情况以及网络接口的显示信息。ss 常见的一个使用场景是找到端口被进程占用的信息。如果要显示路由、网络设备和接口信息，您可以使用 ip 命令。注意，netstat 和 ifconfig 这两个命令已经被前面那些工具所代替了。 网络使用 - nethogs 和 iftop 是非常好的用于对网络占用进行监控的交互式命令行工具。 如果您希望测试一下这些工具，您可以使用 stress 命令来为系统人为地增加负载。\n专用工具 有时候，您只需要对黑盒程序进行基准测试，并依此对软件选择进行评估。 类似 hyperfine 这样的命令行可以帮您快速进行基准测试。例如，我们在 shell 工具和脚本那一节课中我们推荐使用 fd 来代替 find。我们这里可以用hyperfine来比较一下它们。\n例如，下面的例子中，我们可以看到fd 比 find 要快20倍。\n$ hyperfine --warmup 3 \u0026#39;fd -e jpg\u0026#39; \u0026#39;find . -iname \u0026#34;*.jpg\u0026#34;\u0026#39; Benchmark #1: fd -e jpg Time (mean ± σ): 51.4 ms ± 2.9 ms [User: 121.0 ms, System: 160.5 ms] Range (min … max): 44.2 ms … 60.1 ms 56 runs Benchmark #2: find . -iname \u0026#34;*.jpg\u0026#34; Time (mean ± σ): 1.126 s ± 0.101 s [User: 141.1 ms, System: 956.1 ms] Range (min … max): 0.975 s … 1.287 s 10 runs Summary \u0026#39;fd -e jpg\u0026#39; ran 21.89 ± 2.33 times faster than \u0026#39;find . -iname \u0026#34;*.jpg\u0026#34;\u0026#39; 和 debug 一样，浏览器也包含了很多不错的性能分析工具，可以用来分析页面加载，让我们可以搞清楚时间都消耗在什么地方（加载、渲染、脚本等等）。 更多关于 Firefox 和 Chrome的信息可以点击链接。\n课后练习 调试 使用 Linux 上的 journalctl 或 macOS 上的 log show 命令来获取最近一天中超级用户的登陆信息及其所执行的指令。如果找不到相关信息，您可以执行一些无害的命令，例如sudo ls 然后再次查看。\n学习 这份 pdb 实践教程并熟悉相关的命令。更深入的信息您可以参考这份教程。\n安装 shellcheck 并尝试对下面的脚本进行检查。这段代码有什么问题吗？请修复相关问题。在您的编辑器中安装一个linter插件，这样它就可以自动地显示相关警告信息。\n#!/bin/sh ## Example: a typical script with several problems for f in $(ls *.m3u) do grep -qi hq.*mp3 $f \\ \u0026amp;\u0026amp; echo -e \u0026#39;Playlist $f contains a HQ file in mp3 format\u0026#39; done (进阶题) 请阅读 可逆调试 并尝试创建一个可以工作的例子（使用 rr 或 RevPDB）。\n性能分析 这里 有一些排序算法的实现。请使用 cProfile 和 line_profiler 来比较插入排序和快速排序的性能。两种算法的瓶颈分别在哪里？然后使用 memory_profiler 来检查内存消耗，为什么插入排序更好一些？然后在看看原地排序版本的快排。附加题：使用 perf 来查看不同算法的循环次数及缓存命中及丢失情况。\n这里有一些用于计算斐波那契数列 Python 代码，它为计算每个数字都定义了一个函数：\n#!/usr/bin/env python def fib0(): return 0 def fib1(): return 1 s = \u0026#34;\u0026#34;\u0026#34;def fib{}(): return fib{}() + fib{}()\u0026#34;\u0026#34;\u0026#34; if __name__ == \u0026#39;__main__\u0026#39;: for n in range(2, 10): exec(s.format(n, n-1, n-2)) # from functools import lru_cache # for n in range(10): ### exec(\u0026#34;fib{} = lru_cache(1)(fib{})\u0026#34;.format(n, n)) print(eval(\u0026#34;fib9()\u0026#34;)) 将代码拷贝到文件中使其变为一个可执行的程序。安装 pycallgraph。并使用 pycallgraph graphviz -- ./fib.py 来执行代码并查看pycallgraph.png 这个文件。fib0 被调用了多少次？我们可以通过？我们可以通过记忆法来对其进行优化。将注释掉的部分放开，然后重新生成图片。这回每个fibN 函数被调用了多少次？\n我们经常会遇到的情况是某个我们希望去监听的端口已经被其他进程占用了。让我们通过进程的PID查找相应的进程。首先执行 python -m http.server 4444 启动一个最简单的 web 服务器来监听 4444 端口。在另外一个终端中，执行 lsof | grep LISTEN 打印出所有监听端口的进程及相应的端口。找到对应的 PID 然后使用 kill \u0026lt;PID\u0026gt; 停止该进程。\n限制进程资源也是一个非常有用的技术。执行 stress -c 3 并使用htop 对 CPU 消耗进行可视化。现在，执行taskset --cpu-list 0,2 stress -c 3 并可视化。stress 占用了3个 CPU 吗？为什么没有？阅读man taskset来寻找答案。附加题：使用 cgroups来实现相同的操作，尝试使用stress -m来限制内存使用\n(进阶题) curl ipinfo.io 命令或执行 HTTP 请求并获取关于您 IP 的信息。打开 Wireshark 并抓取 curl 发起的请求和收到的回复报文。（提示：可以使用http进行过滤，只显示 HTTP 报文）\n参考 课程列表\n","permalink":"https://blog.niuhemoon.win/posts/tech/coding-tools-profile/","summary":"代码不能完全按照您的想法运行，它只能完全按照您的写法运行，这是编程界的一条金科玉律。 让您的写法符合您的想法是非常困难的。在这节课中，我们会传授给您一些非常有用技术，帮您处理代码中的 bug 和程序性能问题。 调试代码 打印调试法与日志 \u0026ldquo;最有效的 debug 工具就是细致的分析，配合恰当位置的","title":"编程工具之调试和性能分析"},{"content":"Angular 开发环境 Angular 依赖于 Nodejs，需要首先安装 node 和 npm,安装完成后可以查看 node 和 npm 的版本 然后再安装 angular 依赖\nnode -v npm -v # npm换源 npm config set registry https://registry.npm.taobao.org # 查看npm的源 npm config get registry # 安装angular npm install -g @angular/cli # 更新所有套件到最新版 ng update --all --force # 创建一个angular项目 ng new testng StackBlitz是一个在线开发环境，可以快速上手开发．\n进入 testng 项目，其目录结构如下\n├── angular.json\t# angular配置文件 ├── e2e │ ├── protractor.conf.js │ ├── src │ │ ├── app.e2e-spec.ts\t# e2e 端对端测试目录 │ │ └── app.po.ts │ └── tsconfig.json ├── karma.conf.js\t# 执行自动化测试的 ├── node_modules\t# npm包安装目录，使用npm install安装 ├── package.json\t# npm 工具的配置文件，指明了当前这个应用所要用到的模块，Angular 的依赖包 ├── README.md ├── src │ ├── app │ │ ├── app.component.css\t# 项目主样式 │ │ ├── app.component.html\t# 项目的主模板 │ │ ├── app.component.spec.ts\t# 项目单元测试 │ │ ├── app.component.ts\t# 项目的主组件，定义AppModule，这个根模块会告诉Angular如何组装该应用 │ │ ├── app.module.ts\t# 项目主模块 │ │ └── app-routing.module.ts │ ├── assets\t# 静态资源如图片、翻译语言，构建时自动打包 │ ├── environments │ │ ├── environment.prod.ts\t# 生产环境配置 │ │ └── environment.ts\t# 开发环境配置，默认 │ ├── favicon.ico\t# 图标 │ ├── index.html\t# 宿主页面 │ ├── main.ts\t# 整个web应用的入口点，angular通过该项目来启动整个项目 │ ├── polyfills.ts\t# 导入一些必要的库,使得angular可以在一些老版本的浏览器中运行 │ ├── styles.css\t# 公共样式 │ └── test.ts\t# 单元测试入口点 ├── tsconfig.app.json ├── tsconfig.json\t# TypeScript 编译器的参数 ├── tsconfig.spec.json ├── typings.json\t# 为那些 TypeScript 编译器无法识别的库提供了额外的定义文件。 └── tslint.json\t# 定义 ts 文件质量检查的一些规则 参考 Angular 的 8 个核心概念\nAngular4 教程\n","permalink":"https://blog.niuhemoon.win/posts/tech/angular-devenv/","summary":"Angular 开发环境 Angular 依赖于 Nodejs，需要首先安装 node 和 npm,安装完成后可以查看 node 和 npm 的版本 然后再安装 angular 依赖 node -v npm -v # npm换源 npm config set registry https://registry.npm.taobao.org # 查看npm的源 npm config get registry # 安装angular npm install -g @angular/cli # 更新所有套件到最新版 ng update --all --force # 创建一个angular项目 ng new testng StackBlitz是一个在线开","title":"Angular开发环境搭建"},{"content":"Python种基本类型的比较：\nList is a collection which is ordered and mutable. Allows duplicate members. Tuple is a collection which is ordered and immutable. Allows duplicate members. Set is a collection which is unordered and unindexed. No duplicate members. Dictionary is a collection which is unordered, mutable and indexed. No duplicate members. Strings are immutable sequences of Unicode code points. List Python中的list是一个有序容器，容纳不同类型的数据（但推荐列表内数据类型相同)，同时其是可变类型的．\n创建列表 list_1 = [\u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;, \u0026#34;apple\u0026#34;] print(list_1) # Or create an empty list with the list function list_2 = list() print(list_2) # Lists allow different data types list_3 = [5, True, \u0026#34;apple\u0026#34;] print(list_3) # Lists allow duplicates list_4 = [0, 0, 1, 1] print(list_4) 内置方法 修改列表的方法尽量使用内置方法，内置方法效率较高\nmy_list = [\u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;, \u0026#34;apple\u0026#34;] # len() : get the number of elements in a list print(\u0026#34;Length:\u0026#34;, len(my_list)) # append() : adds an element to the end of the list my_list.append(\u0026#34;orange\u0026#34;) # insert() : adds an element at the specified position my_list.insert(1, \u0026#34;blueberry\u0026#34;) print(my_list) # pop() : removes and returns the item at the given position, default is the last item item = my_list.pop() print(\u0026#34;Popped item: \u0026#34;, item) # remove() : removes an item from the list my_list.remove(\u0026#34;cherry\u0026#34;) # Value error if not in the list print(my_list) # clear() : removes all items from the list my_list.clear() print(my_list) # reverse() : reverse the items my_list = [\u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;, \u0026#34;apple\u0026#34;] my_list.reverse() print(\u0026#39;Reversed: \u0026#39;, my_list) # sort() : sort items in ascending order my_list.sort() print(\u0026#39;Sorted: \u0026#39;, my_list) # use sorted() to get a new list, and leave the original unaffected. # sorted() works on any iterable type, not just lists my_list = [\u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;, \u0026#34;apple\u0026#34;] new_list = sorted(my_list) # create list with repeated elements list_with_zeros = [0] * 5 print(list_with_zeros) # concatenation list_concat = list_with_zeros + my_list print(list_concat) # convert string to list string_to_list = list(\u0026#39;Hello\u0026#39;) print(string_to_list) 复制列表 注意拷贝列表内容还是拷贝引用\nlist_org = [\u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;, \u0026#34;apple\u0026#34;] # this just copies the reference to the list, so be careful list_copy = list_org # now modifying the copy also affects the original list_copy.append(True) print(list_copy) print(list_org) # use copy(), or list(x) to actually copy the list # slicing also works: list_copy = list_org[:] list_org = [\u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;, \u0026#34;apple\u0026#34;] list_copy = list_org.copy() # list_copy = list(list_org) # list_copy = list_org[:] # now modifying the copy does not affect the original list_copy.append(True) print(list_copy) print(list_org) 列表切片 # a[start:stop:step], default step is 1 a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] b = a[1:3] # Note that the last index is not included print(b) b = a[2:] # until the end print(b) b = a[:3] # from beginning print(b) a[0:3] = [0] # replace sub-parts, you need an iterable here print(a) b = a[::2] # start to end with every second item print(b) a = a[::-1] # reverse the list with a negative step: print(a) b = a[:] # copy a list with slicing print(b) Tuple Tuple又称为元组，和List列表类似，主要区别在于元组是不可变类型．不可变意味着元组中的元素无法被重新赋值．使用元组而非列表的有如下原因：\nGenerally used for objects that belong together. Use tuple for heterogeneous (different) datatypes and list for homogeneous (similar) datatypes. Since tuple are immutable, iterating through tuple is slightly faster than with list. Tuples with their immutable elements can be used as key for a dictionary. This is not possible with lists. If you have data that doesn\u0026rsquo;t change, implementing it as tuple will guarantee that it remains write-protected. 创建元组 tuple_1 = (\u0026#34;Max\u0026#34;, 28, \u0026#34;New York\u0026#34;) tuple_2 = \u0026#34;Linda\u0026#34;, 25, \u0026#34;Miami\u0026#34; # Parentheses are optional # Special case: a tuple with only one element needs to have a comma at the end, # otherwise it is not recognized as tuple tuple_3 = (25,) print(tuple_1) print(tuple_2) print(tuple_3) # Or convert an iterable (list, dict, string) with the built-in tuple function tuple_4 = tuple([1,2,3]) print(tuple_4) 不可变解释 元组不提供修改元素的方法，其中的item本身无法被赋值，即其指向的对象id（类似内存地址)无法改变，但是若元组中元素item自身是可变类型的，元素本身可以改变．\nPython中可变类型的解释：\npython中对可变数据类型的定义为：当该数据类型的对应变量的值发生了改变，那么它对应的内存地址不发生改变，就称可变数据类型。包括：set（集合）、list（列表）、dict（字典）\nIn [7]: a = (1,[2,3]) In [8]: a[1] Out[8]: [2, 3] In [9]: a[1] = [1,2,3] --------------------------------------------------------------------------- TypeError Traceback (most recent call last) \u0026lt;ipython-input-9-f8fa7e0d45e2\u0026gt; in \u0026lt;module\u0026gt; ----\u0026gt; 1 a[1] = [1,2,3] TypeError: \u0026#39;tuple\u0026#39; object does not support item assignment In [10]: a[1].append(3) In [11]: a Out[11]: (1, [2, 3, 3]) 以此执行下面指令，可以理解一下浅拷贝和深拷贝\na = [1] # shadow copy b = a b is a　# True,has same address id(a) id(b) # deep copy,a point to another memory address a = a+[2] a id(a) # b\u0026#39;s address doesn\u0026#39;t change id(b) 内置方法 my_tuple = (\u0026#39;a\u0026#39;,\u0026#39;p\u0026#39;,\u0026#39;p\u0026#39;,\u0026#39;l\u0026#39;,\u0026#39;e\u0026#39;,) # len() : get the number of elements in a tuple print(len(my_tuple)) # count(x) : Return the number of items that is equal to x print(my_tuple.count(\u0026#39;p\u0026#39;)) # index(x) : Return index of first item that is equal to x print(my_tuple.index(\u0026#39;l\u0026#39;)) # repetition my_tuple = (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;) * 5 print(my_tuple) # concatenation my_tuple = (1,2,3) + (4,5,6) print(my_tuple) # convert list to a tuple and vice versa my_list = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;] list_to_tuple = tuple(my_list) print(list_to_tuple) tuple_to_list = list(list_to_tuple) print(tuple_to_list) # convert string to tuple string_to_tuple = tuple(\u0026#39;Hello\u0026#39;) print(string_to_tuple) # Result \u0026#34;\u0026#34;\u0026#34; 5 2 3 (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;) (1, 2, 3, 4, 5, 6) (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;) [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;] (\u0026#39;H\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;o\u0026#39;) \u0026#34;\u0026#34;\u0026#34; 元组切片 # a[start:stop:step], default step is 1 a = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10) b = a[1:3] # Note that the last index is not included print(b) b = a[2:] # until the end print(b) b = a[:3] # from beginning print(b) b = a[::2] # start to end with every second item print(b) b = a[::-1] # reverse tuple # don\u0026#39;t change a ,create a new tuple and assign it to b print(b) # Result \u0026#34;\u0026#34;\u0026#34; (2, 3) (3, 4, 5, 6, 7, 8, 9, 10) (1, 2, 3) (1, 3, 5, 7, 9) (10, 9, 8, 7, 6, 5, 4, 3, 2, 1) \u0026#34;\u0026#34;\u0026#34; 元组解包 在Python中互换两个变量的值，如\na,b = b,a\n就是等号右侧将b,a自动打包为元组(b,a)，赋值给左侧后再自动解包，同样的，Python中函数返回多个值，也是隐式的将多个值打包为元组，并返回一个元组．\n# number of variables have to match number of tuple elements tuple_1 = (\u0026#34;Max\u0026#34;, 28, \u0026#34;New York\u0026#34;) name, age, city = tuple_1 print(name) print(age) print(city) # tip: unpack multiple elements to a list with * my_tuple = (0, 1, 2, 3, 4, 5) item_first, *items_between, item_last = my_tuple print(item_first) print(items_between) print(item_last) # Result \u0026#34;\u0026#34;\u0026#34; Max 28 New York 0 [1, 2, 3, 4] 5 \u0026#34;\u0026#34;\u0026#34; 元组列表对比 容纳同样的数据，元组的占用空间和迭代速度更高\n# compare the size import sys my_list = [0, 1, 2, \u0026#34;hello\u0026#34;, True] my_tuple = (0, 1, 2, \u0026#34;hello\u0026#34;, True) print(sys.getsizeof(my_list), \u0026#34;bytes\u0026#34;) print(sys.getsizeof(my_tuple), \u0026#34;bytes\u0026#34;) # compare the execution time of a list vs. tuple creation statement import timeit print(timeit.timeit(stmt=\u0026#34;[0, 1, 2, 3, 4, 5]\u0026#34;, number=1000000)) print(timeit.timeit(stmt=\u0026#34;(0, 1, 2, 3, 4, 5)\u0026#34;, number=1000000)) # Result \u0026#34;\u0026#34;\u0026#34; 104 bytes 88 bytes 0.12474981700000853 0.014836141000017733 \u0026#34;\u0026#34;\u0026#34; Dictionary 字典是无序的、可变的、可索引的一种数据类型。\n字典创建 my_dict = {\u0026#34;name\u0026#34;:\u0026#34;Max\u0026#34;, \u0026#34;age\u0026#34;:28, \u0026#34;city\u0026#34;:\u0026#34;New York\u0026#34;} print(my_dict) # or use the dict constructor, note: no quotes necessary for keys my_dict_2 = dict(name=\u0026#34;Lisa\u0026#34;, age=27, city=\u0026#34;Boston\u0026#34;) print(my_dict_2) 常用方法 删除字典元素 my_dict = {\u0026#34;name\u0026#34;:\u0026#34;Max\u0026#34;, \u0026#34;age\u0026#34;:28, \u0026#34;city\u0026#34;:\u0026#34;New York\u0026#34;} # delete a key-value pair del my_dict[\u0026#34;email\u0026#34;] # this returns the value and removes the key-value pair print(\u0026#34;popped value:\u0026#34;, my_dict.pop(\u0026#34;age\u0026#34;)) # return and removes the last inserted key-value pair # (in versions before Python 3.7 it removes an arbitrary pair) print(\u0026#34;popped item:\u0026#34;, my_dict.popitem()) print(my_dict) # clear() : remove all pairs # my_dict.clear() 检查key是否存在 my_dict = {\u0026#34;name\u0026#34;:\u0026#34;Max\u0026#34;, \u0026#34;age\u0026#34;:28, \u0026#34;city\u0026#34;:\u0026#34;New York\u0026#34;} # use if .. in .. if \u0026#34;name\u0026#34; in my_dict: print(my_dict[\u0026#34;name\u0026#34;]) # use try except try: print(my_dict[\u0026#34;firstname\u0026#34;]) except KeyError: print(\u0026#34;No key found\u0026#34;) 迭代字典元素 # loop over keys for key in my_dict: print(key, my_dict[key]) # loop over keys for key in my_dict.keys(): print(key) # loop over values for value in my_dict.values(): print(value) # loop over keys and values for key, value in my_dict.items(): print(key, value) 复制字典 dict_org = {\u0026#34;name\u0026#34;:\u0026#34;Max\u0026#34;, \u0026#34;age\u0026#34;:28, \u0026#34;city\u0026#34;:\u0026#34;New York\u0026#34;} # this just copies the reference to the dict, so be careful dict_copy = dict_org # now modifying the copy also affects the original dict_copy[\u0026#34;name\u0026#34;] = \u0026#34;Lisa\u0026#34; print(dict_copy) print(dict_org) # use copy(), or dict(x) to actually copy the dict dict_org = {\u0026#34;name\u0026#34;:\u0026#34;Max\u0026#34;, \u0026#34;age\u0026#34;:28, \u0026#34;city\u0026#34;:\u0026#34;New York\u0026#34;} dict_copy = dict_org.copy() # dict_copy = dict(dict_org) # now modifying the copy does not affect the original dict_copy[\u0026#34;name\u0026#34;] = \u0026#34;Lisa\u0026#34; print(dict_copy) print(dict_org) 合并两个字典 # Use the update() method to merge 2 dicts # existing keys are overwritten, new keys are added my_dict = {\u0026#34;name\u0026#34;:\u0026#34;Max\u0026#34;, \u0026#34;age\u0026#34;:28, \u0026#34;email\u0026#34;:\u0026#34;max@xyz.com\u0026#34;} my_dict_2 = dict(name=\u0026#34;Lisa\u0026#34;, age=27, city=\u0026#34;Boston\u0026#34;) my_dict.update(my_dict_2) print(my_dict) 可能的Key类型 任何不可变类型都可以作为字典的key，包括数字、字符串。元组如果所有元素都是不可变的，也可以作为key。\n# use numbers as key, but be careful my_dict = {3: 9, 6: 36, 9:81} # do not mistake the keys as indices of a list, e.g my_dict[0] is not possible here print(my_dict[3], my_dict[6], my_dict[9]) # use a tuple with immutable elements (e.g. number, string) my_tuple = (8, 7) my_dict = {my_tuple: 15} print(my_dict[my_tuple]) # print(my_dict[8, 7]) # a list is not possible because it is not immutable # this will raise an Error: # my_list = [8, 7] # my_dict = {my_list: 15} Sets A Set is an unordered collection data type that is unindexed, mutable, and has no duplicate elements.\n创建集合 my_set = {\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;} print(my_set) # or use the set function and create from an iterable, e.g. list, tuple, string my_set_2 = set([\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;]) my_set_2 = set((\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;)) print(my_set_2) my_set_3 = set(\u0026#34;aaabbbcccdddeeeeeffff\u0026#34;) print(my_set_3) # careful: an empty set cannot be created with {}, as this is interpreted as dict # use set() instead a = {} print(type(a)) a = set() print(type(a)) 常用方法 添加元素 my_set = set() # use the add() method to add elements my_set.add(42) my_set.add(True) my_set.add(\u0026#34;Hello\u0026#34;) # note: the order does not matter, and might differ when printed print(my_set) # nothing happens when the element is already present: my_set.add(42) print(my_set) 移除元素 # remove(x): removes x, raises a KeyError if element is not present my_set = {\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;} my_set.remove(\u0026#34;apple\u0026#34;) print(my_set) # KeyError: # my_set.remove(\u0026#34;orange\u0026#34;) # discard(x): removes x, does nothing if element is not present my_set.discard(\u0026#34;cherry\u0026#34;) my_set.discard(\u0026#34;blueberry\u0026#34;) print(my_set) # clear() : remove all elements my_set.clear() print(my_set) # pop() : return and remove a random element a = {True, 2, False, \u0026#34;hi\u0026#34;, \u0026#34;hello\u0026#34;} print(a.pop()) print(a) 交集和并集 不改变原有集合，只是会产生新的集合\nodds = {1, 3, 5, 7, 9} evens = {0, 2, 4, 6, 8} primes = {2, 3, 5, 7} # union() : combine elements from both sets, no duplication # note that this does not change the two sets u = odds.union(evens) print(u) # intersection(): take elements that are in both sets i = odds.intersection(evens) print(i) i = odds.intersection(primes) print(i) i = evens.intersection(primes) print(i) 差集 setB = {1, 2, 3, 10, 11, 12} # difference() : returns a set with all the elements from the setA that are not in setB. diff_set = setA.difference(setB) print(diff_set) # A.difference(B) is not the same as B.difference(A) diff_set = setB.difference(setA) print(diff_set) # symmetric_difference() : returns a set with all the elements that are in setA and setB but not in both diff_set = setA.symmetric_difference(setB) print(diff_set) # A.symmetric_difference(B) = B.symmetric_difference(A) diff_set = setB.symmetric_difference(setA) print(diff_set) 更新集合（交/并/差） setA = {1, 2, 3, 4, 5, 6, 7, 8, 9} setB = {1, 2, 3, 10, 11, 12} # update() : Update the set by adding elements from another set. setA.update(setB) print(setA) # intersection_update() : Update the set by keeping only the elements found in both setA = {1, 2, 3, 4, 5, 6, 7, 8, 9} setA.intersection_update(setB) print(setA) # difference_update() : Update the set by removing elements found in another set. setA = {1, 2, 3, 4, 5, 6, 7, 8, 9} setA.difference_update(setB) print(setA) # symmetric_difference_update() : Update the set by only keeping the elements found in either set, but not in both setA = {1, 2, 3, 4, 5, 6, 7, 8, 9} setA.symmetric_difference_update(setB) print(setA) # Note: all update methods also work with other iterables as argument, e.g lists, tuples # setA.update([1, 2, 3, 4, 5, 6]) 复制集合 set_org = {1, 2, 3, 4, 5} # this just copies the reference to the set, so be careful set_copy = set_org # now modifying the copy also affects the original set_copy.update([3, 4, 5, 6, 7]) print(set_copy) print(set_org) # use copy() to actually copy the set set_org = {1, 2, 3, 4, 5} set_copy = set_org.copy() # now modifying the copy does not affect the original set_copy.update([3, 4, 5, 6, 7]) print(set_copy) print(set_org) 子集/不相交 setA = {1, 2, 3, 4, 5, 6} setB = {1, 2, 3} # issubset(setX): Returns True if setX contains the set print(setA.issubset(setB)) print(setB.issubset(setA)) # True # issuperset(setX): Returns True if the set contains setX print(setA.issuperset(setB)) # True print(setB.issuperset(setA)) # isdisjoint(setX) : Return True if both sets have a null intersection, i.e. no same elements setC = {7, 8, 9} print(setA.isdisjoint(setB)) print(setA.isdisjoint(setC)) Frozenset不可变集合 Frozen set是一种不可变的集合，其在创建以后，集合中的元素id不可变\na = frozenset([0, 1, 2, 3, 4]) # The following is not allowed: # a.add(5) # a.remove(1) # a.discard(1) # a.clear() # Also no update methods are allowed: # a.update([1,2,3]) # Other set operations work odds = frozenset({1, 3, 5, 7, 9}) evens = frozenset({0, 2, 4, 6, 8}) print(odds.union(evens)) print(odds.intersection(evens)) print(odds.difference(evens)) Strings 字符串是一个字符序列，是不可变类型，对于同一个id下的字符串不可变。\n字符串创建 # use singe or double quotes my_string = \u0026#39;Hello\u0026#39; my_string = \u0026#34;Hello\u0026#34; my_string = \u0026#34;I\u0026#39; m a \u0026#39;Geek\u0026#39;\u0026#34; # escaping backslash my_string = \u0026#39;I\\\u0026#39; m a \u0026#34;Geek\u0026#34;\u0026#39; my_string = \u0026#39;I\\\u0026#39; m a \\\u0026#39;Geek\\\u0026#39;\u0026#39; print(my_string) # triple quotes for multiline strings my_string = \u0026#34;\u0026#34;\u0026#34;Hello World\u0026#34;\u0026#34;\u0026#34; print(my_string) # backslash if you want to continue in the next line my_string = \u0026#34;Hello \\ World\u0026#34; print(my_string) 访问字符或者子串 my_string = \u0026#34;Hello World\u0026#34; # get character by referring to index b = my_string[0] print(b) # Substrings with slicing b = my_string[1:3] # Note that the last index is not included print(b) b = my_string[:5] # from beginning print(b) b = my_string[6:] # until the end print(b) b = my_string[::2] # start to end with every second item print(b) b = my_string[::-1] # reverse the string with a negative step: print(b) 常用方法 my_string = \u0026#34; Hello World \u0026#34; # remove white space my_string = my_string.strip() print(my_string) # number of characters print(len(my_string)) # Upper and lower cases print(my_string.upper()) print(my_string.lower()) # startswith and endswith print(\u0026#34;hello\u0026#34;.startswith(\u0026#34;he\u0026#34;)) print(\u0026#34;hello\u0026#34;.endswith(\u0026#34;llo\u0026#34;)) # find first index of a given substring, -1 otherwise print(\u0026#34;Hello\u0026#34;.find(\u0026#34;o\u0026#34;)) # count number of characters/substrings print(\u0026#34;Hello\u0026#34;.count(\u0026#34;e\u0026#34;)) # replace a substring with another string (only if the substring is found) # Note: The original string stays the same message = \u0026#34;Hello World\u0026#34; new_message = message.replace(\u0026#34;World\u0026#34;, \u0026#34;Universe\u0026#34;) print(new_message) # split the string into a list my_string = \u0026#34;how are you doing\u0026#34; a = my_string.split() # default argument is \u0026#34; \u0026#34; print(a) my_string = \u0026#34;one,two,three\u0026#34; a = my_string.split(\u0026#34;,\u0026#34;) print(a) # join elements of a list into a string my_list = [\u0026#39;How\u0026#39;, \u0026#39;are\u0026#39;, \u0026#39;you\u0026#39;, \u0026#39;doing\u0026#39;] a = \u0026#39; \u0026#39;.join(my_list) # the given string is the separator, e.g. \u0026#39; \u0026#39; between each argument print(a) 格式化字符串 # use braces as placeholders a = \u0026#34;Hello {0} and {1}\u0026#34;.format(\u0026#34;Bob\u0026#34;, \u0026#34;Tom\u0026#34;) print(a) # the positions are optional for the default order a = \u0026#34;Hello {} and {}\u0026#34;.format(\u0026#34;Bob\u0026#34;, \u0026#34;Tom\u0026#34;) print(a) a = \u0026#34;The integer value is {}\u0026#34;.format(2) print(a) # some special format rules for numbers a = \u0026#34;The float value is {0:.3f}\u0026#34;.format(2.1234) print(a) a = \u0026#34;The float value is {0:e}\u0026#34;.format(2.1234) print(a) a = \u0026#34;The binary value is {0:b}\u0026#34;.format(2) print(a) # old style formatting by using % operator print(\u0026#34;Hello %s and %s\u0026#34; % (\u0026#34;Bob\u0026#34;, \u0026#34;Tom\u0026#34;)) # must be a tuple for multiple arguments val = 3.14159265359 print(\u0026#34;The decimal value is %d\u0026#34; % val) print(\u0026#34;The float value is %f\u0026#34; % val) print(\u0026#34;The float value is %.2f\u0026#34; % val) # since python3.6 # Use the variables directly inside the braces. name = \u0026#34;Eric\u0026#34; age = 25 a = f\u0026#34;Hello, {name}. You are {age}.\u0026#34; print(a) pi = 3.14159 a = f\u0026#34;Pi is {pi:.3f}\u0026#34; print(a) # f-Strings are evaluated at runtime, which allows expressions a = f\u0026#34;The value is {2*60}\u0026#34; print(a) More on immutability and concatenation # since a string is immutable, adding strings with +, or += always # creates a new string, and therefore is expensive for multiple operations # --\u0026gt; join method is much faster from timeit import default_timer as timer my_list = [\u0026#34;a\u0026#34;] * 1000000 # bad start = timer() a = \u0026#34;\u0026#34; for i in my_list: a += i end = timer() print(\u0026#34;concatenate string with + : %.5f\u0026#34; % (end - start)) # good start = timer() a = \u0026#34;\u0026#34;.join(my_list) end = timer() print(\u0026#34;concatenate string with join(): %.5f\u0026#34; % (end - start)) 参考 Python-Notebook\n","permalink":"https://blog.niuhemoon.win/posts/tech/python-advanced-1/","summary":"Python种基本类型的比较： List is a collection which is ordered and mutable. Allows duplicate members. Tuple is a collection which is ordered and immutable. Allows duplicate members. Set is a collection which is unordered and unindexed. No duplicate members. Dictionary is a collection which is unordered, mutable and indexed. No duplicate members. Strings are immutable sequences of Unicode code points. List Python中的list是一个有序容器，容纳不同类型的数据（但推荐列表内数据类型相同)，同时其是可变类型的． 创建列表 list_1 = [\u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;, \u0026#34;apple\u0026#34;] print(list_1) # Or create","title":"Python进阶上"},{"content":"Microstack 简介 Microstack 是在 ubuntu 平台上快速部署 Openstack 环境的工具，其通过 snap 构建，而 snap 安装目录是一个独立的只读文件系统，这就导致难以改动代码进行调试。 因此，Microstack 环境只适用于 Openstack 初学者学习命令行和数据库等等，调试的话可以通告 gdb 调试，而不便于通过 pdb 调试，因为无法修改源文件，并在文件还中加断点。 Microstack 是目前 Ubuntu 上最简洁的 Openstack 配置工具，可以在笔记本上部署单节点环境用于学习，也可以在多台设备上部署多节点环境。\nMicrostack 安装 需要在终端科学上网，否则 snap 镜像很慢,目前支持到 Openstack 上游的 stein 版本．\n# 配置代理 export https_proxy=http://127.0.0.1:port\u0026amp;\u0026amp; export http_proxy=http://127.0.0.1:port\u0026#34; # 安装snap包 sudo snap install --classic --beta microstack # 初始化microstack环境 sudo microstack.init --auto # 初始化完成后会自动启动Openstack进程 # 查看相关进程 systemctl list-units | grep microstack # 可以看到microstack进程的状态 # 如果全部是loaded active running，表示服务正常启动 Microstack 基本使用 Microstack 由于是 Snap 镜像，可以手动关闭和开启 其源代码在/snap/microstack/196/lib/python3.6/site-packages 但由于 snap 只读文件系统，代码无法修改 此外，其命令行 Client 都加上了 Microstack 前缀\n一些常用的命令行\n# 在.bashrc文件中配置别名 alias openstack=\u0026#34;microstack.openstack\u0026#34; source ~/.bashrc # 查看帮助 openstack --help # 数据库操作，查看nova库 sudo microstack.mysql nova # 几个数据库包括: # |cinder | # | glance | # | keystone | # | mysql | # | neutron | # | nova | # | nova_api | # | nova_cell0 # 查看配置文件和数据库地址 cd /var/snap/microstack # 配置文件，可修改配置文件重启进程 cd /var/snap/microstack/common/etc 也可以在浏览器访问 web 界面http://10.20.20.1/ 默认用户名密码是 admin 和 keystone\n总结\nMicrostack 目前不适用于开发者编辑调试代码，只适用于学习者熟悉环境，用于在自己的电脑上快速部署．\n参考 Microstack 文档\n","permalink":"https://blog.niuhemoon.win/posts/tech/microstack-usage/","summary":"Microstack 简介 Microstack 是在 ubuntu 平台上快速部署 Openstack 环境的工具，其通过 snap 构建，而 snap 安装目录是一个独立的只读文件系统，这就导致难以改动代码进行调试。 因此，Microstack 环境只适用于 Openstack 初学者学习命令行和数据库等等，调试的话可以通告 gdb 调试，而不便于通过 pdb 调试，因为无法修改源文件，并在文件还中加断点。 Microstack","title":"Microstack 基本使用"},{"content":"python3中如何对二维码QRcode进行编码解码\n通常对于二维码，我们需要进行两种操作：\n将二维码图片扫描后解析成字符串 将字符串编码生成二维码图片 这是两个逆过程，在python2中，我们可以通过zbar这个第三方库实现两个功能。可以zbar并不支持python3，而且，zbar在window平台上的安装极其繁琐，有很多坑。\n所以想通过python3处理二维码的过程中，查了很多资料。目前比较好的解决办法如下：\n用pyzbar代替zbar解析二维码 安装：\npip install pyzbar 这是可能的，因为pyzbar是一个围绕zbar库的基于ctypes的包装器，它包含在dll和Windows Python的轮子中。\n使用：\n网络上二维码图片解析 import requests import array from PIL import Image from io import BytesIO from pyzbar.pyzbar import decode # decode_result的格式是[Decoded(data=\u0026#39;****\u0026#39;,……)]，列表里包含一个nametuple def decode_qrcode(url) decode_result = decode(Image.open(BytesIO(requests.get(urls, headers=HEADERS).content)) return str(decode_result[0].data, encoding=\u0026#39;utf-8\u0026#39;) 本地二维码图片解析 from PIL import Image from pyzbar.pyzbar import decode def decode_qrcode(url) decode_result = decode(Image.open(\u0026#39;filename\u0026#39;)) return str(decode_result[0].data, encoding=\u0026#39;utf-8\u0026#39;) 更详细用法参见release页面\n下载zbar.exe文件并安装，通过系统命令行调用来解码 下载地址：zbar-0.10-setup.exe\n说明：\n使用：\nimport os os.system(r\u0026#39;C:\\zbarimg.exe -d d:\\Winapps\\Zbar\\Examples\\barcode.png\u0026#39;) Linux平台上qrtools解码 注：这个方法我没用过。\n安装：\nsudo apt-get install python-qrtools 使用：\nimport qrtools qr = qrtools.QR() qr.decode(\u0026#34;horn.png\u0026#34;) print qr.data 用PyQRCode来生成二维码 安装：\npip install pyqrcode 用法：\nimport pyqrcode url = pyqrcode.create(\u0026#39;http://uca.edu\u0026#39;) url.svg(\u0026#39;uca-url.svg\u0026#39;, scale=8) 说明： pyqrcode具有完善的帮助文档和强大的功能，可以快速生产二维码图片,细节参考：\nRelease页面 帮助文档 其他值得关注的内容 qreader是一个正在开发中的项目，使用纯Python编写的二维码解析库，不依赖zbar。感兴趣的可以去提交PR。\n免费的二维码编码解码API接口 http://api.qrserver.com/ Send a GET request of following form to our system to decode a QR code graphic (=to read a QR code from the web): http(s)://api.qrserver.com/v1/read-qr-code/?fileurl=[URL-encoded-webaddress-url-to-qrcode-image-file]\nhttp://www.7xiwang.com/Tools/Index 解码api：http://www.7xiwang.com/WebService/QRCodeDecode api参数：base64img api请求类型：HttpPost 参数数据格式（JSON）：{\u0026#34;base64img\u0026#34;:\u0026#34;\u0026#34;} api返回数据格式（JSON）： 请求成功：{\u0026#34;status\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;text\u0026#34;:\u0026#34;\u0026#34;} 请求失败：{\u0026#34;status\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;Msg\u0026#34;:\u0026#34;错误信息\u0026#34;} ","permalink":"https://blog.niuhemoon.win/posts/tech/python3-qrcode/","summary":"python3中如何对二维码QRcode进行编码解码 通常对于二维码，我们需要进行两种操作： 将二维码图片扫描后解析成字符串 将字符串编码生成二维码图片 这是两个逆过程，在python2中，我们可以通过zbar这个第三方库实现两个功能。可以zbar并不支持python3，而且，zbar在","title":"Python3操作二维码图片"},{"content":" Linux内核支持用户进程和内核进程两种进程。内核进程指完全运行在内核空间的进程，这种进程主要处理内核事务；用户进程一般运行在用户态，需要使用内核资源时，通过系统调用进入内核态，系统调用结束后，重新返回用户态。\n###创建进程\n可通过fork函数创建子进程，理论上，父子进程拥有各自独立的用户空间。但Linux为了提高效率，采用COW(copy on write)算法。\nfork函数原型如下:\n/* 成功：子进程pid返回给父进程，0返回给子进程 失败：\t-1返回给父进程，设置errno */ pid_t fork(); 案例：创建子进程\n#include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int glob = 10; int main() { int local; pid_t pid; local = 8; //向子进程的pid传值0 if((pid = fork()) == 0) {\t//子进程 sleep(1); printf(\u0026#34;i am in child process,%d\\n\u0026#34;,getpid()); }zijc else {\t//父进程 printf(\u0026#34;i am in father process,%d\\n\u0026#34;,getpid()); glob++; local--; sleep(5); } printf(\u0026#34;pid = %d,glob = %d,localar = %d\\n\u0026#34;,getpid(),glob,local); return 0; } /*输出为： i am in father process,13023 i am in child process,13024 pid = 13024,glob = 10,localar = 8 pid = 13023,glob = 11,localar = 7 */ 当用fork()函数创建子进程时，Linux内核为子进程分配一个进程控制块task_struct。子进程的进程控制块用来存放子进程拥有的资源、管理信息和进程状态等。\n此时，在父子进程没有对数据进行读写操作之前，父子进程共享用户地址空间。当父进程执行glob++，Linux内核采用COW算法，首先为子进程创建相应的数据区，接着内核将父进程地址空间中的数据区相关页复制到子进程地址空间中数据区的相关页,此时，父子进程各自拥有独立的全局变量glob。当执行local\u0026ndash;语句，内核以同样方法在子进程用户地址空间的栈区的相应页建立复制。而代码区是只读的，所以父子进程共享代码区，直接建立映射，不进行复制。\n###程序启动和结束 初始化程序\n在加载可执行文件后，首先运行的是称为start-up的代码，此部分代码在程序链接为可执行程序时，由链接器加入，作用是从内核读取进程运行的环境信息，如环境变量、命令行参数等。\nstart-up完成初始化工作后，调用main函数，执行完进程后，通过exit函数结束进程。\n结束进程\n每个进程都有父进程，当子进程运行结束后，子进程进程僵尸状态，并向父进程发送SIGCHLD信号，通知子进程已经终止。在该状态下子进程几乎释放了所有内存资源，不能被重新调度，仅在进程列表中保留一个位置，只保留进程如何终止的一些状态信息，以供回收者使用。父进程可以通过调用wait或waitpid函数获取子进程的退出码，以便判断子进程结束的原因。由父进程释放子进程余下的所有资源。\n但当父进程在子进程之前终止，子进程的父进程将更改为init进程，由init进程负责子进程的善后处理工作。\n//终止进程,status返回值 void exit(int status); /* 登记终止处理函数，ANSI C规定，一个进程可以登记最多32个终止处理函数，这些函数由exit自动调用。exit以先进后出的方式调用atexit登记的函数，同一函数登记多次，也被调用多次。 根据ANSI C，exit首先调用终止处理函数，然后按需调用fclose，关闭所有打开的文件流，保证基于缓冲区的文件I/O操作完整性。 这样，在进程结束前，将未写入文件的缓冲区数据，通过exit函数进行保存。 func终止处理函数 成功返回0，否则非0 */ int atexit(void(*func)(void)); //直接结束进程，不进行任何其他处理 void _exit(int status); 案例：直接退出进程\n#include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;output begin\\n\u0026#34;); printf(\u0026#34;content in buffer\u0026#34;); printf(\u0026#34;drop the buffer\u0026#34;); _exit(0); } 案例：登记终止处理函数\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; static void my_exit1(void) { printf(\u0026#34;first exit handler\\n\u0026#34;); } static void my_exit2(void) { printf(\u0026#34;second exit handler\\n\u0026#34;); } int main(void) { if(atexit(my_exit2) != 0) printf(\u0026#34;can\u0026#39;t register my_exit2\u0026#34;); if(atexit(my_exit1) != 0) printf(\u0026#34;can\u0026#39;t register my_exit1\u0026#34;); if(atexit(my_exit1) != 0) printf(\u0026#34;can\u0026#39;t register my_exit1\u0026#34;); printf(\u0026#34;main is done\\n\u0026#34;); return 0; } ###进程同步控制\n当创建一个子进程后，父子进程的执行顺序无法控制。当父子进程同事操作共享资源，不同的执行次序有可能导致不同的运行结果，从而出现数据不一致性。为解决这一问题，必须提供进程间的同步控制机制。\nwait和waitpid可用来实现父子进程同步，用来等待子进程结束。 wait函数的功能是获取子进程如何终止的信息，清除子进程的剩余资源。父进程调用wait函数，进入阻塞队列，等待某个子进程的结束。当子进程结束，会产生结束状态字status,并向父进程发送SIGCHLD信号。 父进程收到SIGCHLD信号，若希望知道子进程结束状态，调用wait,否则忽略该信号。\n/* 暂停执行，将子进程结束状态写入status中，并确认子进程已经结束 status 子进程状态 成功返回子进程PID，否则返回-1 */ pid_t wait(int *status); /* 等待指定子进程结束 pid 指定等待的子进程 \u0026lt;-1 pid所代表进程组中进程 -1 任何子进程 0 与该进程同组的进程 \u0026gt;0 进程标识符为pid的进程 status 保存子进程状态 options 等待方式 WNOHANG\t进程不阻塞 WUNTRACED 当有子进程结束时返回 */ pid_t waitpid(pid_t pid,int *status,int options); 案例：依次等待多个子进程结束，并显示结束状态\n#include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;sys/wait.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(void) { pid_t pid[10],wpid; int child_status,i; //创建5个子进程 for(i=0;i\u0026lt;5;i++) { if((pid[i]=fork()) == 0) exit(100+i); } //等待子进程结束，输出status for(i=0;i\u0026lt;5;i++) { wpid = waitpid(pid[i],\u0026amp;child_status,0); if(WIFEXITED(child_status)) printf(\u0026#34;Child %d exit with status %d\\n\u0026#34;, wpid,WEXITSTATUS(child_status)); else printf(\u0026#34;Child %d terminated abnormally\\n\u0026#34;,wpid); } return 0; } ","permalink":"https://blog.niuhemoon.win/posts/tech/linux-c-process-2/","summary":"Linux内核支持用户进程和内核进程两种进程。内核进程指完全运行在内核空间的进程，这种进程主要处理内核事务；用户进程一般运行在用户态，需要使用内核资源时，通过系统调用进入内核态，系统调用结束后，重新返回用户态。 ###创建进程 可通过fork函数创建子进程，理论上，父子进程拥有各自独","title":"Linux进程——进程创建和同步控制"},{"content":" 进程是程序的一次运行过程，除了进程虚拟地址空间和文件描述符等，进程控制块中还存放了进程运行的环境信息，包括用户、用户组、父进程、进程组和会话等。\n###用户和用户组\n//获得当前进程实际用户ID pid_t getuid(void); //获得当前进程有效用户ID pid_t geteuid(void); //获得当前进程实际用户组ID pid_t getgid(void); //获得当前进程有效用户组ID pid_t getegid(void); ###进程和进程组 获得父子进程ID\n//获得当前进程ID pid_t getpid(void); //获得父进程ID pid_t getppid(void); 进程组\n有时，为了完成某个工作，需多个进程参与协作，为便于管理，可以将多个进程定义为一个进程组。一个进程组包含一个以上的进程，领头进程的进程ID等于进程组ID，进程组中不包含进程时，进程组自动消失。\n会话\n会话用于标识用户登录的每一个终端，每个登录终端都有一个会话ID与其对应； 会话包括控制进程（与终端建立连接的领头进程）、一个前台进程组和任意后台进程组。一个会话只能有一个控制终端，通常是登录到其上的终端设备或伪终端设备，产生在控制终端上的输入和信号将发送给会话的前台进程组中的所有进程。\n如果调用setsid函数的进程不是进程组中的领头进程，则可建立新的会话，（可在子进程中建立新的会话），该进程成为领头会话，同时产生一个新的进程组，且该进程为新进程组的领头进程，但不拥有终端。\n/* 获得进程所属会话ID 成功返回会话ID，错误返回-1 */ pid_t getsid(pid_t pid); /* 创建一个新的会话，使进程组ID等于该会话ID 成功返回新的进程组ID，否则-1 */ pid_t setsid(void); 案例：在子进程中创建新的领头会话\n#include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(void) { int p,pid; printf(\u0026#34;now session id %d\\n\\n\u0026#34;,getsid(getpid())); p = fork(); if(p) //父进程退出 exit(0); pid = setsid(); printf(\u0026#34;new session id %d\\n\u0026#34;,pid); return pid; } ###守护进程\n守护进程是一种运行在后台，且不受任何终端影响的进程，因此，需要关闭标准输入、标准输出、标准错误输出的文件描述符.通常守护进程以服务进程的形式存在，例如web服务器。\n同时要使守护进程脱离用户环境，所以要将工作目录修改为系统工作目录。 创建守护进程步骤：\n创建子进程后结束父进程 在子进程中建立新的领头会话 修改工作目录和权限掩码信息 关闭文件描述符0,1,2 案例：创建一个守护进程\n#include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; int daemon_init() { pid_t pid; char buf[80]; FILE * fout; if((pid = fork()) \u0026lt; 0) return -1; else if(pid != 0) exit(0); //结束父进程 setsid(); //创建领头会话 system(\u0026#34;cd /\u0026#34;); //改变工作目录 umask(0); //清除权限掩码 close(0); //关闭文件描述符 close(1); close(2); getcwd(buf,sizeof(buf)); fout = fopen(\u0026#34;/tmp/result.txt\u0026#34;,\u0026#34;w\u0026#34;); fprintf(fout,\u0026#34;work dirctory is %s\\n\u0026#34;,buf); fprintf(fout,\u0026#34;daemon pid is %d\\n\u0026#34;,getpid()); fprintf(fout,\u0026#34;daemon parent pid is %d\\n\u0026#34;,getppid()); fclose(fout); return 0; } int main() { FILE * fout; printf(\u0026#34;start init daemon ...\u0026#34;); daemon_init(); while(1) { fout = fopen(\u0026#34;/tmp/result.txt\u0026#34;,\u0026#34;a\u0026#34;); fputs(\u0026#34;i am still alive\\n\u0026#34;,fout); fflush(fout); sleep(1); } } ###加载可执行映像\n可执行映像是链接好的可执行的代码。\n通常，子进程创建时，继承了父进程的资源，父子进程可以并发运行，它们由同一代码流程控制，具有相似行为。有时，希望子进程拥有独立代码流程，可以通过加载可执行二进制映像文件来实现。内核通过exec系统调用在进程中建立新的运行环境。\nELF格式\nLinux系统中，采用ELF(Excutable and Linkable Format)，ELF有3中基本格式\n可执行格式 目标文件(.o文件) 共享库（.so文件) 加载可执行文件\nELF的可执行文件的加载是通过系统调用exec完成的，当进程调用exec函数加载ELF可执行文件时，exec将以新加载程序的段替换当前进程的相应的正文、数据、堆和栈段；同时保留大部分的进程属性。例如进程ID、父进程ID、进程组ID、实际用户ID、会话ID、当前目录、文件描述符等。\n但当加载可执行文件的SETUID或SETGID位被设置，进程的有效用户ID和有效用户组ID被设置为该文件的属主ID和属主用户组ID。 exec相关函数原型：\n#include \u0026lt;unistd.h\u0026gt; int execl(const char *path,const char *arg,...) int execv(.........)......... int execle(........) int execve(.........) int execlp(.........) int execvp(.........) ","permalink":"https://blog.niuhemoon.win/posts/tech/linux-c-process-3/","summary":"进程是程序的一次运行过程，除了进程虚拟地址空间和文件描述符等，进程控制块中还存放了进程运行的环境信息，包括用户、用户组、父进程、进程组和会话等。 ###用户和用户组 //获得当前进程实际用户ID pid_t getuid(void); //获得当前进程有效用户ID pid_t geteuid(void); //获得当前进程实际用户组ID pid_t getgid(void); //获得当前进程有效","title":"Linux进程——进程环境与加载可执行映像"},{"content":" 可执行程序是存储在磁盘设备上由代码和数据按某种格式组织的静态实体，而进程是可被调度的代码的动态运行。在Linux系统中，在一个进程的生命周期里，都有各自的运行环境和所需的资源，这些信息储存在各自的进程控制块中。\n进程控制块主要结构如下:\n用户标识 进程和会话标识 虚拟地址管理 文件描述符表 信号 ###进程地址空间\n在32位地址总线的计算机上，每个进程拥有4GB的虚拟地址空间。\n可执行程序被加载至进程的用户虚拟地址空阿金，即将可执行程序中的代码段和数据段的内容复制到用户地址空间。为了执行程序，内核需在用户虚拟地址空间中建立一些辅助区域，例如堆区和栈区等，从而将用户虚拟地址空间划分为若干区域，分别为代码区、未初始化数据区、初始化数据区、环境变量和命令行参数区、堆区、栈区。不同区域中存储了不同的信息，有各自不同的属性。\n代码区\n包含指令序列和只读数据，没和在创建进程加载可执行二进制映像文件时，将这部分内容映射到进程的用户地址空间形成代码区。进程运行期间，代码区内容不会改变。\n因此，一个可执行映像的多个进程可共享代码区，只需保持一个复制。\n在可执行映像文件中，代码区的内容被保存在文本段中，文本段又称代码段。\n未初始化数据区\n在可执行二进制映像文件中，未初始化数据包括没有初始化的全局变量和静态局部变量，它们在映像文件中不占用储存空间，只保留其地址和大小信息。\n若映像文件中存在未初始化数据段，内核创建进程时，在进程的用户地址空间中为其分配一块区域，用于进程运行过程中对未初始化数据的存取，成为未初始化数据区。\n初始化数据区\n初始化数据区包括已初始化的全局变量和静态局部变量。在映像文件中，初始化数据被组织在数据段中，内核将初始化数据段映射至用户地址空间形成初始化数据区。该区内容运行过程中会发生变化，一个程序的多个进程实体拥有各自的数据区。\n堆heap\n堆位于数据区和栈之间，用于应用程序的动态内存管理。Linux将动态内存的管理通过glibc实现。Linux的进程控制块中记录了虚拟内存各区域的地址信息，它们在进程初始化时由系统设置，其中包含堆的起始地址和结束地址。\n在初始状态下，brk指针指向堆的顶部。堆区大小可以通过brk和sbrk函数调整。\n栈stack\n栈用来存放进程运行过程中的局部变量、函数返回地址、参数和进程上下文环境。\n环境变量和命令行\n环境变量继承自父进程，作用范围是进程本身及其子孙进程。命令行保存执行程序时的输入参数，它们都被保存在栈区域。\n自由空间\n堆栈之间的自由空间，内核可为进程创建新的区域用于加载共享库、映射共享内存和映射文件I/O等，可以通过mmap和munmap函数申请和释放。\n###环境变量/命令行参数\n每个进程的环境变量以字符串的形式存放在数组中，数组地址存放在全局变量environ中，可通过getenv和putenv对环境变量进行存取。\n命令行参数保存在用户地址空间的栈区域。\n案例：显示当前进程所有环境变量\n#include \u0026lt;stdio.h\u0026gt; int main(int argc,char *argv[]) { int i; char **ptr; extern char **environ; for (ptr = environ;*ptr != NULL;ptr++) printf(\u0026#34;%s\\n\u0026#34;,*ptr); return 0; } 案例:使用getenv和putenv存取环境变量\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(int argc,char *argv[],char *envp[]) { int i; extern char **environ; printf(\u0026#34;form argument envp\\n\u0026#34;); for(i=0;envp[i];i++) puts(envp[i]); putenv(\u0026#34;HONE=/\u0026#34;); printf(\u0026#34;\\nFrom global variable environ\\n\u0026#34;); for(i=0;environ[i];i++) puts(environ[i]); return 0; } 案例:显示所有命令行参数\n#include \u0026lt;stdio.h\u0026gt; int main(int argc,char *argv[]) { int i; for(i=0;i\u0026lt;argc;i++) printf(\u0026#34;argv[%d}:%s\\n\u0026#34;,i,argv[i]); return 0; } ###动态内存管理\n堆介于栈和全局数据区之间，这部分空间用于进程的动态内存分配，堆采用自下向上生长。相关API函数如下：\nvoid *malloc(size_t size); void free(void *ptr); /* 设置堆区域的大小 pend设置数据区域的边界 incr扩展堆区域的字节数 对brk,成功返回0，否则-1 对sbrk成功返回原来的brk,否则-1 */ int brk(void *pend); void *sbrk(int incr); 案例:使用brk和sbrk调整heap大小\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; extern int etext,edata,end; void foo(int); int main() { int ret; void *bv; printf(\u0026#34;text ends at %10p\\n\u0026#34;,\u0026amp;etext);\tprintf(\u0026#34;initailized data ends at %10p\\n\u0026#34;,\u0026amp;edata); printf(\u0026#34;uninitialized data ends at %10p\\n\u0026#34;,\u0026amp;end); bv = sbrk(0); //当前堆区边界地址 printf(\u0026#34;Current break value is %10p \\n\\n\u0026#34;,bv); ret = brk(bv+512); puts(\u0026#34;heap incresed 512bytes\u0026#34;); printf(\u0026#34;brk returned ....%d\\n\u0026#34;,ret); bv = sbrk(0); //当前堆区边界地址 printf(\u0026#34;Current break value is %10p \\n\\n\u0026#34;,bv); foo(64); foo(-1024); return 0; } void foo(int size) { void *bv; bv = sbrk(size); printf(\u0026#34;heap increased %dbytes\\n\u0026#34;,size); printf(\u0026#34;sbrk returned %10p\\n\u0026#34;,bv); bv = sbrk(0); //当前堆区边界地址 printf(\u0026#34;Current break value is %10p \\n\\n\u0026#34;,bv); } 注\n通过brk、sbrk、mmap系统调用会频繁的触发软中断，使程序陷入内核态，比较消耗资源。为了较少系统调用产生的损耗，glibc采用内存池的设计，增加一个代理层，每次内存分配，优先从内存池中寻找一个大小相近的内存块(chunk),若内存池中无法提供，再向内核申请。\n具体参考glibc内存管理\n","permalink":"https://blog.niuhemoon.win/posts/tech/linux-c-process-1/","summary":"可执行程序是存储在磁盘设备上由代码和数据按某种格式组织的静态实体，而进程是可被调度的代码的动态运行。在Linux系统中，在一个进程的生命周期里，都有各自的运行环境和所需的资源，这些信息储存在各自的进程控制块中。 进程控制块主要结构如下: 用户标识 进程和会话标识 虚拟地址管理 文件描述符表","title":"Linux进程——地址空间"},{"content":" Linux提供了应用编程接口，通过这些接口，进程可以向其他进程或进程组发送信号。root权限的进程可以向任何进程发送信号，非root权限的进程智能向属于同一个回话或同一个用户的进程发送信号。\n###发送信号\n常用的函数原型如下\n/* 向进程发送信号 pid\u0026gt;0 进程ID为pid的进程 pid=0 同一进程组的进程 pid\u0026lt;0 \u0026amp;\u0026amp; pid!=-1 进程组ID为-pid的所有进程 pid=-1 除发送给进程自身外，还发送给所有进程ID\u0026gt;1的进程 成功返回0，否则-1 */ int kill(pid_t pid,int signo); /*向进程本身发送信号，等价于kill(getpid(),sig),成功返回0，否则-1*/ int raise(int signo); /*向进程发送SIGABORT信号,默认情况下进程会退出*/ void abort(void); /* 向进程发送实时信号 pid 接收信号的进程ID，只能向一个进程发送信号 sig 指定即将发送的信号 val指定信号传递的参数 成功返回0，否则-1 */ int sigqueue(pid_t pid,int sig,const union sigval val); union sigval { int sival_int;\t//传送一个整形数 void *sival_ptr;\t//传送任何数据结构的指针 }; typedef struct { int si_signo; int si_code; union sigval si_value; int si_errno; pid_t si_pid; uid_t si_uid; void *si_addr; int si_status; int si_band; } siginfo_t; 案例:使用sigqueue发送带参数的信号\n#include \u0026lt;signal.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; void SigHandler(int signo,siginfo_t *info,void *context) { printf(\u0026#34;%s\\n\u0026#34;,(char *)info-\u0026gt;si_value.sival_ptr); } int main() { struct sigaction sigAct; sigval_t val; char *pMsg = \u0026#34;i still believe\u0026#34;; sigAct.sa_flags = SA_SIGINFO; sigAct.sa_sigaction=SigHandler; if(sigaction(SIGUSR1,\u0026amp;sigAct,NULL)==-1) { printf(\u0026#34;fail set sig_handler\u0026#34;); return 1; } val.sival_ptr=pMsg; if(sigqueue(getpid(),SIGUSR1,val)==-1) { printf(\u0026#34;fail send sigqueue\u0026#34;); return 2; } sleep(3); } ###sleep睡眠延时\n可以使用sleep函数将程序延迟一段时间后继续执行，其实现机制是：\n调用alarm函数设置延迟时间 调用pause函数挂起进程，等待系统发送SIGALARM信号，当SIGALARM信号到达进程时，进程被唤醒。 /* 设置时间闹钟 seconds表示闹钟间隔时间，原有闹钟无效 若调用alarm函数前，进程已经设置了闹钟，则返回上一个闹钟剩余时间，否则返回0 */ unsigned int alarm(unsigned int seconds); //等待信号,进程收到信号后，执行信号处理函数，pause函数返回，原进程继续执行 void pause(); 案例：实现sleep函数\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; void alarmhandler(int signum) { printf(\u0026#34;Alarm received from kernel\\n\u0026#34;); } int mysleep(unsigned int time) { printf(\u0026#34;about to sleep for %d seconds\\n\u0026#34;,time); signal(SIGALRM,alarmhandler); alarm(time); pause(); printf(\u0026#34;continue from alarm \\n\u0026#34;); return 0; } int main(int argc,char *argv[]) { printf(\u0026#34;start run the program.\\n\u0026#34;); unsigned int time = atoi(argv[1]); mysleep(time); printf(\u0026#34;i am awake,haha\\n\u0026#34;); return 0; } 间隔计时器 alarm函数计时单位是秒，当延迟时间到来，只能触发一次。不能满足需要高精度时间、有周期性定时需求的需求。为此，引入间隔计时器，其原理是：\n当等待时间来到，内核向处于等待状态的进程发送信号，同时，再次设置时间间隔。间隔计时器属于面向进程的计时器。\n进程运行时间\n通常，LInux系统最小时钟间隔是10ms，意味着每秒产生100个时钟中断。进程以时间片的形式分享CPU，进程的执行有两种模式：用户态和内核态。当进程执行的是用户地址空间的代码，称进程运行在用户态；当进程进入系统调用或硬件中断，称进程运行在内核态。此外，进程还有休眠态，即将CPU交给其他进程。所以进程并非时刻都在运行，而是在用户态、内核态、休眠态之间切换。\n由此内核提供三种计时器：\n真实时间\t用户态+内核态+休眠态时间 虚拟时间\t用户态时间 实用时间\t用户态+内核态时间 /* 获得当前进程中指定类型间隔计时器的值 which 计时器类型 ITIMER_REAL\t真实时间，经过指定时间，内核发送SIGALRM限号 ITIMER_VIRTUAL\t用户态时间，经过指定时间，内核发送SIGVTALRM信号 ITIMER_PROF\t实用时间，经过指定时间，内核发送SIGPRT信号 value 存储获得的间隔计时器的值 */ int getitimer(int which,struct itmerval *value); struct itimerval { struct timeval it_interval;\t//下一个值 struct timeval it_value\t//当前值 }; struct timeval { long tv_sec;\t//秒 long tv_usec;\t//微秒 }; /* 设置间隔计时器 which 指定定时器类型 newval指向被设置值 oldval指向被替换设置值 成功返回0，否则-1 若oldval不为NULL，之前计时器的值将被复制到oldval */ int setitimer(int which,const struct itimerval *newval,struct itimerval *oldval); ","permalink":"https://blog.niuhemoon.win/posts/tech/linux-c-signal-2/","summary":"Linux提供了应用编程接口，通过这些接口，进程可以向其他进程或进程组发送信号。root权限的进程可以向任何进程发送信号，非root权限的进程智能向属于同一个回话或同一个用户的进程发送信号。 ###发送信号 常用的函数原型如下 /* 向进程发送信号 pid\u0026gt;0 进程ID为pid的进程 pid=0 同一进程组的进程","title":"Linux信号处理——发送信号"},{"content":"文件系统概述 Linux内核的各种真实文件系统、块设备和字符设备统一在虚拟文件系统的框架中，虚拟文件系统为应用提供了一组抽象的文件输入输出接口。\n虚拟文件系统是对各种真实文件系统的抽象，在虚拟文件系统中定义了抽象的超级块、i节点和目录，它为真实文件系统提供了一种统一的框架接口。真实文件系统通过这些接口与虚拟文件系统相连接，真实文件系统是这些抽象接口的具体实现。\n虚拟文件系统存在于内存中，在系统启动时产生，随着系统关闭而消失。\n文件操作常用的头文件 C POSIX library是C语言的POSIX系统下的标准库。包含了一些在C语言标准库之外的函数。\n#include \u0026lt;unistd.h\u0026gt; //多种必要的POSIX函数与常量 #include \u0026lt;fcntl.h\u0026gt; //文件打开、创建、加锁等操作 #include \u0026lt;sys/stat.h\u0026gt;//文件信息(stat (Unix)等) #include \u0026lt;sys/types.h\u0026gt;//不同的数据类型 #include \u0026lt;dirent.h\u0026gt; //打开与列出目录内容 //此外，还有C标注库中的 #include \u0026lt;stdio.h\u0026gt;\t//标准缓存输入输出 文件基本输入输出 文件输入输出涉及到以下函数：\nopen、creat 在\u0026lt;fcntl.h\u0026gt;中 read、write、lseek、close 在\u0026lt;unistd.h\u0026gt;中 案例:复制文件\n//cp.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #define PMODE 0644\t//权限定义为rw-r--r-- #define BUFSIZE 200 int main(int argc,char *argv[]) { int fdin,fdout,n; char buf[BUFSIZ]; if(argc !=3) { fprintf(stderr,\u0026#34;Usage:%s filein fileout\\n\u0026#34;,argv[0]); return 1; } if((fdin = open(argv[1],O_RDONLY)) == -1) { perror(argv[1]); return 2; } if((fdout = open(argv[2],O_WRONLY|O_CREAT|O_TRUNC,PMODE)) == -1) { perror(argv[2]); return 3; } while((n = read(fdin,buf,BUFSIZE)) \u0026gt; 0) write(fdout,buf,n); close(fdin); close(fdout); return 0; } ###文件属性操作 文件的属性信息存放在文件对应的i节点中，对于不同类型的物理文件系统，文件属性的组织形式不尽相同，为了获得统一的文件属性格式，Linux定义了struct stat这个数据结构，类型定义如下：\nstruct stat { dev_t st_dev; /* 文件设备编号*/ ino_t st_ino; /* i节点号 */ mode_t st_mode; /* 文件类型和存储权限 */ nlink_t st_nlink; /* 硬链接 */ uid_t st_uid; /* 用户ID */ gid_t st_gid; /* 用户组ID */ dev_t st_rdev; /* Device ID (if special file)*/ off_t st_size; /* 文件字节数bytes */ blksize_t st_blksize; /* 块大小 */ blkcnt_t st_blocks; /* 以512bytes为单位的块数 */ struct timespec st_atim; /* 文件最后一次访问时间 */ struct timespec st_mtim; /* 文件最后一次修改时间 */ struct timespec st_ctim; /* 文件属性最后一次改变时间 */ }; 以之前的cp.c为例:\n可以看到cp.c文件实际大小640bytes，在磁盘上占用了一个4096bytes的块，也就是8个512bytes的块。`\n文件属性操作常用函数：\nstat 获取文件属性信息 chmod 设置文件权限 chown 设置文件属主 utime 获取时间 案例：改变文件读写权限\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; int main() { mode_t fdmode = (S_IRUSR|S_IWUSR|S_IRGRP|S_IROTH); if(chmod(\u0026#34;cp.c\u0026#34;,fdmode) == -1) { printf(\u0026#34;error\\n\u0026#34;); return 1; } return 0; } 编译运行，结果如下，可见文件权限已经被修改。\nniuhe@niuhe-ubuntu:~/Linux$ gcc -o chmod chmod.c niuhe@niuhe-ubuntu:~/Linux$ ls chmod chmod.c cp cp.c niuhe@niuhe-ubuntu:~/Linux$ ll cp.c -rw-rw-r-- 1 niuhe niuhe 640 10月 6 16:55 cp.c niuhe@niuhe-ubuntu:~/Linux$ ./chmod niuhe@niuhe-ubuntu:~/Linux$ ll cp.c -rw-r--r-- 1 niuhe niuhe 640 10月 6 16:55 cp.c ###目录操作 目录是一种特殊的文件，其内容由若干目录项组成，一个目录项包括文件名和i节点号。为了便于管理，每个目录中都包含当前目录\u0026quot;.\u0026ldquo;和父目录\u0026rdquo;..\u0026quot;,当前目录项指向当前目录的i节点编号，父目录项记录了父目录对应的i节点编号。 常用库函数及头文件如下：\n#include \u0026lt;sys/stat.h\u0026gt; //在某目录中创建一个目录项，分配一个i节点和目录项相链接 //分配一个逻辑块用来存放目录内容，并在其中建立当前目录和父目录两个目录项 int mkdir(const char *pathname,mode_t mode); #include \u0026lt;unistd.h\u0026gt; //删除空目录 int rmdir(const char *pathname); //改变工作目录；在每个进程的进程控制块中保存着当前工作目录的i节点 //初始工作目录继承自父进程，进程运行过程可以改变工作目录 int chdir(const char *pathname); //获得调用者进程的当前工作目录，buf存放路径，size路径包含字节数 char *getcwd(char *buf, size_t size); #include \u0026lt;dirent.h\u0026gt; //打开目录,成功返回目录流（字符串） DIR *opendir(const char *pahtname); //读目录，成功返回下一个目录项 struct dirent *readdir(DIR *dp); //关闭目录 int closedir(DIR *dp); 目录是一种特殊的文件，存放着很多目录项，每一个目录项是一个结构体。\nstruct dirent { long d_ino;\t//i节点号 char d_name[NAME_MAX+1];\t//文件名 off_t d_off;\t//在目录文件中偏移量 unsigned short d_reclen;\t//文件名长度 } 案例：改变当前进程工作目录\n#include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; int main(void) { if(chdir(\u0026#34;/tmp\u0026#34;) \u0026lt; 0) printf(\u0026#34;chdir failed\u0026#34;); printf(\u0026#34;chdir to /tmp succeeded\\n\u0026#34;); return 0; } 案例：浏览目录中所有文件名\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;dirent.h\u0026gt; int main(int argc,char *argv[]) { DIR *dirp; struct dirent *direntp; if((dirp = opendir(argv[1])) == NULL) { printf(\u0026#34;cannot open the %s directory\u0026#34;,argv[1]); return 1; } while((direntp = readdir(dirp)) != NULL) printf(\u0026#34;%s\\n\u0026#34;,direntp-\u0026gt;d_name); closedir(dirp); return 0; } ###C标准I/O库\n运用read、write等系统底层函数进行输入输出时，需要在用户态和内核态之间来回切换。若每次读取或写入数据较少，将导致频繁的I/O操作，降低了程序运行效率。 标准I/O库对底层I/O系统调用进行了封装，提供了带格式转换的I/O操作，并在用户空间增加了缓冲管理，可减少程序和输出设备之间I/O次数。函数原型定义在\u0026lt;stdio.h\u0026gt;中。 细节略\nI/O重定向 文件描述符 Linux系统中，进程拥有各自打开文件的描述符。文件描述符按生成的顺序存放在文件描述符表中，Linux内核将文件描述符表用一维数组表述，每个打开的文件占用一个单元，用来存放操作文件的必要信息，如读写操作当前位置、文件打开方式、文件操作集等。 进程在打开一个文件时，返回的是文件描述符所在数组的下标，称为文件描述符。 通常，创建子进程时，子进程从父进程继承文件描述符表，前3个描述符0,1,2分别对应标准输入、标准输出、标准错误输出，与进程的控制终端设备对应。通常已经被打开，进行读写操作时无需重新打开。 一个文件可以同时被多个进程打开，它在不同进程中对应的文件描述符以及操作状态也未必相同。\n####I/O重定向\n程序根据打开文件的描述符对文件进行读写操作，真正完成读写操作的是进程描述符表相应位置中的内容。以输出重定向为例，若将进程描述符表中1号单元的内容替换为打开的文件test，则进程在向标准输出文件输出信息时，原本数据应显示在终端显示器上，但现在这些数据将被输出至文件test。 实现I/O重定向可以通过:\nopen close open方法 系统函数调用：dupdup2 #####open close open方法\nLinux在为进程新打开文件分配描述符时，从下表0开始扫描进程文件描述符表，将打开的文件信息放在找到的第一个空闲单元，并将该下表作为打开文件的描述符。 以标准输入0为例，将标准输入关闭，使得文件描述符表第0号单元成为空闲单元，此时，进程新打开另一个文件，内核将文件描述符表0号单元分配给新打开的文件，并返回描述符0，也就实现了输入重定向。\n#####dup和dup2函数\n使用dup和dup2函数，只是复制文件描述符，使两个文件描述符指向同一个file结构体，并且file结构体引用计数是2。此时，打开文件的状态保存在同一个file结构体中。而使用open函数两次打开一个文件会存在两份file结构体，分别有各自的状态。\n#include \u0026lt;unistd.h\u0026gt; //从进程文件描述符表中寻找一个可用的最小描述符,返回此描述符 //并复制oldfd对应的File结构指针到新的最小描述符 int dup(int oldfd); //oldfd需要复制的文件描述符，newfd是复制后oldfd在文件描述符表中新的序号。 //成功返回一个新描述符，否则返回-1 //若newfd已经打开，则先关闭newfd,然后复制oldfd到newfd,使newfd也指向oldfd,此时oldfd和newfd两个描述符共享同一个文件。 int dump2(int oldfd, int newfd); 案例:输出重定向\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; int main() { int fileID; fileID = creat(\u0026#34;ls.tst\u0026#34;,0640); if(fileID \u0026lt; 0) { fprintf(stderr,\u0026#34;error creating ls.tst\\n\u0026#34;); return 1; } dup2(fileID,1); close(fileID); execl(\u0026#34;/bin/ls\u0026#34;,\u0026#34;ls\u0026#34;,NULL); return 0; } 参考 库函数列表 C POSIX LIB ","permalink":"https://blog.niuhemoon.win/posts/tech/linux-c-io/","summary":"文件系统概述 Linux内核的各种真实文件系统、块设备和字符设备统一在虚拟文件系统的框架中，虚拟文件系统为应用提供了一组抽象的文件输入输出接口。 虚拟文件系统是对各种真实文件系统的抽象，在虚拟文件系统中定义了抽象的超级块、i节点和目录，它为真实文件系统提供了一种统一的框架接口。真实文","title":"Linux下glic库操作文件和目录"},{"content":" 信号是内核和进程之间通信的一种方式，信号是由内核产生，并发送给一个或一组进程的短消息，用不同特定的数字表示不同的信号，信号的作用是表示某种事件的发生。\n信号简介 分类\n非实时不可靠信号，值为1-31 实时的可靠信号，值为32-63 信号由内核生成，信号生成和事件的发生密切相关，可将事件发生源分为以下三类：\n信号事件发生源：\n用户，如键入CTRL+C，终端驱动程序将通知内核产生信号发送到相应的进程 内核，内核执行过程中，遇到非法指令和浮点数溢出等情况 进程，一个进程调用kill函数向另一个进程发送信号，进行进程间通信 通常，LInux为每个信号定义了缺省的处理方式，但是用户可根据需要，对信号的处理方式进行重新定义。\n信号的缺省处理方式包括\nA 结束进程 B 忽略信号 C 结束进程并写入内核文件 D 停止进程 E 信号不能被捕获 F 信号不能被忽略 G 非POSIX信号 ###自定义信号处理函数\n必须重新建立信号值和处理方式之间的对应关系，才能重新定义信号的处理方式。LInux提供signal和sigaction函数来实现信号的设置。signal和sigaction的区别在于signal不支持项信号处理函数传递数据。\n注：SIGKILL和SIGSTOP不能被重定义或忽略。\nsignal函数原型:\n// __sig为需设置的信号，__handler为新信号处理函数；失败返回SIG_ERR，否则成功。 //__handler为SIG_IGN忽略信号，SIG_DEL默认信号处理 extern __sighandler_t signal (int __sig, __sighandler_t __handler) __THROW; 案例：使用signal重定义SIGINT处理函数\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int main() { void f(int); int i; signal(SIGINT,f); for(i=0;i\u0026lt;5;i++) { printf(\u0026#34;hello\\n\u0026#34;); sleep(1); } return 0; } void f(int signum) { printf(\u0026#34;hello Linux\\n\u0026#34;); } sigaction函数原型\n/* signo需要处理的信号 act指向描述信号操作的结构 oact指向被替换操作的结构 成功返回0，否则返回-1 */ int sigaction(int signo,const struct sigaction *act,struct sigaction *oact); /* sa_mask指定在信号处理过程中，何种信号被阻塞。缺省情况是当前信号被阻塞，以免信号处理函数被递归调用。 */ struct sigaction { void(*sa_handler)(int);\t//信号处理函数 void(*sa_sigaction)(int,siginfo_t*,void *);\t//带参数的信号处理函数 sigset_t sa_mask;\t//信号掩码 int sa_flags;\t//设定信号处理相关行为 } 案例：sigaction定义信号SIGINT处理函数，并屏蔽其他信号\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int num=0; void int_handle(int signum) { printf(\u0026#34;SIGINT:%d]n\u0026#34;,signum); printf(\u0026#34;int_handle called %d times\\n\u0026#34;,++num); } int main(void) { static struct sigaction act; void int_handle(int); act.sa_handler = int_handle; sigfillset(\u0026amp;(act.sa_mask)); sigaction(SIGINT,\u0026amp;act,NULL); while(1) { printf(\u0026#34;i am sleepy..\\n\u0026#34;); sleep(1); if(num \u0026gt;=3) { return 0; } } } ###信号集、信号屏蔽与阻塞\n信号屏蔽就是临时阻塞信号被发送到某个进程，它包含一个被阻塞的信号集。当进程屏蔽某个信号时，内核将不发送该信号至屏蔽它的进程，直至该信号的屏蔽被解除。 信号集用于描述所有信号的集合。对于sigaction中的sa_mask字段，每一位对应一个信号，若某一位被设置为1，表示该位对应信号被屏蔽。\n信号集定义及其操作函数\ntypedef struct { unsigned long sig[2]; }sigset_t int sigemptyset(sigset_t *set);\t//清空信号集中所有信号 int sigfillset(sigset_t *set);\t//在set信号集中加入linux支持的所有信号 int sigaddset(sigset_t *set,int signum);\t//向信号集中加入signum信号 int sigdelset(sigset_t *set,int signum);\t//从信号集中删除signum信号 int sigismember(const sigset_t *set, int signum)\t//判断signum信号是否在信号集set中 每个进程定义一个信号掩码，该掩码对应一个信号集，该信号集中的所有信号在发送至进程后都将被阻塞。通过更改进程的信号掩码来阻塞或解除阻塞所选择的信号。以此来保护不希望由信号中断的临界代码。\n信号阻塞函数sigprocmask\n/* how 如何修改信号掩码 SIG_BLOCK 添加信号到进程屏蔽 SIG_UNBLOCK将信号从进程屏蔽中删除 SIG_SETMASK将set的值设定为新的信号掩码 set 指向设置信号列表 oldset指向之前的信号掩码列表 */ int sigprocmask(int how,const sigset_t *set,sigset_t *oldset); 案例:阻塞SIGINT信号3秒后恢复\n#include \u0026lt;signal.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int main(void) { sigset_t set; int count = 3; sigemptyset(\u0026amp;set); sigaddset(\u0026amp;set,SIGINT); sigprocmask(SIG_BLOCK,\u0026amp;set,NULL); while(count) { printf(\u0026#34;don\u0026#39;t disturb me (%d)\\n\u0026#34;,count--); sleep(1); } sigprocmask(SIG_UNBLOCK,\u0026amp;set,NULL); printf(\u0026#34;you did not disturb me!!\\n\u0026#34;); return 0; } ","permalink":"https://blog.niuhemoon.win/posts/tech/linux-c-signal-1/","summary":"信号是内核和进程之间通信的一种方式，信号是由内核产生，并发送给一个或一组进程的短消息，用不同特定的数字表示不同的信号，信号的作用是表示某种事件的发生。 信号简介 分类 非实时不可靠信号，值为1-31 实时的可靠信号，值为32-63 信号由内核生成，信号生成和事件的发生密切相关，可将事件发生","title":"Linux信号处理——自定义信号处理函数"},{"content":"函数库介绍 函数库分为：\n静态库 共享库（动态加载库） 应用程序在链接静态库时候，将使用的静态库对象嵌入至可执行映像文件中；而在链接共享库时，仅在可执行映像文件中保留加载目标对象所需的信息，在调用时，才真正将目标对象加载至内存。 静态库特点：\n运行时无需外部库的支持，可执行文件中已经嵌入了所需的静态库目标对象，所以可执行文件可以脱离静态库独立运行。 较高的运行速度，运行时不需要加载其他目标对象 可执行文件体积较大 不容易维护，每次修改静态库，必须重新链接 共享库特点：\n可执行文件体积较小 容易维护，共享库中对象发生变化，应用程序不需要重新编译 可执行文件中不包含共享库中调用的目标对象，因此不能离开动态库独立运行 运行速度比较慢，因为程序启动时需要加载共享库 静态库 静态库创建 静态库命名规则是lib开头，.a作为文件名后缀。可以使用ar命令作为静态库管理工具。ar可以将多个.o文件打包在一起，构成一个静态库文件。\n案例:\n先准备两个C源文件如下：\n//exam1.c int add(int x, int y) { return x + y; } //exam2.c int func(int count) { int sum=0; int j; for(j=0; j\u0026lt;=count; j++) { sum=sum+j; } return sum; } 编译两个源文件,后使用ar创建静态库：\ngcc -c -Wall exam1.c gcc -c -Wall exam2.c ar -crq libdemo.a exam1.o exam2.o 这样，我们就创建了一个简单的静态库。\n####静态库使用 定义静态库应用接口\n//exam.h extern int add(int x,int y); extern int func(int count); 使用静态库\n//testexam.c #include \u0026lt;stdio.h\u0026gt; #include \u0026#34;exam.h\u0026#34; int main(void) { int val; int x,y; x=12; y=18; val=add(x,y); printf(\u0026#34;the mult of x adn y is %d\\n\u0026#34;,val); val=func(100); printf(\u0026#34;the sum is %d \\n\u0026#34;,val); return 0; } 编译运行\ngcc -o testexam testexam.c -L ./ -ldemo 解释： -L指定了静态库所在的目录， ./就是当前目录\n-ldemo指定了静态库的名称libdemo.a\n共享库 若在同一目录下存在同名的共享库和静态库，gcc会优先使用共享库，除非指定了-static.\n####创建共享库\ngcc -fPIC -c exam1.c gcc -fPIC -c exam2.c gcc -shared -o libdemo.so exam1.o exam2.o 以上三句指令将exam1.c和exam2.c编译成了libdemo.so共享库文件。 -fPIC告诉gcc创建地址独立的目标文件 -shared告诉gcc创建一个共享库文件\n共享库使用 链接着共享库的应用启动时，一个程序装载器将自动运行，该程序装载器为/lib64/ld-linux.so.X,,它的作用是查找并装载应用程序所依赖的所有共享库的中的目标对象。\n将共享库libdemo.so放在/usr/local/lib/目录下 链接共享库\ngcc -o testexam testexam.c /usr/local/lib/libdemo.so 查看程序使用共享库情况\nldd testexam ###动态链接库\n动态链接库是使用共享库的一种方式，在运行的任何时刻可以动态加载共享库。和一般共享库不同，通常应用程序启动时，不立即加载共享库，而是在需要时，动态加载共享库。 以动态链接的方式使用共享库分为三个步骤：\n打开共享库文件 接着取得要调用函数的地址，根据地址使用函数指针进行调用 关闭共享库 Linux环境提供了一组API函数可以动态链接共享库，头文件定义在/usr/include/dlfcn.h中。\n案例\n//exam.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;dlfcn.h\u0026gt; #include \u0026#34;exam.h\u0026#34; #include \u0026lt;stdlib.h\u0026gt; int main(void) { int val; int (*add_d)(int,int); int (*func_d)(int); void *handle; char *err; int x,y; x = 12; y = 18; handle = dlopen(\u0026#34;/usr/local/lib/libdemo.so\u0026#34;,RTLD_LAZY); if (handle == (void *)0) { fputs(dlerror(),stderr); exit(-1); } add_d = dlsym(handle,\u0026#34;add\u0026#34;); err = dlerror(); if (err != NULL) { fputs(err,stderr); exit(-1); } func_d = dlsym(handle,\u0026#34;func\u0026#34;); err = dlerror(); if(err != NULL) { fputs(err,stderr); exit(-1); } val = (*add_d)(x,y); printf(\u0026#34;the mult of x and y is %d\\n\u0026#34;,val); val = (*func_d)(100); printf(\u0026#34;the sum of 1 to 100 is %d\\n\u0026#34;,val); dlclose(handle); return 0; } 编译链接\ngcc -rdynamic exam.c -o exam -ldl 执行\nniuhe@niuhe-ubuntu:/tmp/exp$ ./exam the mult of x and y is 30 the sum of 1 to 100 is 5050 ###GUN C函数库——glibc\nglibc是GNU开发的一套标准C语言标准函数库的实现。通常linux发行版都默认安装好了，查看glic的版本号ldd --version.\n","permalink":"https://blog.niuhemoon.win/posts/tech/linux-c-lib/","summary":"函数库介绍 函数库分为： 静态库 共享库（动态加载库） 应用程序在链接静态库时候，将使用的静态库对象嵌入至可执行映像文件中；而在链接共享库时，仅在可执行映像文件中保留加载目标对象所需的信息，在调用时，才真正将目标对象加载至内存。 静态库特点： 运行时无需外部库的支持，可执行文件中已经嵌入了所","title":"Linux下创建和使用C语言函数库"},{"content":" Shell 是一种命令行解释器，目前 Linux 下最常用的是 bash 解释器。Shell 不仅可以解释用户输入的命令，还可以解释执行基于命令的 Shell 脚本语言。 Shell 脚本是由命令、Shell 变量和控制语句灯语法元素构成的文本文件。默认情况下，Shell 对脚本中的内容逐行分析，并依次在不同的进程中解释执行。通常 Shell 脚本结构如下：\n#!/bin/bash var1 = \u0026#34;hello,shell.\u0026#34; echo $var1 ###Shell 变量\nShell 变量分为四类：\n用户自定义变量 环境变量 位置变量 预定义变量 变量的几种操作:\n操作整数赋值：变量名=变量值 引用：$变量名 清除：unset 变量名 查看：set 输出为环境变量：export 用户自定义变量 位置变量:\n-位置变量和传递参数的位置有关\n$0:脚本程序名称 $1，$2\u0026hellip;..:传递给脚本的参数，$1 代表第一个参数 预定义变量:\n预定义变量 含义 $* 传递到脚本的所有参数内容 $? 命令执行后的返回状态，0 成功，其他值表示错误 $$ 当前进程的进程号 $! 后台运行的最后一个进程号 $# 传递到脚本的参数的数量 命令替换 命令替换可以使命令的输出结果赋值给变量，注意语法形式 2 中是反引号`,不是单引号'\n语法形式：\nvar = $(command) var = `command` 案例：\necho \u0026#34;today is\u0026#34; `date` 输入输出 read 命令 功能：从键盘读取输入，并赋值给变量\n语法： read [选项] 变量名列表\n选项列表：\n选项 含义 -p prompt 设置提示信息 -n num 当 read 读 n 个字符后返回 -s 键盘输入不回显 -t timeout 设置超时时间 -r 取消转义字符的转义作用 -d delim 定义新的换行符 案例：\nread -s -n 1 -p \u0026#34;Yes(Y) or not(N)?\u0026#34; answer echo $answer echo 命令 功能：显示字符串或变量的值\n语法：echo [选项] 字符串\n选项列表：\n选项 -含义 -n 不再最后自动换行 -e 启用反斜线控制字符的转换 -E 不处理转义字符，缺省选项 支持的转义符列表：\\t\\n\\r\\\\b\\a等\n引号 反引号:命令替换\n单引号:单引号中所有字符保留原有字符含义，不能包含单引号。不支持元字符、变量替换、命令替换。\n双引号:不支持元字符，支持变量替换、命令替换。\n条件表达式 条件表达式用力啊判断条件是否满足\n#!/bin/bash hour=$(date +\u0026#34;%H\u0026#34;) case $hour in 0[1-9] | 1[01]) echo \u0026#34;Good morning!!\u0026#34; ;; 1[2-7]) echo \u0026#34;Good afternoon\u0026#34; ;; *) echo \u0026#34;Good evening\u0026#34; ;; esac 测试条件表达式真假方法如下，真 0 假 1：\ntest 条件表达式\n[条件表达式]\n条件表达式中常用五类操作符：\n文件状态操作符 字符串操作符 数字操作符 逻辑操作符 文件状态操作符（略）:\n-x filename 文件可执行返回真 字符串操作符:\n操作符 含义 string string 非空为真 -n string string 长度大于 0 为真 -z sring string 长度为 0 为真 string1=string2 相等为真 string1 != string2 不等为真 数字操作符:\n操作符 含义 n1 -eq n2 n1 和 n2 相等返回 0，否则 1 n1 -ne n2 不等为真 n1 -lt n2 n1 \u0026lt; n2 为真 n1 -gt n2 n1 \u0026gt; n2 为真 n1 -le n2 n1 \u0026lt;= n2 为真 n1 -ge n2 n1 \u0026gt;= n2 为真 逻辑操作符:\n操作符 含义 e1 -a e2 e1 和 e2 两个表达式同时为真返回 0，否则 1 e1 -o e2 e1,e2 有一个为真返回 0 !e1 e1 不为真时返回 0 命令分隔符 命令分隔符可以在一行中运行多个命令\n命令分隔符 含义 cmd1;cmd2 以独立进程依次运行 cmd1 和 cmd2 (cmd1;cmd2) 在同一进程中依次运行 cmd1 和 cmd2 cmd1 \u0026amp; cmd2 cmd1 和 cmd2 同时运行，分属不同进程组 cmd1 \u0026amp;\u0026amp; cmd2 当 cmd1 为真时，才执行 cmd2 cmd1 || cmd2 当 cmd1 为假时，才执行 cmd2 cmd1 | cmd2 管道符号，cmd1 的输出作为 cmd2 的输入 cmd1 \u0026amp; cmd1 在后台运行 判断语句 案例 1：比较两个数字大小\n#!/bin/bash echo \u0026#34;Enter the first interger:\u0026#34; read first echo \u0026#34;Enter the second interger:\u0026#34; read second if (( first \u0026gt; second )); then echo \u0026#34;$first is greater than $second\u0026#34; elif (( first \u0026lt; second ));then echo \u0026#34;$first is less than $second\u0026#34; else echo \u0026#34;$first is equal to $second\u0026#34; echo \u0026#34;Done\u0026#34; fi 案例 2：获取系统时间，判断上午、下午、晚上\n#!/bin/bash hour=$(date +\u0026#34;%H\u0026#34;) case $hour in 0[1-9] | 1[01]) echo \u0026#34;Good morning!!\u0026#34; ;; 1[2-7]) echo \u0026#34;Good afternoon\u0026#34; ;; *) echo \u0026#34;Good evening\u0026#34; ;; esac 循环语句 案例 1：for 循环打印所有命令行参数\n#!/bin/bash #you can write this in short:for arg for arg in $* do echo $arg done 案例 2：while 计算 1-99 的和\n#!/bin/bash i=1 sum=0 while [ $i -lt 100 ] do sum=`expr $sum + $i` i=`expr $i + 1` done echo The sum is $sum 案例 3：显示 1-100 之间的整数\n#!/bin/bash i=1 until [ $i -gt 100 ] do echo $i i=`expr $i + 1` done break [n] 跳出 n 重循环，默认为 1\ncontinue [n]\nexit [n]\n函数 语法：\n函数名() { 命令列表 return } `\n调用方式:\n函数名 参数列表\n注意：\n调用前，必须先定义 使用 shell 位置变量接收参数传递，例如$0$1 返回值取自函数中 return 语句或函数中最后一条命令的返回状态，通过$?获得 使用 local 声明的局部变量，作用仅限于函数本身 案例：\n#!/bin/bash #name:getsum.sh get_sum() { i=$1 sum=0 while [ $i -lt $2 ] do sum=`expr $sum + $i` i=`expr $i + 1` done return $sum } get_sum $2 $3 result=$? echo $1 echo sum of $2 to $3 is $result 运行:\n./getsum.sh \u0026#34;test\u0026#34; 5 7 注意事项 变量赋值的=两侧不能有空格 条件表达式 和表达式间必须有空格 expr 算式表达式中每个运算符两侧必须有空格 ","permalink":"https://blog.niuhemoon.win/posts/tech/basic-shell/","summary":"Shell 是一种命令行解释器，目前 Linux 下最常用的是 bash 解释器。Shell 不仅可以解释用户输入的命令，还可以解释执行基于命令的 Shell 脚本语言。 Shell 脚本是由命令、Shell 变量和控制语句灯语法元素构成的文本文件。默认情况下，Shell 对脚本中的内容逐行分析，并依次在不同的进程中解释执行。通常 Shell 脚本结构","title":"Shell编程基础"},{"content":" 现在很多传感器都使用串口进行数据传送，我们再window上通常使用sscom33这类调试工具，在linux下通常使用带界面的cutecom或者命令行界面的minicom进行调试。 而使用Python写几行程API序进行自定义调试，就非常有用。并且可以快速的对传感器进行测试。本文介绍python的串口读写模块Pyserial\n安装 sudo pip install pyserial 使用 确定串口设备名 Linux下把串口设备抽象成了文件，通常放在/dev/目录下，先找出串口设备的名称。\n断开串口设备的连接，执行 ls /dev/ \u0026gt; /tmp/old.txt 将串口设备连接到计算机，执行 ls /dev/ \u0026gt; /tmp/new.txt 最后，比较old.txt和new.txt，new.txt中多出的设备名就是我们的串口设备\ndiff /tmp/old.txt /tmp/new.txt 例程 以下是我读取超声波测距传感器的例程，传感器返回串口数据,每一帧数据的帧头是0xFF,其后的2byte数据是距离值。\nimport serial import time with serial.Serial(\u0026#39;/dev/ttyUSB0\u0026#39;,9600,stopbits=serial.STOPBITS_ONE,bytesize=serial.EIGHTBITS) as ser: while 1: head = ser.read(1) if head == b\u0026#39;\\xFF\u0026#39;: distance = int.from_bytes(ser.read(2),byteorder=\u0026#39;big\u0026#39;,signed=False) print(str(distance/1000) + \u0026#39;m\u0026#39;) 常用方法 在创建串口对象后，即ser = serial.Serial('/dev/ttyUSB0')，可以操作串口读写。\nser.read(size) ser.readline(size) ser.write(str_data) ser.close() 具体使用参见官方文档API\n参考 API参考\n","permalink":"https://blog.niuhemoon.win/posts/tech/pyserial-tutorial/","summary":"现在很多传感器都使用串口进行数据传送，我们再window上通常使用sscom33这类调试工具，在linux下通常使用带界面的cutecom或者命令行界面的minicom进行调试。 而使用Python写几行程API序进行自定义调试，就非常有用。并且可以快速的对传感器进行测试。本文介绍","title":"Pyserial快速上手"},{"content":"简介 LSM303DLHC是一个三轴加速度和三轴磁场的传感器，具有倾斜补偿，工作电压在2.5-5.5V之间，工作电流10mA，数据接口是I2C接口。\n引脚定义 VIN 2.5-5.5V电压供电引脚，SCL和SDA引脚的高电平电压和VIN引脚的电压相同。\nVDD 根据VIN引脚的连接情况，VDD引脚用途不同，若VIN引脚连接了大于3.3V的电源，VDD可以想歪提供3.3V的电压和大约150mA的电流。如果VIN断开连接，可以使用2.5-3.3的电源连接VDD给LSM303DLHC模块供电。 注意：\n不能同时使用VIN和VDD给LSM303DLHC供电，只能选取一个。 不要将VDD连接到大于3.6V的电源上，会损坏LSM303DLHC模块 GND 0V，连接到电源的地。注意和I2C总线共地。\nSCL 时钟线，高电平是VIN，低电平是0V。SCL和SDA都有电平转换电路，可以使得模块可以使用VIN的逻辑电平进行通信。\nSDA 数据线，高电平是VIN，低电平是0V\nDRDY 数据可读指示，3.3V逻辑电平输出，高电平(3.3V)指示磁场数据可读，低电平表示正在向数据寄存器中写入新的数据。此输出没有电平转换。\nINT1 INT2 两个惯性中断，没有电平转换，3.3V输出。\n例程和库 Arduino例程和库参考： https://github.com/pololu/lsm303-arduino\nLinux例程： https://github.com/ControlEverythingCommunity/LSM303DLHC\n参考 产品说明书\n","permalink":"https://blog.niuhemoon.win/posts/tech/lsm303dlhc-doc/","summary":"简介 LSM303DLHC是一个三轴加速度和三轴磁场的传感器，具有倾斜补偿，工作电压在2.5-5.5V之间，工作电流10mA，数据接口是I2C接口。 引脚定义 VIN 2.5-5.5V电压供电引脚，SCL和SDA引脚的高电平电压和VIN引脚的电压相同。 VDD 根据VIN引脚的连接情况，VDD引脚用","title":"LSM303_Doc"},{"content":" 在局域网下可以通过扫描端口号，获得局域网下树莓派的ip地址，如192.168.1.118。之后通过ssh或者VNC等方法访问树莓派。那么如果我们离开局域网，怎么访问到家中的树莓派呢？ 公网IP相当于街道中的门牌号，如果远程访问到互联网中的设备，必须知道设备的公网IP。\nVPS + SSH远程代理隧道 这是这篇文章重点，需要：\n一个安装了linux的VPS，如一台腾讯云服务器。（如果没有，请看下一种方法：公网IP+路由器端口转发） 连上网络的树莓派,将树莓派ssh公钥放到VPS上 树莓派上使用autossh+crontab sudo apt install autossh cd ~/ echo \u0026#34;sleep 20; /usr/bin/autossh -M 5678 -NfR 9999:localhost:22 user@T.T.T.T -i /home/user/.ssh/id_rsa\u0026#34; \u0026gt; autossh.sh chmod +x autossh.sh crontab -e 在crontab的配置文件中加入\n@reboot /home/nh/autossh.sh \u0026gt;\u0026gt; tunnel.log 在服务器上操作 ssh -fCNL \u0026#34;*:11111:localhost:9999\u0026#34; localhost 远程登录 现在就可以使用服务器作为跳板，连接到家中的树莓派。\nssh -p 11111 user@T.T.T.T 注：user@T.T.T.T,user是树莓派用户名，T.T.T.T是服务器公网IP。-p指定向服务器1111端口发送ssh请求，1111端口转发到9999端口，也就是树莓派的22端口。\n显示效果如下：\n以下树莓派配置方法均不推荐，想折腾的自己玩，服务器配置方法都一样\n树莓派上安装sshpass(可选） sudo apt-get install sshpass 树莓派上编辑shell脚本 #!/bin/bash #saved as create_ssh_tunnel.sh createTunnel() { sshpass -p \u0026#34;Password\u0026#34; ssh -o \u0026#34;ServerAliveInterval 300\u0026#34; -o \u0026#34;ServerAliveCountMax 2\u0026#34; -fCNR 9999:localhost:22 user@T.T.T.T if [[ $? -eq 0 ]]; then echo $(date) Tunnel to jumpbox created successfully \u0026gt;\u0026gt; /root/tunnel.log else echo $(date) An error occurred creating a tunnel to jumpbox. RC was $? \u0026gt;\u0026gt; /root/tunnel.log fi } /bin/pidof ssh if [[ $? -ne 0 ]]; then echo $(date) Creating new tunnel connection \u0026gt;\u0026gt; /root/tunnel.log createTunnel fi 注：这种方式非常危险，不推荐这种方式，因为明文存储了服务器密码。\n\u0026ldquo;Password\u0026quot;指的是你的服务器密码 user@T.T.T.T是你的服务器用户名和IP地址 9999是将树莓派的22端口绑定到服务器额9999端口 推荐将树莓派上的公钥放到远程服务器上，然后使用如下脚本\n#saved as create_ssh_tunnel.sh createTunnel() { ssh -o \u0026#34;ServerAliveInterval 300\u0026#34; -o \u0026#34;ServerAliveCountMax 2\u0026#34; -NR 9999:localhost:22 user@T.T.T.T if [[ $? -eq 0 ]]; then echo $(date) Tunnel to jumpbox created successfully \u0026gt;\u0026gt; ~/tunnel.log else echo $(date) An error occurred creating a tunnel to jumpbox. RC was $? \u0026gt;\u0026gt; ~/tunnel.log fi } /bin/pidof ssh if [[ $? -ne 0 ]]; then echo $(date) Creating new tunnel connection \u0026gt;\u0026gt; ~/tunnel.log createTunnel fi 给脚本添加执行权限\nchmod +x creat_ssh_tunnel.sh 树莓派上开启cron定时任务 sudo crontab -e 在文件最后一行添加：\n*/10 * * * * ～/create_ssh_tunnel.sh \u0026gt;\u0026gt; tunnel.log 2\u0026gt;\u0026amp;1 意思是每十分钟执行一次刚刚我们编辑的shell脚本\n公网IP + 路由器端口转发 如果用网线将树莓派连接到互联网上，只要获得公网IP，皆可以通过ssh访问。但是我们在家中通常是用wifi连接树莓派，我们获得的公网iP，只是路由器的IP。由于一个路由器上连接很多设备，我们无法通过这个公网IP访问到树莓派。而且由于路由器的公网IP是会变动的。所以我们要解决的问题是：\n找到路由器的公网IP 通过公网IP找到路由器下连接的树莓派 可以在路由器设置里将树莓派分配固定的IP，并绑定固定端口。这样就可以通过访问这个端口访问到局域网下的树莓派。之后不管是将公网IP发送到邮箱还是，使用动态DNS解析服务，通过域名访问树莓派，都可以很容易实现。\n参考 SSH反向代理 外网访问树莓派方法汇总 用DDNS服务通过域名访问树莓派 使用crontab让SSH反向代理更持久 ","permalink":"https://blog.niuhemoon.win/posts/tech/raspi-remote-ssh-tunnel/","summary":"在局域网下可以通过扫描端口号，获得局域网下树莓派的ip地址，如192.168.1.118。之后通过ssh或者VNC等方法访问树莓派。那么如果我们离开局域网，怎么访问到家中的树莓派呢？ 公网IP相当于街道中的门牌号，如果远程访问到互联网中的设备，必须知道设备的公网IP。 VPS + SSH远程","title":"远程ssh连接家中的树莓派"},{"content":" 在使用超声测距模块时，需要给超声模块一个方波信号。于是可以用树莓派的的PWM功能产生一个低频的方波信号。\n产生方波信号后，如果手边没有示波器，还可以使用Arduino的ADC采样功能，做一个简单的示波器。\n树莓派产生方波 树莓派的pin12、pin33(GPIO_18、GPIO_13)是树莓派提供的PWM硬件接口，可以产生高频的PWM信号。 由于我只需要产生一个大约50Hz的方波信号。用最简单的GPIO库就可以产生可用的方波。\n#!/usr/bin/python3 # -*- coding: utf-8 -*- import RPi.GPIO as GPIO from time import sleep GPIO.setmode(GPIO.BOARD) GPIO.setup(12,GPIO.OUT) GPIO.setwarnings(False) p=GPIO.PWM(12,50) # 12是pin12,50是频率 p.start(30) # 30表示占空比30% input(\u0026#34;Press Enter key to Stop 50Hz PWM @ 30% duty cycle\u0026#34;) p.stop() GPIO.cleanup() 运行该脚本，就可以在树莓派pin12上产生方波信号。\nArduino和树莓派连线 连线图如下所示： 注意： 要将树莓派和Arduino的地线连接在一起，使它们共地。\nArduino 进行ADC采样 Arduino 有A0-A5共6个模拟输入口，每个模拟口可以进行12位的采样，可以接受0-5V的电压输入，对应着0-1023的采样输出。\n使用A0口进行采样：\nvoid setup() { Serial.begin(9600); // Starting Serial Terminal } void loop() { int value = analogRead(A0); Serial.println(value); } 打开Arduino官方的IDE的【工具】-\u0026gt; 【串口绘图器】\n设置波特率为9600,可以观察到：\n注：树莓派GPIO引脚输出电压为3.3V，而Arduino采样范围是0-5V\n还可以使用SerialPlot这个功能更丰富的串口绘图器，当做简易的示波器。 显示的波形如下： Arduino串口绘图器 Arduino串口绘图器可以绘制多个连续图形，如下程序就是在串口绘图器中画出sin和cos函数图像。\ndouble i = 0; void setup() { Serial.begin(9600); } void loop() { double temp = i*3.1415926/10.0; Serial.print(sin(temp)); Serial.print(\u0026#39;,\u0026#39;); Serial.println(cos(temp)); i+=0.1; delay(5); } 注：\n若只绘制一个图像，使用Serial.println()函数即可 若绘制多个图像，在每个串口值间使用Serial.print(\u0026rsquo;,\u0026rsquo;)进行分隔 ","permalink":"https://blog.niuhemoon.win/posts/tech/arduino-raspberry-squrewave/","summary":"在使用超声测距模块时，需要给超声模块一个方波信号。于是可以用树莓派的的PWM功能产生一个低频的方波信号。 产生方波信号后，如果手边没有示波器，还可以使用Arduino的ADC采样功能，做一个简单的示波器。 树莓派产生方波 树莓派的pin12、pin33(GPIO_18、GPIO_13)","title":"Arduino简易示波器检测树莓派产生的方波"},{"content":" Arduino可以使用PWM产生方波信号，在我的Arduino UNO R3上，支持PWM的输出口是pin 3,5,6,9,10,11这几个引脚，支持大约980Hz的PWM输出。这方面不再赘述。\n本文介绍另一种产生方波的方法，可以使用任何引脚产生方波信号。功能：\n固定频率，占空比，偏移量的方波 通过模拟口连接可调电位器，产生可变频率、占空比、偏移量的方波 // High-accuracy square wave generator // based on Arduino UNO // with runtime adjustable frequency, PWM width and offset // Output wave at pin 13 double freq; // Hz double offset; // percent (0.0 to 1.0) double width; // percent (0.0 to 1.0) // unit: microsecond unsigned long cycle_time; unsigned long raising_edge; unsigned long falling_edge; unsigned long prev_micros; // compare 2 unsigned value // true if X \u0026gt; Y while for all possible (X, Y), X - Y \u0026lt; Z #define TIME_CMP(X, Y, Z) (((X) - (Y)) \u0026lt; (Z)) inline void setHigh() { // 2 CPU cycles to balance execution time with setLow() // this is based on measurement on Arduino UNO R3, your mileage may vary PORTB = B00100000; PORTB = B00100000; } inline void setLow() { PORTB = B00000000; } void setup() { DDRB = B00100000; prev_micros = micros(); while(1) { // read everything from analog input (potentiometer) // frequency: 0.1-102.4 Hz // width: 0-100% // offset: 0-100% //freq = (double)(analogRead(1) + 1) / 10; //width = (double)(analogRead(0) + 1) / 1024; //offset = (double)analogRead(2) / 1024; // OR manual settings // max possible frequency is around 55000Hz with \u0026lt;1KHz deviation // based on measurements on Arduino UNO R3 // you may get to ~77500Hz with significantly larger deviation // note: please uncomment the next 3 expressions, then // move the following 6 expressions ahead of while loop // if you are going to use manual settings, because it is no worth // to recalculate them. freq = 50; width = 0.3; offset = 0.0; cycle_time = 1000000 / freq; raising_edge = (unsigned long)(offset * cycle_time) % cycle_time; falling_edge = (unsigned long)((offset + width) * cycle_time) % cycle_time; if (width + offset \u0026lt; 1) { // raising edge should appear earlier while (TIME_CMP(micros(), prev_micros + raising_edge, cycle_time)); setHigh(); while (TIME_CMP(micros(), prev_micros + falling_edge, cycle_time)); setLow(); } else { // falling edge should appear earlier while (TIME_CMP(micros(), prev_micros + falling_edge, cycle_time)); setLow(); while (TIME_CMP(micros(), prev_micros + raising_edge, cycle_time)); setHigh(); }pin prev_micros += cycle_time; } } 解释：\nPORTB表示的是控制pin8-pin13的寄存器，最高的两位6\u0026amp;7不使用。 可以改变B00100000来在其他pin脚上产生方波信号 同样的PROTD寄存器控制digital pin0-pin7 参考 程序来源；James Swineson github@public.swineson.me, 2017-05\nhttps://gist.github.com/Jamesits/8d164818946a65d0cafcd6203e3e5049\nhttps://blog.swineson.me/high-frequency-square-wave-generator-based-on-arduino-uno/\n操控Arduino端口寄存器\n","permalink":"https://blog.niuhemoon.win/posts/tech/arduino-squrewave/","summary":"Arduino可以使用PWM产生方波信号，在我的Arduino UNO R3上，支持PWM的输出口是pin 3,5,6,9,10,11这几个引脚，支持大约980Hz的PWM输出。这方面不再赘述。 本文介绍另一种产生方波的方法，可以使用任何引脚产生方波信号。功能： 固定频率，占空比，偏移量的方波","title":"Arduino任何引脚产生方波"},{"content":"安装LCD库 使用AdaFruit库来控制lcd库，这个库支持AdaFruit屏幕和使用HD44780的显示屏。\n通过源码安装：\ngit clone https://github.com/adafruit/Adafruit_Python_CharLCD.git cd ./Adafruit_Python_CharLCD sudo python setup.py install 将树莓派和LCD1602连接 连接的图如下所示： LCD电子钟程序 #!/usr/bin/python3 # -*- coding: utf-8 -*- import RPi.GPIO as gpio #to add the LCD library import Adafruit_CharLCD as LCD import time gpio.setmode(gpio.BCM) #声明 LCD pins（对应BCM引脚） lcd_rs = 17 lcd_en = 18 lcd_d4 = 27 lcd_d5 = 22 lcd_d6 = 23 lcd_d7 = 10 lcd_backlight = 2 lcd_columns = 16 #Lcd column lcd_rows = 2 #number of LCD rows lcd = LCD.Adafruit_CharLCD(lcd_rs, lcd_en, \\ lcd_d4, lcd_d5, lcd_d6, lcd_d7, lcd_columns, lcd_rows,\\ lcd_backlight) lcd.set_cursor(0,0) lcd.message(\u0026#39; CLOCK\u0026#39;) while True: lcd.set_cursor(0,1) localtime = time.asctime( time.localtime(time.time()) )[4:-5] print(localtime) lcd.message(localtime) time.sleep(1) 效果图 显示的效果图如下，可以显示日期和时间，每秒钟刷新屏幕一次： ","permalink":"https://blog.niuhemoon.win/posts/tech/raspberrypi-lcd-clock/","summary":"安装LCD库 使用AdaFruit库来控制lcd库，这个库支持AdaFruit屏幕和使用HD44780的显示屏。 通过源码安装： git clone https://github.com/adafruit/Adafruit_Python_CharLCD.git cd ./Adafruit_Python_CharLCD sudo python setup.py install 将树莓派和LCD1602连接 连接的图如下所示： LCD电子钟程序 #!/usr/bin/python3 # -*- coding: utf-8 -*- import RPi.GPIO as gpio #to add the LCD library import Adafruit_CharLCD as LCD import time gpio.setmode(gpio.BCM) #声明 LCD pins（对应BCM引脚","title":"树莓派连接LCD1602做一个电子钟"},{"content":" 在树莓派3B+里启用串口，并通过UART读取GPS模块的数据帧。\n树莓派3启用UART #####先更新系统\nsudo apt-get update sudo apt-get upgrade sudo raspi-config 在raspi-config中设置：\ndisable login shell over serial enable serial hardware port #####然后重启\nsudo reboot #####编辑配置文件\nsudo nano /boot/config.txt 在最后一段加上：\ndtparam=spi=on dtoverlay=pi3-disable-bt core_freq=250 enable_uart=1 force_turbo=1 然后编辑cmdline.txt\nsudo cp boot/cmdline.txt boot/cmdline_backup.txt sudo nano /boot.cmdline.txt 将cmdline.txt的内容替换为： dwc_otg.lpm_enable=0 console=tty1 root=/dev/mmcblk0p2 rootfstype=ext4 elevator=deadline fsck.repair=yes rootwait quiet splash plymouth.ignore-serial-consoles\n#####禁用树莓派Serial Getty服务\nsudo systemctl stop serial-getty@ttyS0.service sudo systemctl disable serial-getty@ttyS0.service 重启系统\nsudo reboot #####激活ttyAMAO 上一步我们禁用了ttyS0,现在我们启用ttyAMA0.\nsudo systemctl enable serial-getty@ttyAMA0.service 好了到了现在，我们已经启用了树莓派的串口，并可以通过/dev/ttyAMA0来访问串口设备。\n树莓派的串口引脚 树莓派的引脚定义图如下所示： UART的收发引脚分别为：\nTx ——GPIO14（pin8) Rx ——GPIO15（pin10) 连接串口设备并测试 我们使用GPS串口设备进行测试，GPS模块有如下5个引脚：\nVCC GND TX RX PPS GPS模块和树莓派连接方式如下：\nVCC ——pin01 GND——pin06 TX——pin10 其他引脚可以不连接。\n使用cat或者minicom调试GPS串口：\ncat /dev/ttyAMA0 #或者 minicom -D /dev/ttyAMA0 -b 9600 能够读取到类似下边的串口输出：\n$GPTXT,01,01,01,ANTENNA OK*35 $GNGGA,115810.475,,,,,0,00,25.5,,,,,,*70 $GNGLL,,,,,115810.475,V,M*6D $GPGSA,A,1,,,,,,,,,,,,,25.5,25.5,25.5*02 $BDGSA,A,1,,,,,,,,,,,,,25.5,25.5,25.5*13 $GPGSV,3,1,09,05,05,121,,10,25,314,27,12,14,138,,13,13,058,16*73 $GPGSV,3,2,09,15,49,043,32,20,53,321,18,21,52,249,,24,77,090,*77 $GPGSV,3,3,09,32,11,265,*40 参考 树莓派UART文档 Raspberry Pi GPS Module Interfacing Tutorial ","permalink":"https://blog.niuhemoon.win/posts/tech/activate-serial-uart/","summary":"在树莓派3B+里启用串口，并通过UART读取GPS模块的数据帧。 树莓派3启用UART #####先更新系统 sudo apt-get update sudo apt-get upgrade sudo raspi-config 在raspi-config中设置： disable login shell over serial enable serial hardware port #####然后重启 sudo reboot #####编辑配置文件 sudo nano /boot/config.txt 在最后一段加上： dtparam=spi=on dtoverlay=pi3-disable-bt core_freq=250 enable_uart=1 force_turbo=1 然后编辑cmdline.txt sudo","title":"树莓派3启用UART并连接GPS传感器"},{"content":"本文介绍树莓派上GPIO引脚的三种编号方式，同时介绍控制引脚的方式。并以BCM-17引脚为例，动手点亮led灯并使其闪烁。\nGPIO是通用输入输出接口。树莓派上有40个引脚，对这40个引脚主要有两种编号方式。\nBOARD 和引脚物理顺序一致 BCM wiringpi编号 wiringPi是一个用来控制GPIO的库，它对40个引脚的编号方式如下：\n详细信息参考此网址\nwiringPi 安装方式 应用于C语言和shell git clone git://git.drogon.net/wiringPi cd wiringPi git pull origin ./build # 测试安装成功 gpio -vmake gpio readall 应用于Python sudo pip install wiringpi2 测试example程序 将发光二极管的阳极连接BOARD的pin11,也就是BCM17，wiringPi 0，中间需要串一个100-500欧姆的限流电阻。阴极连接到GND引脚（BOARD 9）。 命令行输入：\ngpio write 0 1\n可观察到发光二极管被点亮\ngpio函数其他用法参见文档\n编译示例C语言程序程序，使led闪烁\ncd wiringPi/examples/ ./blink.sh # 或者 make blink ./blink 使用Python控制GPIO 树莓派原生系统内置的python已经安装了RPi.GPIO库，通过它可以方便的控制GPIO\n可以参考以下两份文档：\nGeneral-RPIO\nPython-RPIO\nPython实现LED闪烁，引脚依然是BCM-17\n#!/usr/bin/python3 # -*- coding: utf-8 -*- import RPi.GPIO as GPIO from time import sleep GPIO.setmode(GPIO.BCM) GPIO.setwarnings(False) GPIO.setup(17,GPIO.OUT) print(\u0026#34;All set in Python! Let\u0026#39;s blink the LCD on BCM-17\u0026#34;) for i in range(1,10): GPIO.output(17,GPIO.HIGH) sleep(1) GPIO.output(17,GPIO.LOW) sleep(1) GPIO.cleanup() 使用wiringpi库来控制连接BCM-17的led灯闪烁，具体使用说明参看： python-wiringpi使用教程\n#!/usr/bin/python3 # -*- coding: utf-8 -*- import wiringpi from time import sleep # 设置wiringpi编号0引脚为输出模式 wiringpi.wiringPiSetup() wiringpi.pinMode(0,1) while True: wiringpi.digitalWrite(0,True) sleep(1) wiringpi.digitalWrite(0,False) sleep(1) 以下为wiringpi的三种引脚编号：\nBCM BOARD wiringpi 三种控制模式：\ninput output pwm 设置示范如下：\n# GPIO 引脚号就是BCM编号 import wiringpi wiringpi.wiringPiSetupGpio() wiringpi.pinMode(25, 0) # sets GPIO 25 to input wiringpi.pinMode(24, 1) # sets GPIO 24 to output wiringpi.pinMode(18, 2) # sets GPIO 18 to PWM mode # wiringpi 编号 import wiringpi wiringpi.wiringPiSetup() wiringpi.pinMode(6, 0) # sets WP pin 6 to input wiringpi.pinMode(5, 1) # sets WP pin 5 to output wiringpi.pinMode(1, 2) # sets WP pin 1 to PWM mode # 物理编号 BOARD编号 import wiringpi wiringPiSetupPhys() wiringpi.pinMode(22, 0) # sets P1 pin 22 to input wiringpi.pinMode(18, 1) # sets P1 pin 18 to output wiringpi.pinMode(12, 2) # sets P1 pin 12 to PWM mode ","permalink":"https://blog.niuhemoon.win/posts/tech/wiringpi-gpio/","summary":"本文介绍树莓派上GPIO引脚的三种编号方式，同时介绍控制引脚的方式。并以BCM-17引脚为例，动手点亮led灯并使其闪烁。 GPIO是通用输入输出接口。树莓派上有40个引脚，对这40个引脚主要有两种编号方式。 BOARD 和引脚物理顺序一致 BCM wiringpi编号 wiringPi是一个用来控制G","title":"树莓派GPIO入门"},{"content":"Python3实现AES和DES对称加密算法的\n对称算法编写 本实验是使用python来实现AES和DES加密和解密过程，并对加密解密过程的正确性进行验证。\n1.实验目的 掌握分组加密的原理 掌握数据加密标准DES和高级数据加密标准AES的原理及其应用 2.实验工具 Jupyter Notebook Python3.5 3.实验环境 Ubuntu16.04LTS操作系统 Python3标准库 4.实验步骤 4.1 回顾课程，查阅资料 4.2 熟悉AES的原理 AES(Advanced Encryption Standard)高级加密标准，在密码学中又称Rijndael加密法，是美国联邦政府采用的一种区块加密标准。这个标准用来替代原先的DES，已经被多方分析且广为全世界所使用。\nAES加密过程是在一个4×4的字节矩阵上运作，这个矩阵又称为“体（state）”，其初值就是一个明文区块（矩阵中一个元素大小就是明文区块中的一个Byte）。（Rijndael加密法因支持更大的区块，其矩阵行数可视情况增加）加密时，各轮AES加密循环（除最后一轮外）均包含4个步骤：\nAddRoundKey—矩阵中的每一个字节都与该次回合密钥（round key）做XOR运算；每个子密钥由密钥生成方案产生。 SubBytes—通过一个非线性的替换函数，用查找表的方式把每个字节替换成对应的字节。 ShiftRows—将矩阵中的每个横列进行循环式移位。 MixColumns—为了充分混合矩阵中各个直行的操作。这个步骤使用线性转换来混合每内联的四个字节。最后一个加密循环中省略MixColumns步骤，而以另一个AddRoundKey取代。 4.3 编写AES加密解密的测试用例 先使用其他已有工具计算出plaintext对应的\n测试程序如下：\nimport unittest class AES: def __init__(self, master_key): self.change_key(master_key) def change_key(self, master_key): pass def encrypt(self, plaintext): pass def decrypt(self, ciphertext): pass class AES_TEST(unittest.TestCase): def setUp(self): master_key = 0x2b7e151628aed2a6abf7158809cf4f3c self.AES = AES(master_key) def test_encryption(self): plaintext = 0x3243f6a8885a308d313198a2e0370734 encrypted = self.AES.encrypt(plaintext) self.assertEqual(encrypted, 0x3925841d02dc09fbdc118597196a0b32) def test_decryption(self): ciphertext = 0x3925841d02dc09fbdc118597196a0b32 decrypted = self.AES.decrypt(ciphertext) self.assertEqual(decrypted, 0x3243f6a8885a308d313198a2e0370734) if __name__ == \u0026#39;__main__\u0026#39;: unittest.main() 4.4 编写DES算法的测试代码 4.5 编写AES和DES对称加密的python实现，并进行测试验证 代码和测试结果在报告最后\n4.6 总结实验，编写实验报告 5. 实验总结 需要善于借鉴前人经验，搜集资料 实验只支持ascii码，对其他字符编码没有解决 利用优秀的工具，如Jupyter可以提高学习效率 6. 实验完整代码 #!/usr/bin/env python #-*- coding:utf-8 -*- \u0026#34;\u0026#34;\u0026#34; ASE的python实现： 支持128位秘钥 支持秘钥和原文均为数字的AES加密解密 \u0026#34;\u0026#34;\u0026#34; Sbox = ( 0x63, 0x7C, 0x77, 0x7B, 0xF2, 0x6B, 0x6F, 0xC5, 0x30, 0x01, 0x67, 0x2B, 0xFE, 0xD7, 0xAB, 0x76, 0xCA, 0x82, 0xC9, 0x7D, 0xFA, 0x59, 0x47, 0xF0, 0xAD, 0xD4, 0xA2, 0xAF, 0x9C, 0xA4, 0x72, 0xC0, 0xB7, 0xFD, 0x93, 0x26, 0x36, 0x3F, 0xF7, 0xCC, 0x34, 0xA5, 0xE5, 0xF1, 0x71, 0xD8, 0x31, 0x15, 0x04, 0xC7, 0x23, 0xC3, 0x18, 0x96, 0x05, 0x9A, 0x07, 0x12, 0x80, 0xE2, 0xEB, 0x27, 0xB2, 0x75, 0x09, 0x83, 0x2C, 0x1A, 0x1B, 0x6E, 0x5A, 0xA0, 0x52, 0x3B, 0xD6, 0xB3, 0x29, 0xE3, 0x2F, 0x84, 0x53, 0xD1, 0x00, 0xED, 0x20, 0xFC, 0xB1, 0x5B, 0x6A, 0xCB, 0xBE, 0x39, 0x4A, 0x4C, 0x58, 0xCF, 0xD0, 0xEF, 0xAA, 0xFB, 0x43, 0x4D, 0x33, 0x85, 0x45, 0xF9, 0x02, 0x7F, 0x50, 0x3C, 0x9F, 0xA8, 0x51, 0xA3, 0x40, 0x8F, 0x92, 0x9D, 0x38, 0xF5, 0xBC, 0xB6, 0xDA, 0x21, 0x10, 0xFF, 0xF3, 0xD2, 0xCD, 0x0C, 0x13, 0xEC, 0x5F, 0x97, 0x44, 0x17, 0xC4, 0xA7, 0x7E, 0x3D, 0x64, 0x5D, 0x19, 0x73, 0x60, 0x81, 0x4F, 0xDC, 0x22, 0x2A, 0x90, 0x88, 0x46, 0xEE, 0xB8, 0x14, 0xDE, 0x5E, 0x0B, 0xDB, 0xE0, 0x32, 0x3A, 0x0A, 0x49, 0x06, 0x24, 0x5C, 0xC2, 0xD3, 0xAC, 0x62, 0x91, 0x95, 0xE4, 0x79, 0xE7, 0xC8, 0x37, 0x6D, 0x8D, 0xD5, 0x4E, 0xA9, 0x6C, 0x56, 0xF4, 0xEA, 0x65, 0x7A, 0xAE, 0x08, 0xBA, 0x78, 0x25, 0x2E, 0x1C, 0xA6, 0xB4, 0xC6, 0xE8, 0xDD, 0x74, 0x1F, 0x4B, 0xBD, 0x8B, 0x8A, 0x70, 0x3E, 0xB5, 0x66, 0x48, 0x03, 0xF6, 0x0E, 0x61, 0x35, 0x57, 0xB9, 0x86, 0xC1, 0x1D, 0x9E, 0xE1, 0xF8, 0x98, 0x11, 0x69, 0xD9, 0x8E, 0x94, 0x9B, 0x1E, 0x87, 0xE9, 0xCE, 0x55, 0x28, 0xDF, 0x8C, 0xA1, 0x89, 0x0D, 0xBF, 0xE6, 0x42, 0x68, 0x41, 0x99, 0x2D, 0x0F, 0xB0, 0x54, 0xBB, 0x16, ) InvSbox = ( 0x52, 0x09, 0x6A, 0xD5, 0x30, 0x36, 0xA5, 0x38, 0xBF, 0x40, 0xA3, 0x9E, 0x81, 0xF3, 0xD7, 0xFB, 0x7C, 0xE3, 0x39, 0x82, 0x9B, 0x2F, 0xFF, 0x87, 0x34, 0x8E, 0x43, 0x44, 0xC4, 0xDE, 0xE9, 0xCB, 0x54, 0x7B, 0x94, 0x32, 0xA6, 0xC2, 0x23, 0x3D, 0xEE, 0x4C, 0x95, 0x0B, 0x42, 0xFA, 0xC3, 0x4E, 0x08, 0x2E, 0xA1, 0x66, 0x28, 0xD9, 0x24, 0xB2, 0x76, 0x5B, 0xA2, 0x49, 0x6D, 0x8B, 0xD1, 0x25, 0x72, 0xF8, 0xF6, 0x64, 0x86, 0x68, 0x98, 0x16, 0xD4, 0xA4, 0x5C, 0xCC, 0x5D, 0x65, 0xB6, 0x92, 0x6C, 0x70, 0x48, 0x50, 0xFD, 0xED, 0xB9, 0xDA, 0x5E, 0x15, 0x46, 0x57, 0xA7, 0x8D, 0x9D, 0x84, 0x90, 0xD8, 0xAB, 0x00, 0x8C, 0xBC, 0xD3, 0x0A, 0xF7, 0xE4, 0x58, 0x05, 0xB8, 0xB3, 0x45, 0x06, 0xD0, 0x2C, 0x1E, 0x8F, 0xCA, 0x3F, 0x0F, 0x02, 0xC1, 0xAF, 0xBD, 0x03, 0x01, 0x13, 0x8A, 0x6B, 0x3A, 0x91, 0x11, 0x41, 0x4F, 0x67, 0xDC, 0xEA, 0x97, 0xF2, 0xCF, 0xCE, 0xF0, 0xB4, 0xE6, 0x73, 0x96, 0xAC, 0x74, 0x22, 0xE7, 0xAD, 0x35, 0x85, 0xE2, 0xF9, 0x37, 0xE8, 0x1C, 0x75, 0xDF, 0x6E, 0x47, 0xF1, 0x1A, 0x71, 0x1D, 0x29, 0xC5, 0x89, 0x6F, 0xB7, 0x62, 0x0E, 0xAA, 0x18, 0xBE, 0x1B, 0xFC, 0x56, 0x3E, 0x4B, 0xC6, 0xD2, 0x79, 0x20, 0x9A, 0xDB, 0xC0, 0xFE, 0x78, 0xCD, 0x5A, 0xF4, 0x1F, 0xDD, 0xA8, 0x33, 0x88, 0x07, 0xC7, 0x31, 0xB1, 0x12, 0x10, 0x59, 0x27, 0x80, 0xEC, 0x5F, 0x60, 0x51, 0x7F, 0xA9, 0x19, 0xB5, 0x4A, 0x0D, 0x2D, 0xE5, 0x7A, 0x9F, 0x93, 0xC9, 0x9C, 0xEF, 0xA0, 0xE0, 0x3B, 0x4D, 0xAE, 0x2A, 0xF5, 0xB0, 0xC8, 0xEB, 0xBB, 0x3C, 0x83, 0x53, 0x99, 0x61, 0x17, 0x2B, 0x04, 0x7E, 0xBA, 0x77, 0xD6, 0x26, 0xE1, 0x69, 0x14, 0x63, 0x55, 0x21, 0x0C, 0x7D, ) # 参考了C语言实现 http://cs.ucsb.edu/~koc/cs178/projects/JT/aes.c xtime = lambda a: (((a \u0026lt;\u0026lt; 1) ^ 0x1B) \u0026amp; 0xFF) if (a \u0026amp; 0x80) else (a \u0026lt;\u0026lt; 1) Rcon = ( 0x00, 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1B, 0x36, 0x6C, 0xD8, 0xAB, 0x4D, 0x9A, 0x2F, 0x5E, 0xBC, 0x63, 0xC6, 0x97, 0x35, 0x6A, 0xD4, 0xB3, 0x7D, 0xFA, 0xEF, 0xC5, 0x91, 0x39, ) def text2matrix(text): matrix = [] for i in range(16): byte = (text \u0026gt;\u0026gt; (8 * (15 - i))) \u0026amp; 0xFF if i % 4 == 0: matrix.append([byte]) else: matrix[int(i / 4)].append(byte) return matrix def matrix2text(matrix): text = 0 for i in range(4): for j in range(4): text |= (matrix[i][j] \u0026lt;\u0026lt; (120 - 8 * (4 * i + j))) return text class AES: def __init__(self, master_key): self.change_key(master_key) def change_key(self, master_key): self.round_keys = text2matrix(master_key) # print self.round_keys for i in range(4, 4 * 11): self.round_keys.append([]) if i % 4 == 0: byte = self.round_keys[i - 4][0] \\ ^ Sbox[self.round_keys[i - 1][1]] \\ ^ Rcon[int(i / 4)] self.round_keys[i].append(byte) for j in range(1, 4): byte = self.round_keys[i - 4][j] \\ ^ Sbox[self.round_keys[i - 1][(j + 1) % 4]] self.round_keys[i].append(byte) else: for j in range(4): byte = self.round_keys[i - 4][j] \\ ^ self.round_keys[i - 1][j] self.round_keys[i].append(byte) # print self.round_keys def encrypt(self, plaintext): self.plain_state = text2matrix(plaintext) self.__add_round_key(self.plain_state, self.round_keys[:4]) for i in range(1, 10): self.__round_encrypt(self.plain_state, self.round_keys[4 * i : 4 * (i + 1)]) self.__sub_bytes(self.plain_state) self.__shift_rows(self.plain_state) self.__add_round_key(self.plain_state, self.round_keys[40:]) return matrix2text(self.plain_state) def decrypt(self, ciphertext): self.cipher_state = text2matrix(ciphertext) self.__add_round_key(self.cipher_state, self.round_keys[40:]) self.__inv_shift_rows(self.cipher_state) self.__inv_sub_bytes(self.cipher_state) for i in range(9, 0, -1): self.__round_decrypt(self.cipher_state, self.round_keys[4 * i : 4 * (i + 1)]) self.__add_round_key(self.cipher_state, self.round_keys[:4]) return matrix2text(self.cipher_state) def __add_round_key(self, s, k): for i in range(4): for j in range(4): s[i][j] ^= k[i][j] def __round_encrypt(self, state_matrix, key_matrix): self.__sub_bytes(state_matrix) self.__shift_rows(state_matrix) self.__mix_columns(state_matrix) self.__add_round_key(state_matrix, key_matrix) def __round_decrypt(self, state_matrix, key_matrix): self.__add_round_key(state_matrix, key_matrix) self.__inv_mix_columns(state_matrix) self.__inv_shift_rows(state_matrix) self.__inv_sub_bytes(state_matrix) def __sub_bytes(self, s): for i in range(4): for j in range(4): s[i][j] = Sbox[s[i][j]] def __inv_sub_bytes(self, s): for i in range(4): for j in range(4): s[i][j] = InvSbox[s[i][j]] def __shift_rows(self, s): s[0][1], s[1][1], s[2][1], s[3][1] = s[1][1], s[2][1], s[3][1], s[0][1] s[0][2], s[1][2], s[2][2], s[3][2] = s[2][2], s[3][2], s[0][2], s[1][2] s[0][3], s[1][3], s[2][3], s[3][3] = s[3][3], s[0][3], s[1][3], s[2][3] def __inv_shift_rows(self, s): s[0][1], s[1][1], s[2][1], s[3][1] = s[3][1], s[0][1], s[1][1], s[2][1] s[0][2], s[1][2], s[2][2], s[3][2] = s[2][2], s[3][2], s[0][2], s[1][2] s[0][3], s[1][3], s[2][3], s[3][3] = s[1][3], s[2][3], s[3][3], s[0][3] def __mix_single_column(self, a): # please see Sec 4.1.2 in The Design of Rijndael t = a[0] ^ a[1] ^ a[2] ^ a[3] u = a[0] a[0] ^= t ^ xtime(a[0] ^ a[1]) a[1] ^= t ^ xtime(a[1] ^ a[2]) a[2] ^= t ^ xtime(a[2] ^ a[3]) a[3] ^= t ^ xtime(a[3] ^ u) def __mix_columns(self, s): for i in range(4): self.__mix_single_column(s[i]) def __inv_mix_columns(self, s): # see Sec 4.1.3 in The Design of Rijndael for i in range(4): u = xtime(xtime(s[i][0] ^ s[i][2])) v = xtime(xtime(s[i][1] ^ s[i][3])) s[i][0] ^= u s[i][1] ^= v s[i][2] ^= u s[i][3] ^= v self.__mix_columns(s) master_key = 0x2b7e151628aed2a6abf7158809cf4f3c AESbar = AES(master_key) def test_encryption(): plaintext = 0x3243f6a8885a308d313198a2e0370734 encrypted = AESbar.encrypt(plaintext) print(\u0026#39;加密得密文： 0x%x\u0026#39; % encrypted) assert encrypted == 0x3925841d02dc09fbdc118597196a0b32 print(\u0026#39;加密结果正确\u0026#39;) def test_decryption(): ciphertext = 0x3925841d02dc09fbdc118597196a0b32 decrypted = AESbar.decrypt(ciphertext) print(\u0026#39;解密得原文: 0x%x\u0026#39; % decrypted) assert decrypted == 0x3243f6a8885a308d313198a2e0370734 print(\u0026#39;解密成功\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: print(\u0026#39;开始单元测试：\u0026#39;) test_encryption() test_decryption() print(\u0026#39;单元测试成功\u0026#39;) 开始单元测试： 加密得密文： 0x3925841d02dc09fbdc118597196a0b32 加密结果正确 解密得原文: 0x3243f6a8885a308d313198a2e0370734 解密成功 单元测试成功 #!/usr/bin/env python #-*- coding:utf-8 -*- \u0026#39;\u0026#39;\u0026#39; DES加密解密的Python3实现 \u0026#39;\u0026#39;\u0026#39; #Initial permut matrix for the datas PI = [58, 50, 42, 34, 26, 18, 10, 2, 60, 52, 44, 36, 28, 20, 12, 4, 62, 54, 46, 38, 30, 22, 14, 6, 64, 56, 48, 40, 32, 24, 16, 8, 57, 49, 41, 33, 25, 17, 9, 1, 59, 51, 43, 35, 27, 19, 11, 3, 61, 53, 45, 37, 29, 21, 13, 5, 63, 55, 47, 39, 31, 23, 15, 7] #Initial permut made on the key CP_1 = [57, 49, 41, 33, 25, 17, 9, 1, 58, 50, 42, 34, 26, 18, 10, 2, 59, 51, 43, 35, 27, 19, 11, 3, 60, 52, 44, 36, 63, 55, 47, 39, 31, 23, 15, 7, 62, 54, 46, 38, 30, 22, 14, 6, 61, 53, 45, 37, 29, 21, 13, 5, 28, 20, 12, 4] #Permut applied on shifted key to get Ki+1 CP_2 = [14, 17, 11, 24, 1, 5, 3, 28, 15, 6, 21, 10, 23, 19, 12, 4, 26, 8, 16, 7, 27, 20, 13, 2, 41, 52, 31, 37, 47, 55, 30, 40, 51, 45, 33, 48, 44, 49, 39, 56, 34, 53, 46, 42, 50, 36, 29, 32] #Expand matrix to get a 48bits matrix of datas to apply the xor with Ki E = [32, 1, 2, 3, 4, 5, 4, 5, 6, 7, 8, 9, 8, 9, 10, 11, 12, 13, 12, 13, 14, 15, 16, 17, 16, 17, 18, 19, 20, 21, 20, 21, 22, 23, 24, 25, 24, 25, 26, 27, 28, 29, 28, 29, 30, 31, 32, 1] #SBOX S_BOX = [ [[14, 4, 13, 1, 2, 15, 11, 8, 3, 10, 6, 12, 5, 9, 0, 7], [0, 15, 7, 4, 14, 2, 13, 1, 10, 6, 12, 11, 9, 5, 3, 8], [4, 1, 14, 8, 13, 6, 2, 11, 15, 12, 9, 7, 3, 10, 5, 0], [15, 12, 8, 2, 4, 9, 1, 7, 5, 11, 3, 14, 10, 0, 6, 13], ], [[15, 1, 8, 14, 6, 11, 3, 4, 9, 7, 2, 13, 12, 0, 5, 10], [3, 13, 4, 7, 15, 2, 8, 14, 12, 0, 1, 10, 6, 9, 11, 5], [0, 14, 7, 11, 10, 4, 13, 1, 5, 8, 12, 6, 9, 3, 2, 15], [13, 8, 10, 1, 3, 15, 4, 2, 11, 6, 7, 12, 0, 5, 14, 9], ], [[10, 0, 9, 14, 6, 3, 15, 5, 1, 13, 12, 7, 11, 4, 2, 8], [13, 7, 0, 9, 3, 4, 6, 10, 2, 8, 5, 14, 12, 11, 15, 1], [13, 6, 4, 9, 8, 15, 3, 0, 11, 1, 2, 12, 5, 10, 14, 7], [1, 10, 13, 0, 6, 9, 8, 7, 4, 15, 14, 3, 11, 5, 2, 12], ], [[7, 13, 14, 3, 0, 6, 9, 10, 1, 2, 8, 5, 11, 12, 4, 15], [13, 8, 11, 5, 6, 15, 0, 3, 4, 7, 2, 12, 1, 10, 14, 9], [10, 6, 9, 0, 12, 11, 7, 13, 15, 1, 3, 14, 5, 2, 8, 4], [3, 15, 0, 6, 10, 1, 13, 8, 9, 4, 5, 11, 12, 7, 2, 14], ], [[2, 12, 4, 1, 7, 10, 11, 6, 8, 5, 3, 15, 13, 0, 14, 9], [14, 11, 2, 12, 4, 7, 13, 1, 5, 0, 15, 10, 3, 9, 8, 6], [4, 2, 1, 11, 10, 13, 7, 8, 15, 9, 12, 5, 6, 3, 0, 14], [11, 8, 12, 7, 1, 14, 2, 13, 6, 15, 0, 9, 10, 4, 5, 3], ], [[12, 1, 10, 15, 9, 2, 6, 8, 0, 13, 3, 4, 14, 7, 5, 11], [10, 15, 4, 2, 7, 12, 9, 5, 6, 1, 13, 14, 0, 11, 3, 8], [9, 14, 15, 5, 2, 8, 12, 3, 7, 0, 4, 10, 1, 13, 11, 6], [4, 3, 2, 12, 9, 5, 15, 10, 11, 14, 1, 7, 6, 0, 8, 13], ], [[4, 11, 2, 14, 15, 0, 8, 13, 3, 12, 9, 7, 5, 10, 6, 1], [13, 0, 11, 7, 4, 9, 1, 10, 14, 3, 5, 12, 2, 15, 8, 6], [1, 4, 11, 13, 12, 3, 7, 14, 10, 15, 6, 8, 0, 5, 9, 2], [6, 11, 13, 8, 1, 4, 10, 7, 9, 5, 0, 15, 14, 2, 3, 12], ], [[13, 2, 8, 4, 6, 15, 11, 1, 10, 9, 3, 14, 5, 0, 12, 7], [1, 15, 13, 8, 10, 3, 7, 4, 12, 5, 6, 11, 0, 14, 9, 2], [7, 11, 4, 1, 9, 12, 14, 2, 0, 6, 10, 13, 15, 3, 5, 8], [2, 1, 14, 7, 4, 10, 8, 13, 15, 12, 9, 0, 3, 5, 6, 11], ] ] #Permut made after each SBox substitution for each round P = [16, 7, 20, 21, 29, 12, 28, 17, 1, 15, 23, 26, 5, 18, 31, 10, 2, 8, 24, 14, 32, 27, 3, 9, 19, 13, 30, 6, 22, 11, 4, 25] #Final permut for datas after the 16 rounds PI_1 = [40, 8, 48, 16, 56, 24, 64, 32, 39, 7, 47, 15, 55, 23, 63, 31, 38, 6, 46, 14, 54, 22, 62, 30, 37, 5, 45, 13, 53, 21, 61, 29, 36, 4, 44, 12, 52, 20, 60, 28, 35, 3, 43, 11, 51, 19, 59, 27, 34, 2, 42, 10, 50, 18, 58, 26, 33, 1, 41, 9, 49, 17, 57, 25] #Matrix that determine the shift for each round of keys SHIFT = [1,1,2,2,2,2,2,2,1,2,2,2,2,2,2,1] def string_to_bit_array(text):#Convert a string into a list of bits array = list() for char in text: binval = binvalue(char, 8)#Get the char value on one byte array.extend([int(x) for x in list(binval)]) #Add the bits to the final list return array def bit_array_to_string(array): #Recreate the string from the bit array res = \u0026#39;\u0026#39;.join([chr(int(y,2)) for y in [\u0026#39;\u0026#39;.join([str(x) for x in bytes]) for bytes in nsplit(array,8)]]) return res def binvalue(val, bitsize): #Return the binary value as a string of the given size binval = bin(val)[2:] if isinstance(val, int) else bin(ord(val))[2:] if len(binval) \u0026gt; bitsize: raise \u0026#34;binary value larger than the expected size\u0026#34; while len(binval) \u0026lt; bitsize: binval = \u0026#34;0\u0026#34;+binval #Add as many 0 as needed to get the wanted size return binval def nsplit(s, n):#Split a list into sublists of size \u0026#34;n\u0026#34; return [s[k:k+n] for k in range(0, len(s), n)] ENCRYPT=1 DECRYPT=0 class des(): def __init__(self): self.password = None self.text = None self.keys = list() def run(self, key, text, action=ENCRYPT, padding=False): if len(key) \u0026lt; 8: raise \u0026#34;Key Should be 8 bytes long\u0026#34; elif len(key) \u0026gt; 8: key = key[:8] #If key size is above 8bytes, cut to be 8bytes long self.password = key self.text = text if padding and action==ENCRYPT: self.addPadding() elif len(self.text) % 8 != 0:#If not padding specified data size must be multiple of 8 bytes raise \u0026#34;Data size should be multiple of 8\u0026#34; self.generatekeys() #Generate all the keys text_blocks = nsplit(self.text, 8) #Split the text in blocks of 8 bytes so 64 bits result = list() for block in text_blocks:#Loop over all the blocks of data block = string_to_bit_array(block)#Convert the block in bit array block = self.permut(block,PI)#Apply the initial permutation g, d = nsplit(block, 32) #g(LEFT), d(RIGHT) tmp = None for i in range(16): #Do the 16 rounds d_e = self.expand(d, E) #Expand d to match Ki size (48bits) if action == ENCRYPT: tmp = self.xor(self.keys[i], d_e)#If encrypt use Ki else: tmp = self.xor(self.keys[15-i], d_e)#If decrypt start by the last key tmp = self.substitute(tmp) #Method that will apply the SBOXes tmp = self.permut(tmp, P) tmp = self.xor(g, tmp) g = d d = tmp result += self.permut(d+g, PI_1) #Do the last permut and append the result to result final_res = bit_array_to_string(result) if padding and action==DECRYPT: return self.removePadding(final_res) #Remove the padding if decrypt and padding is true else: return final_res #Return the final string of data ciphered/deciphered def substitute(self, d_e):#Substitute bytes using SBOX subblocks = nsplit(d_e, 6)#Split bit array into sublist of 6 bits result = list() for i in range(len(subblocks)): #For all the sublists block = subblocks[i] row = int(str(block[0])+str(block[5]),2)#Get the row with the first and last bit column = int(\u0026#39;\u0026#39;.join([str(x) for x in block[1:][:-1]]),2) #Column is the 2,3,4,5th bits val = S_BOX[i][row][column] #Take the value in the SBOX appropriated for the round (i) bin = binvalue(val, 4)#Convert the value to binary result += [int(x) for x in bin]#And append it to the resulting list return result def permut(self, block, table):#Permut the given block using the given table (so generic method) return [block[x-1] for x in table] def expand(self, block, table):#Do the exact same thing than permut but for more clarity has been renamed return [block[x-1] for x in table] def xor(self, t1, t2):#Apply a xor and return the resulting list return [x^y for x,y in zip(t1,t2)] def generatekeys(self):#Algorithm that generates all the keys self.keys = [] key = string_to_bit_array(self.password) key = self.permut(key, CP_1) #Apply the initial permut on the key g, d = nsplit(key, 28) #Split it in to (g-\u0026gt;LEFT),(d-\u0026gt;RIGHT) for i in range(16):#Apply the 16 rounds g, d = self.shift(g, d, SHIFT[i]) #Apply the shift associated with the round (not always 1) tmp = g + d #Merge them self.keys.append(self.permut(tmp, CP_2)) #Apply the permut to get the Ki def shift(self, g, d, n): #Shift a list of the given value return g[n:] + g[:n], d[n:] + d[:n] def addPadding(self):#Add padding to the datas using PKCS5 spec. pad_len = 8 - (len(self.text) % 8) self.text += pad_len * chr(pad_len) def removePadding(self, data):#Remove the padding of the plain text (it assume there is padding) pad_len = ord(data[-1]) return data[:-pad_len] def encrypt(self, key, text, padding=False): return self.run(key, text, ENCRYPT, padding) def decrypt(self, key, text, padding=False): return self.run(key, text, DECRYPT, padding) if __name__ == \u0026#39;__main__\u0026#39;: key = \u0026#34;secret_k\u0026#34; text= \u0026#34;Hello wo\u0026#34; d = des() r = d.encrypt(key,text) r2 = d.decrypt(key,r) print(\u0026#34;Ciphered: %r\u0026#34; % r) print(\u0026#34;Deciphered: \u0026#34;, r2) assert r2 == text print(\u0026#39;成功实现DES加密解密\u0026#39;) Ciphered: 'ßåýåÚ\\x9f\\\\\\x9d' Deciphered: Hello wo 成功实现DES加密解密 ","permalink":"https://blog.niuhemoon.win/posts/tech/python-symmetric-encryption/","summary":"\u003cp\u003ePython3实现AES和DES对称加密算法的\u003c/p\u003e","title":"Python对称AES和DES加密算法"},{"content":"Python3实现哈希散列算法，包含MD5和sha256。\nHash函数算法编写 本实验是使用python来编写MD5和SHA256加密函数，并对加密函数的正确性进行验证。\n验证的方式是通过和已有的标准库加密结果进行比较，如果结果相同，则加密函数正确。\n1.实验目的 熟悉MD5和SHA256加密函数的原理和应用 实现MD5和SHA256加密函数并验证 2.实验工具 Jupyter Notebook Python3.5 3.实验环境 Ubuntu16.04LTS操作系统 Python3标准库 4.实验步骤 4.1 回顾课程，查阅资料 4.2 熟悉MD5的原理 MD5(Message-Digest Algorithm)消息摘要算法是一种广泛使用的密码散列函数，可以产生出一个128位（16字节）的散列值（hash value），用于确保信息传输完整一致。\nMD5将可变长度的消息处理成128位的固定长度输出。输入消息被分解成512位块（16个32位字）块;该消息被填充以使其长度可以被512整除。\n填充的工作原理如下：\n首先将单个位1附加到消息的末尾 接着填充0，直到消息长度比512的整数倍少64 在接下来64位中填充真实消息的长度值 主MD5算法在128位状态下运行，分为四个32位字，分别表示为A，B，C和D.这些字被初始化为某些固定的常量。\n主算法然后依次使用每个512位消息块来修改状态。\n消息块的处理由四个相似的阶段组成，称为循环;每轮由基于非线性函数F，模加法和左旋等16种类似操作组成。\n图1说明了一轮内的一个操作流程。 图2表示F有四种可能的功能;每一轮使用不同的一个： 下图是非线性函数的四种可能\n4.3 查阅得MD5算法的伪代码 //Note: All variables are unsigned 32 bit and wrap modulo 2^32 when calculating var int[64] s, K var int i //s specifies the per-round shift amounts s[ 0..15] := { 7, 12, 17, 22, 7, 12, 17, 22, 7, 12, 17, 22, 7, 12, 17, 22 } s[16..31] := { 5, 9, 14, 20, 5, 9, 14, 20, 5, 9, 14, 20, 5, 9, 14, 20 } s[32..47] := { 4, 11, 16, 23, 4, 11, 16, 23, 4, 11, 16, 23, 4, 11, 16, 23 } s[48..63] := { 6, 10, 15, 21, 6, 10, 15, 21, 6, 10, 15, 21, 6, 10, 15, 21 } //Use binary integer part of the sines of integers (Radians) as constants: for i from 0 to 63 K[i] := floor(232 × abs(sin(i + 1))) end for //Initialize variables: var int a0 := 0x67452301 //A var int b0 := 0xefcdab89 //B var int c0 := 0x98badcfe //C var int d0 := 0x10325476 //D //Pre-processing: adding a single 1 bit append \u0026#34;1\u0026#34; bit to message // Notice: the input bytes are considered as bits strings, // where the first bit is the most significant bit of the byte.[48] //Pre-processing: padding with zeros append \u0026#34;0\u0026#34; bit until message length in bits ≡ 448 (mod 512) append original length in bits mod 264 to message //Process the message in successive 512-bit chunks: for each 512-bit chunk of padded message break chunk into sixteen 32-bit words M[j], 0 ≤ j ≤ 15 //Initialize hash value for this chunk: var int A := a0 var int B := b0 var int C := c0 var int D := d0 //Main loop: for i from 0 to 63 var int F, g if 0 ≤ i ≤ 15 then F := (B and C) or ((not B) and D) g := i else if 16 ≤ i ≤ 31 F := (D and B) or ((not D) and C) g := (5×i + 1) mod 16 else if 32 ≤ i ≤ 47 F := B xor C xor D g := (3×i + 5) mod 16 else if 48 ≤ i ≤ 63 F := C xor (B or (not D)) g := (7×i) mod 16 //Be wary of the below definitions of a,b,c,d F := F + A + K[i] + M[g] A := D D := C C := B B := B + leftrotate(F, s[i]) end for //Add this chunk\u0026#39;s hash to result so far: a0 := a0 + A b0 := b0 + B c0 := c0 + C d0 := d0 + D end for var char digest[16] := a0 append b0 append c0 append d0 //(Output is in little-endian) //leftrotate function definition leftrotate (x, c) return (x \u0026lt;\u0026lt; c) binary or (x \u0026gt;\u0026gt; (32-c)); 4.4 编写MD5算法测试用例 Python标准库hashlib中提供了生成MD5值的方法，是通过C语言实现的，我们用自己实现的MD5函数计算出MD5值，在和标准库的结果进行比较，如果结果相同，那么证明了MD5加密是正确的。 注意：\n只实现了对ASCII码字符串的处理 demo中存储了测试用例 my_md5()返回自己生成的MD5值 true_md5()返回Python标准库生成的MD5值 若两者结果不同，抛出AssertionError异常 测试程序如下：\nimport hashlib def my_md5(message): pass def true_md5(message): m = hashlib.md5() m.update(message) return m.hexdigest() if __name__==\u0026#39;__main__\u0026#39;: demo = [b\u0026#34;\u0026#34;, b\u0026#34;a\u0026#34;, b\u0026#34;abc\u0026#34;, b\u0026#34;message digest\u0026#34;, b\u0026#34;abcdefghijklmnopqrstuvwxyz\u0026#34;, b\u0026#34;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\u0026#34;, b\u0026#34;12345678901234567890123456789012345678901234567890123456789012345678901234567890\u0026#34;] for message in demo: print(my_md5(message),\u0026#39; \u0026lt;= \u0026#34;\u0026#39;,message.decode(\u0026#39;ascii\u0026#39;),\u0026#39;\u0026#34;\u0026#39;, sep=\u0026#39;\u0026#39;) assert true_md5(message)==my_md5(message) # 若和标准库中不同，会抛出异常 4.5 查阅sha256算法原理和伪代码 sha256是SHA2(Secure Hash Algorithm 2)算法的一个变体，具体内容。\n篇幅原因不再贴sha256的伪代码，维基百科中有详细说明。\n4.6 编写sha256算法的测试代码 import hashlib def my_sha256(message): pass def true_sha256(message): m = hashlib.sha256() m.update(message) return m.hexdigest() if __name__==\u0026#39;__main__\u0026#39;: demo = [b\u0026#34;\u0026#34;, b\u0026#34;a\u0026#34;, b\u0026#34;abc\u0026#34;, b\u0026#34;message digest\u0026#34;, b\u0026#34;abcdefghijklmnopqrstuvwxyz\u0026#34;, b\u0026#34;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\u0026#34;, b\u0026#34;12345678901234567890123456789012345678901234567890123456789012345678901234567890\u0026#34;] for message in demo: print(my_sha256(message),\u0026#39; \u0026lt;= \u0026#34;\u0026#39;,message.decode(\u0026#39;ascii\u0026#39;),\u0026#39;\u0026#34;\u0026#39;, sep=\u0026#39;\u0026#39;) assert true_sha256(message)==my_sha256(message) # 若和标准库中不同，会抛出异常 4.7 编写MD5和SHA256的python实现，并进行测试验证 代码和测试结果在报告最后\n4.8 总结实验，编写实验报告 5. 实验总结 需要善于借鉴前人经验，搜集资料 实验只支持ascii码，对其他字符编码没有解决 利用优秀的工具，如Jupyter可以提高学习效率 6. 实验完整代码 5.1 MD5实现 # MD5 实现及其验证 import math import hashlib rotate_amounts = [7, 12, 17, 22, 7, 12, 17, 22, 7, 12, 17, 22, 7, 12, 17, 22, 5, 9, 14, 20, 5, 9, 14, 20, 5, 9, 14, 20, 5, 9, 14, 20, 4, 11, 16, 23, 4, 11, 16, 23, 4, 11, 16, 23, 4, 11, 16, 23, 6, 10, 15, 21, 6, 10, 15, 21, 6, 10, 15, 21, 6, 10, 15, 21] constants = [int(abs(math.sin(i+1)) * 2**32) \u0026amp; 0xFFFFFFFF for i in range(64)] # A B C D init_values = [0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476] # 非线性函数 functions = 16*[lambda b, c, d: (b \u0026amp; c) | (~b \u0026amp; d)] + \\ 16*[lambda b, c, d: (d \u0026amp; b) | (~d \u0026amp; c)] + \\ 16*[lambda b, c, d: b ^ c ^ d] + \\ 16*[lambda b, c, d: c ^ (b | ~d)] index_functions = 16*[lambda i: i] + \\ 16*[lambda i: (5*i + 1)%16] + \\ 16*[lambda i: (3*i + 5)%16] + \\ 16*[lambda i: (7*i)%16] # 对x左移amount位 def left_rotate(x, amount): x \u0026amp;= 0xFFFFFFFF return ((x\u0026lt;\u0026lt;amount) | (x\u0026gt;\u0026gt;(32-amount))) \u0026amp; 0xFFFFFFFF def md5(message): message = bytearray(message) #copy our input into a mutable buffer orig_len_in_bits = (8 * len(message)) \u0026amp; 0xffffffffffffffff message.append(0x80) while len(message)%64 != 56: message.append(0) message += orig_len_in_bits.to_bytes(8, byteorder=\u0026#39;little\u0026#39;) hash_pieces = init_values[:] for chunk_ofst in range(0, len(message), 64): a, b, c, d = hash_pieces chunk = message[chunk_ofst:chunk_ofst+64] for i in range(64): f = functions[i](b, c, d) g = index_functions[i](i) to_rotate = a + f + constants[i] + int.from_bytes(chunk[4*g:4*g+4], byteorder=\u0026#39;little\u0026#39;) new_b = (b + left_rotate(to_rotate, rotate_amounts[i])) \u0026amp; 0xFFFFFFFF a, b, c, d = d, new_b, b, c for i, val in enumerate([a, b, c, d]): hash_pieces[i] += val hash_pieces[i] \u0026amp;= 0xFFFFFFFF return sum(x\u0026lt;\u0026lt;(32*i) for i, x in enumerate(hash_pieces)) def md5_to_hex(digest): raw = digest.to_bytes(16, byteorder=\u0026#39;little\u0026#39;) return \u0026#39;{:032x}\u0026#39;.format(int.from_bytes(raw, byteorder=\u0026#39;big\u0026#39;)) def true_md5(message): m = hashlib.md5() m.update(message) return m.hexdigest() def my_md5(message): return md5_to_hex(md5(message)) if __name__==\u0026#39;__main__\u0026#39;: demo = [b\u0026#34;\u0026#34;, b\u0026#34;a\u0026#34;, b\u0026#34;abc\u0026#34;, b\u0026#34;message digest\u0026#34;, b\u0026#34;abcdefghijklmnopqrstuvwxyz\u0026#34;, b\u0026#34;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\u0026#34;, b\u0026#34;12345678901234567890123456789012345678901234567890123456789012345678901234567890\u0026#34;] for message in demo: print(my_md5(message),\u0026#39; \u0026lt;= \u0026#34;\u0026#39;,message.decode(\u0026#39;ascii\u0026#39;),\u0026#39;\u0026#34;\u0026#39;, sep=\u0026#39;\u0026#39;) assert true_md5(message)==my_md5(message) # 若和标准库中不同，会抛出异常 print(\u0026#39;\\nMD5测试全部通过\u0026#39;) # d41d8cd98f00b204e9800998ecf8427e \u0026lt;= \u0026#34;\u0026#34; # 0cc175b9c0f1b6a831c399e269772661 \u0026lt;= \u0026#34;a\u0026#34; # 900150983cd24fb0d6963f7d28e17f72 \u0026lt;= \u0026#34;abc\u0026#34; # f96b697d7cb7938d525a2f31aaf161d0 \u0026lt;= \u0026#34;message digest\u0026#34; # c3fcd3d76192e4007dfb496cca67e13b \u0026lt;= \u0026#34;abcdefghijklmnopqrstuvwxyz\u0026#34; # d174ab98d277d9f5a5611c2c9f419d9f \u0026lt;= \u0026#34;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\u0026#34; # 57edf4a22be3c955ac49da2e2107b67a \u0026lt;= \u0026#34;12345678901234567890123456789012345678901234567890123456789012345678901234567890\u0026#34; # # MD5测试全部通过 5.2 Sha256实现 import copy import struct import binascii import hashlib F32 = 0xFFFFFFFF _k = [0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5, 0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174, 0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da, 0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967, 0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85, 0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070, 0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3, 0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2] _h = [0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a, 0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19] def _pad(msglen): mdi = msglen \u0026amp; 0x3F length = struct.pack(\u0026#39;!Q\u0026#39;, msglen \u0026lt;\u0026lt; 3) if mdi \u0026lt; 56: padlen = 55 - mdi else: padlen = 119 - mdi return b\u0026#39;\\x80\u0026#39; + (b\u0026#39;\\x00\u0026#39; * padlen) + length def _rotr(x, y): return ((x \u0026gt;\u0026gt; y) | (x \u0026lt;\u0026lt; (32 - y))) \u0026amp; F32 def _maj(x, y, z): return (x \u0026amp; y) ^ (x \u0026amp; z) ^ (y \u0026amp; z) def _ch(x, y, z): return (x \u0026amp; y) ^ ((~x) \u0026amp; z) class SHA256: _output_size = 8 blocksize = 1 block_size = 64 digest_size = 32 def __init__(self, m=None): self._counter = 0 self._cache = b\u0026#39;\u0026#39; self._k = copy.deepcopy(_k) self._h = copy.deepcopy(_h) self.update(m) def _compress(self, c): w = [0] * 64 w[0:16] = struct.unpack(\u0026#39;!16L\u0026#39;, c) for i in range(16, 64): s0 = _rotr(w[i-15], 7) ^ _rotr(w[i-15], 18) ^ (w[i-15] \u0026gt;\u0026gt; 3) s1 = _rotr(w[i-2], 17) ^ _rotr(w[i-2], 19) ^ (w[i-2] \u0026gt;\u0026gt; 10) w[i] = (w[i-16] + s0 + w[i-7] + s1) \u0026amp; F32 a, b, c, d, e, f, g, h = self._h for i in range(64): s0 = _rotr(a, 2) ^ _rotr(a, 13) ^ _rotr(a, 22) t2 = s0 + _maj(a, b, c) s1 = _rotr(e, 6) ^ _rotr(e, 11) ^ _rotr(e, 25) t1 = h + s1 + _ch(e, f, g) + self._k[i] + w[i] h = g g = f f = e e = (d + t1) \u0026amp; F32 d = c c = b b = a a = (t1 + t2) \u0026amp; F32 for i, (x, y) in enumerate(zip(self._h, [a, b, c, d, e, f, g, h])): self._h[i] = (x + y) \u0026amp; F32 def update(self, m): if not m: return self._counter += len(m) m = self._cache + m for i in range(0, len(m) // 64): self._compress(m[64 * i:64 * (i + 1)]) self._cache = m[-(len(m) % 64):] def digest(self): r = copy.deepcopy(self) r.update(_pad(self._counter)) data = [struct.pack(\u0026#39;!L\u0026#39;, i) for i in r._h[:self._output_size]] return b\u0026#39;\u0026#39;.join(data) def hexdigest(self): return binascii.hexlify(self.digest()).decode(\u0026#39;ascii\u0026#39;) def true_sha256(message): m = hashlib.sha256() m.update(message) return m.hexdigest() def my_sha256(message): return SHA256(message).hexdigest() if __name__==\u0026#39;__main__\u0026#39;: demo = [b\u0026#34;\u0026#34;, b\u0026#34;a\u0026#34;, b\u0026#34;abc\u0026#34;, b\u0026#34;message digest\u0026#34;, b\u0026#34;abcdefghijklmnopqrstuvwxyz\u0026#34;, b\u0026#34;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\u0026#34;, b\u0026#34;12345678901234567890123456789012345678901234567890123456789012345678901234567890\u0026#34;] for message in demo: print(my_sha256(message),\u0026#39; \u0026lt;= \u0026#34;\u0026#39;,message.decode(\u0026#39;ascii\u0026#39;),\u0026#39;\u0026#34;\u0026#39;, sep=\u0026#39;\u0026#39;) assert true_sha256(message)==my_sha256(message) # 若和标准库中不同，会抛出异常 print(\u0026#39;\\nSHA256测试全部通过\u0026#39;) # e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 \u0026lt;= \u0026#34;\u0026#34; # ca978112ca1bbdcafac231b39a23dc4da786eff8147c4e72b9807785afee48bb \u0026lt;= \u0026#34;a\u0026#34; # ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad \u0026lt;= \u0026#34;abc\u0026#34; # f7846f55cf23e14eebeab5b4e1550cad5b509e3348fbc4efa3a1413d393cb650 \u0026lt;= \u0026#34;message digest\u0026#34; # 71c480df93d6ae2f1efad1447c66c9525e316218cf51fc8d9ed832f2daf18b73 \u0026lt;= \u0026#34;abcdefghijklmnopqrstuvwxyz\u0026#34; # db4bfcbd4da0cd85a60c3c37d3fbd8805c77f15fc6b1fdfe614ee0a7c8fdb4c0 \u0026lt;= \u0026#34;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\u0026#34; # f371bc4a311f2b009eef952dd83ca80e2b60026c8e935592d0f9c308453c813e \u0026lt;= \u0026#34;12345678901234567890123456789012345678901234567890123456789012345678901234567890\u0026#34; # # SHA256测试全部通过 ","permalink":"https://blog.niuhemoon.win/posts/tech/python-hash-experiment/","summary":"Python3实现哈希散列算法，包含MD5和sha256。 Hash函数算法编写 本实验是使用python来编写MD5和SHA256加密函数，并对加密函数的正确性进行验证。 验证的方式是通过和已有的标准库加密结果进行比较，如果结果相同，则加密函数正确。 1.实验目的 熟悉MD5和SHA25","title":"Python实现MD5和Sha256"},{"content":"程序效果图如下：\n程序的效果就是可以在Terminal浏览一下每天知乎日报的标题和url，然后根据兴趣选择是否继续阅读。\n程序十分简单，只十几行代码。使用python3，需要安装requests包。\n源代码如下，也可以从我的github下载。\n#!/usr/bin/python3 #-*- coding: utf-8 -*- import requests import json headers = {\u0026#39;User-Agent\u0026#39; : \u0026#39;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)\u0026#39;} def get_daily(): page = requests.get(\u0026#39;http://news-at.zhihu.com/api/3/news/latest\u0026#39;, headers=headers).text response = json.loads(page) date = response[\u0026#39;date\u0026#39;] stories = response[\u0026#39;stories\u0026#39;] date = \u0026#39;\\n%s年%s月%s日\u0026#39; % (date[:4], date[4:6], date[6:]) print(\u0026#39;%s 共%d条日报\\n\u0026#39; % (date, len(stories))) for index,story in enumerate(stories, 1): print(\u0026#39;{0:\u0026lt;2d}：{1:s}\\n url：http://news-at.zhihu.com/story/{2:d}\u0026#39;.format(index, story[\u0026#39;title\u0026#39;], story[\u0026#39;id\u0026#39;])) if __name__ == \u0026#39;__main__\u0026#39;: get_daily() 保存为zhdaily.py文件，然后将文件放到/usr/local/bin/目录下，并给zhdaily.py增加执行权限：\n$ sudo mv zhdaily.py /usr/local/bin/ $ cd /usr/local/bin/ $ sudo chmod +x zhdaily.py 这样，当你下次进入终端，可以直接执行：\n$ zhdaily.py 就可以获得图示的效果。\n碎碎念：\n曾经知乎是一个优秀的社区，也确实让我发现了更大的世界。可是，从某个时刻开始，充斥我时间线的内容都是被知乎官方筛选的。整个社区充斥着喧嚣、广告、营销和带节奏。\n我不喜欢：\n被煽动的愤怒\n被策划的欢乐\n最后，我又回到了RSS的怀抱，可以控制我接收到相对有价值的信息。\n不过，浏览知乎日报能了解下当下热点，增加聊天谈资。省的聊天时都不知道《创造101》是啥？赫赫:)\n我基本每天只浏览日报的标题，这个小程序正好满足需求。\n","permalink":"https://blog.niuhemoon.win/posts/tech/zhihu-daily-crawler/","summary":"程序效果图如下： 程序的效果就是可以在Terminal浏览一下每天知乎日报的标题和url，然后根据兴趣选择是否继续阅读。 程序十分简单，只十几行代码。使用python3，需要安装requests包。 源代码如下，也可以从我的github下载。 #!/usr/bin/python3 #-*- coding: utf-8 -*- import requests import json headers = {\u0026#39;User-Agent\u0026#39; : \u0026#39;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)\u0026#39;} def get_daily(): page","title":"在Linux终端里浏览知乎日报"},{"content":"上一节中，IntegralOccupancyMap()函数用来确定单词位置，其中调用了query_integral_image()方法。而query_integral_image是用来Cython。下边介绍Cython。\nCython介绍 Cython 的本质可以总结如下：Cython 是包含C 数据类型的Python。\nCython可以将Python代码编译成动态链接库，在某些情况下，可以极大提高Python程序的运行效率。\n可以看到源码中包括了query_integral_image.pyx和query_integral_image.c两个文件。其中.c文件是Cython自动生产的对应query_integral_image.pyxC语言程序。\nCython的工作流程大致如下：\n我们只需要关心.pyx文件中的代码\n为了测试使用Cython是否真的可以提高程序效率，我们做如下测试，\n系统：Ubuntu 16\n环境：python3.5\n依赖：\nCython==0.28.2\nnumpy==1.14.2\nPillow==5.1.0\n测试代码均可从github下载\n测试过程 目录tree\n. ├── python_query_integral_image.py ├── query_integral_image.pyx ├── setup.py ├── test.py └── venv setup.py用来编译动态链接库,内容如下：\nfrom distutils.core import setup from Cython.Build import cythonize setup( ext_modules = cythonize(\u0026#34;query_integral_image.pyx\u0026#34;) ) 执行：\npython setup.py build_ext --inplace 然后目录变为了：\n. ├── build ├── python_query_integral_image.py ├── query_integral_image.c ├── query_integral_image.cpython-35m-i386-linux-gnu.so ├── query_integral_image.pyx ├── setup.py ├── test.py └── venv 下边我们就可以在python程序中import编译后的.so文件了, 测试程序test.py如下：\n# 导入python编写的程序，为了和.so区别，改名为python_query_integral_image from python_query_integral_image import query_integral_image as q1 # 导入经过Cython处理的.so链接库 from query_integral_image import query_integral_image as q2 from random import Random import numpy as np import timeit DX = 3000 DY = 3000 # 相当于一个3000*3000=900万像素的图片 integral = np.zeros((DX, DY), dtype=np.uint32) random_state = Random() start_time = timeit.default_timer() q1(integral, 50, 50, random_state) end_time = timeit.default_timer() q1_dur = (end_time - start_time)/60. start_time = timeit.default_timer() q2(integral, 50, 50, random_state) end_time = timeit.default_timer() q2_dur = (end_time - start_time)/60. print(\u0026#39;C程序耗时\u0026#39;, q2_dur, \u0026#39;Python耗时\u0026#39;, q1_dur) print(\u0026#39;相差%f倍\u0026#39; % (float(q1_dur) / float(q2_dur))) 运行测试程序，结果令人吃惊：\nC程序耗时 0.0007940871333024309 Python耗时 0.6854850105833369 相差863.236516倍\n经过Cython简单的处理，同样的代码，运行效率提高了800多倍。刺不刺激？\n可见在作矩阵计算或者循环次数较多时，Cython具有较大作用。\n参考 Cython三分钟入门 Cython官方文档中文版 ","permalink":"https://blog.niuhemoon.win/posts/tech/wordcloud-src-note2/","summary":"上一节中，IntegralOccupancyMap()函数用来确定单词位置，其中调用了query_integral_image()方法。而query_integral_image是用来Cython。下边介绍Cython。 Cython介绍 Cython 的本质可以总结如下：Cython 是包含C 数","title":"wordcloud源码阅读2——Cython"},{"content":"wordcloud是python用来生成词云的第三方库，github地址是word_cloud\n下载源码：\ngit clone https://github.com/amueller/word_cloud 然后，直接看最老的版本，有精力的话看完最老版本可以再看最新的版本。\ngit tag git checkout 1.2.1 现在我们的目录结构如下： 可以看到，核心代码都在wordcloud目录下：\nwordcloud项目主要用了以下第三方库：\nNumpy PIL Cython 储备知识：\nHSL和HSV色彩空间 图片RGB 框架大体流程： 可以看出wordcloud类的两个核心方法process_text()和generate_from_frequencies()。\n如果输入是处理后的{string:frequency}字典类型，直接生成词云的layout，若输入是未处理过的字符串，就要先进行process_text()统计词频等工作。\n继续看generate_from_frequencies()的流程：\n就得到了词云的layout，后边可以通过recolor()重新上色。\nmask是一个n维数组（图片），在我的理解是photoshop里的蒙板，也叫遮色片。在wordcloud里mask决定了生成词云的位置。白色#FFFFFF称为mask out，即不在白色区域绘制词云。\nlayout is list of tuple ,格式(string, int, (int, int), int, color)) 定义了每个单词的（字符串，字体大小，（x位置，y位置), 方向， 颜色）\n参考：\nwordcloud的API可以参考wordcloud文档中文翻译 具体使用也可以参考网易云音乐歌手词云\n","permalink":"https://blog.niuhemoon.win/posts/tech/wordcloud-src-note1/","summary":"wordcloud是python用来生成词云的第三方库，github地址是word_cloud 下载源码： git clone https://github.com/amueller/word_cloud 然后，直接看最老的版本，有精力的话看完最老版本可以再看最新的版本。 git tag git checkout 1.2.1 现在我们的目录结构如下： 可以看到，核心代码都在wordcloud目录下： wordcloud项目","title":"wordcloud源码阅读1——初探"},{"content":"Python模块wordcloud参考文档的中文翻译 官网链接：wordcloud api reference\nGithub链接：wordcloud\n所有函数均封装在WordCloud类里:\nWordCloud([\u0026hellip;]) 生成并绘制WordCloud对象 ImageColorGenerator(image) 词云颜色生成器（基于图片颜色） random_color_func([]) 词云颜色随机生成 wordcloud.WordCloud class wordcloud.WordCloud(font_path=None, width=400, height=200, margin=2, ranks_only=None, prefer_horizontal=0.9, mask=None, scale=1, color_func=None, max_words=200, min_font_size=4, stopwords=None, random_state=None, background_color=\u0026#39;black\u0026#39;, max_font_size=None, font_step=1, mode=\u0026#39;RGB\u0026#39;, relative_scaling=0.5, regexp=None, collocations=True, colormap=None, normalize_plurals=True) 参数： font_path : string\n需要使用的字体路径(支持OTF和TTF)。Linux系统上默认指向DroidSansMono路径。若使用其他操作系统或者没有DroidSansMono字体，需要指定字体路径。\nwidth : int (default=400)\n画布的宽度。\nheight : int (default=200)\n画布的高度。\nprefer_horizontal : float (default=0.90)\n尝试水平摆放字体和垂直摆放字体的比例，若prefer_horizontal \u0026lt; 1，当摆放不合适的时候，算法将尝试旋转单词。目前没有内置的方法来获取垂直单词\nmask : nd-array or None (default=None)\n如果不是None，则在哪里绘制单词时给出二进制掩码。 如果mask不是None，那么宽度和高度将被忽略，并且将使用mask的形状。 所有白色（#FF或#FFFFFF）条目将被视为“被遮盖”，而其他条目将被自由绘制。 [这在最新版本中发生了变化！]\nscale : float (default=1)\n计算值和绘图之间的缩放比例。 对于大型文字云图像，使用缩放而不是较大的画布尺寸要快得多，但可能导致较粗糙的文字。\nmin_font_size : int (default=4)\n使用最小的字体大小。 当没有更多的空间时停止绘制。\nfont_step : int (default=1)\n字体的步长。 font_step \u0026gt; 1时可能会加快计算速度，但会导致糟糕的字体适应性布局。\nmax_words : number (default=200)\n单词的最大数目。\nstopwords : set of strings or None\n敏感词集合，这些词将被忽略。 如果没有，则将使用内置的STOPWORDS列表。\nbackground_color : color value (default=”black”)\n词云图像的背景颜色。\nmax_font_size : int or None (default=None)\n使用的最大字体大小。 默认使用图像的高度。\nmode : string (default=”RGB”)\n当模式为“RGBA”且background_color为None时，会生成透明背景。\nrelative_scaling : float (default=.5)\n字体大小的相对单词频率的重要性。 relative_scaling = 0时，只考虑单词等级。 使用relative_scaling = 1时，频繁两倍的单词将具有两倍的大小。 如果你想考虑单词的频率，而不仅仅是他们的等级，那么0.5左右的relative_scaling通常看起来不错。\ncolor_func : callable, default=None\n可用参数关键字font_size, position, orientation, font_path, random_state调用，它为每个单词返回一个PIL颜色。 覆盖\u0026quot;colormap\u0026quot;。 请参阅colormap来指定matplotlib的颜色映射。\nregexp : string or None (optional)\n正则表达式将输入文本拆分为待处理文本中的标记。 如果指定None，则使用r“\\ w [\\ w\u0026rsquo;] +”。\ncollocations : bool, default=True\n是否包含两个词的搭配（bigrams），默认为True。\ncolormap : string or matplotlib colormap, default=”viridis”\nMatplotlib色彩映射表为每个单词随机绘制颜色。 如果指定了“color_func”，则忽略。\nnormalize_plurals : bool, default=True\n是否从文字中删除“尾随”。 如果为真，当出现以\u0026rsquo;s\u0026rsquo;结尾的单词，则以\u0026rsquo;s\u0026rsquo;结尾的单词将被删除，并将其计数添加到没有\u0026rsquo;s\u0026rsquo;结尾的版本\n以\u0026rsquo;ss\u0026rsquo;结尾的单词被忽略。\n注意： 较大的画布使代码明显变慢。 如果您需要较大的单词云，请尝试较小的画布大小，然后设置缩放参数。\n根据最大字体大小和缩放启发式算法，相比单词实际出现的频率，算法可能会给单词的等级更多的权重。\n属性： words_\n(dict of string to float) 单词标识对应其出现次数，如{\u0026lsquo;hello\u0026rsquo;:90, \u0026lsquo;good\u0026rsquo;:30}\n.. versionchanged: 2.0 words_: 现在是一个字典\nlayout_\n(list of tuples (string, int, (int, int), int, color)))\n编码拟合词云，为每个单词编码字符串，字体大小，位置，方向和颜色。\n方法： # 初始化实例 __init__(font_path=None, width=400, height=200, margin=2, ranks_only=None, prefer_horizontal=0.9, mask=None, scale=1, color_func=None, max_words=200, min_font_size=4, stopwords=None, random_state=None, background_color=\u0026#39;black\u0026#39;, max_font_size=None, font_step=1, mode=\u0026#39;RGB\u0026#39;, relative_scaling=0.5, regexp=None, collocations=True, colormap=None, normalize_plurals=True) fit_words(frequencies)\n根据单词和频率创建一个word_cloud。\n别名为generate_from_frequencies。\n参数:\nfrequencies : array of tuples\n元组包含单词及其频率。Note:最新版已经改为字典了。\n返回值：\nself\ngenerate(text)\n从文本生成wordcloud。\n别名generate_from_text。\n实际调用process_text和generate_from_frequencies。\n返回值：\nself\ngenerate_from_frequencies(frequencies, max_font_size=None)\n根据单词和频率创建词云。\n参数:\nfrequencies : dict from string to float\n字典包含单词及其频率。\nmax_font_size : int\n使用此最大字体大，而不是self.max_font_size\n返回值：\nself\ngenerate_from_text(text)\n从文本生成wordcloud。\n实际调用process_text和generate_from_frequencies。\n..versionchanged:: 1.2.2 process_text（)的返回值不再是generate_from_frequencies（）的参数。\n返回值：\nself\nprocess_text(text)\n将长文本拆分为单词，去除停用词(敏感词)。\n参数:\ntext : string\n待处理的文本\n返回值：\nwords : dict (string, int)\n带有关联频率的词语标记。\n..versionchanged:: 1.2.2 将返回类型从元组列表更改为字典。\nNotes\n有更好的方法做词频分析，在此不做赘述。\nrecolor(random_state=None, color_func=None, colormap=None)\n重新着色现有布局。\n应用新的着色要比生成整个词云快得多。\n参数:\nrandom_state : RandomState, int, or None, default=None\n如果不是None，则使用固定的随机状态。 如果给出了一个int，它将用作random.Random状态的种子。\ncolor_func : function or None, default=None\n根据(word count, font size, position and orientation)字数，字体大小，位置和方向生成新颜色的函数。 如果为None，则使用self.color_func。\ncolormap : string or matplotlib colormap, default=None\n使用此颜色映射表来生成新的颜色。 如果指定了color_func，则忽略。 如果没有，则使用self.color_func（或self.color_map）。\n返回值：\nself\nto_array()\n转换为numpy数组。\n返回值：\nimage : n维数组 (width, height, 3)\n词云图像作为numpy矩阵。\nto_file(filename)\n导出为图像文件。\n参数:\nfilename : string\n要写入的位置。\n返回值：\nself\nwordcloud.ImageColorGenerator class wordcloud.ImageColorGenerator(image) 基于彩色图像的颜色生成器.\n根据RGB图像生成颜色。 一个单词将使用彩色图像中包围矩形的平均颜色进行着色。 构造完成后，该对象充当可调用对象，可以将其作为color_func传递给WordCloud类的构造函数或recolor这个重新着色方法。\n参数:\nimage : n维矩阵, shape (height, width, 3)\n用于生成文字颜色的图像。 Alpha通道被忽略。对于wordcloud实例，这应该和画布大小相同。\n方法\n__call__(word, font_size, font_path, ...)\n使用特定图像为给定单词生成颜色。\n__init__(image)\nwordcloud.random_color_func wordcloud.random_color_func(word=None, font_size=None, position=None, orientation=None, font_path=None, random_state=None) 随机色调颜色生成.\n默认着色方法。 这只是随机选择一个值为80％和光照50％的色调。\n参数:\nword, font_size, position, orientation: ignored.\nrandom_state : random.Random object or None, (default=None)\n如果给定了一个随机对象，则用它来生成随机数。\n","permalink":"https://blog.niuhemoon.win/posts/tech/word-cloud-doc-cn/","summary":"Python模块wordcloud参考文档的中文翻译 官网链接：wordcloud api reference Github链接：wordcloud 所有函数均封装在WordCloud类里: WordCloud([\u0026hellip;]) 生成并绘制WordCloud对象 ImageColorGenerator(image) 词云颜色生成器（基于图片颜色） random_color_func([]) 词云颜色随机生成 wordcloud.WordCloud class wordcloud.WordCloud(font_path=None, width=400, height=200, margin=2, ranks_only=None, prefer_horizontal=0.9, mask=None, scale=1, color_func=None, max_words=200, min_font_size=4, stopwords=None, random_state=None, background_color=\u0026#39;black\u0026#39;, max_font_size=None, font_step=1,","title":"WordCloud文档中文翻译"},{"content":"This is my first blog 美国诗人纳·斯待尔在87岁那年写过一首诗：《我会采更多的雏菊》，摘取片段于下。\n如果我能够从头活过，\n我会试着犯更多的错。\n我会放松一点，我会灵活一点。\n我会比这一趟过得傻。\n很少有什么事情能让我当真。\n我会疯狂一些，我会少讲点卫生。\n我会冒更多的险。我会更经常的旅行。\n我会爬更多的山，游更多的河，看更多的日落。\n我会多吃冰激凌，少吃豆子。\n我会惹更多的麻烦，可是不在想象中担忧。\n噢，我有过难忘的时刻。 如果我能够重来一次，我会要更多这样的时刻。\n我会更经常的逃学。\n我不会考那么高的分数，除非是一不小心。\n我会多骑些旋转木马，\n我会采更多的雏菊。\n人不仅要拥有此生此世，还要那诗意的世界\n","permalink":"https://blog.niuhemoon.win/posts/read/my-first-blog/","summary":"This is my first blog 美国诗人纳·斯待尔在87岁那年写过一首诗：《我会采更多的雏菊》，摘取片段于下。 如果我能够从头活过， 我会试着犯更多的错。 我会放松一点，我会灵活一点。 我会比这一趟过得傻。 很少有什么事情能让我当真。 我会疯狂一些，我会少讲点卫生。 我会冒更多的险。我会更经常的旅行。 我会爬更多的山","title":"一首小诗"},{"content":" ","permalink":"https://blog.niuhemoon.win/about/","summary":"","title":"🙋🏻‍♂️关于我"},{"content":"matlba基础和简单用法\n命令行基础 x = [1,2,3] x = 1:3 A = [1,2;3,4;5,6] B = ones(3,4) C = eye(4) #单位矩阵 D = zeros(3,4)\t#零矩阵 det(C)\t#行列式 x = inv(A)*b\u0026#39;\t#解线性方程,等价于A^-1*b\u0026#39; e = eig(A) #返回一个列向量，其中包含方阵 A 的特征值。 [V,D] = eig(A) #返回特征值的对角矩阵 D 和矩阵 V，其列是对应的右特征向量，使得 A*V = V*D norm(x) #计算向量范数和矩阵范数 gallery()\t#生成测试矩阵 dot(x,y)\t#向量点乘 cross(x,y)\t#向量叉乘 A.*B\t#矩阵点乘（对应元素相同，要求两个矩阵大小相同） A*B\t#矩阵叉乘（要求A的列数等于B的行数） whos\t#查看当前工作空间 class()\t#数据类型 函数 function y = sinh( x ) %UNTITLED Summary of this function goes here % Detailed explanation goes here y = (exp(x) - exp(-x))/2; end 循环 \u0026gt;\u0026gt; for i = [1 3 5 7 9] disp(i); end \u0026gt;\u0026gt; E = randn(1000,1); \u0026gt;\u0026gt; SSE = 0; \u0026gt;\u0026gt; for i = 1:1000 SSE = SSE + E(i)*E(i); end \u0026gt;\u0026gt; SSE SSE = 983.5102 \u0026gt;\u0026gt; SSE/1000 ans = 0.9835 #对一段程序计时 tic E = randn(1000,1); SSE = 0; for i = 1:1000 SSE = SSE + E(i)*E(i); end MSE = SSE/1000; toc #Elapsed time is 0.016618 seconds. # 和点乘比较速度,明显点乘较快 tic E = randn(1000,1); MSE = E.*E /1000; toc # Elapsed time is 0.010042 seconds. 选择 x=1:10; y=zeros(1,10); for i =1:10 if mod(x(i),2) == 0 y(i) = 1; else y(i) = 0; end end #另一种写法，Sum输出为18 X = 1:10;\tSum = 0; for x = X\t#x会遍历X中的元素 if mod(x,3) == 0 Sum =Sum +x; end end x = 1:10 found = 0; i = 0; while ~found i = i +1 if x(i) == 8 disp(\u0026#39;I found it\u0026#39;); found = 1; end end # or for i =1:10 fprintf(\u0026#39;i = %d\\n\u0026#39;,i); if x(i) ==8 disp(\u0026#39;i found it\u0026#39;); break; end end 数据结构 结构体 \u0026gt;\u0026gt; my_struct.name=\u0026#39;niuhe\u0026#39; my_struct = name: \u0026#39;niuhe\u0026#39; \u0026gt;\u0026gt; class(my_struct) ans = struct \u0026gt;\u0026gt; my_struct.age = 25 my_struct = name: \u0026#39;niuhe\u0026#39; age: 25 \u0026gt;\u0026gt; class(my_struct.name) ans = char \u0026gt;\u0026gt; isfield(my_struct,\u0026#39;name\u0026#39;) ans = 1 \u0026gt;\u0026gt; isfield(my_struct,\u0026#39;gender\u0026#39;) ans = 0 \u0026gt;\u0026gt; rmfield(my_struct,\u0026#39;age\u0026#39;) ans = name: \u0026#39;niuhe\u0026#39; \u0026gt;\u0026gt; setfield(my_struct,\u0026#39;gender\u0026#39;,\u0026#39;f\u0026#39;) ans = name: \u0026#39;niuhe\u0026#39; age: 25 gender: \u0026#39;f\u0026#39; \u0026gt;\u0026gt; S = struct(\u0026#39;name\u0026#39;,\u0026#39;bob\u0026#39;,\u0026#39;age\u0026#39;,32,\u0026#39;email\u0026#39;,\u0026#39;123@gmail.com\u0026#39;) S = name: \u0026#39;bob\u0026#39; age: 32 email: \u0026#39;123@gmail.com\u0026#39; 哈希表 \u0026gt;\u0026gt; my_cell{1} = \u0026#39;hello world.\u0026#39; my_cell = \u0026#39;hello world.\u0026#39; \u0026gt;\u0026gt; my_cell{\u0026#39;A\u0026#39;} = [1,2,3,4,5] my_cell = Columns 1 through 9 \u0026#39;hello world.\u0026#39; [] [] [] [] [] [] [] [] Columns 10 through 20 [] [] [] [] [] [] [] [] [] [] [] Columns 21 through 31 [] [] [] [] [] [] [] [] [] [] [] Columns 32 through 42 [] [] [] [] [] [] [] [] [] [] [] Columns 43 through 53 [] [] [] [] [] [] [] [] [] [] [] Columns 54 through 64 [] [] [] [] [] [] [] [] [] [] [] Column 65 [1x5 double] \u0026gt;\u0026gt; my_cell{1} ans = hello world. \u0026gt;\u0026gt; my_cell{\u0026#39;A\u0026#39;} ans = 1 2 3 4 5 plot画图 \u0026gt;\u0026gt; x = [0 0.1 0.2 0.3 ]; \u0026gt;\u0026gt; y = 1:4; \u0026gt;\u0026gt; plot(x,y); \u0026gt;\u0026gt; x = linspace(0,100,200); \u0026gt;\u0026gt; y =sin(x); \u0026gt;\u0026gt; plot(x,y); \u0026gt;\u0026gt; x = linspace(0,2*pi,100); \u0026gt;\u0026gt; y1 = sin(x); \u0026gt;\u0026gt; y2 = cos(x); \u0026gt;\u0026gt; plot(x,y1,x,y2); \u0026gt;\u0026gt; plot(x,y1,\u0026#39;-\u0026#39;,x,y2,\u0026#39;.\u0026#39;); \u0026gt;\u0026gt; plot(x,y1,\u0026#39;--\u0026#39;,x,y2,\u0026#39;.\u0026#39;); \u0026gt;\u0026gt; bar(x)\t#画柱状图 \u0026gt;\u0026gt; x = randn(1000,1)\t#生成1000*1的随机数矩阵，服从均值是0，方差是1的正太分布\t\u0026gt;\u0026gt; hist(x) \u0026gt;\u0026gt; hist(x,50) \u0026gt;\u0026gt; x = 1:5; \u0026gt;\u0026gt; pie(x); \u0026gt;\u0026gt; x = linspace(0,2*pi,1000); \u0026gt;\u0026gt; y = 10*sin(x) + randn(1,1000); \u0026gt;\u0026gt; plot(x,y); \u0026gt;\u0026gt; scatter(x,y); \u0026gt;\u0026gt; x = randn(1000,1) * 2; \u0026gt;\u0026gt; y = 5*sin(x) + rand(1000,1); \u0026gt;\u0026gt; plot(x,y); \u0026gt;\u0026gt; scatter(x,y); subplot()\t#子图 surf() contour() title() xlabel() ylabel() 读写文件 CSV文件\ncsvread() csvwrite() # 保存现有工作空间 save() load() ","permalink":"https://blog.niuhemoon.win/posts/tech/matlab-basic/","summary":"\u003cp\u003ematlba基础和简单用法\u003c/p\u003e","title":"Matlab 基础"},{"content":"Ankidroid和插件 ankidroid下载网址https://apps.ankiweb.net/\n目前还是推荐下载anki2.0旧版，2.1版插件支持的不全。\n必装插件列表：\nAwesome TTS:301952613 Review Heatmap:1771074083 Night Mode:1496166067 词库分享\nanki-deck 从网络抓取单词/例句文本 示例从轻松背单词网站抓取，网站上涵盖了从小学到GRE以及各个专业的单词和例句。内容非常丰富，希望大家多支持这个良心网站。本抓取方法仅作示例，侵删。 网站爬取需要两个参数：\nbook_id group_id 具体爬取代码参见我的github,anki_spider\n食用方法 将爬取下来的文本，保存为文本文件\n编辑单词书的字段，可自定义样式进行美化\n打开anki,选择文件 ——\u0026gt; 导入，文件类型为以tab分割的文件类型，并允许使用HTML，匹配对应字段\n导入结果示意图\n用awesomeTTS批量添加单词和句子发音\n导出制作好的ankidroid单词包，并分享\n完毕\n","permalink":"https://blog.niuhemoon.win/posts/tech/anki-python/","summary":"Ankidroid和插件 ankidroid下载网址https://apps.ankiweb.net/ 目前还是推荐下载anki2.0旧版，2.1版插件支持的不全。 必装插件列表： Awesome TTS:301952613 Review Heatmap:1771074083 Night Mode:1496166067 词库分享 anki-deck 从网络抓取单词/例句文本 示例从轻松背单词网站抓取，网站上涵盖了从小学到GRE以及各个","title":"Python 生成ankidroid单词表/语音包"},{"content":"STM32F103学习笔记 GPIO初始化和读写操作 STM32的GPIO引脚有多种模式使用，在使用前需要进行配置。\nLED灯实验 #include \u0026#34;stm32f10x.h\u0026#34; #define LED GPIO_Pin_All\tvoid delay(u32 i) { while(i--); } //LED的GPIO初始化程序 void LED_Init() { GPIO_InitTypeDef GPIO_InitStructure; //GPIO时钟初始化 SystemInit(); RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOC,ENABLE); //配置GPIO模式和端口 GPIO_InitStructure.GPIO_Pin = LED; GPIO_InitStructure.GPIO_Mode = GPIO_Mode_Out_PP; //推挽模式 GPIO_InitStructure.GPIO_Speed = GPIO_Speed_50MHz; GPIO_Init(GPIOC,\u0026amp;GPIO_InitStructure);\t//初始化GPIO } void led_display() { GPIO_SetBits(GPIOC,LED); delay(6000000); GPIO_ResetBits(GPIOC,LED); delay(6000000); } int main() { LED_Init(); while(1) { led_display(); } } 蜂鸣器实验 使用无源蜂鸣器\n#include \u0026#34;stm32f10x.h\u0026#34; #define BZ GPIO_Pin_5 //PB5\t定义端口PB5 void delay(u32 i) { while(i--); } void BEEP_Init() { GPIO_InitTypeDef GPIO_InitStructure; //GPIO时钟初始化 SystemInit(); RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOB,ENABLE); //配置GPIO模式和端口 GPIO_InitStructure.GPIO_Pin = BZ; GPIO_InitStructure.GPIO_Mode = GPIO_Mode_Out_PP; //推挽模式 GPIO_InitStructure.GPIO_Speed = GPIO_Speed_50MHz; GPIO_Init(GPIOB,\u0026amp;GPIO_InitStructure);\t//初始化GPIO } void sound(u32 i) // i= 5000救护车，i=1000电动车 { while(i--) { GPIO_SetBits(GPIOB,BZ); delay(i); GPIO_ResetBits(GPIOB,BZ); delay(i); } } int main() {\tBEEP_Init();\t//端口初始化 while(1) { sound(5000);\t}\t} SysTick实验 系统滴答计时器比延时函数更加精确，可移植性更高。systick定时器是24位的定时器，当定时器计数到0时，将自动从RELOAD寄存器中重装定时器初值，如果开启了中断，此时还会产生异常中断信号。\n定时器必须要一个时钟来驱动，systick定时器的时钟来源时系统时钟，不过它的时钟可以选择成直接取自系统时钟，也可以将系统时钟8分频后再赋给systick定时器。\nsystick定时器的操作步骤：\n设置systick定时器的时钟源 设置systick定时器的重装初始值（若使用中断，就将中断使能打开） 清零systick定时器计数器的值 打开systick定时器 #include \u0026#34;stm32f10x.h\u0026#34; #define LED GPIO_Pin_All void delay_us(u32 i) { u32 temp; SysTick-\u0026gt;LOAD = 9*i;\t//设置重装数值 72MHz时 SysTick-\u0026gt;CTRL = 0x01;\t//使能，减到零时无动作，采用外部时钟源(8分频系统时钟) SysTick-\u0026gt;VAL = 0;\t//清零计数器 do { temp = SysTick-\u0026gt;CTRL;\t//读取当前计数值 } while((temp \u0026amp; 0x01) \u0026amp;\u0026amp; (!(temp \u0026amp;(1\u0026lt;\u0026lt;16))));\t//与运算取出指定位的数值 //实际上就是CTRL寄存器的第1位为0或第16位为1时，退出循环 SysTick-\u0026gt;CTRL=0;\t//关闭计数器 SysTick-\u0026gt;VAL = 0;\t//清空计数器 } void delay_ms(u32 i) { u32 temp; SysTick-\u0026gt;LOAD=9000*i;\t//设置重装数值, 72MHZ时 SysTick-\u0026gt;CTRL=0x01;\t//使能，减到零是无动作，采用外部时钟源 SysTick-\u0026gt;VAL=0;\t//清零计数器 do { temp=SysTick-\u0026gt;CTRL;\t//读取当前倒计数值 } while((temp\u0026amp;0x01)\u0026amp;\u0026amp;(!(temp\u0026amp;(1\u0026lt;\u0026lt;16))));\t//等待时间到达 SysTick-\u0026gt;CTRL=0;\t//关闭计数器 SysTick-\u0026gt;VAL=0;\t//清空计数器 } //LED的GPIO初始化程序 void LED_Init() { GPIO_InitTypeDef GPIO_InitStructure; //GPIO时钟初始化 SystemInit(); RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOC,ENABLE); //配置GPIO模式和端口 GPIO_InitStructure.GPIO_Pin = LED; GPIO_InitStructure.GPIO_Mode = GPIO_Mode_Out_PP; //推挽模式 GPIO_InitStructure.GPIO_Speed = GPIO_Speed_50MHz; GPIO_Init(GPIOC,\u0026amp;GPIO_InitStructure);\t//初始化GPIO } int main() { u8 i; LED_Init(); while(1) { for(i=0;i\u0026lt;8;i++) { GPIO_Write(GPIOC,(u16)~(0x01\u0026lt;\u0026lt;i)); delay_ms(1000);\t//精确延时1秒 } } } 系统时钟实验 STM32一共可以有4个时钟源\nHSI（High Speed Inner)内部自带的高速时钟，单片机启动后默认使用的时钟源 HSE (High Speed External)外部高速时钟，大多数时8M晶振 LSE（Low Speed External）外部低速时钟，给单片机内部RTC提供时钟 LSI，内部低速时钟，主要给单片机内部RTC和看门狗提供时钟 STM32的系统时钟源，有3个时钟来源：\n直接来自内部高速时钟HSI 直接来自外部的高速时钟HSE 将HSI或HSE进行处理，倍频之后的PLL时钟（Phase-Locked Loops锁相环） STM32设置RCC（复位和时钟控制）时钟的步骤\n以设置外部高速时钟作为PLL输入，然后以PLL作为时钟源的例子：\n复位RCC时钟 打开HSE外部高速时钟 监测HSE外部高速时钟是否开启成功 设置FLASH读写 设置AHB总线的分频，还有APB1和APB2的分频，注：AHB和APB2最大频率72MHz，APB1做大频率36MHz 设置HSE外部高速时钟作为PLLs时钟的时钟输入 设置PLL时钟的倍频倍数 打开PLL时钟的使能 等待PLL时钟的开启成功 将系统时钟源设置为PLL时 等待时钟源切换成功 //在上一个实验基础上 //自定义系统时钟 void RCC_HSE_Configuration() { RCC_DeInit();\t//重置RCC外设寄存器 RCC_HSEConfig(RCC_HSE_ON);\t//设置外部高速晶振（HSE） if(RCC_WaitForHSEStartUp() == SUCCESS)\t//等待HSE起振 { RCC_HCLKConfig(RCC_SYSCLK_Div1);\t//设置AHB时钟 RCC_PCLK1Config(RCC_HCLK_Div2);\t//设置低速AHB时钟（PCLK1） RCC_PCLK2Config(RCC_HCLK_Div1);\t//设置高速AHB时钟（PCLK2） RCC_PLLConfig(RCC_PLLSource_HSE_Div2,RCC_PLLMul_9);//设置PLL时钟源及倍频系数，实际系统时钟36MHz RCC_PLLCmd(ENABLE);\t//PLL使能 while(RCC_GetFlagStatus(RCC_FLAG_PLLRDY)==RESET);//检查指定的RCC标志位设置与否，PLL就绪 RCC_SYSCLKConfig(RCC_SYSCLKSource_PLLCLK);\t//设置系统时钟（SYSCLK） while(RCC_GetSYSCLKSource()网易 != 0x08);\t//返回用作系统时钟的时钟源，0x08，PLL作为系统时钟 } } int main() { LED_Init(); RCC_HSE_Configuration();\t//自定义系统时钟，修改倍频或分频参数 while(1) { GPIO_SetBits(GPIOC,LED); delay_ms(500);\t//精确延时0.5s，实际延时1s GPIO_ResetBits(GPIOC,LED); delay_ms(500); } } 按键实验 注意按键5ms-10ms左右的延时消抖，注意按键的上拉还是下拉\n#include \u0026#34;stm32f10x.h\u0026#34; #define K_UP GPIO_Pin_0 //PA0 #define K_DOWN GPIO_Pin_3 //PE3 #define K_LEFT GPIO_Pin_2 //PE2 #define K_RIGHT GPIO_Pin_4 //PE4 #define k_up GPIO_ReadInputDataBit(GPIOA,K_UP)\t//获取按键的状态 #define k_down GPIO_ReadInputDataBit(GPIOE,K_DOWN) #define k_left GPIO_ReadInputDataBit(GPIOE,K_LEFT) #define k_right GPIO_ReadInputDataBit(GPIOE,K_RIGHT) #define LED GPIO_Pin_All\tvoid delay_ms(u32 i) { u32 temp; SysTick-\u0026gt;LOAD=9000*i;\t//设置重装数值, 72MHZ时 SysTick-\u0026gt;CTRL=0x01;\t//使能，减到零是无动作，采用外部时钟源 SysTick-\u0026gt;VAL=0;\t//清零计数器 do { temp=SysTick-\u0026gt;CTRL;\t//读取当前倒计数值 } while((temp\u0026amp;0x01)\u0026amp;\u0026amp;(!(temp\u0026amp;(1\u0026lt;\u0026lt;16))));\t//等待时间到达 SysTick-\u0026gt;CTRL=0;\t//关闭计数器 SysTick-\u0026gt;VAL=0;\t//清空计数器 } //LED的GPIO初始化程序 void LED_Init() { GPIO_InitTypeDef GPIO_InitStructure; //GPIO时钟初始化 SystemInit(); RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOC,ENABLE); //配置GPIO模式和端口 GPIO_InitStructure.GPIO_Pin = LED; GPIO_InitStructure.GPIO_Mode = GPIO_Mode_Out_PP; //推挽模式 GPIO_InitStructure.GPIO_Speed = GPIO_Speed_50MHz; GPIO_Init(GPIOC,\u0026amp;GPIO_InitStructure);\t//初始化GPIO } void key_init(void) { GPIO_InitTypeDef GPIO_InitStructure; SystemInit(); //开启GPIO时钟 RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOA|RCC_APB2Periph_GPIOE,ENABLE); /* 配置GPIO的模式和IO口 */ GPIO_InitStructure.GPIO_Pin=K_UP;\t//选择你要设置的IO口 GPIO_InitStructure.GPIO_Mode=GPIO_Mode_IPD;//下拉输入 GPIO_InitStructure.GPIO_Speed=GPIO_Speed_50MHz;\t//设置传输速率 GPIO_Init(GPIOA,\u0026amp;GPIO_InitStructure);\t/* 初始化GPIO */ GPIO_InitStructure.GPIO_Pin=K_DOWN|K_LEFT|K_RIGHT; GPIO_InitStructure.GPIO_Mode=GPIO_Mode_IPU;\t//上拉输入 GPIO_InitStructure.GPIO_Speed=GPIO_Speed_50MHz; GPIO_Init(GPIOE,\u0026amp;GPIO_InitStructure); GPIO_ResetBits(GPIOA,K_UP);\t//对K_UP初始化输出0 } void key_pros()\t//按键处理函数 { if(k_up==1)\t//判断按键k_up是否按下 { delay_ms(10); //消抖处理 if(k_up==1)\t//再次判断按键k_up是否按下 { GPIO_Write(GPIOC,(u16)0xfe);\t} while(k_up); //等待按键松开 } if(k_down==0) { delay_ms(10); if(k_down==0) { GPIO_Write(GPIOC,(u16)(0xfd));\t} while(!k_down); } if(k_left==0) { delay_ms(10); if(k_left==0) { GPIO_Write(GPIOC,(u16)(0xfb));\t} while(!k_left); } if(k_right==0) { delay_ms(10); if(k_right==0) { GPIO_Write(GPIOC,(u16)(0xf7));\t} while(!k_right); }\t} int main() {\tLED_Init();\t//LED初始化 key_init();\t//按键端口初始化函数 GPIO_Write(GPIOC,(u16)(0xff)); while(1) {\tkey_pros();\t//按键处理函数\t}\t} 数码管实验 #include \u0026#34;stm32f10x.h\u0026#34; #define smg_duan (GPIO_Pin_0|GPIO_Pin_1|GPIO_Pin_2|GPIO_Pin_3|GPIO_Pin_4|GPIO_Pin_5|GPIO_Pin_6|GPIO_Pin_7)//PC0~PC7 u8 smgduan[16]={0x3F, 0x06, 0x5B, 0x4F, 0x66, 0x6D, 0x7D, 0x07, 0x7F, 0x6F, 0x77, 0x7C, 0x39, 0x5E, 0x79, 0x71};//0~F 数码管段选数据 void delay_ms(u32 i) { u32 temp; SysTick-\u0026gt;LOAD=9000*i;\t//设置重装数值, 72MHZ时 SysTick-\u0026gt;CTRL=0x01;\t//使能，减到零是无动作，采用外部时钟源 SysTick-\u0026gt;VAL=0;\t//清零计数器 do { temp=SysTick-\u0026gt;CTRL;\t//读取当前倒计数值 } while((temp\u0026amp;0x01)\u0026amp;\u0026amp;(!(temp\u0026amp;(1\u0026lt;\u0026lt;16))));\t//等待时间到达 SysTick-\u0026gt;CTRL=0;\t//关闭计数器 SysTick-\u0026gt;VAL=0;\t//清空计数器 } void smg_init() { GPIO_InitTypeDef GPIO_InitStructure; //声明一个结构体变量，用来初始化GPIO /* 开启GPIO时钟 */ RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOC,ENABLE); /* 配置GPIO的模式和IO口 */ GPIO_InitStructure.GPIO_Pin=smg_duan;\t//选择你要设置的IO口 GPIO_InitStructure.GPIO_Mode=GPIO_Mode_Out_PP; GPIO_InitStructure.GPIO_Speed=GPIO_Speed_50MHz; GPIO_Init(GPIOC,\u0026amp;GPIO_InitStructure);\t/* 初始化GPIO */ } void static_smg_display()\t//静态数码管显示 {\tu8 i; for(i=0;i\u0026lt;16;i++) { GPIO_Write(GPIOC,(u16)(~smgduan[i])); delay_ms(1000);\t}\t} int main() {\tsmg_init();\t//数码管端口初始化函数 while(1) { static_smg_display();\t//静态数码管显示 }\t} 中断和定时器 外部中断实验 注意将端口引脚映射到外部中断线路上，注意配置中断优先级\n#include \u0026#34;stm32f10x.h\u0026#34; #include \u0026#34;stm32f10x_exti.h\u0026#34; #include \u0026#34;misc.h\u0026#34; #define k_left GPIO_Pin_2 #define LED GPIO_Pin_All void delay_ms(u32 i) { u32 temp; SysTick-\u0026gt;LOAD=9000*i;\t//设置重装数值, 72MHZ时 SysTick-\u0026gt;CTRL=0x01;\t//使能，减到零是无动作，采用外部时钟源 SysTick-\u0026gt;VAL=0;\t//清零计数器 do { temp=SysTick-\u0026gt;CTRL;\t//读取当前倒计数值 } while((temp\u0026amp;0x01)\u0026amp;\u0026amp;(!(temp\u0026amp;(1\u0026lt;\u0026lt;16))));\t//等待时间到达 SysTick-\u0026gt;CTRL=0;\t//关闭计数器 SysTick-\u0026gt;VAL=0;\t//清空计数器 } //LED的GPIO初始化程序 void led_init(void) { GPIO_InitTypeDef GPIO_InitStructure; //GPIO时钟初始化 SystemInit(); RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOC,ENABLE); //配置GPIO模式和端口 GPIO_InitStructure.GPIO_Pin = LED; GPIO_InitStructure.GPIO_Mode = GPIO_Mode_Out_PP; //推挽模式 GPIO_InitStructure.GPIO_Speed = GPIO_Speed_50MHz; GPIO_Init(GPIOC,\u0026amp;GPIO_InitStructure);\t//初始化GPIO GPIO_SetBits(GPIOC,LED); } void exti_init(void)\t//外部中断初始化 { GPIO_InitTypeDef GPIO_InitStructure; EXTI_InitTypeDef EXTI_InitStructure; NVIC_InitTypeDef NVIC_InitStructure; SystemInit(); //开启GPIO时钟，用到了时引脚复用功能，开启复用时钟 RCC_APB2PeriphClockCmd(RCC_APB2Periph_AFIO,ENABLE); RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOE,ENABLE); GPIO_InitStructure.GPIO_Pin = k_left; GPIO_InitStructure.GPIO_Mode = GPIO_Mode_IPU;\t//上拉输入 GPIO_InitStructure.GPIO_Speed = GPIO_Speed_50MHz; GPIO_Init(GPIOE,\u0026amp;GPIO_InitStructure); //选择外部中断线路对应的GPIO管脚，此处是PE2 GPIO_EXTILineConfig(GPIO_PortSourceGPIOE,GPIO_PinSource2); //设置外部中断的模式 EXTI_InitStructure.EXTI_Line = EXTI_Line2; EXTI_InitStructure.EXTI_Mode = EXTI_Mode_Interrupt; EXTI_InitStructure.EXTI_Trigger = EXTI_Trigger_Falling;\t//下降沿触发 EXTI_InitStructure.EXTI_LineCmd = ENABLE; EXTI_Init(\u0026amp;EXTI_InitStructure); //设置NVIC参数（nested vector interrupt config) NVIC_PriorityGroupConfig(NVIC_PriorityGroup_1); NVIC_InitStructure.NVIC_IRQChannel = EXTI2_IRQn;\t//打开EXTI2的全局中断 NVIC_InitStructure.NVIC_IRQChannelPreemptionPriority = 0;\t//抢占优先级为0 NVIC_InitStructure.NVIC_IRQChannelSubPriority = 0;\t//响应优先级为0 NVIC_InitStructure.NVIC_IRQChannelCmd = ENABLE;\t//使能 NVIC_Init(\u0026amp;NVIC_InitStructure); } void EXTI2_IRQHandler(void)\t//外部中断2中断处理函数 { if(EXTI_GetITStatus(EXTI_Line2)==SET) { EXTI_ClearITPendingBit(EXTI_Line2);//清除EXTI2线路挂起位 delay_ms(10);//消抖 if(GPIO_ReadInputDataBit(GPIOE,k_left)==Bit_RESET)\t//k_left按下 { delay_ms(10);//消抖 if(GPIO_ReadOutputDataBit(GPIOC,GPIO_Pin_0)==Bit_RESET) { //LED熄灭 GPIO_SetBits(GPIOC,GPIO_Pin_0);\t} else { //LED发光 GPIO_ResetBits(GPIOC,GPIO_Pin_0); } } while(GPIO_ReadInputDataBit(GPIOE,GPIO_Pin_2)==0);\t//等待按键松开 }\t} int main() { led_init(); exti_init(); while(1); } 定时器实验 STM32中一共有11个定时器：\n2个高级控制定时器\t（TIM1,TIM8) 4个通用定时器 （TIM2-TIM5） 2个基本定时器 (TIM6,TIm7) 2个看门狗定时器 1个系统滴答定时器 注:TIM2-TIM7的时钟由APB1产生，TIM1和TIM8是由APB2产生时钟\n//实现1s流水灯实验 #include \u0026#34;stm32f10x.h\u0026#34; #include \u0026#34;stm32f10x_tim.h\u0026#34; #include \u0026#34;stm32f10x_exti.h\u0026#34; #include \u0026#34;misc.h\u0026#34; #define LED GPIO_Pin_All //LED的GPIO初始化程序 void led_init(void) { GPIO_InitTypeDef GPIO_InitStructure; //GPIO时钟初始化 SystemInit(); RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOC,ENABLE); //配置GPIO模式和端口 GPIO_InitStructure.GPIO_Pin = LED; GPIO_InitStructure.GPIO_Mode = GPIO_Mode_Out_PP; //推挽模式 GPIO_InitStructure.GPIO_Speed = GPIO_Speed_50MHz; GPIO_Init(GPIOC,\u0026amp;GPIO_InitStructure);\t//初始化GPIO } void time_init() { TIM_TimeBaseInitTypeDef TIM_TimeBaseInitStructure;\t//定时器初始化结构体 NVIC_InitTypeDef NVIC_InitStructure; //开启定时器3时钟 RCC_APB1PeriphClockCmd(RCC_APB1Periph_TIM3,ENABLE); TIM_ClearITPendingBit(TIM3,TIM_IT_Update);\t//清除TIMx的中断待处理位：TIM中断源 TIM_TimeBaseInitStructure.TIM_Period = 2000;//设置自动重装寄存器周期的值 TIM_TimeBaseInitStructure.TIM_Prescaler = 36000-1;//设置作为TIMx时钟频率的预分频值，2Khz计数频率 TIM_TimeBaseInitStructure.TIM_ClockDivision = 0;//设置时钟分割：TDTS = Tck_tim TIM_TimeBaseInitStructure.TIM_CounterMode = TIM_CounterMode_Up;//向上计数模式 TIM_TimeBaseInit(TIM3,\u0026amp;TIM_TimeBaseInitStructure); TIM_Cmd(TIM3,ENABLE);\t//使能或失能TIMx外设 //设置中断参数，并打开中断 TIM_ITConfig(TIM3,TIM_IT_Update,ENABLE);\t//使能或失能指定的TIM中断 //设置NVIC参数 NVIC_PriorityGroupConfig(NVIC_PriorityGroup_1); NVIC_InitStructure.NVIC_IRQChannel = TIM3_IRQn;\t//打开EXTI2的全局中断 NVIC_InitStructure.NVIC_IRQChannelPreemptionPriority = 0;\t//抢占优先级为0 NVIC_InitStructure.NVIC_IRQChannelSubPriority = 1;\t//响应优先级为1 NVIC_InitStructure.NVIC_IRQChannelCmd = ENABLE;\t//使能 NVIC_Init(\u0026amp;NVIC_InitStructure); } void TIM3_IRQHandler()\t//定时器3的中断处理函数 { static u8 i = 0; TIM_ClearITPendingBit(TIM3,TIM_IT_Update); GPIO_Write(GPIOC,(u16)~(0x01\u0026lt;\u0026lt;i++)); if(i==8)i=0; } int main() { time_init(); led_init(); while(1); } ","permalink":"https://blog.niuhemoon.win/posts/tech/stm32-example-1/","summary":"STM32F103学习笔记 GPIO初始化和读写操作 STM32的GPIO引脚有多种模式使用，在使用前需要进行配置。 LED灯实验 #include \u0026#34;stm32f10x.h\u0026#34; #define LED GPIO_Pin_All void delay(u32 i) { while(i--); } //LED的GPIO初始化程序 void LED_Init() { GPIO_InitTypeDef GPIO_InitStructure; //GPIO时钟初始化 SystemInit(); RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOC,ENABLE); //配置GPIO模式和端口 GPIO_InitStructure.GPIO_Pin = LED; GPIO_InitStructure.GPIO_Mode = GPIO_Mode_Out_PP; //推挽模式 GPIO_InitStructure.GPIO_Speed = GPIO_Speed_50MHz; GPIO_Init(GPIOC,\u0026amp;GPIO_InitStructure); //初始化","title":"STM32笔记"},{"content":" 目前ROS只支持Linux版，如果不方便装Linux主机，可以通过以太网桥接的方式获得雷达的数据帧；对一些串口传感器，也可以通过Serial to USB，然后在virtualbox里选择对应的USB设备进行调试。\n本方法适用于通过以太网/WLAN来传送数据包的雷达。\n使用Virtualbox里建立虚拟机，将雷达连接到主机电脑， 设置以太网的IP地址为雷达的目标地址 虚拟机桥接到对应的以太网 在虚拟机中测试收发数据帧 tcpdump ","permalink":"https://blog.niuhemoon.win/posts/tech/virual-lidar/","summary":"目前ROS只支持Linux版，如果不方便装Linux主机，可以通过以太网桥接的方式获得雷达的数据帧；对一些串口传感器，也可以通过Serial to USB，然后在virtualbox里选择对应的USB设备进行调试。 本方法适用于通过以太网/WLAN来传送数据包的雷达。 使用Virtualb","title":"Virtualbox虚拟机连接雷达和UART串口"}]